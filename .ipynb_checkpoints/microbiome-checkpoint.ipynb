{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "716a0985-a3e5-47be-acc6-d58fb95fa8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from tabpfn_new.scripts.transformer_prediction_interface import TabPFNClassifier, MedPFNClassifier\n",
    "from tabpfn_new.scripts.model_builder import load_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from data_prep_utils import *\n",
    "from evaluate import *\n",
    "from load_models import *\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import openml\n",
    "import time\n",
    "import matplotlib as mpl\n",
    "#from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "pd.set_option('display.expand_frame_repr', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0e72742-f9d3-4748-939e-0aee908e04c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"datasets/data_all.csv\"\n",
    "all_data, labels = get_microbiome(path)\n",
    "all_data = remove_zero_features(all_data)\n",
    "all_data, labels = unison_shuffled_copies(all_data, labels, seed=42)\n",
    "#all_data = top_anova(all_data, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10a5130-cda2-47ab-a5c2-70a2840cfa1d",
   "metadata": {},
   "source": [
    "## Baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "adae1ec9-3ead-4f70-8f11-8936c9783725",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " AnovaSelect \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.946         0.000           0.000          0.000        0.000       0.000         0.500        0.000    0.000   0.000         0.000        0.000\n",
      "XGBClassifier                         0.948         0.010           0.463          0.206        0.317       0.203         0.848        0.081    0.364   0.195         0.010        0.001\n",
      "MedPFNClassifier                      0.951         0.011           0.606          0.303        0.367       0.145         0.914        0.054    0.431   0.152         1.487        0.130\n",
      "MedPFNClassifier                      0.952         0.010           0.587          0.126        0.517       0.090         0.915        0.054    0.536   0.060         8.209        0.288\n",
      "RandomForestClassifier                0.950         0.015           0.350          0.391        0.200       0.233         0.896        0.064    0.252   0.289         0.197        0.012\n",
      "LogisticRegressionClassifier          0.939         0.014           0.393          0.245        0.217       0.150         0.825        0.096    0.269   0.169         0.010        0.002\n",
      "TabPFNClassifier                      0.946         0.018           0.373          0.397        0.200       0.194         0.906        0.057    0.259   0.261         3.498        0.091\n"
     ]
    }
   ],
   "source": [
    "save = False\n",
    "sampling = None\n",
    "cv = 10\n",
    "best_delete = 0\n",
    "strat_split = True\n",
    "recomp = False\n",
    "n_optim = 1000\n",
    "cat_optim = 10\n",
    "ft_epochs = 20\n",
    "ft_epochs_forest = 10\n",
    "ft_lr = 1e-5\n",
    "max_s = 1024\n",
    "max_q = 128\n",
    "max_samples = 1024\n",
    "no_pre_process = False\n",
    "multi_decoder = \"permutation\"\n",
    "N_ens = 5\n",
    "seed = 42\n",
    "overwrite = True\n",
    "metrics = [\"accuracy\", \"precision\", \"recall\", \"roc_auc\", \"f1\"]\n",
    "dir_path = os.path.abspath(os.getcwd())\n",
    "#run_name = \"medium_net_mlp_balance_bsplit_baseline\" ## NO PERM, VERY ROBUST\n",
    "#run_name2 = \"large_mlp_var_balance_05weight_anova\" ## das aller bestigste\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_newprior\" ## das aller bestigste\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_newprior\" ## das aller bestigste\n",
    "run_name = \"small_mlp_var_balance_05weight_anova_bestwithnoisebnn_100\" ## good start, best with ft\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_bestwithnoisebnn_100_moreweight\" ## best start, ft no so good\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_200\" ## das aller bestigste\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_longer\" ## das aller bestigste\n",
    "#run_name = \"medium_mlp_balance_lownoisefixparam_anova\"\n",
    "#run_name = \"medium_mlp_0.5static_balance_anova\"\n",
    "#run_name = \"large_mlp_fullbalance\"\n",
    "#run_name = \"small_net_mlp_var_imbalance_05weight\" ## WORKS VERY WELL WITH PERM\n",
    "#run_name = \"small_net_mlp_varbalance_weight_batchunisplit\"\n",
    "#run_name = \"small_net_mlp_variable_balance_weight\"\n",
    "#run_name = \"small_net_mlp_balance_minevalup\"\n",
    "path = dir_path + f\"/logs/trainrun_{run_name}\"\n",
    "#path2 = dir_path + f\"/logs/trainrun_{run_name2}\"\n",
    "#path3 = dir_path + f\"/logs/trainrun_{run_name3}\"\n",
    "filename = \"model\"\n",
    "\n",
    "\n",
    "\n",
    "models = [\n",
    "    MajorityClass(),\n",
    "    XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic'),\n",
    "    #MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=1, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process),\n",
    "    MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process),\n",
    "    MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process,\n",
    "                    ft_epochs=ft_epochs, ft_lr=ft_lr),\n",
    "    RandomForestClassifier(),\n",
    "    #AutoGluon(),\n",
    "    #CatBoostGrid(),\n",
    "    #XGBoostGrid(),\n",
    "    LogisticRegressionClassifier(), \n",
    "    TabPFNClassifier(device='cpu', N_ensemble_configurations=5, no_preprocess_mode=no_pre_process),\n",
    "    #TabForestPFNClassifier(\"saved_models/tabforest/mix600k/tabforestpfn.pt\", \"saved_models/tabforest/mix600k/config_run.yaml\", max_epochs=ft_epochs_forest)\n",
    "]\n",
    "reducer  = AnovaSelect()\n",
    "\n",
    "\n",
    "results_mean = pd.DataFrame(np.zeros((len(models), len(metrics)+1)),\n",
    "                            index=[m.__class__.__name__ for m in models],\n",
    "                            columns=metrics+[\"runtime\"])\n",
    "results_std = pd.DataFrame(np.zeros((len(models), len(metrics)+1)), \n",
    "                           index=[m.__class__.__name__ for m in models],\n",
    "                           columns=metrics+[\"runtime\"])\n",
    "\n",
    "for ii, model in enumerate(models):\n",
    "    results_mean.iloc[ii,:], results_std.iloc[ii,:] = cross_validate_sample(\n",
    "        model, all_data, labels, metrics, strat_split, cv, sampling, \n",
    "        reducer, max_samples, seed=seed, overwrite=overwrite, n_best_delete=best_delete,\n",
    "        recomp=recomp)\n",
    "\n",
    "results_mean = results_mean.add_suffix(\" mean\")\n",
    "results_std = results_std.add_suffix(\" std\")\n",
    "results_full = pd.concat((results_mean, results_std), axis=1)\n",
    "cols = results_full.columns.tolist()\n",
    "new_cols = []\n",
    "for i in range(int(len(cols)/2)):\n",
    "    new_cols.append(cols[i])\n",
    "    new_cols.append(cols[i+int(len(cols)/2)])\n",
    "results_full = results_full[new_cols]\n",
    "red_name = reducer.__class__.__name__\n",
    "if save:\n",
    "    directory = f\"results/{red_name}\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    save_path = f'results/{red_name}/baseline_cv{cv}_mxsamp{max_samples}_sd{seed}_ovrw{int(overwrite)}.csv'\n",
    "    results_full.to_csv(save_path)\n",
    "print(\"\\n\", \"\\n\", red_name, \"\\n\", results_full.round(3))\n",
    "#print(results_full.sort_values(\"roc_auc mean\").round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6c7211-581b-426c-b21f-eaa6988627f1",
   "metadata": {},
   "source": [
    "## Baseline Repeated cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15dfce33-46b0-450b-9710-724286b82add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n"
     ]
    }
   ],
   "source": [
    "max_samples = 1024\n",
    "cv = 10\n",
    "size = min(labels.shape[0],np.floor(max_samples*(cv/(cv-1))))\n",
    "print(all_data.shape[0]//size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4449c3cf-d2c9-4a13-843a-d4dd3348f33d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1137, 1391)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1137, 1391)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1137, 1391)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1137, 1391)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1137, 1391)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1137, 1391)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1137, 1391)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1137, 1391)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1137, 1391)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1137, 1391)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:108: RuntimeWarning: invalid value encountered in divide\n",
      "  msb = ssbn / float(dfbn)\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92, 1391)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 75\u001b[0m\n\u001b[0;32m     73\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m labels[size\u001b[38;5;241m*\u001b[39msection:size\u001b[38;5;241m*\u001b[39m(section\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ii, model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(models):\n\u001b[1;32m---> 75\u001b[0m     out_mean, out_std \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrat_split\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreducer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_best_delete\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbest_delete\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrecomp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecomp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m     results_mean\u001b[38;5;241m.\u001b[39miloc[ii,:] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m out_mean\n\u001b[0;32m     80\u001b[0m     results_std\u001b[38;5;241m.\u001b[39miloc[ii,:] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m out_std \n",
      "File \u001b[1;32m~\\Desktop\\MT\\TabPFN-medical\\evaluate.py:95\u001b[0m, in \u001b[0;36mcross_validate_sample\u001b[1;34m(model, X, y, metrics, strat_split, cv, sampling, reducer, max_samples, seed, overwrite, n_best_delete, recomp)\u001b[0m\n\u001b[0;32m     93\u001b[0m         results[i]\u001b[38;5;241m.\u001b[39mappend(sklearn\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mget_scorer(m)\u001b[38;5;241m.\u001b[39m_score_func(y_test_1hot, probs, multi_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124movr\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 95\u001b[0m         results[i]\u001b[38;5;241m.\u001b[39mappend(\u001b[43msklearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_scorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_score_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43movr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     97\u001b[0m     results[i]\u001b[38;5;241m.\u001b[39mappend(sklearn\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mget_scorer(m)\u001b[38;5;241m.\u001b[39m_score_func(y_test, preds))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:627\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    625\u001b[0m     labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y_true)\n\u001b[0;32m    626\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m label_binarize(y_true, classes\u001b[38;5;241m=\u001b[39mlabels)[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 627\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_average_binary_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_binary_roc_auc_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_fpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_fpr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    630\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    633\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# multilabel-indicator\u001b[39;00m\n\u001b[0;32m    635\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _average_binary_score(\n\u001b[0;32m    636\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[38;5;241m=\u001b[39mmax_fpr),\n\u001b[0;32m    637\u001b[0m         y_true,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    640\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    641\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_base.py:75\u001b[0m, in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m format is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[0;32m     78\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:382\u001b[0m, in \u001b[0;36m_binary_roc_auc_score\u001b[1;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Binary roc auc score.\"\"\"\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y_true)) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 382\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    383\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly one class present in y_true. ROC AUC score \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    384\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not defined in that case.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    385\u001b[0m     )\n\u001b[0;32m    387\u001b[0m fpr, tpr, _ \u001b[38;5;241m=\u001b[39m roc_curve(y_true, y_score, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_fpr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m max_fpr \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "save = True\n",
    "sampling = None\n",
    "cv = 10\n",
    "best_delete = 0\n",
    "strat_split = True\n",
    "recomp = False\n",
    "n_optim = 1000\n",
    "cat_optim = 10\n",
    "ft_epochs = 20\n",
    "ft_epochs_forest = 10\n",
    "ft_lr = 1e-5\n",
    "max_s = 1024\n",
    "max_q = 128\n",
    "max_samples = 1024\n",
    "no_pre_process = False\n",
    "multi_decoder = \"permutation\"\n",
    "N_ens = 5\n",
    "seed = 42\n",
    "overwrite = True\n",
    "metrics = [\"accuracy\", \"precision\", \"recall\", \"roc_auc\", \"f1\"]\n",
    "dir_path = os.path.abspath(os.getcwd())\n",
    "#run_name = \"medium_net_mlp_balance_bsplit_baseline\" ## NO PERM, VERY ROBUST\n",
    "#run_name2 = \"large_mlp_var_balance_05weight_anova\" ## das aller bestigste\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_newprior\" ## das aller bestigste\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_newprior\" ## das aller bestigste\n",
    "run_name = \"small_mlp_var_balance_05weight_anova_bestwithnoisebnn_100\" ## good start, best with ft\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_bestwithnoisebnn_100_moreweight\" ## best start, ft no so good\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_200\" ## das aller bestigste\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_longer\" ## das aller bestigste\n",
    "#run_name = \"medium_mlp_balance_lownoisefixparam_anova\"\n",
    "#run_name = \"medium_mlp_0.5static_balance_anova\"\n",
    "#run_name = \"large_mlp_fullbalance\"\n",
    "#run_name = \"small_net_mlp_var_imbalance_05weight\" ## WORKS VERY WELL WITH PERM\n",
    "#run_name = \"small_net_mlp_varbalance_weight_batchunisplit\"\n",
    "#run_name = \"small_net_mlp_variable_balance_weight\"\n",
    "#run_name = \"small_net_mlp_balance_minevalup\"\n",
    "path = dir_path + f\"/logs/trainrun_{run_name}\"\n",
    "#path2 = dir_path + f\"/logs/trainrun_{run_name2}\"\n",
    "#path3 = dir_path + f\"/logs/trainrun_{run_name3}\"\n",
    "filename = \"model\"\n",
    "\n",
    "\n",
    "\n",
    "models = [\n",
    "    MajorityClass(),\n",
    "    XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic'),\n",
    "    #MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=1, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process),\n",
    "    #MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process),\n",
    "    #MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process,\n",
    "    #                ft_epochs=ft_epochs, ft_lr=ft_lr),\n",
    "    #RandomForestClassifier(),\n",
    "    #AutoGluon(),\n",
    "    #CatBoostGrid(),\n",
    "    #XGBoostGrid(),\n",
    "    #LogisticRegressionClassifier(), \n",
    "    #TabPFNClassifier(device='cpu', N_ensemble_configurations=5, no_preprocess_mode=no_pre_process),\n",
    "    #TabForestPFNClassifier(\"saved_models/tabforest/mix600k/tabforestpfn.pt\", \"saved_models/tabforest/mix600k/config_run.yaml\", max_epochs=ft_epochs_forest)\n",
    "]\n",
    "reducer  = AnovaSelect()\n",
    "\n",
    "\n",
    "results_mean = pd.DataFrame(np.zeros((len(models), len(metrics)+1)),\n",
    "                            index=[m.__class__.__name__ for m in models],\n",
    "                            columns=metrics+[\"runtime\"])\n",
    "results_std = pd.DataFrame(np.zeros((len(models), len(metrics)+1)), \n",
    "                           index=[m.__class__.__name__ for m in models],\n",
    "                           columns=metrics+[\"runtime\"])\n",
    "\n",
    "size = int(min(labels.shape[0],np.floor(max_samples*(cv/(cv-1)))))\n",
    "data_sections, label_sections = stratified_split(all_data, labels,cv=size)\n",
    "for section in range(size):\n",
    "    data = all_data[size*section:size*(section+1)]\n",
    "    print(data.shape)\n",
    "    new_labels = labels[size*section:size*(section+1)]\n",
    "    for ii, model in enumerate(models):\n",
    "        out_mean, out_std = cross_validate_sample(\n",
    "            model, data, new_labels, metrics, strat_split, cv, sampling, \n",
    "            reducer, max_samples, seed=seed, overwrite=overwrite, n_best_delete=best_delete,\n",
    "            recomp=recomp)\n",
    "        results_mean.iloc[ii,:] += out_mean\n",
    "        results_std.iloc[ii,:] += out_std \n",
    "    \n",
    "results_mean = results_mean.add_suffix(\" mean\")\n",
    "results_std = results_std.add_suffix(\" std\")\n",
    "results_full = pd.concat((results_mean, results_std), axis=1)\n",
    "cols = results_full.columns.tolist()\n",
    "new_cols = []\n",
    "for i in range(int(len(cols)/2)):\n",
    "    new_cols.append(cols[i])\n",
    "    new_cols.append(cols[i+int(len(cols)/2)])\n",
    "results_full = results_full[new_cols]\n",
    "results_full = results_full/size\n",
    "red_name = \"repeated_cv\"\n",
    "if save:\n",
    "    directory = f\"results/{red_name}\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    save_path = f'results/{red_name}/baseline_cv{cv}_mxsamp{max_samples}_sd{seed}_ovrw{int(overwrite)}.csv'\n",
    "    results_full.to_csv(save_path)\n",
    "print(\"\\n\", \"\\n\", red_name, \"\\n\", results_full.round(3))\n",
    "#print(results_full.sort_values(\"roc_auc mean\").round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4906d353-1d35-4139-babd-0a320b4bc376",
   "metadata": {},
   "source": [
    "## Mine vs static vs normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31180d61-b1bb-4e55-a0ad-c1b64197bb49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " nomethodscompare \n",
      "                   accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MedPFNClassifier          0.956         0.008           0.663          0.143        0.400       0.153         0.917        0.061    0.485   0.111         7.780        0.467\n",
      "MedPFNClassifier          0.875         0.024           0.267          0.058        0.733       0.133         0.890        0.055    0.389   0.074         8.428        0.954\n",
      "MedPFNClassifier          0.930         0.012           0.404          0.089        0.617       0.198         0.908        0.048    0.475   0.108         7.840        0.623\n"
     ]
    }
   ],
   "source": [
    "save = True\n",
    "sampling = None\n",
    "cv = 10\n",
    "best_delete = 0\n",
    "strat_split = True\n",
    "recomp = False\n",
    "n_optim = 1000\n",
    "cat_optim = 10\n",
    "ft_epochs = 20\n",
    "ft_epochs_forest = 10\n",
    "ft_lr = 1e-5\n",
    "max_s = 1024\n",
    "max_q = 128\n",
    "max_samples = 1024\n",
    "no_pre_process = False\n",
    "multi_decoder = \"permutation\"\n",
    "N_ens = 5\n",
    "seed = 42\n",
    "overwrite = True\n",
    "metrics = [\"accuracy\", \"precision\", \"recall\", \"roc_auc\", \"f1\"]\n",
    "dir_path = os.path.abspath(os.getcwd())\n",
    "run_name = \"medium_mlp_var_balance_05weight_anova_bestwithnoisebnn_100\" \n",
    "run_name2 = \"medium_mlp_static_balance_05weight_anova_bestwithnoisebnn_100\" \n",
    "run_name3 = \"medium_mlp_var_balance_05weight_anova_bestwithnoisebnn_100_normalprior\" \n",
    "path = dir_path + f\"/logs/trainrun_{run_name}\"\n",
    "path2 = dir_path + f\"/logs/trainrun_{run_name2}\"\n",
    "path3 = dir_path + f\"/logs/trainrun_{run_name3}\"\n",
    "filename = \"model\"\n",
    "\n",
    "\n",
    "models = [\n",
    "    \n",
    "    #MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process),\n",
    "    #MedPFNClassifier(base_path=path2, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process),\n",
    "    #MedPFNClassifier(base_path=path3, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process),\n",
    "    MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process, ft_epochs=ft_epochs, ft_lr=ft_lr),\n",
    "    MedPFNClassifier(base_path=path2, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process,ft_epochs=ft_epochs, ft_lr=ft_lr),\n",
    "    MedPFNClassifier(base_path=path3, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process,ft_epochs=ft_epochs, ft_lr=ft_lr),\n",
    "]\n",
    "reducer  = AnovaSelect()\n",
    "#for reducer in [AnovaSelect(), RandomSelect(), NonZeroSelect(), MeanSelect(), StdSelect(), MaxSelect(), PCASelect()]:\n",
    "#data = clr(all_data)\n",
    "\n",
    "#all_data = normalize(all_data)\n",
    "\n",
    "results_mean = pd.DataFrame(np.zeros((len(models), len(metrics)+1)),\n",
    "                            index=[m.__class__.__name__ for m in models],\n",
    "                            columns=metrics+[\"runtime\"])\n",
    "results_std = pd.DataFrame(np.zeros((len(models), len(metrics)+1)), \n",
    "                           index=[m.__class__.__name__ for m in models],\n",
    "                           columns=metrics+[\"runtime\"])\n",
    "\n",
    "for ii, model in enumerate(models):\n",
    "    results_mean.iloc[ii,:], results_std.iloc[ii,:] = cross_validate_sample(\n",
    "        model, all_data, labels, metrics, strat_split, cv, sampling, \n",
    "        reducer, max_samples, seed=seed, overwrite=overwrite, n_best_delete=best_delete,\n",
    "        recomp=recomp)\n",
    "\n",
    "results_mean = results_mean.add_suffix(\" mean\")\n",
    "results_std = results_std.add_suffix(\" std\")\n",
    "results_full = pd.concat((results_mean, results_std), axis=1)\n",
    "cols = results_full.columns.tolist()\n",
    "new_cols = []\n",
    "for i in range(int(len(cols)/2)):\n",
    "    new_cols.append(cols[i])\n",
    "    new_cols.append(cols[i+int(len(cols)/2)])\n",
    "results_full = results_full[new_cols]\n",
    "red_name = \"nomethodscompare\"\n",
    "if save:\n",
    "    directory = f\"results/{red_name}\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    save_path = f'results/{red_name}/results_1mine_2staticbal_3normalprior.csv'\n",
    "    results_full.to_csv(save_path)\n",
    "print(\"\\n\", \"\\n\", red_name, \"\\n\", results_full.round(3))\n",
    "#print(results_full.sort_values(\"roc_auc mean\").round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c65c8e1-8f50-4735-bb45-352f0fb9f1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(save_path)\n",
    "df.round(3).to_csv(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b718491-a7e4-46c1-aeb7-c443398e4379",
   "metadata": {},
   "source": [
    "## Context length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "604773e7-27c7-4417-93a3-204f30d38e5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-03 12:50:52.145\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0856 | Val score: 0.9899\u001b[0m\n",
      "\u001b[32m2024-11-03 12:50:53.350\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1143 | Train score: 0.9625 | Val loss: 0.0760 | Val score: 0.9798\u001b[0m\n",
      "\u001b[32m2024-11-03 12:50:54.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2287 | Train score: 0.9500 | Val loss: 0.0777 | Val score: 0.9798\u001b[0m\n",
      "\u001b[32m2024-11-03 12:50:55.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0535 | Train score: 0.9875 | Val loss: 0.0791 | Val score: 0.9798\u001b[0m\n",
      "\u001b[32m2024-11-03 12:50:57.045\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1063 | Train score: 0.9625 | Val loss: 0.0797 | Val score: 0.9798\u001b[0m\n",
      "\u001b[32m2024-11-03 12:50:58.178\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0825 | Train score: 0.9625 | Val loss: 0.0783 | Val score: 0.9798\u001b[0m\n",
      "\u001b[32m2024-11-03 12:50:59.371\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0773 | Train score: 0.9625 | Val loss: 0.0760 | Val score: 0.9798\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:00.628\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1248 | Train score: 0.9500 | Val loss: 0.0746 | Val score: 0.9798\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:01.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1030 | Train score: 0.9875 | Val loss: 0.0739 | Val score: 0.9798\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:02.997\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0452 | Train score: 1.0000 | Val loss: 0.0740 | Val score: 0.9798\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:04.216\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1260 | Train score: 0.9625 | Val loss: 0.0749 | Val score: 0.9798\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:05.400\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1245 | Val score: 0.9394\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:06.532\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0982 | Train score: 0.9500 | Val loss: 0.1304 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:07.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1129 | Train score: 0.9500 | Val loss: 0.1298 | Val score: 0.9394\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:08.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0775 | Train score: 0.9750 | Val loss: 0.1294 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:09.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0730 | Train score: 0.9750 | Val loss: 0.1294 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:10.878\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1630 | Train score: 0.9625 | Val loss: 0.1233 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:12.007\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1099 | Train score: 0.9750 | Val loss: 0.1182 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:13.148\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0531 | Train score: 0.9875 | Val loss: 0.1174 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:14.703\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0552 | Train score: 1.0000 | Val loss: 0.1186 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:16.194\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0662 | Train score: 0.9750 | Val loss: 0.1201 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:17.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0317 | Train score: 0.9875 | Val loss: 0.1206 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:18.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1438 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:20.437\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2175 | Train score: 0.9125 | Val loss: 0.1423 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:22.048\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1295 | Train score: 0.9625 | Val loss: 0.1390 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:23.648\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1223 | Train score: 0.9500 | Val loss: 0.1343 | Val score: 0.9596\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:25.372\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1126 | Train score: 0.9375 | Val loss: 0.1315 | Val score: 0.9596\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:26.916\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0534 | Train score: 0.9750 | Val loss: 0.1308 | Val score: 0.9596\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:27.915\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1496 | Train score: 0.9625 | Val loss: 0.1296 | Val score: 0.9596\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:29.094\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0785 | Train score: 0.9750 | Val loss: 0.1288 | Val score: 0.9596\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:30.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0791 | Train score: 0.9375 | Val loss: 0.1290 | Val score: 0.9596\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:31.879\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0765 | Train score: 0.9625 | Val loss: 0.1294 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:33.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0874 | Train score: 0.9875 | Val loss: 0.1298 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:34.757\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1932 | Val score: 0.9293\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:35.910\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0661 | Train score: 0.9625 | Val loss: 0.2173 | Val score: 0.9394\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:36.965\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0932 | Train score: 0.9375 | Val loss: 0.2246 | Val score: 0.9394\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:38.348\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1297 | Train score: 0.9500 | Val loss: 0.2126 | Val score: 0.9394\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:39.402\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1242 | Train score: 0.9750 | Val loss: 0.1979 | Val score: 0.9394\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:40.537\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1150 | Train score: 0.9375 | Val loss: 0.1892 | Val score: 0.9293\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:41.799\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0696 | Train score: 0.9500 | Val loss: 0.1825 | Val score: 0.9394\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:42.847\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0947 | Train score: 0.9625 | Val loss: 0.1746 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:44.349\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0826 | Train score: 0.9750 | Val loss: 0.1711 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:45.773\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0595 | Train score: 1.0000 | Val loss: 0.1726 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:47.174\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0849 | Train score: 0.9625 | Val loss: 0.1734 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:48.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0846 | Val score: 0.9596\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:49.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1933 | Train score: 0.9625 | Val loss: 0.1014 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:51.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1237 | Train score: 0.9375 | Val loss: 0.0884 | Val score: 0.9596\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:52.079\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1338 | Train score: 0.9250 | Val loss: 0.0830 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:53.525\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0745 | Train score: 0.9625 | Val loss: 0.0794 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:54.716\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0975 | Train score: 0.9625 | Val loss: 0.0792 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:55.710\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1549 | Train score: 0.9625 | Val loss: 0.0759 | Val score: 0.9798\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:56.782\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1516 | Train score: 0.9625 | Val loss: 0.0757 | Val score: 0.9798\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:57.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0761 | Train score: 0.9875 | Val loss: 0.0744 | Val score: 0.9798\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:58.779\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1757 | Train score: 0.9625 | Val loss: 0.0731 | Val score: 0.9798\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:59.839\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0929 | Train score: 0.9625 | Val loss: 0.0719 | Val score: 0.9798\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:00.994\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1358 | Val score: 0.9596\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:02.033\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1084 | Train score: 0.9625 | Val loss: 0.1354 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:03.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0828 | Train score: 0.9500 | Val loss: 0.1401 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:04.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1849 | Train score: 0.9500 | Val loss: 0.1352 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:05.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0742 | Train score: 0.9625 | Val loss: 0.1300 | Val score: 0.9596\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:06.840\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0389 | Train score: 1.0000 | Val loss: 0.1268 | Val score: 0.9596\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:08.215\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1307 | Train score: 0.9125 | Val loss: 0.1218 | Val score: 0.9596\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:09.602\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0568 | Train score: 0.9750 | Val loss: 0.1198 | Val score: 0.9596\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:10.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0664 | Train score: 0.9625 | Val loss: 0.1195 | Val score: 0.9596\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:11.864\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0863 | Train score: 0.9625 | Val loss: 0.1209 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:12.853\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0963 | Train score: 0.9375 | Val loss: 0.1202 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:14.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1258 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:15.624\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1025 | Train score: 0.9500 | Val loss: 0.1273 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:16.970\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1661 | Train score: 0.9500 | Val loss: 0.1235 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:18.400\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0898 | Train score: 0.9500 | Val loss: 0.1210 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:19.459\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1644 | Train score: 0.9750 | Val loss: 0.1206 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:20.503\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0692 | Train score: 0.9750 | Val loss: 0.1211 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:21.603\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0749 | Train score: 0.9875 | Val loss: 0.1220 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:22.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1140 | Train score: 0.9500 | Val loss: 0.1230 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:24.180\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0645 | Train score: 0.9875 | Val loss: 0.1261 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:25.326\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1402 | Train score: 0.9500 | Val loss: 0.1272 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:26.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0536 | Train score: 0.9750 | Val loss: 0.1279 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:27.495\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1959 | Val score: 0.9394\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:28.688\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1255 | Train score: 0.9375 | Val loss: 0.1737 | Val score: 0.9394\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:29.759\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0895 | Train score: 0.9500 | Val loss: 0.1652 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:30.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0777 | Train score: 0.9500 | Val loss: 0.1693 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:32.062\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0476 | Train score: 0.9500 | Val loss: 0.1800 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:33.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0383 | Train score: 1.0000 | Val loss: 0.2019 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:35.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0348 | Train score: 1.0000 | Val loss: 0.2300 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:36.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0800 | Train score: 0.9750 | Val loss: 0.2297 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:38.067\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0913 | Train score: 0.9625 | Val loss: 0.2331 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:39.542\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0860 | Train score: 0.9500 | Val loss: 0.2464 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:40.877\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0186 | Train score: 1.0000 | Val loss: 0.2640 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:42.367\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0964 | Val score: 0.9596\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:43.749\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1828 | Train score: 0.9375 | Val loss: 0.0952 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:45.530\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1804 | Train score: 0.9500 | Val loss: 0.1097 | Val score: 0.9596\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:47.376\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1603 | Train score: 0.9125 | Val loss: 0.1175 | Val score: 0.9394\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:49.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1311 | Train score: 0.9250 | Val loss: 0.1150 | Val score: 0.9394\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:50.886\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1296 | Train score: 0.9375 | Val loss: 0.1010 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:52.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1741 | Train score: 0.9375 | Val loss: 0.0987 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:53.425\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0959 | Train score: 0.9500 | Val loss: 0.0944 | Val score: 0.9798\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:54.590\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1215 | Train score: 0.9625 | Val loss: 0.0910 | Val score: 0.9798\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:55.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0866 | Train score: 0.9625 | Val loss: 0.0881 | Val score: 0.9798\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:57.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0749 | Train score: 0.9625 | Val loss: 0.0857 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:58.824\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0996 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:53:00.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1868 | Train score: 0.9250 | Val loss: 0.0964 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:53:01.341\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1241 | Train score: 0.9500 | Val loss: 0.0949 | Val score: 0.9596\u001b[0m\n",
      "\u001b[32m2024-11-03 12:53:02.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1513 | Train score: 0.9375 | Val loss: 0.0969 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:53:03.883\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0936 | Train score: 0.9500 | Val loss: 0.0946 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:53:05.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1587 | Train score: 0.9500 | Val loss: 0.0944 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:53:07.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0611 | Train score: 0.9875 | Val loss: 0.0911 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:53:08.945\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0842 | Train score: 0.9750 | Val loss: 0.0872 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:53:10.412\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1225 | Train score: 0.9500 | Val loss: 0.0864 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:53:11.671\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0696 | Train score: 0.9625 | Val loss: 0.0856 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:53:13.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0634 | Train score: 0.9625 | Val loss: 0.0855 | Val score: 0.9697\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " context_length \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.945         0.000           0.000          0.000        0.000       0.000         0.500        0.000    0.000   0.000         0.000        0.000\n",
      "XGBClassifier                         0.945         0.011           0.333          0.325        0.233       0.213         0.896        0.080    0.263   0.233         0.009        0.001\n",
      "MedPFNClassifier                      0.942         0.021           0.583          0.298        0.367       0.100         0.909        0.030    0.420   0.115         0.138        0.017\n",
      "MedPFNClassifier                      0.945         0.014           0.400          0.436        0.167       0.167         0.940        0.033    0.230   0.233         1.044        0.067\n",
      "MedPFNClassifier                      0.945         0.018           0.600          0.416        0.267       0.133         0.931        0.035    0.350   0.189         7.296        1.174\n",
      "RandomForestClassifier                0.951         0.008           0.350          0.450        0.133       0.163         0.895        0.074    0.190   0.234         0.152        0.010\n",
      "CatBoostGrid                          0.945         0.016           0.500          0.447        0.200       0.163         0.881        0.102    0.280   0.232        44.723        9.455\n",
      "XGBoostGrid                           0.951         0.008           0.300          0.458        0.100       0.153         0.852        0.123    0.150   0.229        29.868        3.425\n",
      "LogisticRegressionClassifier          0.947         0.013           0.450          0.415        0.200       0.163         0.887        0.045    0.270   0.224         0.006        0.002\n",
      "TabPFNClassifier                      0.947         0.019           0.533          0.400        0.300       0.180         0.915        0.040    0.363   0.227         1.666        0.194\n",
      "TabForestPFNClassifier                0.942         0.031           0.587          0.427        0.333       0.211         0.883        0.057    0.402   0.265        13.905        1.244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-03 13:11:59.030\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1159 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:01.402\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1374 | Train score: 0.9444 | Val loss: 0.0941 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:03.759\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1526 | Train score: 0.9444 | Val loss: 0.0937 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:06.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2114 | Train score: 0.9444 | Val loss: 0.0986 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:08.452\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1302 | Train score: 0.9444 | Val loss: 0.1002 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:10.770\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1429 | Train score: 0.9568 | Val loss: 0.1011 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:13.412\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1022 | Train score: 0.9753 | Val loss: 0.0986 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:16.454\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1277 | Train score: 0.9568 | Val loss: 0.0963 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:19.041\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0922 | Train score: 0.9630 | Val loss: 0.0939 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:21.399\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1067 | Train score: 0.9568 | Val loss: 0.0916 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:23.802\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0877 | Train score: 0.9815 | Val loss: 0.0893 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:25.947\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0907 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:28.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1061 | Train score: 0.9691 | Val loss: 0.0800 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:30.899\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1183 | Train score: 0.9568 | Val loss: 0.0796 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:33.565\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1391 | Train score: 0.9630 | Val loss: 0.0849 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:36.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1282 | Train score: 0.9691 | Val loss: 0.0876 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:38.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1369 | Train score: 0.9630 | Val loss: 0.0905 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:41.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1241 | Train score: 0.9630 | Val loss: 0.0926 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:43.911\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1133 | Train score: 0.9630 | Val loss: 0.0917 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:47.789\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1088 | Train score: 0.9691 | Val loss: 0.0868 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:50.651\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0900 | Train score: 0.9815 | Val loss: 0.0819 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:53.305\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1095 | Train score: 0.9691 | Val loss: 0.0797 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:55.501\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1126 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:57.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1556 | Train score: 0.9568 | Val loss: 0.1187 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:00.553\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1461 | Train score: 0.9444 | Val loss: 0.1130 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:03.282\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1176 | Train score: 0.9568 | Val loss: 0.1059 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:05.816\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1491 | Train score: 0.9506 | Val loss: 0.1065 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:08.383\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1220 | Train score: 0.9568 | Val loss: 0.1053 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:10.926\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1106 | Train score: 0.9568 | Val loss: 0.1056 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:13.373\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0937 | Train score: 0.9568 | Val loss: 0.1042 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:16.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1819 | Train score: 0.9568 | Val loss: 0.1074 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:19.597\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0973 | Train score: 0.9568 | Val loss: 0.1036 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:22.079\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1359 | Train score: 0.9506 | Val loss: 0.1020 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:24.627\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1471 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:27.917\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1095 | Train score: 0.9568 | Val loss: 0.1631 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:30.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1284 | Train score: 0.9444 | Val loss: 0.1700 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:33.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0955 | Train score: 0.9506 | Val loss: 0.1735 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:35.596\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1766 | Train score: 0.9444 | Val loss: 0.1631 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:38.067\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1351 | Train score: 0.9630 | Val loss: 0.1538 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:40.589\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1207 | Train score: 0.9568 | Val loss: 0.1477 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:43.214\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1725 | Train score: 0.9506 | Val loss: 0.1428 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:46.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1552 | Train score: 0.9568 | Val loss: 0.1397 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:49.225\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1048 | Train score: 0.9568 | Val loss: 0.1389 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:51.963\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0963 | Train score: 0.9815 | Val loss: 0.1388 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:54.285\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1318 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:56.906\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1159 | Train score: 0.9506 | Val loss: 0.1326 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:59.578\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0868 | Train score: 0.9630 | Val loss: 0.1464 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:02.195\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1801 | Train score: 0.9568 | Val loss: 0.1392 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:04.803\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1288 | Train score: 0.9630 | Val loss: 0.1322 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:07.358\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1449 | Train score: 0.9691 | Val loss: 0.1286 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:09.956\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1079 | Train score: 0.9568 | Val loss: 0.1273 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:12.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0914 | Train score: 0.9444 | Val loss: 0.1258 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:15.627\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1434 | Train score: 0.9568 | Val loss: 0.1239 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:18.755\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0978 | Train score: 0.9753 | Val loss: 0.1225 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:21.295\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1440 | Train score: 0.9630 | Val loss: 0.1216 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:23.562\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1185 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:26.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1196 | Train score: 0.9506 | Val loss: 0.1040 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:28.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1178 | Train score: 0.9444 | Val loss: 0.0981 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:31.407\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1341 | Train score: 0.9630 | Val loss: 0.0967 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:33.851\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1560 | Train score: 0.9753 | Val loss: 0.0990 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:36.261\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0555 | Train score: 0.9815 | Val loss: 0.0993 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:38.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0639 | Train score: 0.9753 | Val loss: 0.1001 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:41.324\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1215 | Train score: 0.9630 | Val loss: 0.1011 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:44.034\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0690 | Train score: 0.9877 | Val loss: 0.1033 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:47.283\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0731 | Train score: 0.9877 | Val loss: 0.1068 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:50.014\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0740 | Train score: 0.9630 | Val loss: 0.1136 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:52.265\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1005 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:54.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1323 | Train score: 0.9568 | Val loss: 0.0931 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:57.283\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0963 | Train score: 0.9568 | Val loss: 0.0904 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:59.776\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1400 | Train score: 0.9630 | Val loss: 0.0912 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:02.298\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1098 | Train score: 0.9506 | Val loss: 0.0940 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:04.780\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1045 | Train score: 0.9568 | Val loss: 0.0977 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:07.384\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0779 | Train score: 0.9691 | Val loss: 0.1041 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:09.880\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1553 | Train score: 0.9506 | Val loss: 0.1021 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:12.395\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1189 | Train score: 0.9568 | Val loss: 0.1012 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:15.272\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1382 | Train score: 0.9506 | Val loss: 0.1489 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:18.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1537 | Train score: 0.9753 | Val loss: 0.1003 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:20.634\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1001 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:23.177\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1232 | Train score: 0.9444 | Val loss: 0.0894 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:25.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1276 | Train score: 0.9506 | Val loss: 0.0898 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:28.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0976 | Train score: 0.9444 | Val loss: 0.0946 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:30.791\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1643 | Train score: 0.9506 | Val loss: 0.0917 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:33.381\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0826 | Train score: 0.9630 | Val loss: 0.0909 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:35.907\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1775 | Train score: 0.9444 | Val loss: 0.0923 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:38.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1494 | Train score: 0.9568 | Val loss: 0.0949 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:40.930\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1000 | Train score: 0.9630 | Val loss: 0.0957 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:43.381\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1283 | Train score: 0.9568 | Val loss: 0.0974 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:46.444\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0951 | Train score: 0.9630 | Val loss: 0.0970 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:49.102\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1564 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:51.739\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1597 | Train score: 0.9321 | Val loss: 0.1573 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:54.298\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1122 | Train score: 0.9691 | Val loss: 0.1583 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:56.846\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0946 | Train score: 0.9506 | Val loss: 0.1633 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:59.351\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1132 | Train score: 0.9506 | Val loss: 0.1667 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-03 13:16:01.933\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1057 | Train score: 0.9630 | Val loss: 0.1636 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-03 13:16:04.535\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0938 | Train score: 0.9753 | Val loss: 0.1653 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-03 13:16:07.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0709 | Train score: 0.9815 | Val loss: 0.1758 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-03 13:16:09.697\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1691 | Train score: 0.9568 | Val loss: 0.1693 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-03 13:16:12.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1551 | Train score: 0.9506 | Val loss: 0.1610 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-03 13:16:15.363\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0988 | Train score: 0.9753 | Val loss: 0.1561 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-03 13:16:18.045\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1282 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-03 13:16:20.759\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1033 | Train score: 0.9568 | Val loss: 0.1350 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:16:23.507\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0685 | Train score: 0.9753 | Val loss: 0.1652 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:16:26.358\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1151 | Train score: 0.9691 | Val loss: 0.1559 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:16:28.853\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1949 | Train score: 0.9444 | Val loss: 0.1426 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:16:31.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1724 | Train score: 0.9568 | Val loss: 0.1381 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:16:34.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1522 | Train score: 0.9568 | Val loss: 0.1356 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-03 13:16:36.847\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1032 | Train score: 0.9568 | Val loss: 0.1224 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:16:39.395\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0910 | Train score: 0.9691 | Val loss: 0.1193 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-03 13:16:41.861\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1376 | Train score: 0.9691 | Val loss: 0.1185 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-03 13:16:44.873\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1126 | Train score: 0.9568 | Val loss: 0.1177 | Val score: 0.9653\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " context_length \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.946         0.000           0.000          0.000        0.000       0.000         0.500        0.000    0.000   0.000         0.000        0.000\n",
      "XGBClassifier                         0.948         0.010           0.463          0.206        0.317       0.203         0.848        0.081    0.364   0.195         0.012        0.001\n",
      "MedPFNClassifier                      0.947         0.006           0.400          0.436        0.117       0.130         0.870        0.071    0.166   0.170         0.371        0.047\n",
      "MedPFNClassifier                      0.950         0.008           0.533          0.393        0.200       0.145         0.919        0.055    0.276   0.191         2.034        0.129\n",
      "MedPFNClassifier                      0.951         0.011           0.560          0.115        0.500       0.258         0.916        0.061    0.499   0.137        15.587        1.777\n",
      "RandomForestClassifier                0.952         0.012           0.417          0.443        0.183       0.203         0.903        0.056    0.246   0.269         0.239        0.018\n",
      "CatBoostGrid                          0.949         0.006           0.500          0.447        0.133       0.125         0.901        0.061    0.194   0.164        49.480        5.812\n",
      "XGBoostGrid                           0.946         0.000           0.000          0.000        0.000       0.000         0.871        0.054    0.000   0.000        40.350        5.466\n",
      "LogisticRegressionClassifier          0.939         0.014           0.393          0.245        0.217       0.150         0.825        0.096    0.269   0.169         0.010        0.002\n",
      "TabPFNClassifier                      0.946         0.018           0.373          0.397        0.200       0.194         0.906        0.057    0.259   0.261         3.630        0.183\n",
      "TabForestPFNClassifier                0.939         0.023           0.484          0.311        0.333       0.183         0.886        0.036    0.371   0.206        28.517        0.803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-03 13:53:12.988\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1215 | Val score: 0.9631\u001b[0m\n",
      "\u001b[32m2024-11-03 13:53:19.486\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1317 | Train score: 0.9571 | Val loss: 0.1234 | Val score: 0.9631\u001b[0m\n",
      "\u001b[32m2024-11-03 13:53:24.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1247 | Train score: 0.9571 | Val loss: 0.1260 | Val score: 0.9631\u001b[0m\n",
      "\u001b[32m2024-11-03 13:53:30.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1209 | Train score: 0.9632 | Val loss: 0.1182 | Val score: 0.9656\u001b[0m\n",
      "\u001b[32m2024-11-03 13:53:36.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0861 | Train score: 0.9663 | Val loss: 0.1180 | Val score: 0.9631\u001b[0m\n",
      "\u001b[32m2024-11-03 13:53:41.603\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1200 | Train score: 0.9632 | Val loss: 0.1198 | Val score: 0.9631\u001b[0m\n",
      "\u001b[32m2024-11-03 13:53:48.086\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0946 | Train score: 0.9693 | Val loss: 0.1240 | Val score: 0.9656\u001b[0m\n",
      "\u001b[32m2024-11-03 13:53:53.522\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1213 | Train score: 0.9632 | Val loss: 0.1217 | Val score: 0.9656\u001b[0m\n",
      "\u001b[32m2024-11-03 13:53:59.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1178 | Train score: 0.9632 | Val loss: 0.1176 | Val score: 0.9681\u001b[0m\n",
      "\u001b[32m2024-11-03 13:54:04.442\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1314 | Train score: 0.9540 | Val loss: 0.1175 | Val score: 0.9754\u001b[0m\n",
      "\u001b[32m2024-11-03 13:54:09.878\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0881 | Train score: 0.9724 | Val loss: 0.1155 | Val score: 0.9705\u001b[0m\n",
      "\u001b[32m2024-11-03 13:54:14.979\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1460 | Val score: 0.9459\u001b[0m\n",
      "\u001b[32m2024-11-03 13:54:20.773\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1003 | Train score: 0.9724 | Val loss: 0.1542 | Val score: 0.9484\u001b[0m\n",
      "\u001b[32m2024-11-03 13:54:26.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1353 | Train score: 0.9601 | Val loss: 0.1574 | Val score: 0.9484\u001b[0m\n",
      "\u001b[32m2024-11-03 13:54:31.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1044 | Train score: 0.9663 | Val loss: 0.1584 | Val score: 0.9459\u001b[0m\n",
      "\u001b[32m2024-11-03 13:54:36.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1072 | Train score: 0.9693 | Val loss: 0.1564 | Val score: 0.9459\u001b[0m\n",
      "\u001b[32m2024-11-03 13:54:42.229\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1208 | Train score: 0.9601 | Val loss: 0.1543 | Val score: 0.9459\u001b[0m\n",
      "\u001b[32m2024-11-03 13:54:48.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1684 | Train score: 0.9540 | Val loss: 0.1506 | Val score: 0.9459\u001b[0m\n",
      "\u001b[32m2024-11-03 13:54:54.037\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1018 | Train score: 0.9663 | Val loss: 0.1485 | Val score: 0.9484\u001b[0m\n",
      "\u001b[32m2024-11-03 13:54:59.412\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1048 | Train score: 0.9693 | Val loss: 0.1478 | Val score: 0.9484\u001b[0m\n",
      "\u001b[32m2024-11-03 13:55:04.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0994 | Train score: 0.9663 | Val loss: 0.1487 | Val score: 0.9459\u001b[0m\n",
      "\u001b[32m2024-11-03 13:55:10.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0753 | Train score: 0.9785 | Val loss: 0.1518 | Val score: 0.9459\u001b[0m\n",
      "\u001b[32m2024-11-03 13:55:15.350\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1098 | Val score: 0.9705\u001b[0m\n",
      "\u001b[32m2024-11-03 13:55:21.459\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1135 | Train score: 0.9724 | Val loss: 0.1075 | Val score: 0.9681\u001b[0m\n",
      "\u001b[32m2024-11-03 13:55:27.074\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0996 | Train score: 0.9632 | Val loss: 0.1101 | Val score: 0.9631\u001b[0m\n",
      "\u001b[32m2024-11-03 13:55:32.796\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1426 | Train score: 0.9601 | Val loss: 0.1114 | Val score: 0.9656\u001b[0m\n",
      "\u001b[32m2024-11-03 13:55:38.054\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1365 | Train score: 0.9601 | Val loss: 0.1187 | Val score: 0.9681\u001b[0m\n",
      "\u001b[32m2024-11-03 13:55:43.571\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1029 | Train score: 0.9724 | Val loss: 0.1066 | Val score: 0.9681\u001b[0m\n",
      "\u001b[32m2024-11-03 13:55:49.916\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1377 | Train score: 0.9540 | Val loss: 0.1034 | Val score: 0.9681\u001b[0m\n",
      "\u001b[32m2024-11-03 13:55:55.727\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1113 | Train score: 0.9663 | Val loss: 0.1023 | Val score: 0.9681\u001b[0m\n",
      "\u001b[32m2024-11-03 13:56:01.184\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1615 | Train score: 0.9479 | Val loss: 0.1032 | Val score: 0.9681\u001b[0m\n",
      "\u001b[32m2024-11-03 13:56:06.863\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1512 | Train score: 0.9509 | Val loss: 0.1049 | Val score: 0.9656\u001b[0m\n",
      "\u001b[32m2024-11-03 13:56:12.490\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1405 | Train score: 0.9571 | Val loss: 0.1069 | Val score: 0.9656\u001b[0m\n",
      "\u001b[32m2024-11-03 13:56:18.046\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1253 | Val score: 0.9533\u001b[0m\n",
      "\u001b[32m2024-11-03 13:56:23.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1081 | Train score: 0.9632 | Val loss: 0.1229 | Val score: 0.9459\u001b[0m\n",
      "\u001b[32m2024-11-03 13:56:29.972\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1113 | Train score: 0.9663 | Val loss: 0.1231 | Val score: 0.9435\u001b[0m\n",
      "\u001b[32m2024-11-03 13:56:35.848\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0814 | Train score: 0.9724 | Val loss: 0.1259 | Val score: 0.9459\u001b[0m\n",
      "\u001b[32m2024-11-03 13:56:41.269\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1038 | Train score: 0.9571 | Val loss: 0.1331 | Val score: 0.9484\u001b[0m\n",
      "\u001b[32m2024-11-03 13:56:48.098\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0811 | Train score: 0.9663 | Val loss: 0.1398 | Val score: 0.9459\u001b[0m\n",
      "\u001b[32m2024-11-03 13:56:53.950\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0933 | Train score: 0.9571 | Val loss: 0.1438 | Val score: 0.9484\u001b[0m\n",
      "\u001b[32m2024-11-03 13:56:59.488\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1178 | Train score: 0.9571 | Val loss: 0.1384 | Val score: 0.9435\u001b[0m\n",
      "\u001b[32m2024-11-03 13:57:05.296\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0932 | Train score: 0.9601 | Val loss: 0.1348 | Val score: 0.9459\u001b[0m\n",
      "\u001b[32m2024-11-03 13:57:11.092\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1011 | Train score: 0.9663 | Val loss: 0.1315 | Val score: 0.9459\u001b[0m\n",
      "\u001b[32m2024-11-03 13:57:17.850\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1090 | Train score: 0.9632 | Val loss: 0.1291 | Val score: 0.9459\u001b[0m\n",
      "\u001b[32m2024-11-03 13:57:22.717\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1280 | Val score: 0.9582\u001b[0m\n",
      "\u001b[32m2024-11-03 13:57:27.915\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1494 | Train score: 0.9540 | Val loss: 0.1277 | Val score: 0.9582\u001b[0m\n",
      "\u001b[32m2024-11-03 13:57:33.196\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1447 | Train score: 0.9509 | Val loss: 0.1274 | Val score: 0.9558\u001b[0m\n",
      "\u001b[32m2024-11-03 13:57:38.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1388 | Train score: 0.9601 | Val loss: 0.1258 | Val score: 0.9533\u001b[0m\n",
      "\u001b[32m2024-11-03 13:57:44.048\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1501 | Train score: 0.9601 | Val loss: 0.1265 | Val score: 0.9558\u001b[0m\n",
      "\u001b[32m2024-11-03 13:57:50.217\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1051 | Train score: 0.9663 | Val loss: 0.1254 | Val score: 0.9558\u001b[0m\n",
      "\u001b[32m2024-11-03 13:57:55.590\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1053 | Train score: 0.9663 | Val loss: 0.1253 | Val score: 0.9558\u001b[0m\n",
      "\u001b[32m2024-11-03 13:58:00.951\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1038 | Train score: 0.9663 | Val loss: 0.1269 | Val score: 0.9582\u001b[0m\n",
      "\u001b[32m2024-11-03 13:58:06.365\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1076 | Train score: 0.9724 | Val loss: 0.1302 | Val score: 0.9558\u001b[0m\n",
      "\u001b[32m2024-11-03 13:58:11.746\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1016 | Train score: 0.9663 | Val loss: 0.1329 | Val score: 0.9558\u001b[0m\n",
      "\u001b[32m2024-11-03 13:58:17.952\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1003 | Train score: 0.9601 | Val loss: 0.1351 | Val score: 0.9558\u001b[0m\n",
      "\u001b[32m2024-11-03 13:58:22.945\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1116 | Val score: 0.9607\u001b[0m\n",
      "\u001b[32m2024-11-03 13:58:28.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1388 | Train score: 0.9540 | Val loss: 0.1037 | Val score: 0.9656\u001b[0m\n",
      "\u001b[32m2024-11-03 13:58:33.879\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1205 | Train score: 0.9601 | Val loss: 0.1047 | Val score: 0.9656\u001b[0m\n",
      "\u001b[32m2024-11-03 13:58:39.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0995 | Train score: 0.9632 | Val loss: 0.1081 | Val score: 0.9681\u001b[0m\n",
      "\u001b[32m2024-11-03 13:58:45.378\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1201 | Train score: 0.9632 | Val loss: 0.1071 | Val score: 0.9681\u001b[0m\n",
      "\u001b[32m2024-11-03 13:58:51.329\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1158 | Train score: 0.9693 | Val loss: 0.1081 | Val score: 0.9705\u001b[0m\n",
      "\u001b[32m2024-11-03 13:58:56.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0929 | Train score: 0.9724 | Val loss: 0.1058 | Val score: 0.9705\u001b[0m\n",
      "\u001b[32m2024-11-03 13:59:02.122\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1453 | Train score: 0.9571 | Val loss: 0.1048 | Val score: 0.9705\u001b[0m\n",
      "\u001b[32m2024-11-03 13:59:07.514\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1127 | Train score: 0.9601 | Val loss: 0.1058 | Val score: 0.9705\u001b[0m\n",
      "\u001b[32m2024-11-03 13:59:13.165\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1155 | Train score: 0.9632 | Val loss: 0.1102 | Val score: 0.9656\u001b[0m\n",
      "\u001b[32m2024-11-03 13:59:19.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1102 | Train score: 0.9632 | Val loss: 0.1124 | Val score: 0.9607\u001b[0m\n",
      "\u001b[32m2024-11-03 13:59:24.555\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1272 | Val score: 0.9533\u001b[0m\n",
      "\u001b[32m2024-11-03 13:59:30.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1364 | Train score: 0.9601 | Val loss: 0.1217 | Val score: 0.9656\u001b[0m\n",
      "\u001b[32m2024-11-03 13:59:35.795\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1205 | Train score: 0.9571 | Val loss: 0.1202 | Val score: 0.9558\u001b[0m\n",
      "\u001b[32m2024-11-03 13:59:41.590\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0949 | Train score: 0.9693 | Val loss: 0.1210 | Val score: 0.9582\u001b[0m\n",
      "\u001b[32m2024-11-03 13:59:47.875\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1177 | Train score: 0.9571 | Val loss: 0.1227 | Val score: 0.9533\u001b[0m\n",
      "\u001b[32m2024-11-03 13:59:53.960\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0999 | Train score: 0.9693 | Val loss: 0.1234 | Val score: 0.9533\u001b[0m\n",
      "\u001b[32m2024-11-03 14:00:00.138\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1348 | Train score: 0.9663 | Val loss: 0.1237 | Val score: 0.9509\u001b[0m\n",
      "\u001b[32m2024-11-03 14:00:05.925\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1377 | Train score: 0.9632 | Val loss: 0.1252 | Val score: 0.9484\u001b[0m\n",
      "\u001b[32m2024-11-03 14:00:11.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1085 | Train score: 0.9724 | Val loss: 0.1268 | Val score: 0.9484\u001b[0m\n",
      "\u001b[32m2024-11-03 14:00:18.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1090 | Train score: 0.9693 | Val loss: 0.1272 | Val score: 0.9484\u001b[0m\n",
      "\u001b[32m2024-11-03 14:00:23.800\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0987 | Train score: 0.9785 | Val loss: 0.1274 | Val score: 0.9459\u001b[0m\n",
      "\u001b[32m2024-11-03 14:00:28.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1626 | Val score: 0.9459\u001b[0m\n",
      "\u001b[32m2024-11-03 14:00:34.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1152 | Train score: 0.9571 | Val loss: 0.1664 | Val score: 0.9509\u001b[0m\n",
      "\u001b[32m2024-11-03 14:00:39.604\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1147 | Train score: 0.9540 | Val loss: 0.1641 | Val score: 0.9484\u001b[0m\n",
      "\u001b[32m2024-11-03 14:00:45.624\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1239 | Train score: 0.9632 | Val loss: 0.1568 | Val score: 0.9484\u001b[0m\n",
      "\u001b[32m2024-11-03 14:00:51.890\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1476 | Train score: 0.9479 | Val loss: 0.1533 | Val score: 0.9484\u001b[0m\n",
      "\u001b[32m2024-11-03 14:00:57.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0954 | Train score: 0.9724 | Val loss: 0.1535 | Val score: 0.9484\u001b[0m\n",
      "\u001b[32m2024-11-03 14:01:03.385\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1029 | Train score: 0.9663 | Val loss: 0.1563 | Val score: 0.9484\u001b[0m\n",
      "\u001b[32m2024-11-03 14:01:09.013\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0731 | Train score: 0.9663 | Val loss: 0.1638 | Val score: 0.9484\u001b[0m\n",
      "\u001b[32m2024-11-03 14:01:15.180\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0845 | Train score: 0.9785 | Val loss: 0.1733 | Val score: 0.9509\u001b[0m\n",
      "\u001b[32m2024-11-03 14:01:21.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1180 | Train score: 0.9571 | Val loss: 0.1789 | Val score: 0.9509\u001b[0m\n",
      "\u001b[32m2024-11-03 14:01:27.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1538 | Train score: 0.9601 | Val loss: 0.1741 | Val score: 0.9509\u001b[0m\n",
      "\u001b[32m2024-11-03 14:01:32.162\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1421 | Val score: 0.9509\u001b[0m\n",
      "\u001b[32m2024-11-03 14:01:37.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1298 | Train score: 0.9540 | Val loss: 0.1380 | Val score: 0.9509\u001b[0m\n",
      "\u001b[32m2024-11-03 14:01:43.402\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0868 | Train score: 0.9755 | Val loss: 0.1415 | Val score: 0.9484\u001b[0m\n",
      "\u001b[32m2024-11-03 14:01:50.222\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1214 | Train score: 0.9632 | Val loss: 0.1402 | Val score: 0.9484\u001b[0m\n",
      "\u001b[32m2024-11-03 14:01:55.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0941 | Train score: 0.9632 | Val loss: 0.1414 | Val score: 0.9435\u001b[0m\n",
      "\u001b[32m2024-11-03 14:02:01.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1487 | Train score: 0.9540 | Val loss: 0.1423 | Val score: 0.9410\u001b[0m\n",
      "\u001b[32m2024-11-03 14:02:06.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1265 | Train score: 0.9663 | Val loss: 0.1413 | Val score: 0.9435\u001b[0m\n",
      "\u001b[32m2024-11-03 14:02:12.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1106 | Train score: 0.9571 | Val loss: 0.1415 | Val score: 0.9361\u001b[0m\n",
      "\u001b[32m2024-11-03 14:02:18.528\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1062 | Train score: 0.9571 | Val loss: 0.1409 | Val score: 0.9410\u001b[0m\n",
      "\u001b[32m2024-11-03 14:02:23.894\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1031 | Train score: 0.9571 | Val loss: 0.1392 | Val score: 0.9435\u001b[0m\n",
      "\u001b[32m2024-11-03 14:02:29.716\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0818 | Train score: 0.9785 | Val loss: 0.1381 | Val score: 0.9435\u001b[0m\n",
      "\u001b[32m2024-11-03 14:02:34.341\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1293 | Val score: 0.9582\u001b[0m\n",
      "\u001b[32m2024-11-03 14:02:39.785\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1364 | Train score: 0.9571 | Val loss: 0.1221 | Val score: 0.9582\u001b[0m\n",
      "\u001b[32m2024-11-03 14:02:45.782\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1413 | Train score: 0.9509 | Val loss: 0.1273 | Val score: 0.9607\u001b[0m\n",
      "\u001b[32m2024-11-03 14:02:51.891\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1253 | Train score: 0.9571 | Val loss: 0.1304 | Val score: 0.9607\u001b[0m\n",
      "\u001b[32m2024-11-03 14:02:58.165\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1038 | Train score: 0.9632 | Val loss: 0.1302 | Val score: 0.9582\u001b[0m\n",
      "\u001b[32m2024-11-03 14:03:04.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1359 | Train score: 0.9663 | Val loss: 0.1302 | Val score: 0.9533\u001b[0m\n",
      "\u001b[32m2024-11-03 14:03:11.804\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0955 | Train score: 0.9724 | Val loss: 0.1305 | Val score: 0.9509\u001b[0m\n",
      "\u001b[32m2024-11-03 14:03:19.013\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0925 | Train score: 0.9724 | Val loss: 0.1313 | Val score: 0.9533\u001b[0m\n",
      "\u001b[32m2024-11-03 14:03:26.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1048 | Train score: 0.9693 | Val loss: 0.1311 | Val score: 0.9558\u001b[0m\n",
      "\u001b[32m2024-11-03 14:03:33.222\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1294 | Train score: 0.9632 | Val loss: 0.1305 | Val score: 0.9558\u001b[0m\n",
      "\u001b[32m2024-11-03 14:03:40.408\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1481 | Train score: 0.9479 | Val loss: 0.1308 | Val score: 0.9558\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " context_length \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.942         0.000           0.000          0.000        0.000       0.000         0.500        0.000    0.000   0.000         0.000        0.000\n",
      "XGBClassifier                         0.949         0.008           0.701          0.195        0.338       0.138         0.813        0.041    0.414   0.142         0.019        0.001\n",
      "MedPFNClassifier                      0.944         0.007           0.613          0.350        0.123       0.051         0.839        0.062    0.201   0.085         1.205        0.027\n",
      "MedPFNClassifier                      0.954         0.009           0.787          0.174        0.292       0.191         0.885        0.040    0.392   0.202         6.306        0.297\n",
      "MedPFNClassifier                      0.950         0.007           0.716          0.188        0.369       0.181         0.884        0.041    0.433   0.159        26.488        0.915\n",
      "RandomForestClassifier                0.955         0.011           0.663          0.371        0.269       0.198         0.874        0.050    0.371   0.250         0.363        0.023\n",
      "CatBoostGrid                          0.953         0.011           0.582          0.321        0.277       0.198         0.888        0.039    0.365   0.241        94.159        7.885\n",
      "XGBoostGrid                           0.950         0.007           0.497          0.419        0.192       0.169         0.871        0.054    0.269   0.225        78.125        4.646\n",
      "LogisticRegressionClassifier          0.935         0.011           0.427          0.099        0.346       0.062         0.805        0.068    0.380   0.075         0.018        0.003\n",
      "TabPFNClassifier                      0.954         0.008           0.715          0.084        0.300       0.170         0.885        0.049    0.404   0.163        10.582        0.342\n",
      "TabForestPFNClassifier                0.949         0.005           0.599          0.062        0.354       0.086         0.880        0.038    0.439   0.077        62.915        3.063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-03 15:08:42.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1405 | Val score: 0.9499\u001b[0m\n",
      "\u001b[32m2024-11-03 15:09:01.289\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1178 | Train score: 0.9570 | Val loss: 0.1335 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 15:09:20.857\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1232 | Train score: 0.9668 | Val loss: 0.1321 | Val score: 0.9597\u001b[0m\n",
      "\u001b[32m2024-11-03 15:09:39.970\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1079 | Train score: 0.9668 | Val loss: 0.1322 | Val score: 0.9597\u001b[0m\n",
      "\u001b[32m2024-11-03 15:10:00.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1557 | Train score: 0.9492 | Val loss: 0.1305 | Val score: 0.9584\u001b[0m\n",
      "\u001b[32m2024-11-03 15:10:20.980\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1985 | Train score: 0.9512 | Val loss: 0.1298 | Val score: 0.9584\u001b[0m\n",
      "\u001b[32m2024-11-03 15:10:40.244\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1221 | Train score: 0.9570 | Val loss: 0.1308 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 15:11:01.717\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1424 | Train score: 0.9531 | Val loss: 0.1314 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 15:11:24.289\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1399 | Train score: 0.9570 | Val loss: 0.1324 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 15:11:45.192\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1336 | Train score: 0.9609 | Val loss: 0.1315 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 15:12:06.829\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1250 | Train score: 0.9590 | Val loss: 0.1305 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 15:12:27.377\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1489 | Val score: 0.9462\u001b[0m\n",
      "\u001b[32m2024-11-03 15:12:48.573\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1299 | Train score: 0.9551 | Val loss: 0.1451 | Val score: 0.9535\u001b[0m\n",
      "\u001b[32m2024-11-03 15:13:09.147\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1220 | Train score: 0.9629 | Val loss: 0.1441 | Val score: 0.9535\u001b[0m\n",
      "\u001b[32m2024-11-03 15:13:31.854\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1148 | Train score: 0.9590 | Val loss: 0.1446 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 15:13:54.777\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0816 | Train score: 0.9668 | Val loss: 0.1461 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 15:14:17.347\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1165 | Train score: 0.9609 | Val loss: 0.1478 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 15:14:39.341\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1215 | Train score: 0.9668 | Val loss: 0.1465 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 15:14:57.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1500 | Train score: 0.9629 | Val loss: 0.1439 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 15:15:16.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0964 | Train score: 0.9785 | Val loss: 0.1431 | Val score: 0.9548\u001b[0m\n",
      "\u001b[32m2024-11-03 15:15:34.519\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1214 | Train score: 0.9590 | Val loss: 0.1424 | Val score: 0.9548\u001b[0m\n",
      "\u001b[32m2024-11-03 15:15:51.236\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1105 | Train score: 0.9590 | Val loss: 0.1424 | Val score: 0.9548\u001b[0m\n",
      "\u001b[32m2024-11-03 15:16:08.039\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1270 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 15:16:24.410\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1190 | Train score: 0.9648 | Val loss: 0.1210 | Val score: 0.9584\u001b[0m\n",
      "\u001b[32m2024-11-03 15:16:42.554\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1647 | Train score: 0.9512 | Val loss: 0.1220 | Val score: 0.9584\u001b[0m\n",
      "\u001b[32m2024-11-03 15:17:01.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1232 | Train score: 0.9609 | Val loss: 0.1206 | Val score: 0.9645\u001b[0m\n",
      "\u001b[32m2024-11-03 15:17:19.118\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1326 | Train score: 0.9609 | Val loss: 0.1198 | Val score: 0.9645\u001b[0m\n",
      "\u001b[32m2024-11-03 15:17:36.286\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1160 | Train score: 0.9648 | Val loss: 0.1194 | Val score: 0.9645\u001b[0m\n",
      "\u001b[32m2024-11-03 15:17:53.527\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1321 | Train score: 0.9648 | Val loss: 0.1195 | Val score: 0.9633\u001b[0m\n",
      "\u001b[32m2024-11-03 15:18:10.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1428 | Train score: 0.9453 | Val loss: 0.1189 | Val score: 0.9658\u001b[0m\n",
      "\u001b[32m2024-11-03 15:18:27.756\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1512 | Train score: 0.9512 | Val loss: 0.1183 | Val score: 0.9633\u001b[0m\n",
      "\u001b[32m2024-11-03 15:18:45.215\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1269 | Train score: 0.9492 | Val loss: 0.1174 | Val score: 0.9633\u001b[0m\n",
      "\u001b[32m2024-11-03 15:19:02.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1467 | Train score: 0.9531 | Val loss: 0.1165 | Val score: 0.9645\u001b[0m\n",
      "\u001b[32m2024-11-03 15:19:18.927\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1616 | Val score: 0.9511\u001b[0m\n",
      "\u001b[32m2024-11-03 15:19:36.329\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1411 | Train score: 0.9512 | Val loss: 0.1698 | Val score: 0.9548\u001b[0m\n",
      "\u001b[32m2024-11-03 15:19:53.266\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1109 | Train score: 0.9707 | Val loss: 0.1804 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 15:20:11.382\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1784 | Train score: 0.9531 | Val loss: 0.1712 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 15:20:28.596\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1411 | Train score: 0.9551 | Val loss: 0.1665 | Val score: 0.9548\u001b[0m\n",
      "\u001b[32m2024-11-03 15:20:49.938\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0953 | Train score: 0.9688 | Val loss: 0.1664 | Val score: 0.9535\u001b[0m\n",
      "\u001b[32m2024-11-03 15:21:08.323\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1255 | Train score: 0.9570 | Val loss: 0.1648 | Val score: 0.9535\u001b[0m\n",
      "\u001b[32m2024-11-03 15:21:24.272\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1141 | Train score: 0.9590 | Val loss: 0.1663 | Val score: 0.9511\u001b[0m\n",
      "\u001b[32m2024-11-03 15:21:40.475\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1201 | Train score: 0.9590 | Val loss: 0.1674 | Val score: 0.9523\u001b[0m\n",
      "\u001b[32m2024-11-03 15:22:02.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1264 | Train score: 0.9570 | Val loss: 0.1690 | Val score: 0.9548\u001b[0m\n",
      "\u001b[32m2024-11-03 15:22:24.966\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1301 | Train score: 0.9531 | Val loss: 0.1698 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 15:22:44.422\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1312 | Val score: 0.9535\u001b[0m\n",
      "\u001b[32m2024-11-03 15:23:04.457\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1546 | Train score: 0.9395 | Val loss: 0.1254 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 15:23:24.788\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1536 | Train score: 0.9453 | Val loss: 0.1282 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 15:23:43.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1586 | Train score: 0.9570 | Val loss: 0.1295 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 15:24:03.627\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1263 | Train score: 0.9609 | Val loss: 0.1252 | Val score: 0.9584\u001b[0m\n",
      "\u001b[32m2024-11-03 15:24:23.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1487 | Train score: 0.9492 | Val loss: 0.1231 | Val score: 0.9584\u001b[0m\n",
      "\u001b[32m2024-11-03 15:24:42.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1434 | Train score: 0.9551 | Val loss: 0.1231 | Val score: 0.9621\u001b[0m\n",
      "\u001b[32m2024-11-03 15:25:03.304\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1564 | Train score: 0.9453 | Val loss: 0.1263 | Val score: 0.9609\u001b[0m\n",
      "\u001b[32m2024-11-03 15:25:23.520\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1427 | Train score: 0.9492 | Val loss: 0.1231 | Val score: 0.9621\u001b[0m\n",
      "\u001b[32m2024-11-03 15:25:42.372\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1438 | Train score: 0.9551 | Val loss: 0.1185 | Val score: 0.9621\u001b[0m\n",
      "\u001b[32m2024-11-03 15:26:02.096\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1195 | Train score: 0.9648 | Val loss: 0.1177 | Val score: 0.9621\u001b[0m\n",
      "\u001b[32m2024-11-03 15:26:21.466\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1362 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 15:26:41.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1413 | Train score: 0.9492 | Val loss: 0.1331 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 15:27:01.396\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1500 | Train score: 0.9492 | Val loss: 0.1326 | Val score: 0.9584\u001b[0m\n",
      "\u001b[32m2024-11-03 15:27:21.651\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1266 | Train score: 0.9492 | Val loss: 0.1330 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 15:27:40.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1213 | Train score: 0.9570 | Val loss: 0.1341 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 15:28:01.499\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1349 | Train score: 0.9531 | Val loss: 0.1359 | Val score: 0.9584\u001b[0m\n",
      "\u001b[32m2024-11-03 15:28:26.945\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0990 | Train score: 0.9648 | Val loss: 0.1373 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 15:28:47.320\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1419 | Train score: 0.9590 | Val loss: 0.1379 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 15:29:13.497\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1425 | Train score: 0.9453 | Val loss: 0.1378 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 15:29:36.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1264 | Train score: 0.9609 | Val loss: 0.1371 | Val score: 0.9584\u001b[0m\n",
      "\u001b[32m2024-11-03 15:29:58.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1304 | Train score: 0.9590 | Val loss: 0.1360 | Val score: 0.9584\u001b[0m\n",
      "\u001b[32m2024-11-03 15:30:21.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1576 | Val score: 0.9511\u001b[0m\n",
      "\u001b[32m2024-11-03 15:30:44.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1364 | Train score: 0.9551 | Val loss: 0.1521 | Val score: 0.9487\u001b[0m\n",
      "\u001b[32m2024-11-03 15:31:03.525\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1040 | Train score: 0.9688 | Val loss: 0.1578 | Val score: 0.9474\u001b[0m\n",
      "\u001b[32m2024-11-03 15:31:25.224\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1150 | Train score: 0.9629 | Val loss: 0.1572 | Val score: 0.9511\u001b[0m\n",
      "\u001b[32m2024-11-03 15:31:46.026\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1094 | Train score: 0.9648 | Val loss: 0.1558 | Val score: 0.9487\u001b[0m\n",
      "\u001b[32m2024-11-03 15:32:05.891\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0999 | Train score: 0.9668 | Val loss: 0.1549 | Val score: 0.9487\u001b[0m\n",
      "\u001b[32m2024-11-03 15:32:26.881\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1619 | Train score: 0.9492 | Val loss: 0.1518 | Val score: 0.9487\u001b[0m\n",
      "\u001b[32m2024-11-03 15:32:48.386\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1028 | Train score: 0.9629 | Val loss: 0.1511 | Val score: 0.9474\u001b[0m\n",
      "\u001b[32m2024-11-03 15:33:09.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1073 | Train score: 0.9688 | Val loss: 0.1510 | Val score: 0.9511\u001b[0m\n",
      "\u001b[32m2024-11-03 15:33:29.730\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1087 | Train score: 0.9648 | Val loss: 0.1512 | Val score: 0.9523\u001b[0m\n",
      "\u001b[32m2024-11-03 15:33:50.574\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1068 | Train score: 0.9688 | Val loss: 0.1507 | Val score: 0.9523\u001b[0m\n",
      "\u001b[32m2024-11-03 15:34:10.100\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1552 | Val score: 0.9523\u001b[0m\n",
      "\u001b[32m2024-11-03 15:34:31.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1375 | Train score: 0.9551 | Val loss: 0.1452 | Val score: 0.9535\u001b[0m\n",
      "\u001b[32m2024-11-03 15:34:54.822\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1363 | Train score: 0.9570 | Val loss: 0.1437 | Val score: 0.9523\u001b[0m\n",
      "\u001b[32m2024-11-03 15:35:15.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1266 | Train score: 0.9629 | Val loss: 0.1428 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 15:35:35.843\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1427 | Train score: 0.9492 | Val loss: 0.1416 | Val score: 0.9548\u001b[0m\n",
      "\u001b[32m2024-11-03 15:35:56.145\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1251 | Train score: 0.9609 | Val loss: 0.1419 | Val score: 0.9535\u001b[0m\n",
      "\u001b[32m2024-11-03 15:36:16.293\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1475 | Train score: 0.9570 | Val loss: 0.1404 | Val score: 0.9548\u001b[0m\n",
      "\u001b[32m2024-11-03 15:36:36.881\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1122 | Train score: 0.9590 | Val loss: 0.1385 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 15:36:56.533\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1407 | Train score: 0.9492 | Val loss: 0.1377 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 15:37:17.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1161 | Train score: 0.9629 | Val loss: 0.1377 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 15:37:37.539\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1205 | Train score: 0.9590 | Val loss: 0.1387 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 15:37:58.024\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1382 | Val score: 0.9548\u001b[0m\n",
      "\u001b[32m2024-11-03 15:38:18.154\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1497 | Train score: 0.9414 | Val loss: 0.1409 | Val score: 0.9548\u001b[0m\n",
      "\u001b[32m2024-11-03 15:38:37.861\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1232 | Train score: 0.9531 | Val loss: 0.1449 | Val score: 0.9548\u001b[0m\n",
      "\u001b[32m2024-11-03 15:38:58.920\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1801 | Train score: 0.9336 | Val loss: 0.1432 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 15:39:19.269\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1402 | Train score: 0.9473 | Val loss: 0.1424 | Val score: 0.9609\u001b[0m\n",
      "\u001b[32m2024-11-03 15:39:38.855\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1303 | Train score: 0.9531 | Val loss: 0.1424 | Val score: 0.9609\u001b[0m\n",
      "\u001b[32m2024-11-03 15:39:59.858\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1230 | Train score: 0.9609 | Val loss: 0.1424 | Val score: 0.9584\u001b[0m\n",
      "\u001b[32m2024-11-03 15:40:23.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1364 | Train score: 0.9570 | Val loss: 0.1405 | Val score: 0.9584\u001b[0m\n",
      "\u001b[32m2024-11-03 15:40:44.377\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1102 | Train score: 0.9629 | Val loss: 0.1394 | Val score: 0.9597\u001b[0m\n",
      "\u001b[32m2024-11-03 15:41:06.040\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1059 | Train score: 0.9590 | Val loss: 0.1375 | Val score: 0.9597\u001b[0m\n",
      "\u001b[32m2024-11-03 15:41:27.483\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1252 | Train score: 0.9512 | Val loss: 0.1356 | Val score: 0.9621\u001b[0m\n",
      "\u001b[32m2024-11-03 15:41:44.801\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1269 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 15:42:02.751\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1328 | Train score: 0.9551 | Val loss: 0.1144 | Val score: 0.9548\u001b[0m\n",
      "\u001b[32m2024-11-03 15:42:26.032\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1410 | Train score: 0.9531 | Val loss: 0.1138 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 15:42:43.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1315 | Train score: 0.9551 | Val loss: 0.1152 | Val score: 0.9584\u001b[0m\n",
      "\u001b[32m2024-11-03 15:43:02.074\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1444 | Train score: 0.9473 | Val loss: 0.1174 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 15:43:21.600\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1767 | Train score: 0.9434 | Val loss: 0.1181 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 15:43:44.942\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1516 | Train score: 0.9473 | Val loss: 0.1218 | Val score: 0.9597\u001b[0m\n",
      "\u001b[32m2024-11-03 15:44:07.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1141 | Train score: 0.9727 | Val loss: 0.1217 | Val score: 0.9597\u001b[0m\n",
      "\u001b[32m2024-11-03 15:44:30.395\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1271 | Train score: 0.9531 | Val loss: 0.1190 | Val score: 0.9597\u001b[0m\n",
      "\u001b[32m2024-11-03 15:45:01.804\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1713 | Train score: 0.9492 | Val loss: 0.1164 | Val score: 0.9609\u001b[0m\n",
      "\u001b[32m2024-11-03 15:45:23.482\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1307 | Train score: 0.9590 | Val loss: 0.1153 | Val score: 0.9609\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " context_length \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.941         0.000           0.000          0.000        0.000       0.000         0.500        0.000    0.000   0.000         0.000        0.000\n",
      "XGBClassifier                         0.946         0.009           0.563          0.100        0.419       0.095         0.843        0.055    0.479   0.097         0.046        0.004\n",
      "MedPFNClassifier                      0.948         0.006           0.678          0.142        0.233       0.072         0.856        0.045    0.345   0.096         5.033        0.103\n",
      "MedPFNClassifier                      0.953         0.006           0.735          0.107        0.322       0.086         0.896        0.038    0.443   0.094        28.414        0.407\n",
      "MedPFNClassifier                      0.952         0.008           0.652          0.125        0.470       0.102         0.898        0.036    0.537   0.086        43.367        5.062\n",
      "RandomForestClassifier                0.959         0.004           0.859          0.094        0.374       0.075         0.896        0.040    0.515   0.076         1.055        0.054\n",
      "CatBoostGrid                          0.959         0.005           0.836          0.118        0.389       0.082         0.907        0.028    0.523   0.077       147.728        7.182\n",
      "XGBoostGrid                           0.949         0.005           0.598          0.311        0.222       0.112         0.893        0.035    0.324   0.164       130.904       14.342\n",
      "LogisticRegressionClassifier          0.937         0.007           0.474          0.087        0.385       0.071         0.820        0.051    0.421   0.061         0.030        0.007\n",
      "TabPFNClassifier                      0.954         0.003           0.846          0.049        0.267       0.046         0.911        0.034    0.404   0.057        30.063        3.129\n",
      "TabForestPFNClassifier                0.953         0.006           0.684          0.097        0.422       0.076         0.900        0.028    0.515   0.062       221.526       14.168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-03 17:36:11.437\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1477 | Val score: 0.9481\u001b[0m\n",
      "\u001b[32m2024-11-03 17:36:48.056\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1270 | Train score: 0.9551 | Val loss: 0.1428 | Val score: 0.9469\u001b[0m\n",
      "\u001b[32m2024-11-03 17:37:23.515\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1626 | Train score: 0.9473 | Val loss: 0.1438 | Val score: 0.9481\u001b[0m\n",
      "\u001b[32m2024-11-03 17:38:01.730\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1412 | Train score: 0.9531 | Val loss: 0.1425 | Val score: 0.9524\u001b[0m\n",
      "\u001b[32m2024-11-03 17:38:38.276\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1375 | Train score: 0.9609 | Val loss: 0.1461 | Val score: 0.9481\u001b[0m\n",
      "\u001b[32m2024-11-03 17:39:15.798\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1553 | Train score: 0.9531 | Val loss: 0.1421 | Val score: 0.9530\u001b[0m\n",
      "\u001b[32m2024-11-03 17:39:54.320\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1095 | Train score: 0.9688 | Val loss: 0.1434 | Val score: 0.9517\u001b[0m\n",
      "\u001b[32m2024-11-03 17:40:37.051\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1245 | Train score: 0.9590 | Val loss: 0.1416 | Val score: 0.9524\u001b[0m\n",
      "\u001b[32m2024-11-03 17:41:17.716\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1422 | Train score: 0.9590 | Val loss: 0.1436 | Val score: 0.9517\u001b[0m\n",
      "\u001b[32m2024-11-03 17:41:56.720\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1382 | Train score: 0.9570 | Val loss: 0.1423 | Val score: 0.9524\u001b[0m\n",
      "\u001b[32m2024-11-03 17:42:37.502\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1608 | Train score: 0.9473 | Val loss: 0.1392 | Val score: 0.9511\u001b[0m\n",
      "\u001b[32m2024-11-03 17:43:15.705\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1382 | Val score: 0.9542\u001b[0m\n",
      "\u001b[32m2024-11-03 17:43:53.416\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1480 | Train score: 0.9512 | Val loss: 0.1306 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 17:44:30.130\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1217 | Train score: 0.9590 | Val loss: 0.1279 | Val score: 0.9597\u001b[0m\n",
      "\u001b[32m2024-11-03 17:45:06.829\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1496 | Train score: 0.9551 | Val loss: 0.1227 | Val score: 0.9597\u001b[0m\n",
      "\u001b[32m2024-11-03 17:45:44.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1564 | Train score: 0.9512 | Val loss: 0.1285 | Val score: 0.9585\u001b[0m\n",
      "\u001b[32m2024-11-03 17:46:21.379\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1340 | Train score: 0.9609 | Val loss: 0.1280 | Val score: 0.9566\u001b[0m\n",
      "\u001b[32m2024-11-03 17:46:56.939\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1189 | Train score: 0.9590 | Val loss: 0.1325 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 17:47:33.773\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1279 | Train score: 0.9531 | Val loss: 0.1269 | Val score: 0.9585\u001b[0m\n",
      "\u001b[32m2024-11-03 17:48:08.559\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1481 | Train score: 0.9609 | Val loss: 0.1292 | Val score: 0.9578\u001b[0m\n",
      "\u001b[32m2024-11-03 17:48:43.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1119 | Train score: 0.9648 | Val loss: 0.1286 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 17:49:18.499\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1795 | Train score: 0.9414 | Val loss: 0.1293 | Val score: 0.9585\u001b[0m\n",
      "\u001b[32m2024-11-03 17:49:54.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1415 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-03 17:50:31.575\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1446 | Train score: 0.9512 | Val loss: 0.1273 | Val score: 0.9597\u001b[0m\n",
      "\u001b[32m2024-11-03 17:51:07.910\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1615 | Train score: 0.9473 | Val loss: 0.1262 | Val score: 0.9597\u001b[0m\n",
      "\u001b[32m2024-11-03 17:51:45.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1147 | Train score: 0.9668 | Val loss: 0.1286 | Val score: 0.9578\u001b[0m\n",
      "\u001b[32m2024-11-03 17:52:21.758\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1223 | Train score: 0.9531 | Val loss: 0.1287 | Val score: 0.9609\u001b[0m\n",
      "\u001b[32m2024-11-03 17:52:57.759\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1070 | Train score: 0.9668 | Val loss: 0.1258 | Val score: 0.9578\u001b[0m\n",
      "\u001b[32m2024-11-03 17:53:33.571\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1333 | Train score: 0.9473 | Val loss: 0.1272 | Val score: 0.9597\u001b[0m\n",
      "\u001b[32m2024-11-03 17:54:10.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1429 | Train score: 0.9551 | Val loss: 0.1250 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 17:54:44.806\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1183 | Train score: 0.9590 | Val loss: 0.1266 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 17:55:22.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1548 | Train score: 0.9570 | Val loss: 0.1274 | Val score: 0.9591\u001b[0m\n",
      "\u001b[32m2024-11-03 17:56:00.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1155 | Train score: 0.9570 | Val loss: 0.1269 | Val score: 0.9578\u001b[0m\n",
      "\u001b[32m2024-11-03 17:56:36.588\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1427 | Val score: 0.9456\u001b[0m\n",
      "\u001b[32m2024-11-03 17:57:28.577\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1765 | Train score: 0.9355 | Val loss: 0.1348 | Val score: 0.9524\u001b[0m\n",
      "\u001b[32m2024-11-03 17:58:16.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1581 | Train score: 0.9336 | Val loss: 0.1286 | Val score: 0.9530\u001b[0m\n",
      "\u001b[32m2024-11-03 17:58:55.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1282 | Train score: 0.9551 | Val loss: 0.1307 | Val score: 0.9548\u001b[0m\n",
      "\u001b[32m2024-11-03 17:59:31.939\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1445 | Train score: 0.9570 | Val loss: 0.1325 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 18:00:07.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0969 | Train score: 0.9590 | Val loss: 0.1336 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 18:00:44.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1307 | Train score: 0.9551 | Val loss: 0.1299 | Val score: 0.9524\u001b[0m\n",
      "\u001b[32m2024-11-03 18:01:21.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1111 | Train score: 0.9707 | Val loss: 0.1355 | Val score: 0.9585\u001b[0m\n",
      "\u001b[32m2024-11-03 18:01:57.915\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1728 | Train score: 0.9512 | Val loss: 0.1341 | Val score: 0.9530\u001b[0m\n",
      "\u001b[32m2024-11-03 18:02:39.033\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1211 | Train score: 0.9590 | Val loss: 0.1312 | Val score: 0.9511\u001b[0m\n",
      "\u001b[32m2024-11-03 18:03:25.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1086 | Train score: 0.9590 | Val loss: 0.1342 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 18:04:06.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1411 | Val score: 0.9530\u001b[0m\n",
      "\u001b[32m2024-11-03 18:04:48.945\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1353 | Train score: 0.9531 | Val loss: 0.1390 | Val score: 0.9530\u001b[0m\n",
      "\u001b[32m2024-11-03 18:05:31.241\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1433 | Train score: 0.9512 | Val loss: 0.1405 | Val score: 0.9517\u001b[0m\n",
      "\u001b[32m2024-11-03 18:06:09.637\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1027 | Train score: 0.9551 | Val loss: 0.1374 | Val score: 0.9536\u001b[0m\n",
      "\u001b[32m2024-11-03 18:06:45.355\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1779 | Train score: 0.9570 | Val loss: 0.1375 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 18:07:24.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1786 | Train score: 0.9316 | Val loss: 0.1339 | Val score: 0.9566\u001b[0m\n",
      "\u001b[32m2024-11-03 18:08:03.192\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1129 | Train score: 0.9609 | Val loss: 0.1341 | Val score: 0.9524\u001b[0m\n",
      "\u001b[32m2024-11-03 18:08:38.698\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1204 | Train score: 0.9668 | Val loss: 0.1372 | Val score: 0.9517\u001b[0m\n",
      "\u001b[32m2024-11-03 18:09:14.328\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1075 | Train score: 0.9688 | Val loss: 0.1380 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-03 18:09:52.019\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1353 | Train score: 0.9609 | Val loss: 0.1331 | Val score: 0.9548\u001b[0m\n",
      "\u001b[32m2024-11-03 18:10:29.563\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1099 | Train score: 0.9727 | Val loss: 0.1338 | Val score: 0.9566\u001b[0m\n",
      "\u001b[32m2024-11-03 18:11:04.390\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1366 | Val score: 0.9511\u001b[0m\n",
      "\u001b[32m2024-11-03 18:11:41.126\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1491 | Train score: 0.9512 | Val loss: 0.1292 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 18:12:18.204\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1264 | Train score: 0.9668 | Val loss: 0.1344 | Val score: 0.9542\u001b[0m\n",
      "\u001b[32m2024-11-03 18:12:54.975\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1823 | Train score: 0.9434 | Val loss: 0.1330 | Val score: 0.9536\u001b[0m\n",
      "\u001b[32m2024-11-03 18:13:29.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1091 | Train score: 0.9629 | Val loss: 0.1292 | Val score: 0.9542\u001b[0m\n",
      "\u001b[32m2024-11-03 18:14:04.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1438 | Train score: 0.9551 | Val loss: 0.1331 | Val score: 0.9542\u001b[0m\n",
      "\u001b[32m2024-11-03 18:14:39.525\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1365 | Train score: 0.9531 | Val loss: 0.1325 | Val score: 0.9536\u001b[0m\n",
      "\u001b[32m2024-11-03 18:15:17.542\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1306 | Train score: 0.9590 | Val loss: 0.1341 | Val score: 0.9542\u001b[0m\n",
      "\u001b[32m2024-11-03 18:15:52.845\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1836 | Train score: 0.9473 | Val loss: 0.1277 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 18:16:30.648\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1944 | Train score: 0.9375 | Val loss: 0.1287 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 18:17:05.802\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1022 | Train score: 0.9648 | Val loss: 0.1275 | Val score: 0.9548\u001b[0m\n",
      "\u001b[32m2024-11-03 18:17:42.422\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1368 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 18:18:17.898\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1418 | Train score: 0.9492 | Val loss: 0.1279 | Val score: 0.9566\u001b[0m\n",
      "\u001b[32m2024-11-03 18:18:51.890\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1459 | Train score: 0.9492 | Val loss: 0.1243 | Val score: 0.9597\u001b[0m\n",
      "\u001b[32m2024-11-03 18:19:28.091\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1533 | Train score: 0.9434 | Val loss: 0.1250 | Val score: 0.9621\u001b[0m\n",
      "\u001b[32m2024-11-03 18:20:05.373\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1541 | Train score: 0.9512 | Val loss: 0.1253 | Val score: 0.9621\u001b[0m\n",
      "\u001b[32m2024-11-03 18:20:40.117\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1317 | Train score: 0.9570 | Val loss: 0.1272 | Val score: 0.9627\u001b[0m\n",
      "\u001b[32m2024-11-03 18:21:18.719\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1202 | Train score: 0.9609 | Val loss: 0.1232 | Val score: 0.9603\u001b[0m\n",
      "\u001b[32m2024-11-03 18:21:56.459\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1233 | Train score: 0.9707 | Val loss: 0.1191 | Val score: 0.9633\u001b[0m\n",
      "\u001b[32m2024-11-03 18:22:31.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1338 | Train score: 0.9590 | Val loss: 0.1218 | Val score: 0.9646\u001b[0m\n",
      "\u001b[32m2024-11-03 18:23:06.480\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1614 | Train score: 0.9473 | Val loss: 0.1237 | Val score: 0.9646\u001b[0m\n",
      "\u001b[32m2024-11-03 18:23:40.725\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1371 | Train score: 0.9531 | Val loss: 0.1247 | Val score: 0.9640\u001b[0m\n",
      "\u001b[32m2024-11-03 18:24:16.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1510 | Val score: 0.9487\u001b[0m\n",
      "\u001b[32m2024-11-03 18:24:53.320\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1316 | Train score: 0.9531 | Val loss: 0.1504 | Val score: 0.9487\u001b[0m\n",
      "\u001b[32m2024-11-03 18:25:30.733\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1481 | Train score: 0.9492 | Val loss: 0.1481 | Val score: 0.9462\u001b[0m\n",
      "\u001b[32m2024-11-03 18:26:09.805\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1654 | Train score: 0.9512 | Val loss: 0.1469 | Val score: 0.9493\u001b[0m\n",
      "\u001b[32m2024-11-03 18:26:45.034\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1501 | Train score: 0.9531 | Val loss: 0.1472 | Val score: 0.9499\u001b[0m\n",
      "\u001b[32m2024-11-03 18:27:20.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1191 | Train score: 0.9609 | Val loss: 0.1467 | Val score: 0.9487\u001b[0m\n",
      "\u001b[32m2024-11-03 18:27:57.762\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1379 | Train score: 0.9473 | Val loss: 0.1453 | Val score: 0.9493\u001b[0m\n",
      "\u001b[32m2024-11-03 18:28:33.800\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1141 | Train score: 0.9629 | Val loss: 0.1440 | Val score: 0.9524\u001b[0m\n",
      "\u001b[32m2024-11-03 18:29:10.076\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1296 | Train score: 0.9570 | Val loss: 0.1439 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-03 18:29:44.123\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1238 | Train score: 0.9688 | Val loss: 0.1481 | Val score: 0.9511\u001b[0m\n",
      "\u001b[32m2024-11-03 18:30:19.054\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1182 | Train score: 0.9570 | Val loss: 0.1483 | Val score: 0.9487\u001b[0m\n",
      "\u001b[32m2024-11-03 18:30:54.853\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1338 | Val score: 0.9511\u001b[0m\n",
      "\u001b[32m2024-11-03 18:31:30.790\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1466 | Train score: 0.9512 | Val loss: 0.1218 | Val score: 0.9536\u001b[0m\n",
      "\u001b[32m2024-11-03 18:32:05.347\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1508 | Train score: 0.9531 | Val loss: 0.1176 | Val score: 0.9585\u001b[0m\n",
      "\u001b[32m2024-11-03 18:32:41.027\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1514 | Train score: 0.9492 | Val loss: 0.1199 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 18:33:15.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1461 | Train score: 0.9531 | Val loss: 0.1191 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 18:33:50.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1514 | Train score: 0.9570 | Val loss: 0.1229 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 18:34:27.850\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1483 | Train score: 0.9434 | Val loss: 0.1191 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 18:35:03.030\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1899 | Train score: 0.9355 | Val loss: 0.1218 | Val score: 0.9603\u001b[0m\n",
      "\u001b[32m2024-11-03 18:35:37.403\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1632 | Train score: 0.9414 | Val loss: 0.1204 | Val score: 0.9578\u001b[0m\n",
      "\u001b[32m2024-11-03 18:36:12.287\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1295 | Train score: 0.9551 | Val loss: 0.1203 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 18:36:50.455\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1420 | Train score: 0.9492 | Val loss: 0.1174 | Val score: 0.9585\u001b[0m\n",
      "\u001b[32m2024-11-03 18:37:29.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1470 | Val score: 0.9499\u001b[0m\n",
      "\u001b[32m2024-11-03 18:38:02.453\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1158 | Train score: 0.9648 | Val loss: 0.1480 | Val score: 0.9511\u001b[0m\n",
      "\u001b[32m2024-11-03 18:38:37.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1255 | Train score: 0.9512 | Val loss: 0.1500 | Val score: 0.9536\u001b[0m\n",
      "\u001b[32m2024-11-03 18:39:12.411\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2037 | Train score: 0.9395 | Val loss: 0.1473 | Val score: 0.9548\u001b[0m\n",
      "\u001b[32m2024-11-03 18:39:49.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1565 | Train score: 0.9434 | Val loss: 0.1465 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 18:40:26.751\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1620 | Train score: 0.9492 | Val loss: 0.1481 | Val score: 0.9536\u001b[0m\n",
      "\u001b[32m2024-11-03 18:41:05.171\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1186 | Train score: 0.9727 | Val loss: 0.1475 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-03 18:41:40.045\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1489 | Train score: 0.9414 | Val loss: 0.1472 | Val score: 0.9511\u001b[0m\n",
      "\u001b[32m2024-11-03 18:42:15.294\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1030 | Train score: 0.9668 | Val loss: 0.1474 | Val score: 0.9499\u001b[0m\n",
      "\u001b[32m2024-11-03 18:42:50.883\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1489 | Train score: 0.9453 | Val loss: 0.1473 | Val score: 0.9517\u001b[0m\n",
      "\u001b[32m2024-11-03 18:43:31.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1529 | Train score: 0.9570 | Val loss: 0.1459 | Val score: 0.9542\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " context_length \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.939         0.000           0.000          0.000        0.000       0.000         0.500        0.000    0.000   0.000         0.000        0.000\n",
      "XGBClassifier                         0.944         0.006           0.563          0.072        0.375       0.052         0.865        0.014    0.449   0.058         0.053        0.005\n",
      "MedPFNClassifier                      0.943         0.003           0.739          0.189        0.093       0.071         0.850        0.018    0.155   0.108        20.498        2.235\n",
      "MedPFNClassifier                      0.951         0.003           0.837          0.096        0.238       0.035         0.894        0.020    0.369   0.047        83.616       12.374\n",
      "MedPFNClassifier                      0.951         0.006           0.694          0.109        0.353       0.060         0.892        0.022    0.462   0.061        92.291        4.785\n",
      "RandomForestClassifier                0.955         0.004           0.795          0.075        0.344       0.058         0.908        0.021    0.477   0.060         2.385        0.049\n",
      "CatBoostGrid                          0.957         0.005           0.789          0.088        0.389       0.043         0.900        0.027    0.520   0.052       160.159       10.800\n",
      "XGBoostGrid                           0.955         0.004           0.788          0.061        0.362       0.044         0.916        0.018    0.495   0.048       185.743       14.649\n",
      "LogisticRegressionClassifier          0.945         0.004           0.577          0.057        0.333       0.039         0.842        0.026    0.421   0.038         0.053        0.011\n",
      "TabPFNClassifier                      0.951         0.005           0.817          0.116        0.253       0.050         0.906        0.020    0.384   0.067        96.494        3.199\n",
      "TabForestPFNClassifier                0.954         0.006           0.725          0.102        0.380       0.060         0.895        0.024    0.497   0.068       406.890       16.181\n"
     ]
    }
   ],
   "source": [
    "save = True\n",
    "sampling = None\n",
    "cv = 10\n",
    "best_delete = 0\n",
    "strat_split = True\n",
    "recomp = False\n",
    "n_optim = 1000\n",
    "cat_optim = 10\n",
    "ft_epochs = 20\n",
    "ft_epochs_forest = 10\n",
    "ft_lr = 1e-5\n",
    "max_s = 1024\n",
    "max_q = 128\n",
    "max_samples = 1024\n",
    "no_pre_process = False\n",
    "multi_decoder = \"permutation\"\n",
    "N_ens = 5\n",
    "seed = 42\n",
    "overwrite = True\n",
    "metrics = [\"accuracy\", \"precision\", \"recall\", \"roc_auc\", \"f1\"]\n",
    "dir_path = os.path.abspath(os.getcwd())\n",
    "#run_name = \"medium_net_mlp_balance_bsplit_baseline\" ## NO PERM, VERY ROBUST\n",
    "#run_name2 = \"large_mlp_var_balance_05weight_anova\" ## das aller bestigste\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_newprior\" ## das aller bestigste\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_newprior\" ## das aller bestigste\n",
    "run_name = \"medium_mlp_var_balance_05weight_anova_bestwithnoisebnn_100\" ## good start, best with ft\n",
    "#run_name3 = \"medium_mlp_var_balance_05weight_anova_bestwithnoisebnn_100_moreweight\" ## best start, ft no so good\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_200\" ## das aller bestigste\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_longer\" ## das aller bestigste\n",
    "#run_name = \"medium_mlp_balance_lownoisefixparam_anova\"\n",
    "#run_name = \"medium_mlp_0.5static_balance_anova\"\n",
    "#run_name = \"large_mlp_fullbalance\"\n",
    "#run_name = \"small_net_mlp_var_imbalance_05weight\" ## WORKS VERY WELL WITH PERM\n",
    "#run_name = \"small_net_mlp_varbalance_weight_batchunisplit\"\n",
    "#run_name = \"small_net_mlp_variable_balance_weight\"\n",
    "#run_name = \"small_net_mlp_balance_minevalup\"\n",
    "path = dir_path + f\"/logs/trainrun_{run_name}\"\n",
    "#path2 = dir_path + f\"/logs/trainrun_{run_name2}\"\n",
    "#path3 = dir_path + f\"/logs/trainrun_{run_name3}\"\n",
    "filename = \"model\"\n",
    "\n",
    "lengths = [512,1024,2048,4096,8192]\n",
    "\n",
    "models = [\n",
    "    MajorityClass(),\n",
    "    XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic'),\n",
    "    MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=1, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process),\n",
    "    MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process),\n",
    "    MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process,\n",
    "                    ft_epochs=ft_epochs, ft_lr=ft_lr),\n",
    "    RandomForestClassifier(),\n",
    "    #AutoGluon(),\n",
    "    CatBoostGrid(),\n",
    "    XGBoostGrid(),\n",
    "    LogisticRegressionClassifier(), \n",
    "    TabPFNClassifier(device='cpu', N_ensemble_configurations=5, no_preprocess_mode=no_pre_process),\n",
    "    TabForestPFNClassifier(\"saved_models/tabforest/mix600k/tabforestpfn.pt\", \"saved_models/tabforest/mix600k/config_run.yaml\", max_epochs=ft_epochs_forest)\n",
    "]\n",
    "reducer  = AnovaSelect()\n",
    "#for reducer in [AnovaSelect(), RandomSelect(), NonZeroSelect(), MeanSelect(), StdSelect(), MaxSelect(), PCASelect()]:\n",
    "#data = clr(all_data)\n",
    "\n",
    "#all_data = normalize(all_data)\n",
    "\n",
    "for cl in lengths:\n",
    "    results_mean = pd.DataFrame(np.zeros((len(models), len(metrics)+1)),\n",
    "                                index=[m.__class__.__name__ for m in models],\n",
    "                                columns=metrics+[\"runtime\"])\n",
    "    results_std = pd.DataFrame(np.zeros((len(models), len(metrics)+1)), \n",
    "                               index=[m.__class__.__name__ for m in models],\n",
    "                               columns=metrics+[\"runtime\"])\n",
    "    \n",
    "    for ii, model in enumerate(models):\n",
    "        results_mean.iloc[ii,:], results_std.iloc[ii,:] = cross_validate_sample(\n",
    "            model, all_data, labels, metrics, strat_split, cv, sampling, \n",
    "            reducer, cl, seed=seed, overwrite=overwrite, n_best_delete=best_delete,\n",
    "            recomp=recomp)\n",
    "    \n",
    "    results_mean = results_mean.add_suffix(\" mean\")\n",
    "    results_std = results_std.add_suffix(\" std\")\n",
    "    results_full = pd.concat((results_mean, results_std), axis=1)\n",
    "    cols = results_full.columns.tolist()\n",
    "    new_cols = []\n",
    "    for i in range(int(len(cols)/2)):\n",
    "        new_cols.append(cols[i])\n",
    "        new_cols.append(cols[i+int(len(cols)/2)])\n",
    "    results_full = results_full[new_cols]\n",
    "    red_name = \"context_length\"\n",
    "    if save:\n",
    "        directory = f\"results/{red_name}\"\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        save_path = f'results/{red_name}/context_length_{cl}.csv'\n",
    "        results_full.to_csv(save_path)\n",
    "    print(\"\\n\", \"\\n\", red_name, \"\\n\", results_full.round(3))\n",
    "    #print(results_full.sort_values(\"roc_auc mean\").round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "03b4b8c5-0c53-43b5-96a7-3eec013f6415",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\AppData\\Local\\Temp\\ipykernel_8164\\550965774.py:41: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  fig.show()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'df = pd.read_csv(path)\\n        accuracies.append(df.iloc[m,1])\\n        rocs.append(df.iloc[m,7])\\n        f1s.append(df.iloc[m,9])\\n    axs[0].plot(lengths, accuracies)\\n    axs[1].plot(lengths, rocs, label = models[m])\\n    axs[2].plot(lengths, f1s)\\n    \\naxs[1].legend(fontsize=12)\\nfig.show()'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "models = [\"Majclass\", \"MedPFN-1\", \"MedPFN-7\", \"MedPFN-7FT\", \"RandomForest\", \"CatBoost\", \"XGBoost\", \"Logistic Regression\", \"TabPFN\", \"TabForestPFN\"]\n",
    "fig, axs = plt.subplots(1,1,figsize=(10,5))#plt.subplots(1, 3, figsize=(25, 5))\n",
    "all_accuracies = []\n",
    "all_rocs = []\n",
    "all_f1s = []\n",
    "lengths = [512,1024,2048,4096,8192]\n",
    "for m in range(1,len(models)):\n",
    "    accuracies = []\n",
    "    rocs = []\n",
    "    f1s = []\n",
    "    for cl in lengths:\n",
    "    \n",
    "        path = f'results/context_length/context_length_{cl}.csv'\n",
    "        df = pd.read_csv(path)\n",
    "        accuracies.append(df.iloc[m,1])\n",
    "        rocs.append(df.iloc[m,7])\n",
    "        f1s.append(df.iloc[m,9])\n",
    "    all_accuracies.append(accuracies)\n",
    "    all_rocs.append(rocs)\n",
    "    all_f1s.append(f1s)\n",
    "    \n",
    "#axs[0].plot(all_accuracies[3])\n",
    "#axs[1].plot(all_rocs[3])\n",
    "#axs[2].plot(all_f1s[2])\n",
    "mean_accuracies = all_accuracies[3]-np.max(np.array(all_accuracies)[4:],axis=0)\n",
    "#axs.plot(fracs, mean_accuracies)\n",
    "mean_rocs = all_rocs[3]-np.max(np.array(all_rocs)[4:],axis=0)\n",
    "#axs.plot(fracs, mean_rocs)\n",
    "mean_f1s = all_f1s[3]-np.max(np.array(all_f1s)[4:],axis=0)\n",
    "#axs.plot(fracs, mean_f1s)\n",
    "axs.plot(lengths, np.zeros(len(lengths)), linestyle='--', c=\"black\", label=\"Win threshhold\")\n",
    "axs.plot(lengths, mean_rocs, marker=\"v\", linewidth=2.5, markersize=7.0, label='ROC AUC', c=\"darkviolet\")\n",
    "axs.plot(lengths, mean_accuracies, marker=\"v\", linewidth=2.5, markersize=7.0, label='Accuracy', c=\"crimson\")\n",
    "axs.plot(lengths, mean_f1s, marker=\"v\", linewidth=2.5, markersize=7.0, label='F1-score', c=\"limegreen\")\n",
    "#axs.set_yticks([-0.05,0,0.05,0.1])\n",
    "#axs.set_xlim(0.5,0.94)\n",
    "axs.set_xlabel(\"Fraction of class 0 in data\")\n",
    "axs.set_ylabel(\"MedPFN - mean[baselines]\")\n",
    "axs.grid()\n",
    "axs.legend(fontsize=12)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "'''df = pd.read_csv(path)\n",
    "        accuracies.append(df.iloc[m,1])\n",
    "        rocs.append(df.iloc[m,7])\n",
    "        f1s.append(df.iloc[m,9])\n",
    "    axs[0].plot(lengths, accuracies)\n",
    "    axs[1].plot(lengths, rocs, label = models[m])\n",
    "    axs[2].plot(lengths, f1s)\n",
    "    \n",
    "axs[1].legend(fontsize=12)\n",
    "fig.show()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc866d4c-75ed-4715-a25d-b0cb8caf5d63",
   "metadata": {},
   "source": [
    "## Imbalance anaysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2d2fcae7-9f0c-4d93-a6a2-b2b6bf4bcf8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700 7087\n",
      "(7787, 1391)\n",
      "0.9101065879029151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 12:29:22.635\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1850 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:24.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2190 | Train score: 0.9383 | Val loss: 0.1841 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:25.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2080 | Train score: 0.9383 | Val loss: 0.1781 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:27.430\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2253 | Train score: 0.9259 | Val loss: 0.1775 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:29.024\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1605 | Train score: 0.9815 | Val loss: 0.1739 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:30.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1880 | Train score: 0.9383 | Val loss: 0.1726 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:32.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1869 | Train score: 0.9321 | Val loss: 0.1719 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:33.977\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.2066 | Train score: 0.9321 | Val loss: 0.1705 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:35.483\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1986 | Train score: 0.9444 | Val loss: 0.1695 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:37.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1860 | Train score: 0.9568 | Val loss: 0.1690 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:38.702\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1524 | Train score: 0.9568 | Val loss: 0.1687 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:40.310\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1837 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:42.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1991 | Train score: 0.9321 | Val loss: 0.1793 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:43.768\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1918 | Train score: 0.9321 | Val loss: 0.1758 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:45.360\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2105 | Train score: 0.9259 | Val loss: 0.1764 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:47.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.2111 | Train score: 0.9136 | Val loss: 0.1791 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:48.581\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1609 | Train score: 0.9321 | Val loss: 0.1817 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:50.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1383 | Train score: 0.9506 | Val loss: 0.1815 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:51.728\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1482 | Train score: 0.9383 | Val loss: 0.1807 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:53.279\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1466 | Train score: 0.9506 | Val loss: 0.1796 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:54.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1410 | Train score: 0.9630 | Val loss: 0.1795 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:56.665\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1334 | Train score: 0.9506 | Val loss: 0.1813 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:58.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1677 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:59.917\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1767 | Train score: 0.9444 | Val loss: 0.1614 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:01.489\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1885 | Train score: 0.9259 | Val loss: 0.1654 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:03.123\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1464 | Train score: 0.9259 | Val loss: 0.1713 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:04.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1640 | Train score: 0.9383 | Val loss: 0.1777 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:06.497\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.2146 | Train score: 0.9383 | Val loss: 0.1633 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:08.234\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.2237 | Train score: 0.9136 | Val loss: 0.1576 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:09.737\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1705 | Train score: 0.9259 | Val loss: 0.1562 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:11.426\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1258 | Train score: 0.9506 | Val loss: 0.1554 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:13.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1676 | Train score: 0.9444 | Val loss: 0.1547 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:14.839\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1716 | Train score: 0.9630 | Val loss: 0.1534 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:16.497\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1651 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:18.150\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2029 | Train score: 0.9321 | Val loss: 0.1605 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:19.887\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2150 | Train score: 0.9383 | Val loss: 0.1575 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:21.448\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1691 | Train score: 0.9506 | Val loss: 0.1552 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:23.042\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1710 | Train score: 0.9321 | Val loss: 0.1567 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:24.664\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.2064 | Train score: 0.9383 | Val loss: 0.1582 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:26.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.2034 | Train score: 0.9444 | Val loss: 0.1576 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:27.862\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1738 | Train score: 0.9444 | Val loss: 0.1578 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:29.463\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1563 | Train score: 0.9568 | Val loss: 0.1575 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:31.015\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1616 | Train score: 0.9506 | Val loss: 0.1571 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:32.548\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1855 | Train score: 0.9506 | Val loss: 0.1559 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:34.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1768 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:35.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1663 | Train score: 0.9568 | Val loss: 0.1705 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:37.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2004 | Train score: 0.9259 | Val loss: 0.1682 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:38.889\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1724 | Train score: 0.9506 | Val loss: 0.1670 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:40.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1616 | Train score: 0.9506 | Val loss: 0.1669 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:42.189\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1559 | Train score: 0.9568 | Val loss: 0.1680 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:43.847\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.2419 | Train score: 0.9321 | Val loss: 0.1703 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:45.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1903 | Train score: 0.9259 | Val loss: 0.1712 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:47.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1416 | Train score: 0.9506 | Val loss: 0.1691 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:48.586\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1717 | Train score: 0.9444 | Val loss: 0.1676 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:50.227\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1674 | Train score: 0.9568 | Val loss: 0.1665 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:51.816\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1563 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:53.755\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2477 | Train score: 0.9259 | Val loss: 0.1748 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:55.428\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2037 | Train score: 0.9444 | Val loss: 0.1611 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:57.300\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1925 | Train score: 0.9259 | Val loss: 0.1502 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:59.161\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1647 | Train score: 0.9568 | Val loss: 0.1438 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:00.943\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1733 | Train score: 0.9383 | Val loss: 0.1370 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:02.595\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1756 | Train score: 0.9383 | Val loss: 0.1298 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:04.243\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1958 | Train score: 0.9321 | Val loss: 0.1268 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:06.049\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1898 | Train score: 0.9506 | Val loss: 0.1249 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:07.860\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1609 | Train score: 0.9444 | Val loss: 0.1237 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:09.515\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1871 | Train score: 0.9321 | Val loss: 0.1232 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:11.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1558 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:12.599\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2213 | Train score: 0.9321 | Val loss: 0.1620 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:14.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1970 | Train score: 0.9321 | Val loss: 0.1503 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:15.810\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2133 | Train score: 0.9383 | Val loss: 0.1436 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:17.460\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.2010 | Train score: 0.9568 | Val loss: 0.1401 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:18.946\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.2089 | Train score: 0.9444 | Val loss: 0.1394 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:20.508\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1791 | Train score: 0.9259 | Val loss: 0.1408 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:22.037\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.2178 | Train score: 0.9383 | Val loss: 0.1437 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:23.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.2409 | Train score: 0.9383 | Val loss: 0.1468 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:25.184\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1746 | Train score: 0.9444 | Val loss: 0.1491 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:26.695\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1703 | Train score: 0.9506 | Val loss: 0.1503 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:28.363\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1788 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:29.908\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1514 | Train score: 0.9444 | Val loss: 0.1762 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:31.533\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2036 | Train score: 0.9383 | Val loss: 0.1749 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:33.084\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2253 | Train score: 0.9259 | Val loss: 0.1727 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:34.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1794 | Train score: 0.9383 | Val loss: 0.1712 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:36.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1747 | Train score: 0.9259 | Val loss: 0.1718 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:37.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1911 | Train score: 0.9259 | Val loss: 0.1722 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:39.478\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1719 | Train score: 0.9444 | Val loss: 0.1710 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:41.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1497 | Train score: 0.9630 | Val loss: 0.1691 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:42.585\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.2134 | Train score: 0.9383 | Val loss: 0.1679 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:44.171\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1554 | Train score: 0.9444 | Val loss: 0.1665 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:45.793\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1934 | Val score: 0.9158\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:47.425\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2283 | Train score: 0.9321 | Val loss: 0.2030 | Val score: 0.9109\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:49.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1611 | Train score: 0.9691 | Val loss: 0.2043 | Val score: 0.9158\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:50.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2109 | Train score: 0.9444 | Val loss: 0.2031 | Val score: 0.9158\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:52.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.2013 | Train score: 0.9321 | Val loss: 0.2047 | Val score: 0.9158\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:53.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1632 | Train score: 0.9444 | Val loss: 0.2061 | Val score: 0.9158\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:55.389\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1371 | Train score: 0.9630 | Val loss: 0.2098 | Val score: 0.9158\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:56.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1096 | Train score: 0.9815 | Val loss: 0.2142 | Val score: 0.9158\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:58.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1618 | Train score: 0.9444 | Val loss: 0.2214 | Val score: 0.9208\u001b[0m\n",
      "\u001b[32m2024-11-04 12:32:00.437\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1255 | Train score: 0.9630 | Val loss: 0.2343 | Val score: 0.9158\u001b[0m\n",
      "\u001b[32m2024-11-04 12:32:02.074\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1768 | Train score: 0.9568 | Val loss: 0.2391 | Val score: 0.9109\u001b[0m\n",
      "\u001b[32m2024-11-04 12:32:03.720\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1902 | Val score: 0.9257\u001b[0m\n",
      "\u001b[32m2024-11-04 12:32:05.428\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1448 | Train score: 0.9568 | Val loss: 0.2011 | Val score: 0.9257\u001b[0m\n",
      "\u001b[32m2024-11-04 12:32:07.049\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1684 | Train score: 0.9321 | Val loss: 0.1996 | Val score: 0.9257\u001b[0m\n",
      "\u001b[32m2024-11-04 12:32:08.782\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1478 | Train score: 0.9506 | Val loss: 0.1979 | Val score: 0.9257\u001b[0m\n",
      "\u001b[32m2024-11-04 12:32:10.499\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1306 | Train score: 0.9568 | Val loss: 0.1982 | Val score: 0.9257\u001b[0m\n",
      "\u001b[32m2024-11-04 12:32:12.165\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1590 | Train score: 0.9321 | Val loss: 0.1982 | Val score: 0.9307\u001b[0m\n",
      "\u001b[32m2024-11-04 12:32:13.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1620 | Train score: 0.9383 | Val loss: 0.1978 | Val score: 0.9257\u001b[0m\n",
      "\u001b[32m2024-11-04 12:32:15.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1472 | Train score: 0.9506 | Val loss: 0.1977 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 12:32:17.512\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1274 | Train score: 0.9506 | Val loss: 0.2004 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 12:32:19.239\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1484 | Train score: 0.9630 | Val loss: 0.2032 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 12:32:20.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1726 | Train score: 0.9506 | Val loss: 0.2046 | Val score: 0.9356\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " imbalance \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.911         0.000           0.000          0.000         0.00       0.000         0.500        0.000    0.000   0.000         0.000        0.000\n",
      "MedPFNClassifier                      0.907         0.026           0.447          0.277         0.34       0.201         0.869        0.061    0.378   0.219         0.255        0.010\n",
      "MedPFNClassifier                      0.935         0.011           0.851          0.131         0.36       0.174         0.879        0.054    0.469   0.175         1.609        0.026\n",
      "MedPFNClassifier                      0.927         0.018           0.660          0.228         0.40       0.179         0.871        0.055    0.478   0.166        10.763        0.108\n",
      "RandomForestClassifier                0.934         0.011           0.860          0.147         0.31       0.104         0.887        0.043    0.448   0.123         0.250        0.014\n",
      "CatBoostGrid                          0.931         0.009           0.960          0.080         0.25       0.120         0.876        0.059    0.377   0.148        68.022        6.152\n",
      "XGBoostGrid                           0.923         0.011           0.493          0.417         0.20       0.179         0.887        0.040    0.273   0.233        39.759        1.738\n",
      "LogisticRegressionClassifier          0.918         0.019           0.542          0.096         0.63       0.090         0.858        0.064    0.580   0.084         0.008        0.001\n",
      "TabPFNClassifier                      0.929         0.012           0.727          0.189         0.32       0.117         0.900        0.043    0.434   0.141         2.473        0.043\n",
      "TabForestPFNClassifier                0.927         0.019           0.736          0.217         0.37       0.135         0.876        0.058    0.468   0.122        17.733        0.627\n",
      "700 8061\n",
      "(8761, 1391)\n",
      "0.9201004451546627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 12:57:12.036\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1674 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:57:14.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1606 | Train score: 0.9444 | Val loss: 0.1682 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 12:57:16.395\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1432 | Train score: 0.9568 | Val loss: 0.1702 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:57:18.565\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1428 | Train score: 0.9568 | Val loss: 0.1640 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 12:57:20.744\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1925 | Train score: 0.9321 | Val loss: 0.1631 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 12:57:22.979\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1926 | Train score: 0.9259 | Val loss: 0.1607 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 12:57:25.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1583 | Train score: 0.9444 | Val loss: 0.1618 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:57:27.349\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1129 | Train score: 0.9568 | Val loss: 0.1688 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 12:57:29.559\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1991 | Train score: 0.9383 | Val loss: 0.1687 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:57:31.794\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1255 | Train score: 0.9568 | Val loss: 0.1707 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:57:33.979\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.2030 | Train score: 0.9012 | Val loss: 0.1702 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:57:35.996\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1781 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 12:57:38.176\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1898 | Train score: 0.9444 | Val loss: 0.1913 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:57:40.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1957 | Train score: 0.9321 | Val loss: 0.1874 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 12:57:42.659\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1917 | Train score: 0.9321 | Val loss: 0.1796 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:57:44.896\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1667 | Train score: 0.9383 | Val loss: 0.1709 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:57:47.041\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1675 | Train score: 0.9383 | Val loss: 0.1634 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:57:49.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1285 | Train score: 0.9506 | Val loss: 0.1616 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:57:51.392\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1690 | Train score: 0.9321 | Val loss: 0.1626 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:57:53.652\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1350 | Train score: 0.9321 | Val loss: 0.1664 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:57:55.893\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1547 | Train score: 0.9568 | Val loss: 0.1711 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:57:58.177\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0911 | Train score: 0.9630 | Val loss: 0.1785 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:00.221\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1631 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:02.563\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1677 | Train score: 0.9383 | Val loss: 0.1752 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:04.943\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2261 | Train score: 0.9259 | Val loss: 0.1723 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:07.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1770 | Train score: 0.9321 | Val loss: 0.1721 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:09.315\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1337 | Train score: 0.9630 | Val loss: 0.1704 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:11.652\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1804 | Train score: 0.9444 | Val loss: 0.1680 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:14.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1710 | Train score: 0.9321 | Val loss: 0.1651 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:16.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1970 | Train score: 0.9321 | Val loss: 0.1631 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:18.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.2151 | Train score: 0.9321 | Val loss: 0.1604 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:20.956\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.2427 | Train score: 0.9383 | Val loss: 0.1584 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:23.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1958 | Train score: 0.9259 | Val loss: 0.1589 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:25.371\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1617 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:27.697\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1708 | Train score: 0.9321 | Val loss: 0.1608 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:30.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2123 | Train score: 0.9444 | Val loss: 0.1718 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:32.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1583 | Train score: 0.9506 | Val loss: 0.1658 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:35.000\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1686 | Train score: 0.9568 | Val loss: 0.1622 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:37.429\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.2105 | Train score: 0.9259 | Val loss: 0.1622 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:39.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1438 | Train score: 0.9444 | Val loss: 0.1610 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:42.327\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1850 | Train score: 0.9198 | Val loss: 0.1609 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:44.787\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1214 | Train score: 0.9691 | Val loss: 0.1600 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:47.129\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1081 | Train score: 0.9691 | Val loss: 0.1596 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:49.665\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1284 | Train score: 0.9568 | Val loss: 0.1599 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:51.763\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1489 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:54.092\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1315 | Train score: 0.9444 | Val loss: 0.1519 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:56.378\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1381 | Train score: 0.9444 | Val loss: 0.1589 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:58.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1989 | Train score: 0.9444 | Val loss: 0.1565 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:01.250\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1156 | Train score: 0.9444 | Val loss: 0.1595 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:03.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1449 | Train score: 0.9568 | Val loss: 0.1643 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:05.900\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1263 | Train score: 0.9444 | Val loss: 0.1681 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:08.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1354 | Train score: 0.9321 | Val loss: 0.1685 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:10.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1486 | Train score: 0.9630 | Val loss: 0.1707 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:12.888\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1431 | Train score: 0.9198 | Val loss: 0.1691 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:15.259\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1653 | Train score: 0.9383 | Val loss: 0.1658 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:17.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1553 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:19.652\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1717 | Train score: 0.9321 | Val loss: 0.1531 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:21.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1615 | Train score: 0.9568 | Val loss: 0.1526 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:24.229\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1515 | Train score: 0.9321 | Val loss: 0.1564 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:26.495\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1595 | Train score: 0.9444 | Val loss: 0.1539 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:28.800\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1153 | Train score: 0.9753 | Val loss: 0.1543 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:31.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1150 | Train score: 0.9691 | Val loss: 0.1559 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:33.402\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1800 | Train score: 0.9259 | Val loss: 0.1537 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:35.603\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1113 | Train score: 0.9630 | Val loss: 0.1530 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:37.783\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1757 | Train score: 0.9383 | Val loss: 0.1523 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:39.997\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1411 | Train score: 0.9568 | Val loss: 0.1523 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:42.035\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1828 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:44.301\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1516 | Train score: 0.9506 | Val loss: 0.1791 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:46.448\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1522 | Train score: 0.9383 | Val loss: 0.1788 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:48.642\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1314 | Train score: 0.9568 | Val loss: 0.1833 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:50.961\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1066 | Train score: 0.9630 | Val loss: 0.1947 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:53.197\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0888 | Train score: 0.9568 | Val loss: 0.2122 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:55.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1323 | Train score: 0.9568 | Val loss: 0.2224 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:57.739\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1044 | Train score: 0.9444 | Val loss: 0.2418 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:59.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1102 | Train score: 0.9753 | Val loss: 0.2268 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:02.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1380 | Train score: 0.9506 | Val loss: 0.2137 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:04.301\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1623 | Train score: 0.9630 | Val loss: 0.2041 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:06.326\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1351 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:08.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1578 | Train score: 0.9506 | Val loss: 0.1279 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:10.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2004 | Train score: 0.9506 | Val loss: 0.1292 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:13.294\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1660 | Train score: 0.9259 | Val loss: 0.1275 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:15.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1885 | Train score: 0.9383 | Val loss: 0.1263 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:17.817\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1682 | Train score: 0.9506 | Val loss: 0.1277 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:20.056\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1885 | Train score: 0.9383 | Val loss: 0.1289 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:22.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1247 | Train score: 0.9568 | Val loss: 0.1285 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:24.338\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1580 | Train score: 0.9383 | Val loss: 0.1283 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:26.486\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1297 | Train score: 0.9444 | Val loss: 0.1272 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:28.762\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1824 | Train score: 0.9383 | Val loss: 0.1274 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:30.811\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1533 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:33.046\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1378 | Train score: 0.9383 | Val loss: 0.1543 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:35.555\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1563 | Train score: 0.9444 | Val loss: 0.1553 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:37.805\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0973 | Train score: 0.9506 | Val loss: 0.1662 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:40.234\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1482 | Train score: 0.9630 | Val loss: 0.1688 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:42.539\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0957 | Train score: 0.9691 | Val loss: 0.1737 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:44.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1907 | Train score: 0.9444 | Val loss: 0.2683 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:47.150\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1699 | Train score: 0.9630 | Val loss: 0.1663 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:49.409\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1503 | Train score: 0.9568 | Val loss: 0.1674 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:51.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1167 | Train score: 0.9568 | Val loss: 0.1662 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:53.891\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1459 | Train score: 0.9198 | Val loss: 0.1651 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:55.888\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.2049 | Val score: 0.9208\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:58.093\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1997 | Train score: 0.9506 | Val loss: 0.2008 | Val score: 0.9158\u001b[0m\n",
      "\u001b[32m2024-11-04 13:01:00.225\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1439 | Train score: 0.9383 | Val loss: 0.2012 | Val score: 0.9208\u001b[0m\n",
      "\u001b[32m2024-11-04 13:01:02.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1751 | Train score: 0.9444 | Val loss: 0.2056 | Val score: 0.9208\u001b[0m\n",
      "\u001b[32m2024-11-04 13:01:04.588\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1343 | Train score: 0.9691 | Val loss: 0.2100 | Val score: 0.9257\u001b[0m\n",
      "\u001b[32m2024-11-04 13:01:06.721\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1634 | Train score: 0.9444 | Val loss: 0.2158 | Val score: 0.9307\u001b[0m\n",
      "\u001b[32m2024-11-04 13:01:08.860\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1548 | Train score: 0.9383 | Val loss: 0.2213 | Val score: 0.9307\u001b[0m\n",
      "\u001b[32m2024-11-04 13:01:10.980\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1258 | Train score: 0.9630 | Val loss: 0.2280 | Val score: 0.9257\u001b[0m\n",
      "\u001b[32m2024-11-04 13:01:13.162\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1666 | Train score: 0.9444 | Val loss: 0.2373 | Val score: 0.9158\u001b[0m\n",
      "\u001b[32m2024-11-04 13:01:15.370\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0921 | Train score: 0.9630 | Val loss: 0.2537 | Val score: 0.9158\u001b[0m\n",
      "\u001b[32m2024-11-04 13:01:17.527\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0785 | Train score: 0.9753 | Val loss: 0.2687 | Val score: 0.9158\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " imbalance \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.920         0.000           0.000          0.000        0.000       0.000         0.500        0.000    0.000   0.000         0.000        0.000\n",
      "MedPFNClassifier                      0.905         0.013           0.386          0.124        0.311       0.109         0.827        0.082    0.341   0.111         0.266        0.022\n",
      "MedPFNClassifier                      0.924         0.011           0.587          0.224        0.278       0.090         0.851        0.048    0.365   0.105         1.624        0.026\n",
      "MedPFNClassifier                      0.921         0.014           0.541          0.187        0.333       0.122         0.854        0.048    0.396   0.119        10.702        0.479\n",
      "RandomForestClassifier                0.932         0.009           0.801          0.185        0.256       0.087         0.866        0.059    0.369   0.101         0.237        0.009\n",
      "CatBoostGrid                          0.931         0.011           0.760          0.317        0.233       0.153         0.845        0.038    0.324   0.182        82.143        5.790\n",
      "XGBoostGrid                           0.923         0.007           0.250          0.316        0.089       0.130         0.835        0.040    0.129   0.181        50.140        1.597\n",
      "LogisticRegressionClassifier          0.909         0.031           0.472          0.206        0.489       0.124         0.786        0.096    0.474   0.156         0.009        0.001\n",
      "TabPFNClassifier                      0.930         0.010           0.655          0.165        0.322       0.126         0.869        0.061    0.413   0.130         3.223        0.076\n",
      "TabForestPFNClassifier                0.925         0.011           0.557          0.095        0.422       0.109         0.888        0.042    0.470   0.076        24.470        0.777\n",
      "700 9313\n",
      "(10013, 1391)\n",
      "0.9300908818535903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 13:19:59.276\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1598 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:01.523\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1559 | Train score: 0.9568 | Val loss: 0.1595 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:03.595\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1670 | Train score: 0.9506 | Val loss: 0.1530 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:05.644\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1299 | Train score: 0.9691 | Val loss: 0.1494 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:07.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1686 | Train score: 0.9568 | Val loss: 0.1480 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:09.747\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1165 | Train score: 0.9568 | Val loss: 0.1468 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:11.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1286 | Train score: 0.9506 | Val loss: 0.1458 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:13.934\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.2067 | Train score: 0.9506 | Val loss: 0.1445 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:16.009\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1329 | Train score: 0.9568 | Val loss: 0.1439 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:18.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1198 | Train score: 0.9691 | Val loss: 0.1433 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:20.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1408 | Train score: 0.9444 | Val loss: 0.1445 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:22.050\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1617 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:24.372\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1191 | Train score: 0.9383 | Val loss: 0.1601 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:26.757\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1363 | Train score: 0.9630 | Val loss: 0.1650 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:29.001\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1452 | Train score: 0.9444 | Val loss: 0.1641 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:31.233\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1920 | Train score: 0.9444 | Val loss: 0.1585 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:33.511\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1104 | Train score: 0.9691 | Val loss: 0.1573 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:35.747\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0919 | Train score: 0.9630 | Val loss: 0.1574 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:37.930\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1379 | Train score: 0.9444 | Val loss: 0.1579 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:40.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1016 | Train score: 0.9691 | Val loss: 0.1575 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:42.349\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1097 | Train score: 0.9568 | Val loss: 0.1566 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:44.561\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1368 | Train score: 0.9568 | Val loss: 0.1551 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:46.597\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1420 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:48.674\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1251 | Train score: 0.9506 | Val loss: 0.1483 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:50.690\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1017 | Train score: 0.9630 | Val loss: 0.1616 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:52.701\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0920 | Train score: 0.9753 | Val loss: 0.1719 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:54.739\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1097 | Train score: 0.9691 | Val loss: 0.1660 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:56.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1461 | Train score: 0.9444 | Val loss: 0.1528 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:58.770\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0735 | Train score: 0.9877 | Val loss: 0.1484 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:00.847\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1430 | Train score: 0.9444 | Val loss: 0.1415 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:02.882\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1227 | Train score: 0.9630 | Val loss: 0.1372 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:04.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0951 | Train score: 0.9506 | Val loss: 0.1374 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:06.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1159 | Train score: 0.9691 | Val loss: 0.1388 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:08.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1650 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:11.151\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1425 | Train score: 0.9691 | Val loss: 0.1750 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:13.202\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1312 | Train score: 0.9630 | Val loss: 0.1779 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:15.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1793 | Train score: 0.9568 | Val loss: 0.1731 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:17.358\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1063 | Train score: 0.9753 | Val loss: 0.1692 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:19.404\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1684 | Train score: 0.9506 | Val loss: 0.1633 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:21.453\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1487 | Train score: 0.9568 | Val loss: 0.1622 | Val score: 0.9307\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:23.571\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1590 | Train score: 0.9630 | Val loss: 0.1628 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:25.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1189 | Train score: 0.9568 | Val loss: 0.1624 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:27.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0969 | Train score: 0.9753 | Val loss: 0.1622 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:29.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1273 | Train score: 0.9568 | Val loss: 0.1746 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:31.646\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1541 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:33.815\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1197 | Train score: 0.9506 | Val loss: 0.1719 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:35.895\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1198 | Train score: 0.9506 | Val loss: 0.1687 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:38.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1211 | Train score: 0.9753 | Val loss: 0.1607 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:40.033\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1162 | Train score: 0.9753 | Val loss: 0.1528 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:42.130\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1431 | Train score: 0.9568 | Val loss: 0.1473 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:44.176\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1226 | Train score: 0.9753 | Val loss: 0.1455 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:46.218\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0723 | Train score: 0.9877 | Val loss: 0.1459 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:48.277\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1390 | Train score: 0.9568 | Val loss: 0.1479 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:50.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1004 | Train score: 0.9630 | Val loss: 0.1495 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:52.410\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0966 | Train score: 0.9691 | Val loss: 0.1505 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:54.425\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1583 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:56.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1293 | Train score: 0.9630 | Val loss: 0.1556 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:58.950\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0748 | Train score: 0.9815 | Val loss: 0.1617 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:01.168\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0517 | Train score: 0.9815 | Val loss: 0.1689 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:03.377\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1528 | Train score: 0.9568 | Val loss: 0.1634 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:05.512\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0907 | Train score: 0.9753 | Val loss: 0.1663 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:07.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0978 | Train score: 0.9815 | Val loss: 0.1636 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:10.009\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1375 | Train score: 0.9691 | Val loss: 0.1555 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:12.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0813 | Train score: 0.9877 | Val loss: 0.1535 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:14.364\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.2799 | Train score: 0.9568 | Val loss: 0.1520 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:16.532\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1311 | Train score: 0.9506 | Val loss: 0.1470 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:18.463\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1668 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:20.601\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1204 | Train score: 0.9444 | Val loss: 0.1712 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:22.681\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1094 | Train score: 0.9691 | Val loss: 0.1853 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:24.696\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1428 | Train score: 0.9691 | Val loss: 0.1770 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:26.810\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1339 | Train score: 0.9630 | Val loss: 0.1720 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:28.891\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1165 | Train score: 0.9753 | Val loss: 0.1678 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:31.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0932 | Train score: 0.9691 | Val loss: 0.1657 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:33.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1260 | Train score: 0.9568 | Val loss: 0.1650 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:35.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1103 | Train score: 0.9691 | Val loss: 0.1661 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:37.217\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1129 | Train score: 0.9691 | Val loss: 0.1680 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:39.239\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0889 | Train score: 0.9691 | Val loss: 0.1697 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:41.175\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1623 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:43.282\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1211 | Train score: 0.9568 | Val loss: 0.1698 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:45.496\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0877 | Train score: 0.9753 | Val loss: 0.1811 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:47.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0866 | Train score: 0.9753 | Val loss: 0.1837 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:49.864\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0699 | Train score: 0.9877 | Val loss: 0.1800 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:52.030\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1108 | Train score: 0.9691 | Val loss: 0.1699 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:54.284\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1580 | Train score: 0.9568 | Val loss: 0.1598 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:56.496\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0991 | Train score: 0.9691 | Val loss: 0.1553 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:58.597\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1160 | Train score: 0.9691 | Val loss: 0.1528 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:00.763\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1899 | Train score: 0.9506 | Val loss: 0.1500 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:03.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1232 | Train score: 0.9691 | Val loss: 0.1504 | Val score: 0.9505\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 13:23:05.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1357 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:07.286\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1349 | Train score: 0.9630 | Val loss: 0.1325 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:09.402\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1602 | Train score: 0.9444 | Val loss: 0.1301 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:11.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1050 | Train score: 0.9630 | Val loss: 0.1288 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:13.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1252 | Train score: 0.9630 | Val loss: 0.1287 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:16.016\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1584 | Train score: 0.9568 | Val loss: 0.1277 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:18.139\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1053 | Train score: 0.9630 | Val loss: 0.1294 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:20.297\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0896 | Train score: 0.9691 | Val loss: 0.1305 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:22.495\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1184 | Train score: 0.9630 | Val loss: 0.1322 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:24.695\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0782 | Train score: 0.9815 | Val loss: 0.1342 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:26.793\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0798 | Train score: 0.9753 | Val loss: 0.1388 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:28.825\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1140 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:30.982\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1091 | Train score: 0.9691 | Val loss: 0.1100 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:33.103\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1665 | Train score: 0.9630 | Val loss: 0.1107 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:35.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1304 | Train score: 0.9691 | Val loss: 0.1109 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:37.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1547 | Train score: 0.9568 | Val loss: 0.1120 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:39.339\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1202 | Train score: 0.9630 | Val loss: 0.1125 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:41.468\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1199 | Train score: 0.9630 | Val loss: 0.1102 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:43.779\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1409 | Train score: 0.9568 | Val loss: 0.1078 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:46.090\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1557 | Train score: 0.9506 | Val loss: 0.1058 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:48.189\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1059 | Train score: 0.9691 | Val loss: 0.1043 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:50.349\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1656 | Train score: 0.9630 | Val loss: 0.1041 | Val score: 0.9653\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " imbalance \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.938         0.000           0.000          0.000        0.000       0.000         0.500        0.000    0.000   0.000         0.000        0.000\n",
      "MedPFNClassifier                      0.949         0.012           0.617          0.245        0.371       0.171         0.891        0.054    0.458   0.193         0.342        0.010\n",
      "MedPFNClassifier                      0.959         0.013           0.900          0.300        0.357       0.172         0.930        0.045    0.501   0.203         1.968        0.038\n",
      "MedPFNClassifier                      0.955         0.022           0.750          0.316        0.414       0.216         0.928        0.048    0.524   0.241        14.024        0.178\n",
      "RandomForestClassifier                0.960         0.007           1.000          0.000        0.357       0.115         0.883        0.077    0.516   0.128         0.208        0.011\n",
      "CatBoostGrid                          0.957         0.008           1.000          0.000        0.314       0.125         0.914        0.067    0.464   0.152        56.842        6.155\n",
      "XGBoostGrid                           0.947         0.014           0.433          0.473        0.186       0.203         0.916        0.066    0.260   0.284        34.845        2.021\n",
      "LogisticRegressionClassifier          0.936         0.022           0.521          0.266        0.371       0.171         0.801        0.115    0.420   0.184         0.008        0.001\n",
      "TabPFNClassifier                      0.961         0.017           0.833          0.307        0.414       0.225         0.928        0.047    0.539   0.248         3.118        0.062\n",
      "TabForestPFNClassifier                0.948         0.010           0.608          0.247        0.343       0.146         0.899        0.063    0.434   0.174        23.022        0.711\n",
      "686 10761\n",
      "(11447, 1391)\n",
      "0.9400716344893859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 13:41:52.093\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1273 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:41:54.198\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1378 | Train score: 0.9444 | Val loss: 0.1164 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:41:56.380\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1456 | Train score: 0.9506 | Val loss: 0.1171 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:41:58.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1714 | Train score: 0.9444 | Val loss: 0.1157 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:00.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1554 | Train score: 0.9506 | Val loss: 0.1149 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:02.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1326 | Train score: 0.9630 | Val loss: 0.1157 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:05.239\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1146 | Train score: 0.9630 | Val loss: 0.1158 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:07.649\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1146 | Train score: 0.9568 | Val loss: 0.1162 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:09.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1708 | Train score: 0.9383 | Val loss: 0.1148 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:12.089\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1223 | Train score: 0.9568 | Val loss: 0.1142 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:14.217\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1354 | Train score: 0.9568 | Val loss: 0.1138 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:16.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1342 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:18.467\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1615 | Train score: 0.9568 | Val loss: 0.1321 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:20.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1340 | Train score: 0.9506 | Val loss: 0.1338 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:22.884\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1428 | Train score: 0.9383 | Val loss: 0.1321 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:25.036\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1622 | Train score: 0.9444 | Val loss: 0.1299 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:27.186\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1329 | Train score: 0.9568 | Val loss: 0.1273 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:29.336\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1406 | Train score: 0.9568 | Val loss: 0.1263 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:31.500\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1268 | Train score: 0.9506 | Val loss: 0.1257 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:33.641\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1927 | Train score: 0.9444 | Val loss: 0.1268 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:35.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1294 | Train score: 0.9753 | Val loss: 0.1273 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:38.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1297 | Train score: 0.9568 | Val loss: 0.1271 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:40.147\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1579 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:42.317\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1244 | Train score: 0.9506 | Val loss: 0.1660 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:44.466\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1564 | Train score: 0.9383 | Val loss: 0.1550 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:46.642\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0870 | Train score: 0.9753 | Val loss: 0.1604 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:48.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.2071 | Train score: 0.9444 | Val loss: 0.1559 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:50.857\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1435 | Train score: 0.9630 | Val loss: 0.1537 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:52.952\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1340 | Train score: 0.9568 | Val loss: 0.1533 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:55.188\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1259 | Train score: 0.9568 | Val loss: 0.1534 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:57.451\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1080 | Train score: 0.9568 | Val loss: 0.1532 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:59.559\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1182 | Train score: 0.9630 | Val loss: 0.1527 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:01.791\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1521 | Train score: 0.9383 | Val loss: 0.1524 | Val score: 0.9554\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 13:43:03.762\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0794 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:05.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1299 | Train score: 0.9506 | Val loss: 0.0769 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:08.086\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1760 | Train score: 0.9321 | Val loss: 0.0779 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:10.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1654 | Train score: 0.9259 | Val loss: 0.0815 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:12.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1683 | Train score: 0.9444 | Val loss: 0.0953 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:14.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1453 | Train score: 0.9444 | Val loss: 0.0929 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:16.746\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1319 | Train score: 0.9630 | Val loss: 0.0946 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:18.890\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1343 | Train score: 0.9568 | Val loss: 0.0944 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:21.068\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1462 | Train score: 0.9506 | Val loss: 0.0959 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:23.183\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1395 | Train score: 0.9444 | Val loss: 0.0961 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:25.292\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1256 | Train score: 0.9630 | Val loss: 0.0938 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:27.301\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1178 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:29.530\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1609 | Train score: 0.9444 | Val loss: 0.1140 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:31.834\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1587 | Train score: 0.9444 | Val loss: 0.1112 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:34.032\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1069 | Train score: 0.9568 | Val loss: 0.1093 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:36.196\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1323 | Train score: 0.9568 | Val loss: 0.1097 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:38.455\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1353 | Train score: 0.9568 | Val loss: 0.1126 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:40.791\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1185 | Train score: 0.9691 | Val loss: 0.1131 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:42.855\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1560 | Train score: 0.9506 | Val loss: 0.1110 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:44.970\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1676 | Train score: 0.9568 | Val loss: 0.1091 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:47.091\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1327 | Train score: 0.9691 | Val loss: 0.1094 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:49.219\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1135 | Train score: 0.9691 | Val loss: 0.1072 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:51.181\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1421 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:53.359\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1497 | Train score: 0.9383 | Val loss: 0.1462 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:55.527\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1242 | Train score: 0.9568 | Val loss: 0.1473 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:57.755\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0881 | Train score: 0.9630 | Val loss: 0.1489 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:59.973\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1311 | Train score: 0.9568 | Val loss: 0.1449 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:02.128\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1667 | Train score: 0.9444 | Val loss: 0.1368 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:04.295\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1439 | Train score: 0.9444 | Val loss: 0.1346 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:06.514\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1258 | Train score: 0.9568 | Val loss: 0.1345 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:08.655\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1132 | Train score: 0.9506 | Val loss: 0.1348 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:10.847\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1239 | Train score: 0.9383 | Val loss: 0.1373 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:12.957\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1191 | Train score: 0.9630 | Val loss: 0.1393 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:14.900\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1340 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:17.057\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1696 | Train score: 0.9383 | Val loss: 0.1597 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:19.219\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1566 | Train score: 0.9444 | Val loss: 0.1463 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:21.512\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1571 | Train score: 0.9444 | Val loss: 0.1358 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:23.659\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1674 | Train score: 0.9383 | Val loss: 0.1321 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:25.782\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1322 | Train score: 0.9444 | Val loss: 0.1300 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:27.899\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1691 | Train score: 0.9506 | Val loss: 0.1292 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:30.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1419 | Train score: 0.9444 | Val loss: 0.1275 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:32.130\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1401 | Train score: 0.9506 | Val loss: 0.1264 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:34.279\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1020 | Train score: 0.9753 | Val loss: 0.1264 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:36.555\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1702 | Train score: 0.9321 | Val loss: 0.1262 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:38.525\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1161 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:40.700\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1293 | Train score: 0.9568 | Val loss: 0.1141 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:42.771\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1929 | Train score: 0.9506 | Val loss: 0.1164 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:44.995\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1717 | Train score: 0.9383 | Val loss: 0.1187 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:47.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1477 | Train score: 0.9444 | Val loss: 0.1187 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:49.310\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1472 | Train score: 0.9568 | Val loss: 0.1153 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:51.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1364 | Train score: 0.9691 | Val loss: 0.1123 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:53.541\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1037 | Train score: 0.9568 | Val loss: 0.1081 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:55.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1252 | Train score: 0.9753 | Val loss: 0.1049 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:57.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1051 | Train score: 0.9753 | Val loss: 0.0997 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:59.939\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1041 | Train score: 0.9691 | Val loss: 0.1062 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:45:01.890\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1277 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:45:03.990\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1284 | Train score: 0.9568 | Val loss: 0.1293 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:45:06.072\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1531 | Train score: 0.9444 | Val loss: 0.1270 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:45:08.332\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1234 | Train score: 0.9506 | Val loss: 0.1264 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:45:10.511\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1117 | Train score: 0.9753 | Val loss: 0.1263 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:45:12.593\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1300 | Train score: 0.9630 | Val loss: 0.1259 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:45:14.688\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1227 | Train score: 0.9506 | Val loss: 0.1264 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:45:16.767\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1518 | Train score: 0.9691 | Val loss: 0.1263 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:45:18.826\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1080 | Train score: 0.9630 | Val loss: 0.1276 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:45:20.876\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1039 | Train score: 0.9753 | Val loss: 0.1284 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:45:23.196\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1258 | Train score: 0.9630 | Val loss: 0.1290 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:45:25.148\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1250 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:45:27.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1831 | Train score: 0.9444 | Val loss: 0.1166 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:45:29.335\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1506 | Train score: 0.9444 | Val loss: 0.1029 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:45:31.446\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1448 | Train score: 0.9444 | Val loss: 0.0994 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:45:33.561\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1727 | Train score: 0.9506 | Val loss: 0.0981 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:45:35.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1469 | Train score: 0.9630 | Val loss: 0.0960 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:45:37.790\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1822 | Train score: 0.9506 | Val loss: 0.0966 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:45:39.982\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1163 | Train score: 0.9568 | Val loss: 0.0957 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:45:42.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1011 | Train score: 0.9568 | Val loss: 0.0921 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:45:44.217\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1224 | Train score: 0.9568 | Val loss: 0.0897 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:45:46.320\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0929 | Train score: 0.9753 | Val loss: 0.0864 | Val score: 0.9653\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " imbalance \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.946         0.000           0.000          0.000        0.000       0.000         0.500        0.000    0.000   0.000         0.000        0.000\n",
      "MedPFNClassifier                      0.959         0.015           0.742          0.303        0.433       0.335         0.897        0.063    0.464   0.273         0.341        0.011\n",
      "MedPFNClassifier                      0.963         0.019           0.760          0.388        0.400       0.309         0.910        0.059    0.484   0.321         1.957        0.019\n",
      "MedPFNClassifier                      0.957         0.019           0.678          0.372        0.433       0.309         0.905        0.065    0.474   0.286        13.943        0.122\n",
      "RandomForestClassifier                0.959         0.012           0.800          0.400        0.250       0.201         0.910        0.066    0.361   0.247         0.191        0.012\n",
      "CatBoostGrid                          0.949         0.012           0.350          0.436        0.133       0.194         0.919        0.068    0.177   0.239        52.881        7.111\n",
      "XGBoostGrid                           0.957         0.007           0.800          0.400        0.200       0.125         0.891        0.055    0.314   0.184        34.862        2.254\n",
      "LogisticRegressionClassifier          0.949         0.020           0.560          0.202        0.467       0.145         0.774        0.058    0.502   0.163         0.009        0.001\n",
      "TabPFNClassifier                      0.962         0.015           0.860          0.297        0.350       0.263         0.921        0.050    0.448   0.271         3.179        0.077\n",
      "TabForestPFNClassifier                0.960         0.015           0.680          0.371        0.383       0.259         0.890        0.084    0.458   0.283        23.344        0.305\n",
      "566 10761\n",
      "(11327, 1391)\n",
      "0.9500308996203761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 14:04:08.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0783 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:10.457\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1395 | Train score: 0.9506 | Val loss: 0.0822 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:12.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1387 | Train score: 0.9630 | Val loss: 0.0854 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:14.806\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1734 | Train score: 0.9568 | Val loss: 0.0951 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:16.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1208 | Train score: 0.9691 | Val loss: 0.0900 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:19.103\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1255 | Train score: 0.9506 | Val loss: 0.0861 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:21.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1259 | Train score: 0.9691 | Val loss: 0.0841 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:23.652\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0883 | Train score: 0.9691 | Val loss: 0.0816 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:25.789\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1225 | Train score: 0.9630 | Val loss: 0.0810 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:27.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.2077 | Train score: 0.9383 | Val loss: 0.0825 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:30.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0850 | Train score: 0.9691 | Val loss: 0.0834 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:32.086\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1300 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:34.332\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0796 | Train score: 0.9753 | Val loss: 0.1364 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:36.664\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1612 | Train score: 0.9630 | Val loss: 0.1284 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:39.056\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1047 | Train score: 0.9753 | Val loss: 0.1249 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:41.472\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0843 | Train score: 0.9815 | Val loss: 0.1235 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:43.773\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0700 | Train score: 0.9630 | Val loss: 0.1240 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:46.036\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1064 | Train score: 0.9691 | Val loss: 0.1240 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:48.244\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1144 | Train score: 0.9630 | Val loss: 0.1234 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:50.500\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0818 | Train score: 0.9691 | Val loss: 0.1233 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:52.713\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1344 | Train score: 0.9568 | Val loss: 0.1233 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:54.942\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0526 | Train score: 0.9753 | Val loss: 0.1242 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:56.969\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1036 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:59.159\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1012 | Train score: 0.9568 | Val loss: 0.0980 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:01.399\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0849 | Train score: 0.9753 | Val loss: 0.1000 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:03.600\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1354 | Train score: 0.9568 | Val loss: 0.0996 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:05.814\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0941 | Train score: 0.9630 | Val loss: 0.0978 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:08.051\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0944 | Train score: 0.9506 | Val loss: 0.0960 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:10.226\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0989 | Train score: 0.9630 | Val loss: 0.0923 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:12.448\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1024 | Train score: 0.9691 | Val loss: 0.0896 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:14.625\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0821 | Train score: 0.9753 | Val loss: 0.0880 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:16.807\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1238 | Train score: 0.9568 | Val loss: 0.0869 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:19.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0771 | Train score: 0.9753 | Val loss: 0.0864 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:21.078\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1154 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:23.276\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1002 | Train score: 0.9506 | Val loss: 0.1328 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:25.447\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0673 | Train score: 0.9630 | Val loss: 0.1535 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:27.588\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1071 | Train score: 0.9691 | Val loss: 0.1447 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:29.714\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0748 | Train score: 0.9691 | Val loss: 0.1389 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:32.009\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1077 | Train score: 0.9568 | Val loss: 0.1299 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:34.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0674 | Train score: 0.9815 | Val loss: 0.1260 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:36.280\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1026 | Train score: 0.9753 | Val loss: 0.1196 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:38.459\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1216 | Train score: 0.9630 | Val loss: 0.1147 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:40.600\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0547 | Train score: 0.9815 | Val loss: 0.1142 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:42.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0873 | Train score: 0.9691 | Val loss: 0.1148 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:44.788\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1273 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:47.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0843 | Train score: 0.9691 | Val loss: 0.1401 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:49.451\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1420 | Train score: 0.9630 | Val loss: 0.1291 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:51.590\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1042 | Train score: 0.9568 | Val loss: 0.1256 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:53.957\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0794 | Train score: 0.9691 | Val loss: 0.1290 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:56.138\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0581 | Train score: 0.9753 | Val loss: 0.1353 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:58.322\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0611 | Train score: 0.9753 | Val loss: 0.1400 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:00.487\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0595 | Train score: 0.9753 | Val loss: 0.1433 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:02.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1087 | Train score: 0.9815 | Val loss: 0.1315 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:04.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0902 | Train score: 0.9568 | Val loss: 0.1298 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:06.898\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1207 | Train score: 0.9753 | Val loss: 0.1261 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:08.907\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1397 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:11.269\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1587 | Train score: 0.9321 | Val loss: 0.1308 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:13.678\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1370 | Train score: 0.9506 | Val loss: 0.1299 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:15.982\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1277 | Train score: 0.9506 | Val loss: 0.1285 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:18.299\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0944 | Train score: 0.9691 | Val loss: 0.1287 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:20.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1007 | Train score: 0.9568 | Val loss: 0.1319 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:22.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0882 | Train score: 0.9691 | Val loss: 0.1393 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:25.206\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1688 | Train score: 0.9568 | Val loss: 0.1361 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:27.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0964 | Train score: 0.9753 | Val loss: 0.1336 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:29.982\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1068 | Train score: 0.9630 | Val loss: 0.1314 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:32.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0837 | Train score: 0.9691 | Val loss: 0.1307 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:34.438\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1435 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:36.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0972 | Train score: 0.9691 | Val loss: 0.1553 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:38.771\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0868 | Train score: 0.9753 | Val loss: 0.1545 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:40.933\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1187 | Train score: 0.9506 | Val loss: 0.1514 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:43.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1383 | Train score: 0.9691 | Val loss: 0.1477 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:45.297\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1544 | Train score: 0.9630 | Val loss: 0.1449 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:47.398\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0913 | Train score: 0.9753 | Val loss: 0.1440 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:49.521\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1104 | Train score: 0.9753 | Val loss: 0.1415 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:51.681\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1020 | Train score: 0.9753 | Val loss: 0.1419 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:53.766\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0859 | Train score: 0.9691 | Val loss: 0.1416 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:55.859\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0755 | Train score: 0.9691 | Val loss: 0.1430 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:57.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0943 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:59.952\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1061 | Train score: 0.9630 | Val loss: 0.0895 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:02.092\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0893 | Train score: 0.9630 | Val loss: 0.0920 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:04.341\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1079 | Train score: 0.9691 | Val loss: 0.0914 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:06.469\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0550 | Train score: 0.9815 | Val loss: 0.0921 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:08.736\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0765 | Train score: 0.9691 | Val loss: 0.0932 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:10.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0569 | Train score: 0.9815 | Val loss: 0.0943 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:12.837\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1406 | Train score: 0.9753 | Val loss: 0.0920 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:15.042\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0509 | Train score: 0.9753 | Val loss: 0.0904 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:17.363\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0614 | Train score: 0.9630 | Val loss: 0.0908 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:19.494\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0931 | Train score: 0.9753 | Val loss: 0.0914 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:21.486\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1249 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:23.692\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0926 | Train score: 0.9506 | Val loss: 0.1332 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:25.817\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1160 | Train score: 0.9568 | Val loss: 0.1258 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:28.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0822 | Train score: 0.9753 | Val loss: 0.1219 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:30.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0738 | Train score: 0.9630 | Val loss: 0.1204 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:32.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0896 | Train score: 0.9630 | Val loss: 0.1193 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:34.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0812 | Train score: 0.9753 | Val loss: 0.1201 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:36.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1177 | Train score: 0.9630 | Val loss: 0.1201 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:38.870\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1103 | Train score: 0.9691 | Val loss: 0.1176 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:41.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1092 | Train score: 0.9506 | Val loss: 0.1149 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:43.249\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0788 | Train score: 0.9753 | Val loss: 0.1131 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:45.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1619 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:47.593\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0977 | Train score: 0.9506 | Val loss: 0.1483 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:49.673\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1243 | Train score: 0.9568 | Val loss: 0.1462 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:51.879\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1117 | Train score: 0.9506 | Val loss: 0.1497 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:54.118\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1547 | Train score: 0.9506 | Val loss: 0.1430 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:56.301\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0963 | Train score: 0.9568 | Val loss: 0.1449 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:58.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1368 | Train score: 0.9568 | Val loss: 0.1460 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:08:00.802\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1286 | Train score: 0.9568 | Val loss: 0.1475 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:08:02.929\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0873 | Train score: 0.9691 | Val loss: 0.1506 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:08:04.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1029 | Train score: 0.9568 | Val loss: 0.1541 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:08:07.175\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0756 | Train score: 0.9753 | Val loss: 0.1591 | Val score: 0.9653\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " imbalance \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.955         0.000           0.000          0.000         0.00       0.000         0.500        0.000    0.000   0.000         0.000        0.000\n",
      "MedPFNClassifier                      0.951         0.008           0.447          0.324         0.20       0.126         0.839        0.094    0.254   0.136         0.338        0.010\n",
      "MedPFNClassifier                      0.962         0.011           0.713          0.335         0.32       0.133         0.881        0.095    0.418   0.165         1.986        0.051\n",
      "MedPFNClassifier                      0.956         0.015           0.520          0.288         0.36       0.174         0.876        0.096    0.414   0.210        14.229        0.236\n",
      "RandomForestClassifier                0.960         0.007           0.625          0.375         0.24       0.174         0.854        0.105    0.317   0.189         0.184        0.007\n",
      "CatBoostGrid                          0.962         0.008           0.733          0.318         0.30       0.134         0.883        0.098    0.403   0.160        55.086        2.911\n",
      "XGBoostGrid                           0.962         0.011           0.625          0.407         0.28       0.160         0.870        0.121    0.373   0.217        34.335        0.940\n",
      "LogisticRegressionClassifier          0.937         0.010           0.297          0.096         0.30       0.100         0.733        0.133    0.297   0.097         0.009        0.001\n",
      "TabPFNClassifier                      0.960         0.010           0.700          0.332         0.26       0.128         0.879        0.085    0.360   0.157         3.216        0.071\n",
      "TabForestPFNClassifier                0.961         0.018           0.678          0.334         0.38       0.140         0.851        0.096    0.478   0.193        23.812        0.608\n",
      "448 10761\n",
      "(11209, 1391)\n",
      "0.9600321170488001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 14:31:30.285\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1190 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:31:32.397\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1127 | Train score: 0.9630 | Val loss: 0.1217 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:31:34.492\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0810 | Train score: 0.9630 | Val loss: 0.1250 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:31:36.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1205 | Train score: 0.9630 | Val loss: 0.1239 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:31:38.712\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1091 | Train score: 0.9630 | Val loss: 0.1223 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:31:40.817\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1076 | Train score: 0.9815 | Val loss: 0.1199 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:31:42.874\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1025 | Train score: 0.9753 | Val loss: 0.1171 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:31:45.054\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0973 | Train score: 0.9815 | Val loss: 0.1180 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:31:47.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0949 | Train score: 0.9877 | Val loss: 0.1197 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:31:49.164\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1242 | Train score: 0.9630 | Val loss: 0.1202 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:31:51.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1080 | Train score: 0.9691 | Val loss: 0.1206 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:31:53.289\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0973 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:31:55.394\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1248 | Train score: 0.9630 | Val loss: 0.0785 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:31:57.519\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0971 | Train score: 0.9630 | Val loss: 0.0707 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:31:59.631\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0730 | Train score: 0.9691 | Val loss: 0.0733 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:01.827\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0743 | Train score: 0.9691 | Val loss: 0.0752 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:03.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0411 | Train score: 0.9815 | Val loss: 0.0818 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:06.162\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0928 | Train score: 0.9753 | Val loss: 0.0779 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:08.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1381 | Train score: 0.9630 | Val loss: 0.0754 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:10.390\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0977 | Train score: 0.9753 | Val loss: 0.0732 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:12.553\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1198 | Train score: 0.9630 | Val loss: 0.1022 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:14.635\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1414 | Train score: 0.9753 | Val loss: 0.0673 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:16.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1113 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:18.680\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1212 | Train score: 0.9630 | Val loss: 0.1052 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:20.893\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1258 | Train score: 0.9691 | Val loss: 0.1059 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:23.151\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0934 | Train score: 0.9691 | Val loss: 0.1064 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:25.427\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1259 | Train score: 0.9506 | Val loss: 0.1081 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:27.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1238 | Train score: 0.9753 | Val loss: 0.1140 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:29.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1113 | Train score: 0.9383 | Val loss: 0.1100 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:32.196\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0591 | Train score: 0.9877 | Val loss: 0.1094 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:34.279\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1140 | Train score: 0.9753 | Val loss: 0.1102 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:36.600\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0818 | Train score: 0.9815 | Val loss: 0.1128 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:38.946\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1201 | Train score: 0.9691 | Val loss: 0.1139 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:41.011\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1229 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:43.278\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1132 | Train score: 0.9568 | Val loss: 0.1244 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:45.427\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1099 | Train score: 0.9691 | Val loss: 0.1239 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:47.544\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1287 | Train score: 0.9691 | Val loss: 0.1232 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:49.672\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1273 | Train score: 0.9691 | Val loss: 0.1225 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:51.740\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1431 | Train score: 0.9630 | Val loss: 0.1220 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:53.797\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1245 | Train score: 0.9568 | Val loss: 0.1190 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:55.878\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1057 | Train score: 0.9753 | Val loss: 0.1150 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:57.952\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0889 | Train score: 0.9815 | Val loss: 0.1122 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:00.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1128 | Train score: 0.9691 | Val loss: 0.1115 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:02.163\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1110 | Train score: 0.9753 | Val loss: 0.1118 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:04.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1067 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:06.328\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1350 | Train score: 0.9568 | Val loss: 0.1150 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:08.519\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1291 | Train score: 0.9630 | Val loss: 0.1135 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:10.773\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1284 | Train score: 0.9630 | Val loss: 0.1071 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:13.014\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0886 | Train score: 0.9630 | Val loss: 0.1015 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:15.263\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1620 | Train score: 0.9383 | Val loss: 0.1021 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:17.494\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1612 | Train score: 0.9568 | Val loss: 0.1030 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:19.709\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1076 | Train score: 0.9691 | Val loss: 0.1041 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:21.917\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0778 | Train score: 0.9691 | Val loss: 0.1055 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:24.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0997 | Train score: 0.9630 | Val loss: 0.1072 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:26.331\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1518 | Train score: 0.9630 | Val loss: 0.1101 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:28.332\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1118 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:30.548\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1021 | Train score: 0.9691 | Val loss: 0.1102 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:32.700\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0874 | Train score: 0.9691 | Val loss: 0.1156 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:34.778\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0962 | Train score: 0.9630 | Val loss: 0.1184 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:36.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0667 | Train score: 0.9815 | Val loss: 0.1188 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:38.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0632 | Train score: 0.9815 | Val loss: 0.1219 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:40.928\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0855 | Train score: 0.9691 | Val loss: 0.1245 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:43.049\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1128 | Train score: 0.9815 | Val loss: 0.1209 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:45.172\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1112 | Train score: 0.9691 | Val loss: 0.1170 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:47.327\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0764 | Train score: 0.9753 | Val loss: 0.1137 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:49.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1542 | Train score: 0.9630 | Val loss: 0.1094 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:52.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1189 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:54.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1094 | Train score: 0.9630 | Val loss: 0.1167 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:56.555\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1165 | Train score: 0.9691 | Val loss: 0.1136 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:58.675\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0927 | Train score: 0.9630 | Val loss: 0.1150 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:00.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1172 | Train score: 0.9630 | Val loss: 0.1137 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:03.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0756 | Train score: 0.9568 | Val loss: 0.1143 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:05.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0976 | Train score: 0.9568 | Val loss: 0.1146 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:07.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0496 | Train score: 0.9753 | Val loss: 0.1148 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:09.587\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1131 | Train score: 0.9568 | Val loss: 0.1156 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:11.825\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1048 | Train score: 0.9691 | Val loss: 0.1166 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:14.042\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0662 | Train score: 0.9753 | Val loss: 0.1203 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:16.036\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1070 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:18.171\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1106 | Train score: 0.9630 | Val loss: 0.1080 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:20.429\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1063 | Train score: 0.9506 | Val loss: 0.1078 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:22.533\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1009 | Train score: 0.9691 | Val loss: 0.1063 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:24.636\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1001 | Train score: 0.9630 | Val loss: 0.1050 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:26.880\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1052 | Train score: 0.9630 | Val loss: 0.1039 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:29.101\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1053 | Train score: 0.9630 | Val loss: 0.1022 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:31.384\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0576 | Train score: 0.9753 | Val loss: 0.1007 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:33.533\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0896 | Train score: 0.9691 | Val loss: 0.1003 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:35.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0997 | Train score: 0.9630 | Val loss: 0.1007 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:37.940\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1012 | Train score: 0.9568 | Val loss: 0.1002 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:39.918\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1053 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:42.169\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1156 | Train score: 0.9630 | Val loss: 0.1088 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:44.520\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1127 | Train score: 0.9630 | Val loss: 0.0993 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:46.878\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1336 | Train score: 0.9630 | Val loss: 0.0960 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:49.092\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1058 | Train score: 0.9691 | Val loss: 0.0961 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:51.429\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1289 | Train score: 0.9691 | Val loss: 0.0955 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:53.795\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0898 | Train score: 0.9630 | Val loss: 0.0888 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:56.187\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1059 | Train score: 0.9630 | Val loss: 0.0888 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:58.580\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0758 | Train score: 0.9815 | Val loss: 0.0895 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:35:01.012\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1237 | Train score: 0.9568 | Val loss: 0.0907 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:35:03.193\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0996 | Train score: 0.9691 | Val loss: 0.0914 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:35:05.204\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1039 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:35:07.387\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1358 | Train score: 0.9630 | Val loss: 0.1006 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:35:09.584\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0859 | Train score: 0.9691 | Val loss: 0.0985 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:35:11.769\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0955 | Train score: 0.9753 | Val loss: 0.0998 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:35:13.988\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1281 | Train score: 0.9630 | Val loss: 0.1000 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:35:16.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0786 | Train score: 0.9753 | Val loss: 0.1003 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:35:18.345\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0581 | Train score: 0.9753 | Val loss: 0.1012 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:35:20.532\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1470 | Train score: 0.9568 | Val loss: 0.1011 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:35:22.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0639 | Train score: 0.9815 | Val loss: 0.1015 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:35:24.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.2533 | Train score: 0.9630 | Val loss: 0.1001 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:35:27.021\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0850 | Train score: 0.9753 | Val loss: 0.1003 | Val score: 0.9703\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " imbalance \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.964         0.000            0.00          0.000        0.000       0.000         0.500        0.000    0.000   0.000         0.000        0.000\n",
      "MedPFNClassifier                      0.962         0.004            0.10          0.200        0.050       0.100         0.746        0.199    0.067   0.133         0.344        0.010\n",
      "MedPFNClassifier                      0.969         0.004            0.50          0.500        0.125       0.125         0.761        0.194    0.200   0.200         1.959        0.031\n",
      "MedPFNClassifier                      0.969         0.006            0.50          0.447        0.175       0.160         0.758        0.202    0.253   0.225        14.170        0.189\n",
      "RandomForestClassifier                0.966         0.004            0.30          0.400        0.100       0.122         0.769        0.160    0.147   0.181         0.228        0.020\n",
      "CatBoostGrid                          0.962         0.004            0.00          0.000        0.000       0.000         0.755        0.176    0.000   0.000        80.081        8.472\n",
      "XGBoostGrid                           0.967         0.004            0.45          0.415        0.150       0.122         0.742        0.152    0.220   0.181        39.499        1.958\n",
      "LogisticRegressionClassifier          0.951         0.013            0.30          0.176        0.250       0.158         0.618        0.194    0.269   0.160         0.009        0.001\n",
      "TabPFNClassifier                      0.965         0.006            0.30          0.458        0.075       0.115         0.800        0.135    0.120   0.183         3.206        0.066\n",
      "TabForestPFNClassifier                0.965         0.009            0.45          0.472        0.150       0.166         0.778        0.125    0.220   0.235        23.517        0.672\n",
      "332 10761\n",
      "(11093, 1391)\n",
      "0.970071216082214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 14:58:00.418\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0457 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:02.622\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0795 | Train score: 0.9691 | Val loss: 0.0437 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:04.895\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0696 | Train score: 0.9691 | Val loss: 0.0401 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:07.128\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0962 | Train score: 0.9753 | Val loss: 0.0395 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:09.361\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0595 | Train score: 0.9753 | Val loss: 0.0390 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:11.773\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0434 | Train score: 0.9815 | Val loss: 0.0378 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:13.900\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0599 | Train score: 0.9630 | Val loss: 0.0364 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:16.038\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0800 | Train score: 0.9691 | Val loss: 0.0358 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:18.151\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0574 | Train score: 0.9815 | Val loss: 0.0349 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:20.372\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0690 | Train score: 0.9691 | Val loss: 0.0345 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:22.525\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0889 | Train score: 0.9506 | Val loss: 0.0342 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:24.513\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0514 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:26.589\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0731 | Train score: 0.9691 | Val loss: 0.0466 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:28.779\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0553 | Train score: 0.9753 | Val loss: 0.0456 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:31.013\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0434 | Train score: 0.9815 | Val loss: 0.0445 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:33.282\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1085 | Train score: 0.9691 | Val loss: 0.0439 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:35.524\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0930 | Train score: 0.9691 | Val loss: 0.0429 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:37.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0885 | Train score: 0.9691 | Val loss: 0.0427 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:39.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0458 | Train score: 0.9877 | Val loss: 0.0435 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:41.936\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0774 | Train score: 0.9815 | Val loss: 0.0444 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:44.168\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0673 | Train score: 0.9691 | Val loss: 0.0451 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:46.322\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0651 | Train score: 0.9753 | Val loss: 0.0455 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:48.324\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0625 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:50.599\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0891 | Train score: 0.9691 | Val loss: 0.0504 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:52.747\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0812 | Train score: 0.9753 | Val loss: 0.0499 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:54.987\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0708 | Train score: 0.9815 | Val loss: 0.0491 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:57.166\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0553 | Train score: 0.9691 | Val loss: 0.0474 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:59.491\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0666 | Train score: 0.9877 | Val loss: 0.0457 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:01.775\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0431 | Train score: 0.9815 | Val loss: 0.0436 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:03.991\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0327 | Train score: 0.9877 | Val loss: 0.0428 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:06.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0779 | Train score: 0.9815 | Val loss: 0.0401 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:08.570\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1018 | Train score: 0.9691 | Val loss: 0.0407 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:10.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0863 | Train score: 0.9691 | Val loss: 0.0431 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:12.862\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0510 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:15.144\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0900 | Train score: 0.9691 | Val loss: 0.0449 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:17.488\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0611 | Train score: 0.9691 | Val loss: 0.0395 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:19.678\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0761 | Train score: 0.9753 | Val loss: 0.0366 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:21.967\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0506 | Train score: 0.9691 | Val loss: 0.0342 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:24.302\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1357 | Train score: 0.9691 | Val loss: 0.0340 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:26.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1121 | Train score: 0.9691 | Val loss: 0.0350 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:28.825\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0802 | Train score: 0.9691 | Val loss: 0.0362 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:30.951\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0664 | Train score: 0.9691 | Val loss: 0.0364 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:33.218\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0782 | Train score: 0.9815 | Val loss: 0.0364 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:35.521\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0549 | Train score: 0.9691 | Val loss: 0.0354 | Val score: 0.9851\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 14:59:37.539\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0831 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:39.694\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0944 | Train score: 0.9691 | Val loss: 0.0730 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:41.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0900 | Train score: 0.9691 | Val loss: 0.0693 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:44.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1300 | Train score: 0.9630 | Val loss: 0.0728 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:46.250\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1036 | Train score: 0.9691 | Val loss: 0.0770 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:48.583\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0776 | Train score: 0.9691 | Val loss: 0.0744 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:50.785\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0690 | Train score: 0.9691 | Val loss: 0.0694 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:53.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0743 | Train score: 0.9815 | Val loss: 0.0657 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:55.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0751 | Train score: 0.9691 | Val loss: 0.0641 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:57.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0691 | Train score: 0.9630 | Val loss: 0.0642 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:59.697\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0587 | Train score: 0.9815 | Val loss: 0.0654 | Val score: 0.9653\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 15:00:01.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0511 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:03.939\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1223 | Train score: 0.9630 | Val loss: 0.0559 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:06.370\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0768 | Train score: 0.9691 | Val loss: 0.0470 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:08.714\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0694 | Train score: 0.9691 | Val loss: 0.0409 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:10.860\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0944 | Train score: 0.9691 | Val loss: 0.0390 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:13.040\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1548 | Train score: 0.9691 | Val loss: 0.0406 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:15.203\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0694 | Train score: 0.9691 | Val loss: 0.0416 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:17.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0568 | Train score: 0.9753 | Val loss: 0.0418 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:19.590\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0524 | Train score: 0.9877 | Val loss: 0.0408 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:21.757\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0653 | Train score: 0.9815 | Val loss: 0.0394 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:23.977\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0940 | Train score: 0.9691 | Val loss: 0.0405 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:26.017\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0777 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:28.154\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0712 | Train score: 0.9753 | Val loss: 0.0723 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:30.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0548 | Train score: 0.9691 | Val loss: 0.0716 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:32.370\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0775 | Train score: 0.9630 | Val loss: 0.0673 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:34.487\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0721 | Train score: 0.9877 | Val loss: 0.0639 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:36.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0759 | Train score: 0.9753 | Val loss: 0.0620 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:38.814\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0457 | Train score: 0.9753 | Val loss: 0.0613 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:41.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0582 | Train score: 0.9815 | Val loss: 0.0613 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:43.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0499 | Train score: 0.9753 | Val loss: 0.0613 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:45.376\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0549 | Train score: 0.9753 | Val loss: 0.0610 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:47.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0739 | Train score: 0.9815 | Val loss: 0.0604 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:49.630\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0722 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:51.817\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0986 | Train score: 0.9691 | Val loss: 0.0729 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:54.078\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0881 | Train score: 0.9630 | Val loss: 0.0717 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:56.285\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0931 | Train score: 0.9691 | Val loss: 0.0710 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:58.503\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0642 | Train score: 0.9877 | Val loss: 0.0712 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:00.633\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0723 | Train score: 0.9753 | Val loss: 0.0727 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:02.858\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0734 | Train score: 0.9815 | Val loss: 0.0742 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:04.975\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0504 | Train score: 0.9815 | Val loss: 0.0758 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:07.227\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0582 | Train score: 0.9753 | Val loss: 0.0773 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:09.462\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0428 | Train score: 0.9753 | Val loss: 0.0795 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:11.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0854 | Train score: 0.9691 | Val loss: 0.0781 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:13.625\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0519 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:15.751\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0778 | Train score: 0.9815 | Val loss: 0.0551 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:17.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1370 | Train score: 0.9691 | Val loss: 0.0590 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:20.015\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0610 | Train score: 0.9753 | Val loss: 0.0578 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:22.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0676 | Train score: 0.9753 | Val loss: 0.0523 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:24.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0593 | Train score: 0.9753 | Val loss: 0.0486 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:26.426\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0731 | Train score: 0.9691 | Val loss: 0.0477 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:28.562\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0608 | Train score: 0.9691 | Val loss: 0.0470 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:30.718\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0498 | Train score: 0.9877 | Val loss: 0.0467 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:32.889\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0513 | Train score: 0.9753 | Val loss: 0.0471 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:35.007\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0623 | Train score: 0.9691 | Val loss: 0.0479 | Val score: 0.9752\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 15:01:37.040\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0403 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:39.250\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0990 | Train score: 0.9691 | Val loss: 0.0437 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:41.498\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1388 | Train score: 0.9630 | Val loss: 0.0477 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:43.697\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0735 | Train score: 0.9753 | Val loss: 0.0494 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:45.901\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0600 | Train score: 0.9691 | Val loss: 0.0497 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:48.221\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0616 | Train score: 0.9753 | Val loss: 0.0488 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:50.391\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0723 | Train score: 0.9753 | Val loss: 0.0468 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:52.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0555 | Train score: 0.9753 | Val loss: 0.0443 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:54.755\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0869 | Train score: 0.9815 | Val loss: 0.0425 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:56.972\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0520 | Train score: 0.9753 | Val loss: 0.0402 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:59.196\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0696 | Train score: 0.9753 | Val loss: 0.0380 | Val score: 0.9901\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " imbalance \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.973         0.000           0.000          0.000        0.000       0.000         0.500        0.000    0.000   0.000         0.000        0.000\n",
      "MedPFNClassifier                      0.972         0.009           0.450          0.400        0.233       0.153         0.890        0.075    0.287   0.202         0.352        0.005\n",
      "MedPFNClassifier                      0.973         0.006           0.300          0.400        0.133       0.163         0.925        0.080    0.180   0.223         1.984        0.060\n",
      "MedPFNClassifier                      0.973         0.006           0.300          0.400        0.133       0.163         0.928        0.079    0.180   0.223        14.227        0.242\n",
      "RandomForestClassifier                0.973         0.000           0.000          0.000        0.000       0.000         0.898        0.104    0.000   0.000         0.206        0.015\n",
      "CatBoostGrid                          0.973         0.000           0.000          0.000        0.000       0.000         0.909        0.117    0.000   0.000        79.324        9.699\n",
      "XGBoostGrid                           0.971         0.004           0.000          0.000        0.000       0.000         0.904        0.114    0.000   0.000        35.243        1.744\n",
      "LogisticRegressionClassifier          0.973         0.009           0.517          0.425        0.233       0.153         0.809        0.124    0.307   0.210         0.008        0.001\n",
      "TabPFNClassifier                      0.973         0.006           0.200          0.400        0.067       0.133         0.938        0.086    0.100   0.200         3.173        0.073\n",
      "TabForestPFNClassifier                0.974         0.009           0.327          0.352        0.300       0.348         0.923        0.086    0.302   0.325        23.804        0.375\n",
      "219 10761\n",
      "(10980, 1391)\n",
      "0.9800546448087432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 15:23:09.327\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0862 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:23:11.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0569 | Train score: 0.9815 | Val loss: 0.0876 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:23:13.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0700 | Train score: 0.9753 | Val loss: 0.0832 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:23:16.306\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0440 | Train score: 0.9815 | Val loss: 0.0833 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:23:18.497\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0368 | Train score: 0.9877 | Val loss: 0.0897 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:23:20.651\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0450 | Train score: 0.9815 | Val loss: 0.1027 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:23:22.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0399 | Train score: 0.9815 | Val loss: 0.1032 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:23:25.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0387 | Train score: 0.9691 | Val loss: 0.1037 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:23:27.364\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0307 | Train score: 0.9815 | Val loss: 0.1034 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:23:29.681\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0312 | Train score: 0.9877 | Val loss: 0.1035 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:23:31.801\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0202 | Train score: 0.9938 | Val loss: 0.1071 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:23:33.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0788 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:23:36.034\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0586 | Train score: 0.9815 | Val loss: 0.0799 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:23:38.360\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0442 | Train score: 0.9815 | Val loss: 0.0866 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:23:40.536\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0489 | Train score: 0.9815 | Val loss: 0.0864 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:23:42.695\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0488 | Train score: 0.9938 | Val loss: 0.0838 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:23:44.848\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0507 | Train score: 0.9753 | Val loss: 0.0800 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:23:47.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0350 | Train score: 0.9877 | Val loss: 0.0792 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:23:49.313\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0360 | Train score: 0.9938 | Val loss: 0.0804 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:23:51.475\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0429 | Train score: 0.9815 | Val loss: 0.0807 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:23:53.594\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0885 | Train score: 0.9877 | Val loss: 0.0772 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:23:55.904\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0279 | Train score: 0.9938 | Val loss: 0.0752 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:23:57.905\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0653 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:00.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0638 | Train score: 0.9815 | Val loss: 0.0663 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:02.385\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0574 | Train score: 0.9815 | Val loss: 0.0672 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:04.526\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0363 | Train score: 0.9815 | Val loss: 0.0714 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:06.738\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0245 | Train score: 0.9938 | Val loss: 0.0790 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:09.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0475 | Train score: 0.9877 | Val loss: 0.0845 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:11.224\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0970 | Train score: 0.9753 | Val loss: 0.0828 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:13.392\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0270 | Train score: 0.9815 | Val loss: 0.0823 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:15.569\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1258 | Train score: 0.9815 | Val loss: 0.0816 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:17.755\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0454 | Train score: 0.9815 | Val loss: 0.0794 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:19.912\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0166 | Train score: 0.9938 | Val loss: 0.0778 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:21.925\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0786 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:24.160\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0610 | Train score: 0.9815 | Val loss: 0.0746 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:26.466\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0599 | Train score: 0.9815 | Val loss: 0.0731 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:28.694\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0497 | Train score: 0.9815 | Val loss: 0.0760 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:30.996\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0400 | Train score: 0.9815 | Val loss: 0.0815 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:33.243\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0335 | Train score: 0.9753 | Val loss: 0.0859 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:35.547\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0428 | Train score: 0.9815 | Val loss: 0.0841 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:37.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0534 | Train score: 0.9753 | Val loss: 0.0775 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:40.092\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0546 | Train score: 0.9815 | Val loss: 0.0685 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:42.400\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0420 | Train score: 0.9877 | Val loss: 0.0706 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:44.657\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0622 | Train score: 0.9815 | Val loss: 0.0642 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:46.659\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0695 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:49.016\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0665 | Train score: 0.9815 | Val loss: 0.0643 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:51.375\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0802 | Train score: 0.9815 | Val loss: 0.0637 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:53.736\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0577 | Train score: 0.9815 | Val loss: 0.0621 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:56.145\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0553 | Train score: 0.9815 | Val loss: 0.0594 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:58.443\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0495 | Train score: 0.9815 | Val loss: 0.0568 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:00.750\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0576 | Train score: 0.9815 | Val loss: 0.0569 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:03.032\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0465 | Train score: 0.9815 | Val loss: 0.0569 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:05.359\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0495 | Train score: 0.9815 | Val loss: 0.0574 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:07.686\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0428 | Train score: 0.9815 | Val loss: 0.0581 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:10.029\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0470 | Train score: 0.9815 | Val loss: 0.0559 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:12.025\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0540 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:14.151\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0727 | Train score: 0.9753 | Val loss: 0.0535 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:16.249\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0541 | Train score: 0.9815 | Val loss: 0.0476 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:18.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0528 | Train score: 0.9815 | Val loss: 0.0471 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:20.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0598 | Train score: 0.9815 | Val loss: 0.0505 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:22.848\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0757 | Train score: 0.9815 | Val loss: 0.0491 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:25.098\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0389 | Train score: 0.9815 | Val loss: 0.0487 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:27.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0715 | Train score: 0.9815 | Val loss: 0.0484 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:29.365\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0443 | Train score: 0.9815 | Val loss: 0.0490 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:31.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0556 | Train score: 0.9753 | Val loss: 0.0491 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:33.804\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0524 | Train score: 0.9815 | Val loss: 0.0494 | Val score: 0.9752\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 15:25:35.793\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0567 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:37.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0710 | Train score: 0.9815 | Val loss: 0.0581 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:40.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0525 | Train score: 0.9815 | Val loss: 0.0591 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:42.038\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0868 | Train score: 0.9815 | Val loss: 0.0591 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:44.063\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0809 | Train score: 0.9691 | Val loss: 0.0560 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:46.158\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0596 | Train score: 0.9753 | Val loss: 0.0531 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:48.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0425 | Train score: 0.9815 | Val loss: 0.0508 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:50.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0395 | Train score: 0.9877 | Val loss: 0.0490 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:52.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0784 | Train score: 0.9877 | Val loss: 0.0493 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:54.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0880 | Train score: 0.9877 | Val loss: 0.0497 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:56.273\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0456 | Train score: 0.9753 | Val loss: 0.0500 | Val score: 0.9802\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 15:25:58.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0523 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:00.317\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0620 | Train score: 0.9815 | Val loss: 0.0441 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:02.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0428 | Train score: 0.9815 | Val loss: 0.0418 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:04.506\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0823 | Train score: 0.9753 | Val loss: 0.0397 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:06.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1121 | Train score: 0.9815 | Val loss: 0.0390 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:08.695\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0440 | Train score: 0.9815 | Val loss: 0.0396 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:10.814\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0367 | Train score: 0.9753 | Val loss: 0.0392 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:12.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0424 | Train score: 0.9815 | Val loss: 0.0390 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:15.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0461 | Train score: 0.9877 | Val loss: 0.0397 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:17.475\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0209 | Train score: 0.9877 | Val loss: 0.0407 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:19.568\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0723 | Train score: 0.9877 | Val loss: 0.0426 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:21.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0696 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:23.771\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0883 | Train score: 0.9815 | Val loss: 0.0722 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:25.996\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0747 | Train score: 0.9815 | Val loss: 0.0740 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:28.097\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0561 | Train score: 0.9815 | Val loss: 0.0743 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:30.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0530 | Train score: 0.9815 | Val loss: 0.0753 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:32.337\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0534 | Train score: 0.9815 | Val loss: 0.0781 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:34.586\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0273 | Train score: 0.9815 | Val loss: 0.0827 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:36.706\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0364 | Train score: 0.9815 | Val loss: 0.0870 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:38.808\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0454 | Train score: 0.9877 | Val loss: 0.0904 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:40.989\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0342 | Train score: 0.9877 | Val loss: 0.0934 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:43.150\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0714 | Train score: 0.9877 | Val loss: 0.0930 | Val score: 0.9703\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 15:26:45.197\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0646 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:47.431\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0517 | Train score: 0.9815 | Val loss: 0.0629 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:49.671\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0577 | Train score: 0.9815 | Val loss: 0.0678 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:51.975\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0514 | Train score: 0.9815 | Val loss: 0.0711 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:54.181\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0737 | Train score: 0.9753 | Val loss: 0.0689 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:56.445\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0430 | Train score: 0.9815 | Val loss: 0.0648 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:58.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0773 | Train score: 0.9877 | Val loss: 0.0607 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:27:00.825\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0504 | Train score: 0.9753 | Val loss: 0.0592 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:27:03.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0547 | Train score: 0.9815 | Val loss: 0.0576 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:27:05.404\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0588 | Train score: 0.9815 | Val loss: 0.0565 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:27:07.658\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0341 | Train score: 0.9815 | Val loss: 0.0552 | Val score: 0.9802\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " imbalance \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.982         0.000             0.0            0.0         0.00        0.00         0.500        0.000    0.000     0.0         0.000        0.000\n",
      "MedPFNClassifier                      0.982         0.000             0.0            0.0         0.00        0.00         0.780        0.131    0.000     0.0         0.345        0.010\n",
      "MedPFNClassifier                      0.982         0.000             0.0            0.0         0.00        0.00         0.837        0.118    0.000     0.0         1.943        0.036\n",
      "MedPFNClassifier                      0.982         0.000             0.0            0.0         0.00        0.00         0.840        0.117    0.000     0.0        14.103        0.143\n",
      "RandomForestClassifier                0.983         0.003             0.1            0.3         0.05        0.15         0.811        0.136    0.067     0.2         0.179        0.007\n",
      "CatBoostGrid                          0.983         0.003             0.1            0.3         0.05        0.15         0.801        0.120    0.067     0.2        75.123        3.790\n",
      "XGBoostGrid                           0.982         0.000             0.0            0.0         0.00        0.00         0.842        0.153    0.000     0.0        31.351        0.949\n",
      "LogisticRegressionClassifier          0.968         0.011             0.0            0.0         0.00        0.00         0.401        0.261    0.000     0.0         0.009        0.001\n",
      "TabPFNClassifier                      0.979         0.004             0.0            0.0         0.00        0.00         0.832        0.158    0.000     0.0         3.134        0.067\n",
      "TabForestPFNClassifier                0.978         0.007             0.1            0.3         0.05        0.15         0.791        0.152    0.067     0.2        23.753        0.771\n",
      "108 10761\n",
      "(10869, 1391)\n",
      "0.9900634833011317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 15:56:39.061\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0469 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:56:41.270\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0454 | Train score: 0.9877 | Val loss: 0.0506 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:56:43.259\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0648 | Train score: 0.9815 | Val loss: 0.0484 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:56:44.982\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0292 | Train score: 0.9938 | Val loss: 0.0492 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:56:46.664\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0724 | Train score: 0.9815 | Val loss: 0.0499 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:56:48.507\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0272 | Train score: 0.9938 | Val loss: 0.0505 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:56:50.269\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0543 | Train score: 0.9877 | Val loss: 0.0507 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:56:51.977\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0347 | Train score: 0.9877 | Val loss: 0.0506 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:56:53.705\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0405 | Train score: 0.9877 | Val loss: 0.0507 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:56:55.370\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0174 | Train score: 0.9938 | Val loss: 0.0511 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:56:57.053\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0245 | Train score: 0.9877 | Val loss: 0.0520 | Val score: 0.9851\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 15:56:58.701\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0691 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:00.286\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0316 | Train score: 0.9877 | Val loss: 0.0755 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:01.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0230 | Train score: 0.9877 | Val loss: 0.0763 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:03.462\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0174 | Train score: 0.9938 | Val loss: 0.0832 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:05.001\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0506 | Train score: 0.9815 | Val loss: 0.0757 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:06.547\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0270 | Train score: 0.9938 | Val loss: 0.0743 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:08.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0221 | Train score: 0.9938 | Val loss: 0.0794 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:09.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0529 | Train score: 0.9877 | Val loss: 0.0778 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:11.162\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0290 | Train score: 0.9877 | Val loss: 0.0795 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:12.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0243 | Train score: 0.9938 | Val loss: 0.0811 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:15.395\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0328 | Train score: 0.9877 | Val loss: 0.0828 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:17.961\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0558 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:22.123\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0473 | Train score: 0.9877 | Val loss: 0.0597 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:24.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0259 | Train score: 0.9877 | Val loss: 0.0655 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:26.455\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0663 | Train score: 0.9877 | Val loss: 0.0648 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:28.181\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0538 | Train score: 0.9938 | Val loss: 0.0645 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:30.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0174 | Train score: 0.9938 | Val loss: 0.0651 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:33.007\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0152 | Train score: 0.9938 | Val loss: 0.0667 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:35.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0339 | Train score: 0.9938 | Val loss: 0.0685 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:37.969\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0113 | Train score: 0.9938 | Val loss: 0.0712 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:39.922\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0195 | Train score: 0.9938 | Val loss: 0.0747 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:41.571\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0250 | Train score: 0.9877 | Val loss: 0.0811 | Val score: 0.9802\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 15:57:43.496\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0465 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:45.338\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0484 | Train score: 0.9877 | Val loss: 0.0430 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:47.043\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0334 | Train score: 0.9877 | Val loss: 0.0411 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:48.802\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0260 | Train score: 0.9877 | Val loss: 0.0494 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:50.705\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0209 | Train score: 0.9877 | Val loss: 0.0472 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:52.433\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1384 | Train score: 0.9877 | Val loss: 0.0443 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:54.407\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0645 | Train score: 0.9938 | Val loss: 0.0401 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:56.291\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0616 | Train score: 0.9877 | Val loss: 0.0407 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:58.368\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0123 | Train score: 1.0000 | Val loss: 0.0431 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:00.177\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0477 | Train score: 0.9938 | Val loss: 0.0423 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:01.893\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0407 | Train score: 0.9877 | Val loss: 0.0412 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:03.727\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0630 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:05.570\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0400 | Train score: 0.9877 | Val loss: 0.0744 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:07.329\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0237 | Train score: 0.9877 | Val loss: 0.0870 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:09.381\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0217 | Train score: 0.9877 | Val loss: 0.0998 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:11.853\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0166 | Train score: 0.9938 | Val loss: 0.1086 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:14.545\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0238 | Train score: 0.9877 | Val loss: 0.1099 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:17.574\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0786 | Train score: 0.9877 | Val loss: 0.0971 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:20.939\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0671 | Train score: 0.9877 | Val loss: 0.0816 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:23.535\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0175 | Train score: 0.9938 | Val loss: 0.0738 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:25.717\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0457 | Train score: 0.9877 | Val loss: 0.0669 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:28.028\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0382 | Train score: 0.9938 | Val loss: 0.0627 | Val score: 0.9901\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 15:58:30.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0435 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:32.757\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0556 | Train score: 0.9877 | Val loss: 0.0423 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:35.270\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0580 | Train score: 0.9877 | Val loss: 0.0418 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:37.803\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0517 | Train score: 0.9877 | Val loss: 0.0414 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:40.361\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0425 | Train score: 0.9877 | Val loss: 0.0406 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:42.881\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0343 | Train score: 0.9877 | Val loss: 0.0406 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:45.565\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0404 | Train score: 0.9877 | Val loss: 0.0414 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:48.222\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0680 | Train score: 0.9877 | Val loss: 0.0419 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:50.671\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0511 | Train score: 0.9877 | Val loss: 0.0424 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:53.139\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0274 | Train score: 0.9877 | Val loss: 0.0441 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:55.630\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0449 | Train score: 0.9877 | Val loss: 0.0467 | Val score: 0.9901\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 15:58:57.877\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0325 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:00.390\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0645 | Train score: 0.9877 | Val loss: 0.0363 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:03.174\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0552 | Train score: 0.9877 | Val loss: 0.0360 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:05.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0473 | Train score: 0.9877 | Val loss: 0.0342 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:08.026\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0760 | Train score: 0.9877 | Val loss: 0.0353 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:10.474\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0372 | Train score: 0.9815 | Val loss: 0.0356 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:13.429\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0389 | Train score: 0.9877 | Val loss: 0.0350 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:16.186\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0339 | Train score: 0.9877 | Val loss: 0.0360 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:18.916\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0254 | Train score: 0.9877 | Val loss: 0.0394 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:21.242\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0161 | Train score: 0.9938 | Val loss: 0.0450 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:23.282\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0277 | Train score: 0.9877 | Val loss: 0.0501 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:25.331\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0470 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:27.430\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0635 | Train score: 0.9877 | Val loss: 0.0469 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:29.458\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0376 | Train score: 0.9877 | Val loss: 0.0456 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:31.501\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0296 | Train score: 0.9877 | Val loss: 0.0458 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:33.709\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0310 | Train score: 0.9877 | Val loss: 0.0466 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:35.646\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0624 | Train score: 0.9877 | Val loss: 0.0464 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:37.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0416 | Train score: 0.9877 | Val loss: 0.0468 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:39.569\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0341 | Train score: 0.9938 | Val loss: 0.0475 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:41.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0433 | Train score: 0.9877 | Val loss: 0.0493 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:43.635\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0542 | Train score: 0.9877 | Val loss: 0.0471 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:46.062\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0317 | Train score: 0.9938 | Val loss: 0.0465 | Val score: 0.9901\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 15:59:48.341\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0567 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:50.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0342 | Train score: 0.9877 | Val loss: 0.0581 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:52.715\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0477 | Train score: 0.9938 | Val loss: 0.0558 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:54.649\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0317 | Train score: 0.9877 | Val loss: 0.0558 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:56.654\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0384 | Train score: 0.9938 | Val loss: 0.0562 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:58.497\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0162 | Train score: 1.0000 | Val loss: 0.0571 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 16:00:00.357\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0215 | Train score: 0.9877 | Val loss: 0.0590 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 16:00:02.312\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0119 | Train score: 0.9938 | Val loss: 0.0623 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 16:00:04.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0330 | Train score: 0.9938 | Val loss: 0.0671 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 16:00:06.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0369 | Train score: 0.9938 | Val loss: 0.0702 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 16:00:07.885\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0131 | Train score: 0.9938 | Val loss: 0.0726 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 16:00:09.737\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0426 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 16:00:11.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0440 | Train score: 0.9877 | Val loss: 0.0390 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 16:00:13.481\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0642 | Train score: 0.9877 | Val loss: 0.0373 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 16:00:15.577\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0238 | Train score: 0.9877 | Val loss: 0.0349 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 16:00:18.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0189 | Train score: 0.9938 | Val loss: 0.0341 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 16:00:20.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0242 | Train score: 0.9877 | Val loss: 0.0342 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 16:00:22.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0559 | Train score: 0.9877 | Val loss: 0.0314 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 16:00:23.846\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0265 | Train score: 0.9938 | Val loss: 0.0311 | Val score: 0.9950\u001b[0m\n",
      "\u001b[32m2024-11-04 16:00:25.789\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0204 | Train score: 0.9938 | Val loss: 0.0310 | Val score: 0.9950\u001b[0m\n",
      "\u001b[32m2024-11-04 16:00:27.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0127 | Train score: 1.0000 | Val loss: 0.0310 | Val score: 0.9950\u001b[0m\n",
      "\u001b[32m2024-11-04 16:00:29.416\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0402 | Train score: 0.9877 | Val loss: 0.0315 | Val score: 0.9950\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " imbalance \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.991         0.000             0.0            0.0          0.0         0.0         0.500        0.000      0.0     0.0         0.000        0.000\n",
      "MedPFNClassifier                      0.991         0.000             0.0            0.0          0.0         0.0         0.805        0.229      0.0     0.0         0.360        0.006\n",
      "MedPFNClassifier                      0.991         0.000             0.0            0.0          0.0         0.0         0.814        0.200      0.0     0.0         1.987        0.076\n",
      "MedPFNClassifier                      0.991         0.000             0.0            0.0          0.0         0.0         0.796        0.233      0.0     0.0        14.202        0.326\n",
      "RandomForestClassifier                0.991         0.000             0.0            0.0          0.0         0.0         0.666        0.293      0.0     0.0         0.212        0.015\n",
      "CatBoostGrid                          0.991         0.000             0.0            0.0          0.0         0.0         0.737        0.219      0.0     0.0       125.652       18.589\n",
      "XGBoostGrid                           0.991         0.000             0.0            0.0          0.0         0.0         0.618        0.220      0.0     0.0        31.094        3.714\n",
      "LogisticRegressionClassifier          0.989         0.004             0.0            0.0          0.0         0.0         0.678        0.310      0.0     0.0         0.005        0.001\n",
      "TabPFNClassifier                      0.991         0.000             0.0            0.0          0.0         0.0         0.802        0.215      0.0     0.0         2.829        0.525\n",
      "TabForestPFNClassifier                0.988         0.004             0.0            0.0          0.0         0.0         0.796        0.356      0.0     0.0        22.925        3.237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "save = True\n",
    "sampling = None\n",
    "cv = 10\n",
    "best_delete = 0\n",
    "strat_split = True\n",
    "recomp = False\n",
    "n_optim = 1000\n",
    "cat_optim = 10\n",
    "ft_epochs = 20\n",
    "ft_epochs_forest = 10\n",
    "ft_lr = 1e-5\n",
    "max_s = 1024\n",
    "max_q = 128\n",
    "max_samples = 1024\n",
    "no_pre_process = False\n",
    "multi_decoder = \"permutation\"\n",
    "N_ens = 5\n",
    "seed = 42\n",
    "overwrite = True\n",
    "metrics = [\"accuracy\", \"precision\", \"recall\", \"roc_auc\", \"f1\"]\n",
    "dir_path = os.path.abspath(os.getcwd())\n",
    "#run_name = \"medium_net_mlp_balance_bsplit_baseline\" ## NO PERM, VERY ROBUST\n",
    "#run_name2 = \"large_mlp_var_balance_05weight_anova\" ## das aller bestigste\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_newprior\" ## das aller bestigste\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_newprior\" ## das aller bestigste\n",
    "run_name = \"medium_mlp_var_balance_05weight_anova_bestwithnoisebnn_100\" ## good start, best with ft\n",
    "#run_name3 = \"medium_mlp_var_balance_05weight_anova_bestwithnoisebnn_100_moreweight\" ## best start, ft no so good\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_200\" ## das aller bestigste\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_longer\" ## das aller bestigste\n",
    "#run_name = \"medium_mlp_balance_lownoisefixparam_anova\"\n",
    "#run_name = \"medium_mlp_0.5static_balance_anova\"\n",
    "#run_name = \"large_mlp_fullbalance\"\n",
    "#run_name = \"small_net_mlp_var_imbalance_05weight\" ## WORKS VERY WELL WITH PERM\n",
    "#run_name = \"small_net_mlp_varbalance_weight_batchunisplit\"\n",
    "#run_name = \"small_net_mlp_variable_balance_weight\"\n",
    "#run_name = \"small_net_mlp_balance_minevalup\"\n",
    "path = dir_path + f\"/logs/trainrun_{run_name}\"\n",
    "#path2 = dir_path + f\"/logs/trainrun_{run_name2}\"\n",
    "#path3 = dir_path + f\"/logs/trainrun_{run_name3}\"\n",
    "filename = \"model\"\n",
    "\n",
    "\n",
    "\n",
    "models = [\n",
    "    MajorityClass(),\n",
    "    #XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic'),\n",
    "    MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=1, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process),\n",
    "    MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process),\n",
    "    MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process,\n",
    "                    ft_epochs=ft_epochs, ft_lr=ft_lr),\n",
    "    RandomForestClassifier(),\n",
    "    #AutoGluon(),\n",
    "    CatBoostGrid(),\n",
    "    XGBoostGrid(),\n",
    "    LogisticRegressionClassifier(), \n",
    "    TabPFNClassifier(device='cpu', N_ensemble_configurations=5, no_preprocess_mode=no_pre_process),\n",
    "    TabForestPFNClassifier(\"saved_models/tabforest/mix600k/tabforestpfn.pt\", \"saved_models/tabforest/mix600k/config_run.yaml\", max_epochs=ft_epochs_forest)\n",
    "]\n",
    "reducer  = AnovaSelect()\n",
    "#for reducer in [AnovaSelect(), RandomSelect(), NonZeroSelect(), MeanSelect(), StdSelect(), MaxSelect(), PCASelect()]:\n",
    "#data = clr(all_data)\n",
    "\n",
    "#all_data = normalize(all_data)\n",
    "\n",
    "frac = [0.91,0.92,0.93,0.94,0.95,0.96,0.97,0.98,0.99]\n",
    "for f in frac:\n",
    "    data_c0 = all_data[labels==0]\n",
    "    data_c1 = all_data[labels==1]\n",
    "    num_c1 = data_c1.shape[0]\n",
    "    num_c0 = min(int(num_c1*f/(1-f)),data_c0.shape[0])\n",
    "    num_c1 = min(num_c1, int(num_c0*(1-f)/f))\n",
    "    print(num_c1,num_c0)\n",
    "    data = np.concatenate((data_c0[:num_c0], data_c1[:num_c1]), axis=0)\n",
    "    print(data.shape)\n",
    "    labels_new = np.concatenate((np.zeros(num_c0), np.ones(num_c1)))\n",
    "    data_new, labels_new = unison_shuffled_copies(data, labels_new)\n",
    "    counts = np.unique(labels_new, return_counts=True)[1]\n",
    "    print(counts[0]/np.sum(counts))\n",
    "    results_mean = pd.DataFrame(np.zeros((len(models), len(metrics)+1)),\n",
    "                                index=[m.__class__.__name__ for m in models],\n",
    "                                columns=metrics+[\"runtime\"])\n",
    "    results_std = pd.DataFrame(np.zeros((len(models), len(metrics)+1)), \n",
    "                               index=[m.__class__.__name__ for m in models],\n",
    "                               columns=metrics+[\"runtime\"])\n",
    "    \n",
    "    for ii, model in enumerate(models):\n",
    "        results_mean.iloc[ii,:], results_std.iloc[ii,:] = cross_validate_sample(\n",
    "            model, data_new, labels_new, metrics, strat_split, cv, sampling, \n",
    "            reducer, max_samples, seed=seed, overwrite=overwrite, n_best_delete=best_delete,\n",
    "            recomp=recomp)\n",
    "    \n",
    "    results_mean = results_mean.add_suffix(\" mean\")\n",
    "    results_std = results_std.add_suffix(\" std\")\n",
    "    results_full = pd.concat((results_mean, results_std), axis=1)\n",
    "    cols = results_full.columns.tolist()\n",
    "    new_cols = []\n",
    "    for i in range(int(len(cols)/2)):\n",
    "        new_cols.append(cols[i])\n",
    "        new_cols.append(cols[i+int(len(cols)/2)])\n",
    "    results_full = results_full[new_cols]\n",
    "    red_name = \"imbalance\"\n",
    "    if save:\n",
    "        directory = f\"results/{red_name}\"\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        save_path = f'results/{red_name}/majclass_{f}.csv'\n",
    "        results_full.to_csv(save_path)\n",
    "    print(\"\\n\", \"\\n\", red_name, \"\\n\", results_full.round(3))\n",
    "    #print(results_full.sort_values(\"roc_auc mean\").round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "eb97879e-b2c6-4571-ab1d-c0ec7cba47ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9388413889373582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\AppData\\Local\\Temp\\ipykernel_19724\\3596895818.py:45: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  fig.show()\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_imb = all_data[labels==0].shape[0]/(all_data[labels==0].shape[0]+all_data[labels==1].shape[0])\n",
    "print(data_imb)\n",
    "models = [\"Majclass\", \"MedPFN-1\", \"MedPFN-7\", \"MedPFN-7FT\", \"RandomForest\", \"CatBoost\", \"XGBoost\", \"Logistic Regression\", \"TabPFN\", \"TabForestPFN\"]\n",
    "fig, axs = plt.subplots(1, 1, figsize=(10, 5))\n",
    "all_accuracies = []\n",
    "all_rocs = []\n",
    "all_f1s = []\n",
    "fracs = [0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.91,0.92,0.93,0.94,0.95,0.96,0.97,0.98]\n",
    "for m in range(0,len(models)):\n",
    "    accuracies = []\n",
    "    rocs = []\n",
    "    f1s = []\n",
    "    for f in fracs:\n",
    "    \n",
    "        path = f'results/imbalance/majclass_{f}.csv'\n",
    "        df = pd.read_csv(path)\n",
    "        accuracies.append(df.iloc[m,1])\n",
    "        rocs.append(df.iloc[m,7])\n",
    "        f1s.append(df.iloc[m,9])\n",
    "    all_accuracies.append(accuracies)\n",
    "    all_rocs.append(rocs)\n",
    "    all_f1s.append(f1s)\n",
    "    \n",
    "#axs[0].plot(all_accuracies[3])\n",
    "#axs[1].plot(all_rocs[3])\n",
    "#axs[2].plot(all_f1s[2])\n",
    "mean_accuracies = all_accuracies[3]-np.mean(np.array(all_accuracies)[4:],axis=0)\n",
    "#axs.plot(fracs, mean_accuracies)\n",
    "mean_rocs = all_rocs[3]-np.mean(np.array(all_rocs)[4:],axis=0)\n",
    "#axs.plot(fracs, mean_rocs)\n",
    "mean_f1s = all_f1s[3]-np.mean(np.array(all_f1s)[4:],axis=0)\n",
    "#axs.plot(fracs, mean_f1s)\n",
    "axs.plot(fracs, np.zeros(len(fracs)), linestyle='--', c=\"black\", label=\"Win threshhold\")\n",
    "axs.vlines(data_imb,-0.075,0.125, linestyles=\"dashed\", colors=\"crimson\", label=\"Original data\")\n",
    "axs.plot(fracs, mean_rocs, marker=\"v\", linewidth=2.5, markersize=7.0, label='ROC AUC', c=\"teal\")\n",
    "axs.plot(fracs, mean_accuracies, marker=\"v\", linewidth=2.5, markersize=7.0, label='Accuracy', c=\"darkorange\")\n",
    "axs.plot(fracs, mean_f1s, marker=\"v\", linewidth=2.5, markersize=7.0, label='F1-score', c=\"purple\")\n",
    "axs.set_yticks([-0.05,0,0.05,0.1])\n",
    "axs.set_ylim(-0.075,0.125)\n",
    "axs.set_xlim(0.5,0.99)\n",
    "axs.set_xlabel(\"Fraction of class 0 in data\")\n",
    "axs.set_ylabel(\"MedPFN - mean[baselines]\")\n",
    "axs.grid()\n",
    "axs.legend(fontsize=12)\n",
    "fig.show()\n",
    "fig.savefig(\"results/plots/imbalance.eps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92b57f2-8a3b-41ad-98b6-235cd6a2454f",
   "metadata": {},
   "source": [
    "## Ensemble testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "730e1ff3-52fd-4746-b51e-7cce8cc46c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " ensemble \n",
      "     accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "1           0.947         0.006           0.400          0.436        0.117       0.130         0.870        0.071    0.166   0.170         0.460        0.080\n",
      "2           0.947         0.006           0.300          0.306        0.167       0.167         0.911        0.063    0.213   0.214         1.368        0.113\n",
      "3           0.951         0.009           0.600          0.436        0.183       0.138         0.907        0.060    0.266   0.189         1.978        0.240\n",
      "4           0.950         0.008           0.533          0.393        0.200       0.145         0.922        0.054    0.276   0.191         2.562        0.185\n",
      "5           0.950         0.008           0.533          0.393        0.200       0.145         0.919        0.055    0.276   0.191         2.810        0.218\n",
      "6           0.950         0.008           0.533          0.393        0.200       0.145         0.919        0.056    0.276   0.191         3.069        0.258\n",
      "7           0.950         0.008           0.533          0.393        0.200       0.145         0.915        0.057    0.276   0.191         3.565        0.436\n",
      "8           0.949         0.007           0.533          0.393        0.183       0.138         0.914        0.056    0.255   0.177         3.152        0.393\n",
      "9           0.949         0.007           0.533          0.393        0.183       0.138         0.915        0.056    0.255   0.177         4.416        0.538\n",
      "10          0.949         0.007           0.533          0.393        0.183       0.138         0.916        0.052    0.255   0.177         5.720        0.516\n",
      "11          0.949         0.007           0.533          0.393        0.183       0.138         0.918        0.052    0.255   0.177         4.744        0.378\n",
      "12          0.949         0.007           0.533          0.393        0.183       0.138         0.916        0.052    0.255   0.177         4.949        0.272\n",
      "13          0.950         0.011           0.613          0.380        0.233       0.133         0.914        0.053    0.319   0.175         5.320        0.310\n",
      "14          0.950         0.011           0.613          0.380        0.233       0.133         0.914        0.053    0.319   0.175         5.573        0.306\n",
      "15          0.947         0.008           0.513          0.397        0.183       0.138         0.913        0.054    0.247   0.171         6.179        0.433\n",
      "16          0.947         0.008           0.513          0.397        0.183       0.138         0.913        0.053    0.247   0.171         6.079        0.299\n",
      "17          0.947         0.008           0.513          0.397        0.183       0.138         0.913        0.054    0.247   0.171         6.229        0.375\n",
      "18          0.946         0.007           0.480          0.389        0.150       0.117         0.914        0.054    0.208   0.141         7.002        0.318\n",
      "19          0.948         0.010           0.580          0.382        0.200       0.125         0.914        0.055    0.280   0.164         7.117        0.591\n",
      "20          0.948         0.010           0.580          0.382        0.200       0.125         0.916        0.053    0.280   0.164         7.832        0.600\n"
     ]
    }
   ],
   "source": [
    "save = True\n",
    "sampling = None\n",
    "cv = 10\n",
    "best_delete = 0\n",
    "strat_split = True\n",
    "recomp = False\n",
    "n_optim = 1000\n",
    "cat_optim = 10\n",
    "ft_epochs = 10\n",
    "ft_lr = 1e-5\n",
    "max_s = 1024\n",
    "max_q = 128\n",
    "max_samples = 1024\n",
    "no_pre_process = False\n",
    "multi_decoder = \"permutation\"\n",
    "N_ens = 7\n",
    "seed = 42\n",
    "overwrite = True\n",
    "metrics = [\"accuracy\", \"precision\", \"recall\", \"roc_auc\", \"f1\"]\n",
    "dir_path = os.path.abspath(os.getcwd())\n",
    "run_name = \"medium_mlp_var_balance_05weight_anova_bestwithnoisebnn_100\"\n",
    "path = dir_path + f\"/logs/trainrun_{run_name}\"\n",
    "filename = \"model\"\n",
    "\n",
    "ens_num = 20\n",
    "\n",
    "    \n",
    "reducer  = AnovaSelect()\n",
    "\n",
    "results_mean = pd.DataFrame(np.zeros((ens_num, len(metrics)+1)),\n",
    "                            index=np.arange(1,1+ens_num),\n",
    "                            columns=metrics+[\"runtime\"])\n",
    "results_std = pd.DataFrame(np.zeros((ens_num, len(metrics)+1)), \n",
    "                           index=np.arange(1,1+ens_num),\n",
    "                           columns=metrics+[\"runtime\"])\n",
    "\n",
    "for ens in range(1,ens_num+1):\n",
    "    model = MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process)\n",
    "    results_mean.iloc[ens-1,:], results_std.iloc[ens-1,:] = cross_validate_sample(\n",
    "        model, all_data, labels, metrics, strat_split, cv, sampling, \n",
    "        reducer, max_samples, seed=seed, overwrite=overwrite, n_best_delete=best_delete,\n",
    "        recomp=recomp)\n",
    "    #print(results_mean)\n",
    "results_mean = results_mean.add_suffix(\" mean\")\n",
    "results_std = results_std.add_suffix(\" std\")\n",
    "results_full = pd.concat((results_mean, results_std), axis=1)\n",
    "cols = results_full.columns.tolist()\n",
    "new_cols = []\n",
    "for i in range(int(len(cols)/2)):\n",
    "    new_cols.append(cols[i])\n",
    "    new_cols.append(cols[i+int(len(cols)/2)])\n",
    "results_full = results_full[new_cols]\n",
    "red_name = \"ensemble\"\n",
    "if save:\n",
    "    directory = f\"results/{red_name}\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    save_path = f'results/{red_name}/medpfn_maxens{ens_num}'\n",
    "    results_full.to_csv(save_path)\n",
    "print(\"\\n\", \"\\n\", red_name, \"\\n\", results_full.round(3))\n",
    "    #print(results_full.sort_values(\"roc_auc mean\").round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "90749abf-81cc-4bbe-8f85-6f3326524d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    }
   ],
   "source": [
    "ens_num = 20\n",
    "results_full = pd.read_csv(f'results/ensemble/medpfn_maxens{20}')\n",
    "#for i in range(ens_num):\n",
    "x = np.arange(1,1+ens_num)\n",
    "acc = results_full.iloc[:,1]\n",
    "acc_error = results_full.iloc[:,2]\n",
    "roc = results_full.iloc[:,7]\n",
    "roc_error = results_full.iloc[:,8]\n",
    "f1 = results_full.iloc[:,9]\n",
    "f1_error = results_full.iloc[:,10]\n",
    "\n",
    "heights = [1,1,1]\n",
    "mpl.rcParams['axes.linewidth'] = 1.5\n",
    "fig, ax = plt.subplots(3, 1, figsize=(8, 8), gridspec_kw={'height_ratios': heights},sharex=True)\n",
    "\n",
    "colors = [\"teal\", \"darkorange\", \"purple\"]\n",
    "#ax[0].fill_between(x, roc - roc_error, roc + roc_error, alpha=0.25, color=colors[0])\n",
    "#ax[1].fill_between(x, acc - acc_error, acc + acc_error, alpha=0.25,color=colors[1])\n",
    "#ax[2].fill_between(x, f1 - f1_error, f1 + f1_error, alpha=0.25, color=colors[2])\n",
    "ax[1].plot(x, acc, marker=\"v\", linewidth=2.5, markersize=7.0, label='Accuracy', c=colors[1])\n",
    "ax[0].plot(x, roc, marker=\"v\", linewidth=2.5, markersize=7.0, label='ROC AUC', c=colors[0])\n",
    "ax[2].plot(x, f1, marker=\"v\", linewidth=2.5, markersize=7.0, label='F1-score', color=colors[2])\n",
    "\n",
    "ax[0].set_ylim(0.85,0.95)\n",
    "ax[1].set_ylim(0.945,0.955)\n",
    "ax[2].set_ylim(0.15,0.35)\n",
    "ax[0].set_yticks([0.85,0.9,0.95])\n",
    "ax[1].set_yticks([0.945,0.95])\n",
    "ax[2].set_yticks([0.15,0.25])\n",
    "# Adding labels and title\n",
    "ax[0].set_ylabel('ROC AUC')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "ax[2].set_ylabel('$F_1$-score')\n",
    "ax[2].set_xlabel('Ensemble size')\n",
    "ax[2].set_xticks([1,5,10,15,20])\n",
    "#plt.yticks([0.3,0.6,0.9])\n",
    "ax[2].set_xlim(1,20)\n",
    "#plt.ylim(0,1)\n",
    "ax[0].grid()\n",
    "ax[1].grid()\n",
    "ax[2].grid()\n",
    "#plt.ylabel('Metric score')\n",
    "#plt.title('Plot with Uncertainty Band')\n",
    "fig.legend(loc=(0.7,0.65), fontsize=15)\n",
    "plt.subplots_adjust(hspace=0)\n",
    "#plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(\"results/plots/ensemble.eps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c0856f-0ec2-4a8d-8cc9-b8c0cccf7f2c",
   "metadata": {},
   "source": [
    "## Finetuning analysis ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a73c8e1-1139-4049-a448-03f5060243ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "\n",
      " \n",
      " finetuning \n",
      "     accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "1           0.950         0.008           0.533          0.393        0.200       0.145         0.915        0.058    0.276   0.191         3.222        0.107\n",
      "2           0.952         0.006           0.717          0.236        0.267       0.082         0.915        0.058    0.365   0.078         3.622        0.079\n",
      "3           0.952         0.007           0.617          0.299        0.267       0.111         0.914        0.061    0.358   0.141         4.197        0.132\n",
      "4           0.953         0.004           0.677          0.176        0.317       0.090         0.915        0.062    0.409   0.074         4.766        0.218\n",
      "5           0.954         0.007           0.635          0.150        0.350       0.090         0.917        0.060    0.443   0.090         5.467        0.645\n",
      "6           0.952         0.007           0.623          0.157        0.333       0.000         0.915        0.061    0.429   0.036         5.745        0.598\n",
      "7           0.952         0.006           0.617          0.150        0.333       0.075         0.915        0.061    0.423   0.067         6.179        0.522\n",
      "8           0.951         0.008           0.588          0.120        0.350       0.050         0.917        0.060    0.435   0.063         6.540        0.364\n",
      "9           0.953         0.006           0.608          0.092        0.350       0.050         0.916        0.060    0.442   0.057         7.204        0.545\n",
      "10          0.954         0.009           0.611          0.099        0.417       0.171         0.918        0.059    0.482   0.123         7.528        0.162\n",
      "11          0.955         0.008           0.617          0.076        0.467       0.208         0.915        0.059    0.509   0.119         8.179        0.305\n",
      "12          0.957         0.010           0.633          0.098        0.517       0.203         0.916        0.060    0.548   0.127         8.804        0.587\n",
      "13          0.958         0.007           0.681          0.120        0.450       0.167         0.917        0.058    0.520   0.107         9.766        1.228\n",
      "14          0.954         0.009           0.608          0.092        0.450       0.167         0.917        0.058    0.502   0.117         9.720        0.217\n",
      "15          0.954         0.009           0.603          0.087        0.483       0.203         0.916        0.058    0.515   0.119        10.115        0.506\n",
      "16          0.953         0.010           0.627          0.156        0.433       0.153         0.919        0.057    0.487   0.086        10.906        0.519\n",
      "17          0.953         0.008           0.571          0.079        0.533       0.256         0.917        0.058    0.521   0.127        14.388        4.149\n",
      "18          0.951         0.011           0.574          0.107        0.467       0.125         0.918        0.058    0.500   0.091        13.466        0.572\n",
      "19          0.951         0.011           0.567          0.103        0.467       0.194         0.916        0.060    0.491   0.114        14.406        1.160\n",
      "20          0.956         0.010           0.610          0.081        0.550       0.248         0.913        0.063    0.550   0.136        12.424        1.119\n",
      "21          0.949         0.014           0.557          0.119        0.567       0.238         0.914        0.058    0.529   0.117        11.990        0.329\n",
      "22          0.954         0.010           0.573          0.081        0.567       0.238         0.917        0.060    0.548   0.124        12.761        0.576\n",
      "23          0.951         0.015           0.552          0.121        0.567       0.238         0.916        0.058    0.537   0.145        13.281        0.615\n",
      "24          0.954         0.015           0.578          0.113        0.567       0.238         0.916        0.060    0.550   0.146        15.043        3.671\n",
      "25          0.949         0.013           0.530          0.107        0.483       0.203         0.916        0.057    0.491   0.133        17.972        0.747\n",
      "26          0.951         0.013           0.558          0.105        0.583       0.227         0.916        0.060    0.546   0.121        19.374        1.385\n",
      "27          0.948         0.013           0.528          0.109        0.550       0.236         0.917        0.059    0.517   0.128        21.025        1.533\n",
      "28          0.947         0.015           0.526          0.107        0.567       0.238         0.912        0.060    0.521   0.127        18.767        2.693\n",
      "29          0.949         0.013           0.524          0.112        0.517       0.174         0.916        0.059    0.514   0.133        19.386        3.121\n",
      "30          0.950         0.013           0.547          0.115        0.550       0.211         0.916        0.059    0.528   0.126        18.159        1.515\n",
      "31          0.947         0.014           0.537          0.114        0.567       0.226         0.916        0.058    0.523   0.107        19.650        3.922\n",
      "32          0.949         0.014           0.548          0.123        0.550       0.211         0.911        0.063    0.526   0.124        23.900        2.345\n",
      "33          0.942         0.016           0.494          0.098        0.550       0.248         0.918        0.055    0.489   0.103        25.204        2.225\n",
      "34          0.943         0.016           0.517          0.127        0.517       0.189         0.913        0.060    0.487   0.086        23.564        1.392\n",
      "35          0.946         0.014           0.508          0.127        0.550       0.248         0.914        0.059    0.503   0.134        25.361        2.896\n",
      "36          0.945         0.017           0.534          0.179        0.533       0.245         0.914        0.058    0.494   0.120        25.708        1.469\n",
      "37          0.946         0.015           0.527          0.127        0.450       0.107         0.915        0.057    0.471   0.088        26.875        1.773\n",
      "38          0.948         0.017           0.545          0.139        0.500       0.183         0.917        0.058    0.504   0.126        26.298        1.322\n",
      "39          0.949         0.015           0.548          0.122        0.517       0.189         0.914        0.060    0.513   0.121        26.466        2.214\n",
      "40          0.948         0.018           0.550          0.132        0.583       0.214         0.915        0.058    0.539   0.130        25.128        1.994\n",
      "41          0.943         0.013           0.489          0.097        0.567       0.238         0.915        0.056    0.501   0.112        25.197        2.381\n",
      "42          0.948         0.011           0.537          0.087        0.600       0.200         0.915        0.062    0.543   0.090        28.193        8.419\n",
      "43          0.940         0.022           0.512          0.145        0.583       0.239         0.914        0.058    0.506   0.114        22.208        1.175\n",
      "44          0.952         0.013           0.562          0.105        0.583       0.239         0.914        0.059    0.547   0.131        22.895        1.617\n",
      "45          0.946         0.019           0.546          0.141        0.517       0.117         0.916        0.057    0.514   0.104        21.326        0.113\n",
      "46          0.944         0.015           0.513          0.116        0.533       0.194         0.915        0.059    0.497   0.095        21.699        0.128\n",
      "47          0.946         0.017           0.533          0.134        0.517       0.189         0.913        0.059    0.500   0.106        22.180        0.068\n",
      "48          0.951         0.015           0.559          0.117        0.583       0.239         0.912        0.061    0.545   0.137        22.606        0.130\n",
      "49          0.948         0.013           0.559          0.114        0.500       0.197         0.915        0.057    0.498   0.089        23.008        0.108\n",
      "50          0.950         0.008           0.533          0.393        0.200       0.145         0.915        0.057    0.276   0.191         3.041        0.499\n"
     ]
    }
   ],
   "source": [
    "save = True\n",
    "sampling = None\n",
    "cv = 10\n",
    "best_delete = 0\n",
    "strat_split = True\n",
    "recomp = False\n",
    "n_optim = 1000\n",
    "cat_optim = 10\n",
    "ft_epochs = 10\n",
    "ft_lr = 1e-5\n",
    "max_s = 1024\n",
    "max_q = 128\n",
    "max_samples = 1024\n",
    "no_pre_process = False\n",
    "multi_decoder = \"permutation\"\n",
    "N_ens = 7\n",
    "seed = 42\n",
    "overwrite = True\n",
    "metrics = [\"accuracy\", \"precision\", \"recall\", \"roc_auc\", \"f1\"]\n",
    "dir_path = os.path.abspath(os.getcwd())\n",
    "run_name = \"medium_mlp_var_balance_05weight_anova_bestwithnoisebnn_100\"\n",
    "path = dir_path + f\"/logs/trainrun_{run_name}\"\n",
    "filename = \"model\"\n",
    "\n",
    "ens_num = 50\n",
    "\n",
    "    \n",
    "reducer  = AnovaSelect()\n",
    "\n",
    "results_mean = pd.DataFrame(np.zeros((ens_num, len(metrics)+1)),\n",
    "                            index=np.arange(1,1+ens_num),\n",
    "                            columns=metrics+[\"runtime\"])\n",
    "results_std = pd.DataFrame(np.zeros((ens_num, len(metrics)+1)), \n",
    "                           index=np.arange(1,1+ens_num),\n",
    "                           columns=metrics+[\"runtime\"])\n",
    "\n",
    "for ens in range(0,ens_num):\n",
    "    print(ens)\n",
    "    model = MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process,\n",
    "                    ft_epochs=ens, ft_lr=ft_lr)\n",
    "    results_mean.iloc[ens-1,:], results_std.iloc[ens-1,:] = cross_validate_sample(\n",
    "        model, all_data, labels, metrics, strat_split, cv, sampling, \n",
    "        reducer, max_samples, seed=seed, overwrite=overwrite, n_best_delete=best_delete,\n",
    "        recomp=recomp)\n",
    "    #print(results_mean)\n",
    "results_mean = results_mean.add_suffix(\" mean\")\n",
    "results_std = results_std.add_suffix(\" std\")\n",
    "results_full = pd.concat((results_mean, results_std), axis=1)\n",
    "cols = results_full.columns.tolist()\n",
    "new_cols = []\n",
    "for i in range(int(len(cols)/2)):\n",
    "    new_cols.append(cols[i])\n",
    "    new_cols.append(cols[i+int(len(cols)/2)])\n",
    "results_full = results_full[new_cols]\n",
    "red_name = \"finetuning\"\n",
    "if save:\n",
    "    directory = f\"results/{red_name}\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    save_path = f'results/{red_name}/medpfn_maxsteps{ens_num}_lr{ft_lr}'\n",
    "    results_full.to_csv(save_path)\n",
    "print(\"\\n\", \"\\n\", red_name, \"\\n\", results_full.round(3))\n",
    "    #print(results_full.sort_values(\"roc_auc mean\").round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a7ea4aae-125f-4d43-af6b-bfaffa9674c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    }
   ],
   "source": [
    "ens_num = 50\n",
    "results_full = pd.read_csv(f'results/finetuning/medpfn_maxens{ens_num}')\n",
    "#for i in range(ens_num):\n",
    "x = np.arange(0,ens_num)\n",
    "acc = results_full.iloc[:,1]\n",
    "acc_error = results_full.iloc[:,2]\n",
    "roc = results_full.iloc[:,7]\n",
    "roc_error = results_full.iloc[:,8]\n",
    "f1 = results_full.iloc[:,9]\n",
    "f1_error = results_full.iloc[:,10]\n",
    "\n",
    "heights = [1,1,1]\n",
    "mpl.rcParams['axes.linewidth'] = 1.5\n",
    "fig, ax = plt.subplots(3, 1, figsize=(8, 8), gridspec_kw={'height_ratios': heights},sharex=True)\n",
    "\n",
    "colors = [\"teal\", \"darkorange\", \"purple\"]\n",
    "#ax[0].fill_between(x, roc - roc_error, roc + roc_error, alpha=0.25, color=colors[0])\n",
    "#ax[1].fill_between(x, acc - acc_error, acc + acc_error, alpha=0.25,color=colors[1])\n",
    "#ax[2].fill_between(x, f1 - f1_error, f1 + f1_error, alpha=0.25, color=colors[2])\n",
    "ax[1].plot(x, acc, marker=\"v\", linewidth=2.5, markersize=7.0, label='Accuracy', c=colors[1])\n",
    "ax[0].plot(x, roc, marker=\"v\", linewidth=2.5, markersize=7.0, label='ROC AUC', c=colors[0])\n",
    "ax[2].plot(x, f1, marker=\"v\", linewidth=2.5, markersize=7.0, label='F1-score', color=colors[2])\n",
    "\n",
    "ax[0].set_ylim(0.9,0.94)\n",
    "ax[1].set_ylim(0.90,0.98)\n",
    "ax[2].set_ylim(0.2,0.6)\n",
    "ax[0].set_yticks([0.9,0.92,0.94])\n",
    "ax[1].set_yticks([0.90,0.94])\n",
    "ax[2].set_yticks([0.2,0.4])\n",
    "# Adding labels and title\n",
    "ax[2].set_xlabel('Finetuning iterations')\n",
    "ax[0].set_ylabel('ROC AUC')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "ax[2].set_ylabel('$F_1$-score')\n",
    "ax[2].set_xticks(np.arange(0,50,10))\n",
    "#plt.yticks([0.3,0.6,0.9])\n",
    "ax[2].set_xlim(0,48)\n",
    "#plt.ylim(0,1)\n",
    "ax[0].grid()\n",
    "ax[1].grid()\n",
    "ax[2].grid()\n",
    "#plt.ylabel('Metric score')\n",
    "#plt.title('Plot with Uncertainty Band')\n",
    "fig.legend(loc=(0.7,0.65), fontsize=15)\n",
    "plt.subplots_adjust(hspace=0)\n",
    "#plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(\"results/plots/finetuning.eps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29f154f-c835-46c7-bc4f-729e8a6bb353",
   "metadata": {},
   "source": [
    "### Feature removal ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f3f2fce-a23e-4370-9c28-15a0e7f6170d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 23:32:57.659\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1203 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:32:59.638\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1255 | Train score: 0.9444 | Val loss: 0.1103 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:01.358\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0809 | Train score: 0.9877 | Val loss: 0.1197 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:03.352\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1320 | Train score: 0.9506 | Val loss: 0.1173 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:05.224\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1549 | Train score: 0.9691 | Val loss: 0.1054 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:07.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1521 | Train score: 0.9691 | Val loss: 0.0990 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:08.764\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1214 | Train score: 0.9691 | Val loss: 0.0981 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:10.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1500 | Train score: 0.9630 | Val loss: 0.0977 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:12.481\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0912 | Train score: 0.9815 | Val loss: 0.0957 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:14.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1409 | Train score: 0.9691 | Val loss: 0.0957 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:16.320\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0896 | Train score: 0.9630 | Val loss: 0.0991 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:18.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1265 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:21.121\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1210 | Train score: 0.9506 | Val loss: 0.1134 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:23.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0902 | Train score: 0.9691 | Val loss: 0.1184 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:24.970\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1738 | Train score: 0.9568 | Val loss: 0.1136 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:26.716\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1768 | Train score: 0.9444 | Val loss: 0.1163 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:28.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1170 | Train score: 0.9630 | Val loss: 0.1187 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:30.407\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0819 | Train score: 0.9691 | Val loss: 0.1205 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:32.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0918 | Train score: 0.9691 | Val loss: 0.1217 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:34.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1166 | Train score: 0.9506 | Val loss: 0.1198 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:35.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1108 | Train score: 0.9568 | Val loss: 0.1195 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:37.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0740 | Train score: 0.9753 | Val loss: 0.1323 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:39.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1796 | Val score: 0.9307\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:41.291\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1250 | Train score: 0.9568 | Val loss: 0.1806 | Val score: 0.9257\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:43.289\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0930 | Train score: 0.9753 | Val loss: 0.2040 | Val score: 0.9257\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:45.727\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0623 | Train score: 0.9815 | Val loss: 0.2331 | Val score: 0.9208\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:48.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1584 | Train score: 0.9630 | Val loss: 0.2261 | Val score: 0.9158\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:50.171\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0800 | Train score: 0.9753 | Val loss: 0.2238 | Val score: 0.9208\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:51.956\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1190 | Train score: 0.9815 | Val loss: 0.2239 | Val score: 0.9208\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:53.682\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1220 | Train score: 0.9568 | Val loss: 0.2165 | Val score: 0.9257\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:55.506\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1142 | Train score: 0.9691 | Val loss: 0.2067 | Val score: 0.9158\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:57.511\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1014 | Train score: 0.9753 | Val loss: 0.2054 | Val score: 0.9208\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:59.341\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1598 | Train score: 0.9568 | Val loss: 0.1972 | Val score: 0.9208\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:01.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1343 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:02.996\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1259 | Train score: 0.9444 | Val loss: 0.1331 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:05.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1099 | Train score: 0.9506 | Val loss: 0.1403 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:06.874\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1209 | Train score: 0.9506 | Val loss: 0.1430 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:08.752\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1832 | Train score: 0.9198 | Val loss: 0.1390 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:10.511\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0905 | Train score: 0.9568 | Val loss: 0.1395 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:12.302\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0994 | Train score: 0.9444 | Val loss: 0.1423 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:14.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1098 | Train score: 0.9506 | Val loss: 0.1454 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:16.678\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1053 | Train score: 0.9506 | Val loss: 0.1490 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:19.094\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1006 | Train score: 0.9568 | Val loss: 0.1541 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:20.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0934 | Train score: 0.9630 | Val loss: 0.1591 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:22.762\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1050 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:24.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1398 | Train score: 0.9444 | Val loss: 0.0993 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:26.401\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1511 | Train score: 0.9444 | Val loss: 0.0987 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:28.243\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1245 | Train score: 0.9259 | Val loss: 0.0963 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:30.001\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1093 | Train score: 0.9630 | Val loss: 0.0947 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:31.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1037 | Train score: 0.9753 | Val loss: 0.0944 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:33.524\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1418 | Train score: 0.9630 | Val loss: 0.0939 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:35.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1196 | Train score: 0.9630 | Val loss: 0.0932 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:37.409\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1164 | Train score: 0.9630 | Val loss: 0.0946 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:39.359\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1024 | Train score: 0.9815 | Val loss: 0.0961 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:41.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1145 | Train score: 0.9630 | Val loss: 0.0974 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:43.061\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1735 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:45.297\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1186 | Train score: 0.9630 | Val loss: 0.1603 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:47.803\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0948 | Train score: 0.9630 | Val loss: 0.1601 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:50.184\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0867 | Train score: 0.9691 | Val loss: 0.1588 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:51.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0976 | Train score: 0.9691 | Val loss: 0.1618 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:53.688\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1210 | Train score: 0.9691 | Val loss: 0.1639 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:55.515\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0816 | Train score: 0.9815 | Val loss: 0.1620 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:57.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0592 | Train score: 0.9815 | Val loss: 0.1620 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:59.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1008 | Train score: 0.9630 | Val loss: 0.1608 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:02.118\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0874 | Train score: 0.9691 | Val loss: 0.1596 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:04.319\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0618 | Train score: 0.9815 | Val loss: 0.1591 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:06.123\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1321 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:08.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1506 | Train score: 0.9691 | Val loss: 0.1402 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:10.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1440 | Train score: 0.9444 | Val loss: 0.1381 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:12.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1129 | Train score: 0.9568 | Val loss: 0.1391 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:14.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0721 | Train score: 0.9753 | Val loss: 0.1408 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:16.515\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0671 | Train score: 0.9691 | Val loss: 0.1476 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:19.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1118 | Train score: 0.9691 | Val loss: 0.1485 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:21.477\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1006 | Train score: 0.9630 | Val loss: 0.1459 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:23.470\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1614 | Train score: 0.9444 | Val loss: 0.1422 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:25.516\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1016 | Train score: 0.9568 | Val loss: 0.1391 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:27.580\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0904 | Train score: 0.9691 | Val loss: 0.1378 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:29.295\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1156 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:31.104\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1428 | Train score: 0.9321 | Val loss: 0.1055 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:32.970\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1358 | Train score: 0.9321 | Val loss: 0.1139 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:34.770\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1042 | Train score: 0.9506 | Val loss: 0.1090 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:36.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1280 | Train score: 0.9568 | Val loss: 0.1083 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:38.491\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1495 | Train score: 0.9444 | Val loss: 0.1084 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:40.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0874 | Train score: 0.9691 | Val loss: 0.1077 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:42.278\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1119 | Train score: 0.9506 | Val loss: 0.1069 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:44.131\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1275 | Train score: 0.9630 | Val loss: 0.1076 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:46.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1404 | Train score: 0.9506 | Val loss: 0.1100 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:49.104\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1089 | Train score: 0.9568 | Val loss: 0.1121 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:50.993\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1410 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:52.795\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1551 | Train score: 0.9444 | Val loss: 0.1391 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:54.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1105 | Train score: 0.9506 | Val loss: 0.1389 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:56.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0955 | Train score: 0.9506 | Val loss: 0.1404 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:58.315\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0786 | Train score: 0.9506 | Val loss: 0.1460 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:36:00.363\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1205 | Train score: 0.9753 | Val loss: 0.1484 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:36:02.227\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1037 | Train score: 0.9691 | Val loss: 0.1489 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:36:04.072\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1056 | Train score: 0.9753 | Val loss: 0.1477 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:36:06.042\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1057 | Train score: 0.9630 | Val loss: 0.1464 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:36:08.030\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0943 | Train score: 0.9691 | Val loss: 0.1454 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:36:09.908\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0809 | Train score: 0.9691 | Val loss: 0.1454 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:36:11.809\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1100 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:36:13.682\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1447 | Train score: 0.9630 | Val loss: 0.1086 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:36:15.787\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0897 | Train score: 0.9506 | Val loss: 0.1054 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:36:18.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0884 | Train score: 0.9630 | Val loss: 0.1056 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:36:20.656\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0930 | Train score: 0.9691 | Val loss: 0.1065 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:36:22.470\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1169 | Train score: 0.9691 | Val loss: 0.1065 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:36:24.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0886 | Train score: 0.9691 | Val loss: 0.1066 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:36:26.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1003 | Train score: 0.9691 | Val loss: 0.1061 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:36:28.247\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0873 | Train score: 0.9815 | Val loss: 0.1058 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:36:30.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1203 | Train score: 0.9568 | Val loss: 0.1063 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:36:31.965\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1332 | Train score: 0.9506 | Val loss: 0.1073 | Val score: 0.9604\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " 0 \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.946         0.000           0.000          0.000        0.000       0.000         0.500        0.000    0.000   0.000         0.000        0.000\n",
      "MedPFNClassifier                      0.947         0.006           0.400          0.436        0.117       0.130         0.870        0.071    0.166   0.170         0.722        0.299\n",
      "MedPFNClassifier                      0.950         0.008           0.533          0.393        0.200       0.145         0.919        0.055    0.276   0.191         2.673        0.387\n",
      "MedPFNClassifier                      0.949         0.010           0.552          0.117        0.417       0.171         0.917        0.061    0.456   0.105        21.327        2.060\n",
      "RandomForestClassifier                0.950         0.013           0.350          0.391        0.183       0.217         0.893        0.066    0.235   0.268         0.209        0.021\n",
      "LogisticRegressionClassifier          0.939         0.014           0.393          0.245        0.217       0.150         0.825        0.096    0.269   0.169         0.010        0.005\n",
      "TabPFNClassifier                      0.946         0.018           0.373          0.397        0.200       0.194         0.906        0.057    0.259   0.261         2.951        0.279\n",
      "TabForestPFNClassifier                0.938         0.016           0.402          0.193        0.367       0.163         0.884        0.046    0.376   0.169        21.326        0.926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 23:39:43.577\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1255 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:39:45.764\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1584 | Train score: 0.9506 | Val loss: 0.1346 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:39:48.115\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1418 | Train score: 0.9383 | Val loss: 0.1195 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:39:50.261\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1207 | Train score: 0.9444 | Val loss: 0.1150 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:39:51.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1021 | Train score: 0.9691 | Val loss: 0.1165 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:39:53.757\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1086 | Train score: 0.9630 | Val loss: 0.1178 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:39:55.757\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0887 | Train score: 0.9691 | Val loss: 0.1164 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:39:57.701\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1769 | Train score: 0.9506 | Val loss: 0.1146 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:39:59.554\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1621 | Train score: 0.9506 | Val loss: 0.1127 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:01.363\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1309 | Train score: 0.9568 | Val loss: 0.1117 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:03.741\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1279 | Train score: 0.9568 | Val loss: 0.1117 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:06.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1501 | Val score: 0.9307\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:08.165\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1249 | Train score: 0.9383 | Val loss: 0.1432 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:09.943\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1057 | Train score: 0.9630 | Val loss: 0.1439 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:11.850\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1510 | Train score: 0.9506 | Val loss: 0.1391 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:13.738\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1100 | Train score: 0.9630 | Val loss: 0.1360 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:16.084\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1307 | Train score: 0.9506 | Val loss: 0.1344 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:18.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1209 | Train score: 0.9691 | Val loss: 0.1350 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:20.685\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1004 | Train score: 0.9630 | Val loss: 0.1381 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:22.494\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0932 | Train score: 0.9630 | Val loss: 0.1376 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:24.309\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0648 | Train score: 0.9877 | Val loss: 0.1366 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:26.222\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1291 | Train score: 0.9630 | Val loss: 0.1367 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:28.041\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1128 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:30.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1210 | Train score: 0.9444 | Val loss: 0.1009 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:32.234\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1189 | Train score: 0.9506 | Val loss: 0.0999 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:34.278\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1180 | Train score: 0.9568 | Val loss: 0.0991 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:36.325\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1684 | Train score: 0.9568 | Val loss: 0.1022 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:38.357\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1474 | Train score: 0.9630 | Val loss: 0.1055 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:40.385\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1371 | Train score: 0.9568 | Val loss: 0.1081 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:42.385\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1383 | Train score: 0.9568 | Val loss: 0.1096 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:44.338\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1414 | Train score: 0.9444 | Val loss: 0.1099 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:46.576\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1403 | Train score: 0.9630 | Val loss: 0.1100 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:49.093\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1061 | Train score: 0.9691 | Val loss: 0.1085 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:51.216\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1103 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:53.232\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1414 | Train score: 0.9444 | Val loss: 0.0955 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:55.261\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1020 | Train score: 0.9444 | Val loss: 0.0940 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:57.273\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1806 | Train score: 0.9506 | Val loss: 0.0958 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:59.371\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1106 | Train score: 0.9568 | Val loss: 0.0950 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:01.475\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1010 | Train score: 0.9506 | Val loss: 0.0939 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:03.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1003 | Train score: 0.9630 | Val loss: 0.0923 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:05.355\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1371 | Train score: 0.9506 | Val loss: 0.0934 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:07.566\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1100 | Train score: 0.9630 | Val loss: 0.0948 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:10.332\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0717 | Train score: 0.9630 | Val loss: 0.0964 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:12.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0786 | Train score: 0.9815 | Val loss: 0.0980 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:15.126\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1243 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:17.805\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1232 | Train score: 0.9630 | Val loss: 0.1195 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:20.839\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0945 | Train score: 0.9568 | Val loss: 0.1207 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:23.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0713 | Train score: 0.9753 | Val loss: 0.1258 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:26.317\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1383 | Train score: 0.9568 | Val loss: 0.1231 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:28.791\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1726 | Train score: 0.9383 | Val loss: 0.1190 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:31.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1763 | Train score: 0.9506 | Val loss: 0.1175 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:34.188\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0660 | Train score: 0.9691 | Val loss: 0.1190 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:36.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1207 | Train score: 0.9506 | Val loss: 0.1195 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:38.216\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0721 | Train score: 0.9630 | Val loss: 0.1194 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:40.098\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0797 | Train score: 0.9753 | Val loss: 0.1194 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:42.027\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1383 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:43.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1590 | Train score: 0.9506 | Val loss: 0.1425 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:46.092\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1411 | Train score: 0.9630 | Val loss: 0.1433 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:48.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1283 | Train score: 0.9568 | Val loss: 0.1392 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:51.185\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0977 | Train score: 0.9630 | Val loss: 0.1409 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:54.331\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1038 | Train score: 0.9630 | Val loss: 0.1430 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:57.471\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.2067 | Train score: 0.9444 | Val loss: 0.1439 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:59.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1171 | Train score: 0.9568 | Val loss: 0.1433 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:01.881\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1397 | Train score: 0.9568 | Val loss: 0.1418 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:03.854\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1035 | Train score: 0.9753 | Val loss: 0.1405 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:05.595\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1040 | Train score: 0.9691 | Val loss: 0.1399 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:07.481\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1459 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:09.752\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1490 | Train score: 0.9444 | Val loss: 0.1386 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:11.293\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1391 | Train score: 0.9506 | Val loss: 0.1357 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:13.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0938 | Train score: 0.9753 | Val loss: 0.1342 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:15.001\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0854 | Train score: 0.9691 | Val loss: 0.1344 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:16.929\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1005 | Train score: 0.9506 | Val loss: 0.1366 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:18.898\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1122 | Train score: 0.9630 | Val loss: 0.1377 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:21.024\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0529 | Train score: 0.9877 | Val loss: 0.1406 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:22.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0882 | Train score: 0.9753 | Val loss: 0.1438 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:24.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0661 | Train score: 0.9815 | Val loss: 0.1464 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:25.950\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1451 | Train score: 0.9630 | Val loss: 0.1448 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:27.583\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1158 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:29.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1569 | Train score: 0.9383 | Val loss: 0.1169 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:30.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1410 | Train score: 0.9444 | Val loss: 0.1116 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:32.536\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1275 | Train score: 0.9383 | Val loss: 0.1044 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:34.497\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1299 | Train score: 0.9506 | Val loss: 0.1003 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:36.433\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1269 | Train score: 0.9753 | Val loss: 0.0993 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:38.194\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1234 | Train score: 0.9568 | Val loss: 0.1009 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:39.840\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1297 | Train score: 0.9506 | Val loss: 0.1040 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:41.669\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0741 | Train score: 0.9691 | Val loss: 0.1037 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:43.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1882 | Train score: 0.9568 | Val loss: 0.1040 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:45.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1653 | Train score: 0.9630 | Val loss: 0.1061 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:47.928\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1413 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:49.980\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1154 | Train score: 0.9383 | Val loss: 0.1347 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:52.370\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0918 | Train score: 0.9691 | Val loss: 0.1384 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:55.161\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1310 | Train score: 0.9444 | Val loss: 0.1388 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:58.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1112 | Train score: 0.9506 | Val loss: 0.1378 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:43:00.350\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1303 | Train score: 0.9506 | Val loss: 0.1363 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:43:02.678\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1014 | Train score: 0.9815 | Val loss: 0.1341 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:43:05.527\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1094 | Train score: 0.9753 | Val loss: 0.1320 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:43:08.502\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1031 | Train score: 0.9630 | Val loss: 0.1304 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:43:11.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1661 | Train score: 0.9506 | Val loss: 0.1290 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:43:13.714\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1760 | Train score: 0.9444 | Val loss: 0.1283 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:43:16.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1169 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:43:18.918\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1410 | Train score: 0.9444 | Val loss: 0.1081 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:43:21.426\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1361 | Train score: 0.9506 | Val loss: 0.1076 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 23:43:23.962\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1217 | Train score: 0.9568 | Val loss: 0.1080 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:43:26.487\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1091 | Train score: 0.9568 | Val loss: 0.1090 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 23:43:29.099\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1170 | Train score: 0.9630 | Val loss: 0.1117 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:43:31.688\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1218 | Train score: 0.9568 | Val loss: 0.1164 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:43:34.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1531 | Train score: 0.9630 | Val loss: 0.1175 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:43:36.719\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1085 | Train score: 0.9568 | Val loss: 0.1171 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:43:39.315\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0828 | Train score: 0.9753 | Val loss: 0.1158 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:43:41.786\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0985 | Train score: 0.9630 | Val loss: 0.1148 | Val score: 0.9653\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " 1 \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.946         0.000           0.000          0.000        0.000       0.000         0.500        0.000    0.000   0.000         0.000        0.000\n",
      "MedPFNClassifier                      0.941         0.004           0.167          0.211        0.067       0.082         0.822        0.069    0.094   0.116         0.297        0.011\n",
      "MedPFNClassifier                      0.949         0.011           0.513          0.397        0.217       0.150         0.890        0.046    0.290   0.200         1.926        0.170\n",
      "MedPFNClassifier                      0.949         0.011           0.600          0.169        0.433       0.153         0.892        0.051    0.466   0.097        13.004        0.472\n",
      "RandomForestClassifier                0.943         0.006           0.240          0.329        0.100       0.133         0.877        0.075    0.130   0.164         0.199        0.014\n",
      "LogisticRegressionClassifier          0.934         0.016           0.335          0.244        0.200       0.125         0.756        0.097    0.245   0.159         0.008        0.001\n",
      "TabPFNClassifier                      0.945         0.015           0.423          0.378        0.183       0.138         0.893        0.048    0.250   0.199         2.915        0.231\n",
      "TabForestPFNClassifier                0.931         0.025           0.379          0.301        0.300       0.180         0.875        0.036    0.317   0.197        23.708        2.885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 23:47:51.978\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1266 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:47:54.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1073 | Train score: 0.9630 | Val loss: 0.1258 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:47:57.209\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1581 | Train score: 0.9383 | Val loss: 0.1229 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:47:59.518\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0755 | Train score: 0.9630 | Val loss: 0.1236 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:01.852\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1184 | Train score: 0.9568 | Val loss: 0.1239 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:04.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1333 | Train score: 0.9506 | Val loss: 0.1209 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:06.417\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1058 | Train score: 0.9630 | Val loss: 0.1185 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:08.678\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1311 | Train score: 0.9506 | Val loss: 0.1173 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:10.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1022 | Train score: 0.9568 | Val loss: 0.1173 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:13.222\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1083 | Train score: 0.9691 | Val loss: 0.1175 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:15.633\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0979 | Train score: 0.9691 | Val loss: 0.1176 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:17.794\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1381 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:20.150\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1223 | Train score: 0.9383 | Val loss: 0.1450 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:22.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1094 | Train score: 0.9444 | Val loss: 0.1448 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:24.790\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1143 | Train score: 0.9568 | Val loss: 0.1322 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:27.140\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1613 | Train score: 0.9506 | Val loss: 0.1157 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:29.508\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0997 | Train score: 0.9691 | Val loss: 0.1104 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:31.956\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1304 | Train score: 0.9568 | Val loss: 0.1078 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:34.447\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1306 | Train score: 0.9568 | Val loss: 0.1070 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:37.013\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1088 | Train score: 0.9506 | Val loss: 0.1075 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:39.371\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1063 | Train score: 0.9630 | Val loss: 0.1083 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:41.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1048 | Train score: 0.9568 | Val loss: 0.1089 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:43.868\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1083 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:46.184\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1239 | Train score: 0.9568 | Val loss: 0.1040 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:48.635\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1143 | Train score: 0.9568 | Val loss: 0.1053 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:51.024\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1497 | Train score: 0.9568 | Val loss: 0.1031 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:53.242\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0891 | Train score: 0.9815 | Val loss: 0.1008 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:55.481\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0992 | Train score: 0.9630 | Val loss: 0.0987 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:57.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1750 | Train score: 0.9383 | Val loss: 0.0975 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:00.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1404 | Train score: 0.9691 | Val loss: 0.0977 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:02.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1583 | Train score: 0.9568 | Val loss: 0.0990 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:04.718\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0687 | Train score: 0.9815 | Val loss: 0.0991 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:07.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0855 | Train score: 0.9691 | Val loss: 0.0991 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:09.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1193 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:11.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1512 | Train score: 0.9506 | Val loss: 0.1241 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:14.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1177 | Train score: 0.9444 | Val loss: 0.1172 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:16.961\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1071 | Train score: 0.9444 | Val loss: 0.1129 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:19.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1422 | Train score: 0.9259 | Val loss: 0.1107 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:23.310\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0876 | Train score: 0.9568 | Val loss: 0.1085 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:25.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1264 | Train score: 0.9630 | Val loss: 0.1062 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:28.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0853 | Train score: 0.9630 | Val loss: 0.1064 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:30.975\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0836 | Train score: 0.9630 | Val loss: 0.1146 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:33.373\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1003 | Train score: 0.9691 | Val loss: 0.1129 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:35.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1259 | Train score: 0.9568 | Val loss: 0.1072 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:38.076\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1161 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:40.674\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1058 | Train score: 0.9568 | Val loss: 0.1044 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:43.091\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1297 | Train score: 0.9568 | Val loss: 0.1040 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:45.574\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0922 | Train score: 0.9506 | Val loss: 0.1025 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:48.148\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1460 | Train score: 0.9630 | Val loss: 0.1008 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:50.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0879 | Train score: 0.9753 | Val loss: 0.0999 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:53.013\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1360 | Train score: 0.9691 | Val loss: 0.0999 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:54.756\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0971 | Train score: 0.9815 | Val loss: 0.1003 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:56.730\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0964 | Train score: 0.9568 | Val loss: 0.1021 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:58.767\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1222 | Train score: 0.9630 | Val loss: 0.1033 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:00.845\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0924 | Train score: 0.9630 | Val loss: 0.1041 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:02.549\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1456 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:04.237\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1104 | Train score: 0.9444 | Val loss: 0.1548 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:05.968\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1249 | Train score: 0.9691 | Val loss: 0.1660 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:07.799\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1004 | Train score: 0.9568 | Val loss: 0.1758 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:09.537\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0685 | Train score: 0.9815 | Val loss: 0.1921 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:11.114\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1866 | Train score: 0.9506 | Val loss: 0.1834 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:12.744\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0779 | Train score: 0.9691 | Val loss: 0.1797 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:14.370\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0963 | Train score: 0.9630 | Val loss: 0.1787 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:15.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0872 | Train score: 0.9691 | Val loss: 0.1808 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:17.739\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0856 | Train score: 0.9815 | Val loss: 0.1845 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:19.702\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1534 | Train score: 0.9691 | Val loss: 0.1868 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:21.673\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1563 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:23.778\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1429 | Train score: 0.9444 | Val loss: 0.1495 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:25.679\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1204 | Train score: 0.9630 | Val loss: 0.1461 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:27.740\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1319 | Train score: 0.9630 | Val loss: 0.1450 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:29.737\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0987 | Train score: 0.9630 | Val loss: 0.1495 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:31.785\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1049 | Train score: 0.9691 | Val loss: 0.1558 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:33.748\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1061 | Train score: 0.9630 | Val loss: 0.1598 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:35.543\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1245 | Train score: 0.9506 | Val loss: 0.1536 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:37.373\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0759 | Train score: 0.9815 | Val loss: 0.1535 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:39.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1049 | Train score: 0.9753 | Val loss: 0.1538 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:41.148\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0890 | Train score: 0.9691 | Val loss: 0.1529 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:42.878\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1144 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:44.584\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1489 | Train score: 0.9630 | Val loss: 0.1167 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:46.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1477 | Train score: 0.9691 | Val loss: 0.1194 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:47.840\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1408 | Train score: 0.9444 | Val loss: 0.1170 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:49.425\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1414 | Train score: 0.9568 | Val loss: 0.1172 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:51.170\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1319 | Train score: 0.9753 | Val loss: 0.1158 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:52.839\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0728 | Train score: 0.9815 | Val loss: 0.1163 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:54.482\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0955 | Train score: 0.9630 | Val loss: 0.1197 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:56.169\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1128 | Train score: 0.9630 | Val loss: 0.1245 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:57.879\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1459 | Train score: 0.9506 | Val loss: 0.1299 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:59.506\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0754 | Train score: 0.9753 | Val loss: 0.1345 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:51:01.266\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1631 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:51:02.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1307 | Train score: 0.9506 | Val loss: 0.1657 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:51:04.358\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1570 | Train score: 0.9444 | Val loss: 0.1608 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:51:05.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1081 | Train score: 0.9630 | Val loss: 0.1619 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:51:07.549\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1369 | Train score: 0.9506 | Val loss: 0.1627 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:51:09.209\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1211 | Train score: 0.9506 | Val loss: 0.1644 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:51:10.943\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1188 | Train score: 0.9383 | Val loss: 0.1666 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:51:12.543\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1364 | Train score: 0.9568 | Val loss: 0.1665 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:51:14.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1645 | Train score: 0.9444 | Val loss: 0.1624 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:51:16.294\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1154 | Train score: 0.9630 | Val loss: 0.1591 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:51:17.955\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1059 | Train score: 0.9691 | Val loss: 0.1566 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:51:19.814\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1367 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:51:21.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1871 | Train score: 0.9444 | Val loss: 0.1487 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:51:23.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1525 | Train score: 0.9444 | Val loss: 0.1420 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:51:25.571\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1316 | Train score: 0.9444 | Val loss: 0.1316 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:51:27.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1205 | Train score: 0.9815 | Val loss: 0.1221 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:51:29.377\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1884 | Train score: 0.9506 | Val loss: 0.1188 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:51:31.193\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1168 | Train score: 0.9630 | Val loss: 0.1170 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:51:32.902\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1479 | Train score: 0.9506 | Val loss: 0.1167 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:51:34.581\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1279 | Train score: 0.9630 | Val loss: 0.1173 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:51:36.121\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1128 | Train score: 0.9630 | Val loss: 0.1180 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:51:37.704\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1228 | Train score: 0.9630 | Val loss: 0.1190 | Val score: 0.9653\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " 5 \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.946         0.000           0.000          0.000        0.000       0.000         0.500        0.000    0.000   0.000         0.000        0.000\n",
      "MedPFNClassifier                      0.945         0.004           0.000          0.000        0.000       0.000         0.787        0.056    0.000   0.000         0.417        0.043\n",
      "MedPFNClassifier                      0.946         0.011           0.483          0.410        0.150       0.117         0.848        0.051    0.215   0.161         2.217        0.073\n",
      "MedPFNClassifier                      0.953         0.011           0.611          0.191        0.417       0.154         0.839        0.054    0.477   0.127        17.612        1.621\n",
      "RandomForestClassifier                0.938         0.010           0.100          0.200        0.033       0.067         0.858        0.085    0.050   0.100         0.214        0.014\n",
      "LogisticRegressionClassifier          0.942         0.013           0.390          0.253        0.250       0.171         0.744        0.119    0.301   0.202         0.010        0.001\n",
      "TabPFNClassifier                      0.941         0.012           0.323          0.260        0.150       0.117         0.844        0.060    0.200   0.157         3.642        0.063\n",
      "TabForestPFNClassifier                0.931         0.027           0.384          0.268        0.283       0.183         0.836        0.080    0.314   0.210        22.460        3.603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 23:54:38.148\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1831 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:54:40.109\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1067 | Train score: 0.9630 | Val loss: 0.1907 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 23:54:42.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0974 | Train score: 0.9630 | Val loss: 0.1916 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 23:54:44.863\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0719 | Train score: 0.9753 | Val loss: 0.2005 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 23:54:46.814\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0878 | Train score: 0.9630 | Val loss: 0.2146 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:54:49.128\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1039 | Train score: 0.9753 | Val loss: 0.2154 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:54:51.331\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1057 | Train score: 0.9630 | Val loss: 0.2086 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:54:53.227\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0526 | Train score: 0.9815 | Val loss: 0.2107 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:54:55.012\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0506 | Train score: 0.9815 | Val loss: 0.2192 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:54:56.804\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0717 | Train score: 0.9691 | Val loss: 0.2276 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 23:54:58.684\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0520 | Train score: 0.9815 | Val loss: 0.2437 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:00.515\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1437 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:02.458\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1443 | Train score: 0.9444 | Val loss: 0.1461 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:04.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1349 | Train score: 0.9568 | Val loss: 0.1478 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:05.895\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1121 | Train score: 0.9630 | Val loss: 0.1511 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:07.571\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0964 | Train score: 0.9691 | Val loss: 0.1534 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:09.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0896 | Train score: 0.9815 | Val loss: 0.1531 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:10.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1189 | Train score: 0.9630 | Val loss: 0.1466 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:12.738\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1856 | Train score: 0.9444 | Val loss: 0.1395 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:14.326\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0830 | Train score: 0.9753 | Val loss: 0.1370 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:16.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1056 | Train score: 0.9630 | Val loss: 0.1363 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:17.879\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0916 | Train score: 0.9753 | Val loss: 0.1358 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:19.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1016 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:21.745\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1810 | Train score: 0.9506 | Val loss: 0.1125 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:23.658\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1443 | Train score: 0.9444 | Val loss: 0.1051 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:25.762\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1484 | Train score: 0.9444 | Val loss: 0.0980 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:27.629\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1640 | Train score: 0.9444 | Val loss: 0.0949 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:29.579\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1089 | Train score: 0.9444 | Val loss: 0.0889 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:31.545\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1366 | Train score: 0.9444 | Val loss: 0.0857 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:33.409\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1042 | Train score: 0.9630 | Val loss: 0.0835 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:35.047\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1272 | Train score: 0.9630 | Val loss: 0.0832 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:36.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1105 | Train score: 0.9630 | Val loss: 0.0847 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:38.936\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1250 | Train score: 0.9753 | Val loss: 0.0858 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:40.542\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1761 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:42.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0979 | Train score: 0.9506 | Val loss: 0.2008 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:43.673\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1216 | Train score: 0.9506 | Val loss: 0.1995 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:45.322\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0883 | Train score: 0.9568 | Val loss: 0.2014 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:47.062\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0934 | Train score: 0.9753 | Val loss: 0.2026 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:48.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1059 | Train score: 0.9753 | Val loss: 0.1942 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:50.414\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0588 | Train score: 0.9753 | Val loss: 0.1904 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:51.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1068 | Train score: 0.9691 | Val loss: 0.1746 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:53.640\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0951 | Train score: 0.9753 | Val loss: 0.1628 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:55.497\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0683 | Train score: 0.9753 | Val loss: 0.1577 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:57.364\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0993 | Train score: 0.9691 | Val loss: 0.1559 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:59.041\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1110 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:00.864\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1616 | Train score: 0.9383 | Val loss: 0.1136 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:03.755\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1394 | Train score: 0.9383 | Val loss: 0.1088 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:05.412\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1522 | Train score: 0.9630 | Val loss: 0.1056 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:07.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1333 | Train score: 0.9691 | Val loss: 0.1029 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:08.515\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1228 | Train score: 0.9568 | Val loss: 0.0992 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:10.039\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1084 | Train score: 0.9506 | Val loss: 0.0966 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:11.771\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1079 | Train score: 0.9630 | Val loss: 0.0929 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:13.349\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1107 | Train score: 0.9568 | Val loss: 0.0883 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:15.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0828 | Train score: 0.9568 | Val loss: 0.0871 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:17.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1015 | Train score: 0.9691 | Val loss: 0.0903 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:19.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1131 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:21.413\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1324 | Train score: 0.9506 | Val loss: 0.1108 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:23.317\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1087 | Train score: 0.9630 | Val loss: 0.1123 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:25.214\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1438 | Train score: 0.9506 | Val loss: 0.1102 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:26.980\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1052 | Train score: 0.9753 | Val loss: 0.1073 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:28.822\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1417 | Train score: 0.9568 | Val loss: 0.1066 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:30.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0890 | Train score: 0.9815 | Val loss: 0.1077 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:32.827\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0849 | Train score: 0.9691 | Val loss: 0.1098 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:35.210\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0695 | Train score: 0.9877 | Val loss: 0.1123 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:37.827\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0944 | Train score: 0.9630 | Val loss: 0.1145 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:40.961\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1084 | Train score: 0.9630 | Val loss: 0.1168 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:46.942\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1306 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:51.305\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1425 | Train score: 0.9568 | Val loss: 0.1242 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:53.436\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1146 | Train score: 0.9568 | Val loss: 0.1230 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:55.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1372 | Train score: 0.9506 | Val loss: 0.1242 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:57.411\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1552 | Train score: 0.9630 | Val loss: 0.1230 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:59.294\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1141 | Train score: 0.9630 | Val loss: 0.1230 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:57:01.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1265 | Train score: 0.9691 | Val loss: 0.1233 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:57:05.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1112 | Train score: 0.9630 | Val loss: 0.1246 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:57:10.049\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0916 | Train score: 0.9753 | Val loss: 0.1267 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:57:13.408\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1284 | Train score: 0.9691 | Val loss: 0.1295 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:57:17.235\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1138 | Train score: 0.9630 | Val loss: 0.1318 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:57:20.183\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1298 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:57:23.029\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1763 | Train score: 0.9444 | Val loss: 0.1432 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:57:25.806\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1473 | Train score: 0.9444 | Val loss: 0.1318 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:57:28.730\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1351 | Train score: 0.9383 | Val loss: 0.1286 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:57:31.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1345 | Train score: 0.9568 | Val loss: 0.1291 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:57:34.001\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1271 | Train score: 0.9383 | Val loss: 0.1328 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:57:36.693\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1199 | Train score: 0.9691 | Val loss: 0.1377 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:57:39.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1156 | Train score: 0.9691 | Val loss: 0.1445 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:57:42.644\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1029 | Train score: 0.9506 | Val loss: 0.1482 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:57:45.050\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1515 | Train score: 0.9568 | Val loss: 0.1461 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 23:57:47.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1459 | Train score: 0.9444 | Val loss: 0.1419 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 23:57:48.951\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1571 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:57:51.085\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1275 | Train score: 0.9321 | Val loss: 0.1602 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:57:53.158\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1083 | Train score: 0.9568 | Val loss: 0.1804 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:57:55.122\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1255 | Train score: 0.9568 | Val loss: 0.1804 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:57:57.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1774 | Train score: 0.9568 | Val loss: 0.1679 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:57:59.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1240 | Train score: 0.9630 | Val loss: 0.1603 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:58:00.514\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1082 | Train score: 0.9506 | Val loss: 0.1588 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:58:02.157\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0964 | Train score: 0.9568 | Val loss: 0.1617 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:58:03.698\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0666 | Train score: 0.9753 | Val loss: 0.1693 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:58:05.241\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1344 | Train score: 0.9691 | Val loss: 0.1744 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:58:07.083\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1093 | Train score: 0.9506 | Val loss: 0.1740 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:58:08.688\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1986 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:58:10.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1163 | Train score: 0.9630 | Val loss: 0.2157 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:58:12.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0906 | Train score: 0.9630 | Val loss: 0.2353 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:58:13.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0808 | Train score: 0.9815 | Val loss: 0.2629 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:58:15.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1805 | Train score: 0.9630 | Val loss: 0.2311 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:58:16.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0938 | Train score: 0.9568 | Val loss: 0.2095 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:58:18.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0885 | Train score: 0.9815 | Val loss: 0.2021 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:58:19.965\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1233 | Train score: 0.9630 | Val loss: 0.1982 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:58:21.654\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0899 | Train score: 0.9691 | Val loss: 0.2087 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:58:23.327\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0857 | Train score: 0.9691 | Val loss: 0.2012 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:58:24.858\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0839 | Train score: 0.9753 | Val loss: 0.1929 | Val score: 0.9406\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " 10 \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.946         0.000           0.000          0.000        0.000       0.000         0.500        0.000    0.000   0.000         0.000        0.000\n",
      "MedPFNClassifier                      0.946         0.003           0.000          0.000        0.000       0.000         0.781        0.066    0.000   0.000         0.285        0.035\n",
      "MedPFNClassifier                      0.941         0.017           0.383          0.409        0.117       0.130         0.839        0.061    0.171   0.181         1.698        0.127\n",
      "MedPFNClassifier                      0.951         0.011           0.503          0.194        0.433       0.238         0.837        0.066    0.450   0.195        12.035        0.735\n",
      "RandomForestClassifier                0.941         0.006           0.158          0.206        0.067       0.082         0.860        0.084    0.092   0.114         0.210        0.013\n",
      "LogisticRegressionClassifier          0.939         0.011           0.345          0.216        0.267       0.186         0.728        0.059    0.299   0.198         0.008        0.001\n",
      "TabPFNClassifier                      0.942         0.013           0.273          0.350        0.117       0.130         0.847        0.065    0.154   0.175         2.907        0.220\n",
      "TabForestPFNClassifier                0.933         0.025           0.417          0.271        0.333       0.167         0.857        0.056    0.355   0.191        22.537        5.077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:01:00.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1494 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:01.687\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1376 | Train score: 0.9383 | Val loss: 0.1542 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:03.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1391 | Train score: 0.9444 | Val loss: 0.1489 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:04.719\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1195 | Train score: 0.9444 | Val loss: 0.1482 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:06.172\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1755 | Train score: 0.9506 | Val loss: 0.1460 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:07.634\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1439 | Train score: 0.9568 | Val loss: 0.1447 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:09.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1060 | Train score: 0.9630 | Val loss: 0.1442 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:10.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1022 | Train score: 0.9630 | Val loss: 0.1441 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:12.374\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1206 | Train score: 0.9506 | Val loss: 0.1439 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:13.905\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0734 | Train score: 0.9753 | Val loss: 0.1438 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:15.372\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1123 | Train score: 0.9630 | Val loss: 0.1437 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:16.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1559 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:18.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1565 | Train score: 0.9444 | Val loss: 0.1500 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:19.921\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1686 | Train score: 0.9568 | Val loss: 0.1522 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:21.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1809 | Train score: 0.9383 | Val loss: 0.1494 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:22.960\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1890 | Train score: 0.9444 | Val loss: 0.1482 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:24.391\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1367 | Train score: 0.9506 | Val loss: 0.1470 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:25.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1320 | Train score: 0.9691 | Val loss: 0.1467 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:27.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1434 | Train score: 0.9506 | Val loss: 0.1434 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:28.861\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0979 | Train score: 0.9630 | Val loss: 0.1428 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:30.399\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1564 | Train score: 0.9568 | Val loss: 0.1438 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:31.864\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1343 | Train score: 0.9630 | Val loss: 0.1471 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:33.405\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1630 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:34.858\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1469 | Train score: 0.9444 | Val loss: 0.1622 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:36.279\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1516 | Train score: 0.9568 | Val loss: 0.1649 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:37.782\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1002 | Train score: 0.9691 | Val loss: 0.1726 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:39.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1993 | Train score: 0.9568 | Val loss: 0.1695 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:40.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1188 | Train score: 0.9444 | Val loss: 0.1677 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:42.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0814 | Train score: 0.9815 | Val loss: 0.1685 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:43.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1176 | Train score: 0.9691 | Val loss: 0.1672 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:45.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1041 | Train score: 0.9753 | Val loss: 0.1662 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:46.485\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1334 | Train score: 0.9691 | Val loss: 0.1635 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:47.945\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1357 | Train score: 0.9568 | Val loss: 0.1600 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:49.485\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1761 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:50.984\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1375 | Train score: 0.9444 | Val loss: 0.1842 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:52.577\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1469 | Train score: 0.9568 | Val loss: 0.1828 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:54.205\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1450 | Train score: 0.9506 | Val loss: 0.1788 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:55.755\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1345 | Train score: 0.9444 | Val loss: 0.1766 | Val score: 0.9307\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:57.332\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1418 | Train score: 0.9630 | Val loss: 0.1760 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:58.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0947 | Train score: 0.9691 | Val loss: 0.1775 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:00.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1666 | Train score: 0.9568 | Val loss: 0.1783 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:01.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1339 | Train score: 0.9568 | Val loss: 0.1799 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:03.628\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0893 | Train score: 0.9753 | Val loss: 0.1828 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:05.188\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1152 | Train score: 0.9568 | Val loss: 0.1868 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:06.751\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1467 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:08.294\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1292 | Train score: 0.9444 | Val loss: 0.1366 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:09.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1224 | Train score: 0.9630 | Val loss: 0.1387 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:11.368\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1684 | Train score: 0.9568 | Val loss: 0.1366 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:12.883\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1449 | Train score: 0.9506 | Val loss: 0.1331 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:14.410\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1549 | Train score: 0.9444 | Val loss: 0.1317 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:15.921\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1146 | Train score: 0.9691 | Val loss: 0.1315 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:17.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1566 | Train score: 0.9506 | Val loss: 0.1324 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:18.941\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1605 | Train score: 0.9506 | Val loss: 0.1341 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:20.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1193 | Train score: 0.9568 | Val loss: 0.1339 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:22.164\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1399 | Train score: 0.9568 | Val loss: 0.1315 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:23.749\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1591 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:25.548\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1447 | Train score: 0.9321 | Val loss: 0.1537 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:27.096\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1220 | Train score: 0.9444 | Val loss: 0.1597 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:28.578\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1316 | Train score: 0.9383 | Val loss: 0.1594 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:30.087\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1211 | Train score: 0.9568 | Val loss: 0.1581 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:31.567\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1002 | Train score: 0.9444 | Val loss: 0.1586 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:33.037\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1297 | Train score: 0.9506 | Val loss: 0.1581 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:34.526\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0984 | Train score: 0.9815 | Val loss: 0.1578 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:36.010\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1062 | Train score: 0.9691 | Val loss: 0.1588 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:37.476\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1082 | Train score: 0.9630 | Val loss: 0.1599 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:38.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1155 | Train score: 0.9630 | Val loss: 0.1615 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:40.498\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1707 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:41.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1477 | Train score: 0.9444 | Val loss: 0.1775 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:43.487\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1617 | Train score: 0.9568 | Val loss: 0.1770 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:44.942\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1329 | Train score: 0.9444 | Val loss: 0.1754 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:46.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1148 | Train score: 0.9568 | Val loss: 0.1765 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:48.054\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1059 | Train score: 0.9691 | Val loss: 0.1788 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:49.489\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1207 | Train score: 0.9568 | Val loss: 0.1795 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:50.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1364 | Train score: 0.9568 | Val loss: 0.1804 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:52.409\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1371 | Train score: 0.9568 | Val loss: 0.1751 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:54.035\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1492 | Train score: 0.9630 | Val loss: 0.1691 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:55.455\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1415 | Train score: 0.9630 | Val loss: 0.1655 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:57.021\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1553 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:58.689\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1535 | Train score: 0.9444 | Val loss: 0.1384 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:00.429\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1421 | Train score: 0.9506 | Val loss: 0.1397 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:02.065\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1748 | Train score: 0.9506 | Val loss: 0.1360 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:03.794\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1988 | Train score: 0.9630 | Val loss: 0.1358 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:05.437\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1646 | Train score: 0.9506 | Val loss: 0.1402 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:07.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1281 | Train score: 0.9630 | Val loss: 0.1427 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:08.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1080 | Train score: 0.9753 | Val loss: 0.1409 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:10.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1466 | Train score: 0.9506 | Val loss: 0.1391 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:12.124\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1039 | Train score: 0.9691 | Val loss: 0.1361 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:13.817\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1365 | Train score: 0.9568 | Val loss: 0.1343 | Val score: 0.9455\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:03:15.397\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1587 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:16.845\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1428 | Train score: 0.9444 | Val loss: 0.1606 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:18.329\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1305 | Train score: 0.9568 | Val loss: 0.1615 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:19.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1217 | Train score: 0.9568 | Val loss: 0.1633 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:21.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1064 | Train score: 0.9630 | Val loss: 0.1661 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:22.749\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0970 | Train score: 0.9691 | Val loss: 0.1703 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:24.247\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1575 | Train score: 0.9506 | Val loss: 0.1708 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:25.845\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1815 | Train score: 0.9568 | Val loss: 0.1679 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:27.523\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1488 | Train score: 0.9383 | Val loss: 0.1648 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:29.008\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1008 | Train score: 0.9630 | Val loss: 0.1626 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:30.658\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1525 | Train score: 0.9568 | Val loss: 0.1602 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:32.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1753 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:33.710\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1354 | Train score: 0.9568 | Val loss: 0.1793 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:35.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1567 | Train score: 0.9383 | Val loss: 0.1760 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:36.761\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1007 | Train score: 0.9568 | Val loss: 0.1776 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:38.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1672 | Train score: 0.9444 | Val loss: 0.1748 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:39.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1568 | Train score: 0.9506 | Val loss: 0.1725 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:41.250\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1095 | Train score: 0.9630 | Val loss: 0.1723 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:42.727\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1102 | Train score: 0.9691 | Val loss: 0.1734 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:44.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0944 | Train score: 0.9691 | Val loss: 0.1772 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:45.714\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1221 | Train score: 0.9506 | Val loss: 0.1814 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:47.286\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1074 | Train score: 0.9630 | Val loss: 0.1850 | Val score: 0.9356\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " 25 \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.946         0.000           0.000          0.000        0.000       0.000         0.500        0.000    0.000   0.000         0.000        0.000\n",
      "MedPFNClassifier                      0.944         0.008           0.100          0.300        0.017       0.050         0.801        0.101    0.029   0.086         0.257        0.010\n",
      "MedPFNClassifier                      0.941         0.009           0.300          0.384        0.083       0.083         0.854        0.073    0.122   0.125         1.584        0.019\n",
      "MedPFNClassifier                      0.941         0.020           0.536          0.268        0.350       0.117         0.835        0.095    0.396   0.116        10.326        0.102\n",
      "RandomForestClassifier                0.947         0.006           0.300          0.458        0.050       0.076         0.832        0.081    0.086   0.131         0.226        0.015\n",
      "LogisticRegressionClassifier          0.940         0.011           0.333          0.253        0.217       0.150         0.712        0.074    0.260   0.184         0.007        0.000\n",
      "TabPFNClassifier                      0.944         0.007           0.267          0.389        0.067       0.082         0.864        0.063    0.102   0.126         2.423        0.018\n",
      "TabForestPFNClassifier                0.938         0.020           0.395          0.279        0.283       0.150         0.872        0.049    0.323   0.191        16.585        0.590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:06:22.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1916 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:23.671\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1435 | Train score: 0.9444 | Val loss: 0.1974 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:25.163\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1660 | Train score: 0.9506 | Val loss: 0.1907 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:26.727\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1576 | Train score: 0.9568 | Val loss: 0.1866 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:28.260\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1767 | Train score: 0.9444 | Val loss: 0.1817 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:29.788\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1356 | Train score: 0.9444 | Val loss: 0.1812 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:31.335\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1133 | Train score: 0.9630 | Val loss: 0.1820 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:32.809\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1630 | Train score: 0.9506 | Val loss: 0.1822 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:34.316\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1301 | Train score: 0.9444 | Val loss: 0.1833 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:35.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1551 | Train score: 0.9444 | Val loss: 0.1845 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:37.290\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1482 | Train score: 0.9444 | Val loss: 0.1858 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:38.852\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1769 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:40.324\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1579 | Train score: 0.9383 | Val loss: 0.1732 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:41.799\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1381 | Train score: 0.9506 | Val loss: 0.1766 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:43.234\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1434 | Train score: 0.9506 | Val loss: 0.1754 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:44.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1627 | Train score: 0.9444 | Val loss: 0.1728 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:46.157\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1728 | Train score: 0.9506 | Val loss: 0.1658 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:47.596\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1215 | Train score: 0.9568 | Val loss: 0.1598 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:49.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1718 | Train score: 0.9568 | Val loss: 0.1538 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:50.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1431 | Train score: 0.9568 | Val loss: 0.1503 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:51.973\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1358 | Train score: 0.9506 | Val loss: 0.1502 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:53.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1459 | Train score: 0.9444 | Val loss: 0.1510 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:54.961\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1968 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:56.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1343 | Train score: 0.9444 | Val loss: 0.2157 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:57.957\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1671 | Train score: 0.9321 | Val loss: 0.2114 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:59.440\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1250 | Train score: 0.9506 | Val loss: 0.2149 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:00.982\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1238 | Train score: 0.9506 | Val loss: 0.2173 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:02.448\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1865 | Train score: 0.9321 | Val loss: 0.2079 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:03.958\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1551 | Train score: 0.9321 | Val loss: 0.1980 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:05.471\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1512 | Train score: 0.9506 | Val loss: 0.1900 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:07.079\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1272 | Train score: 0.9568 | Val loss: 0.1864 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:08.594\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1180 | Train score: 0.9383 | Val loss: 0.1852 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:10.149\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1112 | Train score: 0.9506 | Val loss: 0.1857 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:11.703\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1550 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:13.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1884 | Train score: 0.9506 | Val loss: 0.1444 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:14.600\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1631 | Train score: 0.9383 | Val loss: 0.1375 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:16.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1333 | Train score: 0.9444 | Val loss: 0.1370 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:17.500\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1520 | Train score: 0.9383 | Val loss: 0.1384 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:18.995\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1444 | Train score: 0.9383 | Val loss: 0.1405 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:20.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1277 | Train score: 0.9444 | Val loss: 0.1471 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:22.015\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1281 | Train score: 0.9691 | Val loss: 0.1492 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:23.601\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1529 | Train score: 0.9506 | Val loss: 0.1503 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:25.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1651 | Train score: 0.9506 | Val loss: 0.1493 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:26.589\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1333 | Train score: 0.9506 | Val loss: 0.1461 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:28.121\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1311 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:29.594\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1590 | Train score: 0.9444 | Val loss: 0.1186 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:31.203\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1355 | Train score: 0.9444 | Val loss: 0.1135 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:32.633\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1830 | Train score: 0.9383 | Val loss: 0.1125 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:34.092\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1646 | Train score: 0.9506 | Val loss: 0.1133 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:35.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1360 | Train score: 0.9506 | Val loss: 0.1138 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:37.140\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1005 | Train score: 0.9506 | Val loss: 0.1135 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:38.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1745 | Train score: 0.9383 | Val loss: 0.1139 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:40.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.2024 | Train score: 0.9383 | Val loss: 0.1159 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:41.532\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1371 | Train score: 0.9444 | Val loss: 0.1181 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:43.027\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1233 | Train score: 0.9568 | Val loss: 0.1207 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:44.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1523 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:46.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1520 | Train score: 0.9444 | Val loss: 0.1496 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:47.533\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1457 | Train score: 0.9506 | Val loss: 0.1513 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:49.000\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1489 | Train score: 0.9568 | Val loss: 0.1527 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:50.427\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1760 | Train score: 0.9444 | Val loss: 0.1515 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:51.883\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1456 | Train score: 0.9506 | Val loss: 0.1499 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:53.344\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1305 | Train score: 0.9568 | Val loss: 0.1479 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:54.804\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1426 | Train score: 0.9506 | Val loss: 0.1468 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:56.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1513 | Train score: 0.9568 | Val loss: 0.1465 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:57.725\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1247 | Train score: 0.9506 | Val loss: 0.1464 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:59.176\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1595 | Train score: 0.9568 | Val loss: 0.1465 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:00.745\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1884 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:02.169\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1539 | Train score: 0.9444 | Val loss: 0.1927 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:03.597\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1309 | Train score: 0.9444 | Val loss: 0.2005 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:05.037\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1417 | Train score: 0.9568 | Val loss: 0.1928 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:06.587\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1678 | Train score: 0.9506 | Val loss: 0.1835 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:08.063\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1221 | Train score: 0.9383 | Val loss: 0.1823 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:09.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1334 | Train score: 0.9444 | Val loss: 0.1825 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:11.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1233 | Train score: 0.9506 | Val loss: 0.1845 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:12.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1309 | Train score: 0.9506 | Val loss: 0.1886 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:14.014\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1082 | Train score: 0.9691 | Val loss: 0.1947 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:15.477\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1420 | Train score: 0.9506 | Val loss: 0.2025 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:17.067\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1455 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:18.731\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1580 | Train score: 0.9444 | Val loss: 0.1407 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:20.301\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1793 | Train score: 0.9444 | Val loss: 0.1391 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:21.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1342 | Train score: 0.9506 | Val loss: 0.1375 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:23.431\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1418 | Train score: 0.9568 | Val loss: 0.1361 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:25.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1244 | Train score: 0.9568 | Val loss: 0.1353 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:26.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1907 | Train score: 0.9321 | Val loss: 0.1338 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:28.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1361 | Train score: 0.9506 | Val loss: 0.1326 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:29.715\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1803 | Train score: 0.9630 | Val loss: 0.1321 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:31.268\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1408 | Train score: 0.9506 | Val loss: 0.1324 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:32.726\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1768 | Train score: 0.9444 | Val loss: 0.1332 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:34.284\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1685 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:35.855\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1170 | Train score: 0.9444 | Val loss: 0.1695 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:37.490\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2347 | Train score: 0.9444 | Val loss: 0.1612 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:38.972\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1373 | Train score: 0.9506 | Val loss: 0.1571 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:40.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1318 | Train score: 0.9630 | Val loss: 0.1540 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:42.050\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.2079 | Train score: 0.9383 | Val loss: 0.1521 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:43.654\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1378 | Train score: 0.9383 | Val loss: 0.1515 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:45.234\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1390 | Train score: 0.9444 | Val loss: 0.1510 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:46.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1435 | Train score: 0.9444 | Val loss: 0.1506 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:48.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1273 | Train score: 0.9444 | Val loss: 0.1506 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:50.048\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1585 | Train score: 0.9444 | Val loss: 0.1506 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:51.596\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1860 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:53.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1604 | Train score: 0.9444 | Val loss: 0.1920 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:54.521\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1327 | Train score: 0.9506 | Val loss: 0.1942 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:56.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1793 | Train score: 0.9444 | Val loss: 0.1908 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:57.534\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1247 | Train score: 0.9568 | Val loss: 0.1906 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:59.022\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1349 | Train score: 0.9444 | Val loss: 0.1909 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:09:00.500\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1705 | Train score: 0.9444 | Val loss: 0.1879 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:09:01.979\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1779 | Train score: 0.9506 | Val loss: 0.1843 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:09:03.428\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1309 | Train score: 0.9506 | Val loss: 0.1833 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:09:04.918\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1205 | Train score: 0.9568 | Val loss: 0.1842 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:09:06.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1681 | Train score: 0.9444 | Val loss: 0.1845 | Val score: 0.9406\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " 50 \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.946         0.000           0.000          0.000        0.000       0.000         0.500        0.000    0.000   0.000         0.000        0.000\n",
      "MedPFNClassifier                      0.942         0.004           0.183          0.229        0.067       0.082         0.790        0.165    0.097   0.119         0.247        0.009\n",
      "MedPFNClassifier                      0.942         0.004           0.217          0.224        0.083       0.083         0.828        0.111    0.119   0.120         1.579        0.030\n",
      "MedPFNClassifier                      0.942         0.007           0.218          0.236        0.117       0.150         0.817        0.125    0.147   0.172        10.249        0.055\n",
      "RandomForestClassifier                0.947         0.005           0.200          0.400        0.033       0.067         0.820        0.092    0.057   0.114         0.273        0.022\n",
      "LogisticRegressionClassifier          0.931         0.008           0.199          0.201        0.183       0.203         0.576        0.208    0.187   0.197         0.007        0.001\n",
      "TabPFNClassifier                      0.943         0.004           0.067          0.133        0.033       0.067         0.853        0.064    0.044   0.089         2.423        0.030\n",
      "TabForestPFNClassifier                0.936         0.009           0.190          0.196        0.100       0.111         0.862        0.034    0.128   0.134        16.312        0.392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:11:41.794\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1775 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:11:43.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1906 | Train score: 0.9383 | Val loss: 0.1698 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:11:44.746\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1519 | Train score: 0.9506 | Val loss: 0.1680 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:11:46.201\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1939 | Train score: 0.9506 | Val loss: 0.1666 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:11:47.689\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1635 | Train score: 0.9506 | Val loss: 0.1668 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:11:49.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1762 | Train score: 0.9444 | Val loss: 0.1694 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:11:50.633\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1504 | Train score: 0.9630 | Val loss: 0.1718 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:11:52.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1545 | Train score: 0.9506 | Val loss: 0.1751 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:11:53.768\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1315 | Train score: 0.9506 | Val loss: 0.1788 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:11:55.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1809 | Train score: 0.9444 | Val loss: 0.1815 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:11:56.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1357 | Train score: 0.9444 | Val loss: 0.1817 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:11:58.399\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1610 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:00.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1641 | Train score: 0.9383 | Val loss: 0.1673 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:01.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1566 | Train score: 0.9444 | Val loss: 0.1659 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:03.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1581 | Train score: 0.9321 | Val loss: 0.1680 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:04.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1561 | Train score: 0.9198 | Val loss: 0.1719 | Val score: 0.9307\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:06.371\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1824 | Train score: 0.9444 | Val loss: 0.1711 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:07.991\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1264 | Train score: 0.9568 | Val loss: 0.1702 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:09.527\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1772 | Train score: 0.9259 | Val loss: 0.1690 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:11.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1487 | Train score: 0.9383 | Val loss: 0.1678 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:12.731\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1641 | Train score: 0.9259 | Val loss: 0.1672 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:14.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1513 | Train score: 0.9506 | Val loss: 0.1663 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:15.841\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1685 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:17.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1555 | Train score: 0.9444 | Val loss: 0.1687 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:18.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1509 | Train score: 0.9383 | Val loss: 0.1684 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:20.384\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1662 | Train score: 0.9444 | Val loss: 0.1700 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:21.857\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1186 | Train score: 0.9506 | Val loss: 0.1806 | Val score: 0.9307\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:23.335\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1311 | Train score: 0.9383 | Val loss: 0.1881 | Val score: 0.9307\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:24.838\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1279 | Train score: 0.9444 | Val loss: 0.1965 | Val score: 0.9307\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:26.365\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1140 | Train score: 0.9506 | Val loss: 0.2065 | Val score: 0.9307\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:28.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1031 | Train score: 0.9506 | Val loss: 0.2193 | Val score: 0.9307\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:29.582\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1825 | Train score: 0.9444 | Val loss: 0.2169 | Val score: 0.9257\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:31.112\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1447 | Train score: 0.9444 | Val loss: 0.2151 | Val score: 0.9257\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:32.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1766 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:34.205\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1548 | Train score: 0.9506 | Val loss: 0.1761 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:35.672\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2721 | Train score: 0.9259 | Val loss: 0.1744 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:37.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1257 | Train score: 0.9568 | Val loss: 0.1742 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:38.673\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1515 | Train score: 0.9506 | Val loss: 0.1735 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:40.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1258 | Train score: 0.9630 | Val loss: 0.1737 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:41.583\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1696 | Train score: 0.9259 | Val loss: 0.1747 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:43.221\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1300 | Train score: 0.9383 | Val loss: 0.1763 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:44.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1591 | Train score: 0.9444 | Val loss: 0.1768 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:46.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1448 | Train score: 0.9506 | Val loss: 0.1775 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:47.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1352 | Train score: 0.9506 | Val loss: 0.1790 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:49.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1456 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:50.815\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1831 | Train score: 0.9444 | Val loss: 0.1446 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:52.385\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1720 | Train score: 0.9444 | Val loss: 0.1434 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:53.969\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2089 | Train score: 0.9444 | Val loss: 0.1458 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:55.535\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1718 | Train score: 0.9444 | Val loss: 0.1467 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:57.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1650 | Train score: 0.9444 | Val loss: 0.1456 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:58.714\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1601 | Train score: 0.9506 | Val loss: 0.1432 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:00.302\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1811 | Train score: 0.9506 | Val loss: 0.1427 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:01.804\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1693 | Train score: 0.9506 | Val loss: 0.1415 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:03.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1289 | Train score: 0.9630 | Val loss: 0.1380 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:04.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1817 | Train score: 0.9506 | Val loss: 0.1363 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:06.563\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1484 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:08.020\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1466 | Train score: 0.9444 | Val loss: 0.1461 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:09.595\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1935 | Train score: 0.9321 | Val loss: 0.1520 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:11.085\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1288 | Train score: 0.9444 | Val loss: 0.1466 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:12.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1608 | Train score: 0.9444 | Val loss: 0.1455 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:14.078\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1319 | Train score: 0.9506 | Val loss: 0.1466 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:15.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1375 | Train score: 0.9444 | Val loss: 0.1490 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:17.061\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.2127 | Train score: 0.9383 | Val loss: 0.1496 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:18.545\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1711 | Train score: 0.9383 | Val loss: 0.1504 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:20.093\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1443 | Train score: 0.9444 | Val loss: 0.1507 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:21.578\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1353 | Train score: 0.9444 | Val loss: 0.1535 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:23.176\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1432 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:24.808\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1479 | Train score: 0.9383 | Val loss: 0.1456 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:26.583\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1797 | Train score: 0.9444 | Val loss: 0.1475 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:28.296\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1540 | Train score: 0.9383 | Val loss: 0.1474 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:29.983\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1868 | Train score: 0.9444 | Val loss: 0.1473 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:31.622\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1533 | Train score: 0.9383 | Val loss: 0.1476 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:33.215\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1525 | Train score: 0.9444 | Val loss: 0.1483 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:34.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1361 | Train score: 0.9444 | Val loss: 0.1495 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:36.544\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1172 | Train score: 0.9444 | Val loss: 0.1531 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:38.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1411 | Train score: 0.9506 | Val loss: 0.1572 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:39.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1503 | Train score: 0.9444 | Val loss: 0.1587 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:41.576\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1450 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:43.325\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1706 | Train score: 0.9444 | Val loss: 0.1432 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:44.838\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1525 | Train score: 0.9506 | Val loss: 0.1413 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:46.562\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1720 | Train score: 0.9444 | Val loss: 0.1430 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:48.115\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1607 | Train score: 0.9444 | Val loss: 0.1446 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:49.785\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1525 | Train score: 0.9444 | Val loss: 0.1423 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:51.317\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1673 | Train score: 0.9383 | Val loss: 0.1420 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:52.918\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1655 | Train score: 0.9383 | Val loss: 0.1422 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:54.465\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1550 | Train score: 0.9444 | Val loss: 0.1427 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:56.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1373 | Train score: 0.9444 | Val loss: 0.1442 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:57.853\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1313 | Train score: 0.9383 | Val loss: 0.1466 | Val score: 0.9505\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:13:59.442\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1512 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:14:00.916\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1803 | Train score: 0.9383 | Val loss: 0.1467 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:14:02.471\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1312 | Train score: 0.9568 | Val loss: 0.1475 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:14:03.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1571 | Train score: 0.9444 | Val loss: 0.1506 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-05 00:14:05.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1657 | Train score: 0.9506 | Val loss: 0.1524 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-05 00:14:06.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1762 | Train score: 0.9321 | Val loss: 0.1541 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:14:08.445\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1455 | Train score: 0.9506 | Val loss: 0.1558 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:14:10.057\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1578 | Train score: 0.9444 | Val loss: 0.1564 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:14:11.736\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1084 | Train score: 0.9630 | Val loss: 0.1608 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:14:13.193\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1245 | Train score: 0.9506 | Val loss: 0.1664 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:14:14.630\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1148 | Train score: 0.9444 | Val loss: 0.1764 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:14:16.220\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1356 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:14:17.698\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1560 | Train score: 0.9444 | Val loss: 0.1312 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:14:19.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1670 | Train score: 0.9444 | Val loss: 0.1312 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:14:20.670\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1562 | Train score: 0.9506 | Val loss: 0.1301 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:14:22.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.2043 | Train score: 0.9444 | Val loss: 0.1319 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:14:23.590\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1414 | Train score: 0.9506 | Val loss: 0.1313 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:14:25.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1658 | Train score: 0.9383 | Val loss: 0.1318 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:14:26.552\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1472 | Train score: 0.9568 | Val loss: 0.1313 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:14:28.074\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.2111 | Train score: 0.9321 | Val loss: 0.1332 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:14:29.555\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1425 | Train score: 0.9383 | Val loss: 0.1340 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:14:31.036\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1497 | Train score: 0.9568 | Val loss: 0.1334 | Val score: 0.9505\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " 100 \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.946         0.000           0.000          0.000        0.000       0.000         0.500        0.000    0.000   0.000         0.000        0.000\n",
      "MedPFNClassifier                      0.935         0.006           0.117          0.183        0.050       0.076         0.755        0.138    0.069   0.106         0.247        0.012\n",
      "MedPFNClassifier                      0.945         0.007           0.350          0.391        0.083       0.083         0.815        0.116    0.132   0.133         1.551        0.016\n",
      "MedPFNClassifier                      0.941         0.009           0.250          0.403        0.050       0.076         0.819        0.113    0.082   0.126        10.229        0.049\n",
      "RandomForestClassifier                0.946         0.003           0.000          0.000        0.000       0.000         0.787        0.094    0.000   0.000         0.372        0.011\n",
      "LogisticRegressionClassifier          0.927         0.011           0.130          0.166        0.100       0.133         0.606        0.167    0.113   0.147         0.008        0.001\n",
      "TabPFNClassifier                      0.946         0.000           0.000          0.000        0.000       0.000         0.823        0.109    0.000   0.000         2.416        0.032\n",
      "TabForestPFNClassifier                0.949         0.011           0.558          0.398        0.183       0.157         0.839        0.079    0.260   0.197        16.807        0.629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:17:04.848\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.2094 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:06.327\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2128 | Train score: 0.9444 | Val loss: 0.1959 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:07.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1937 | Train score: 0.9444 | Val loss: 0.1977 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:09.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1781 | Train score: 0.9444 | Val loss: 0.2104 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:11.103\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.2322 | Train score: 0.9506 | Val loss: 0.2094 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:12.582\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.2034 | Train score: 0.9444 | Val loss: 0.2047 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:14.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.2362 | Train score: 0.9444 | Val loss: 0.2016 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:15.565\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1891 | Train score: 0.9444 | Val loss: 0.2007 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:17.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.2136 | Train score: 0.9444 | Val loss: 0.2000 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:18.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1859 | Train score: 0.9444 | Val loss: 0.1999 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:20.050\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1871 | Train score: 0.9444 | Val loss: 0.2001 | Val score: 0.9455\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:17:21.629\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1899 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:23.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1970 | Train score: 0.9444 | Val loss: 0.1763 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:24.994\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2374 | Train score: 0.9321 | Val loss: 0.1761 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:26.665\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2441 | Train score: 0.9383 | Val loss: 0.1781 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:28.357\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.2059 | Train score: 0.9383 | Val loss: 0.1805 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:30.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1878 | Train score: 0.9444 | Val loss: 0.1818 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:31.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1947 | Train score: 0.9444 | Val loss: 0.1822 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:33.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1918 | Train score: 0.9444 | Val loss: 0.1826 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:35.125\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1949 | Train score: 0.9444 | Val loss: 0.1829 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:36.785\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1755 | Train score: 0.9444 | Val loss: 0.1832 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:38.465\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1823 | Train score: 0.9444 | Val loss: 0.1852 | Val score: 0.9455\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:17:40.035\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.2047 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:41.573\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2027 | Train score: 0.9444 | Val loss: 0.1882 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:43.345\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1924 | Train score: 0.9383 | Val loss: 0.1894 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:44.899\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2219 | Train score: 0.9444 | Val loss: 0.1930 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:46.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1963 | Train score: 0.9444 | Val loss: 0.1965 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:48.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1870 | Train score: 0.9444 | Val loss: 0.1951 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:49.681\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1920 | Train score: 0.9383 | Val loss: 0.1939 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:51.368\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1847 | Train score: 0.9444 | Val loss: 0.1938 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:52.950\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1801 | Train score: 0.9444 | Val loss: 0.1942 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:54.499\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1754 | Train score: 0.9506 | Val loss: 0.1953 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:56.100\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1823 | Train score: 0.9444 | Val loss: 0.1955 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:57.672\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1944 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:59.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1965 | Train score: 0.9444 | Val loss: 0.1927 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:00.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2196 | Train score: 0.9321 | Val loss: 0.1930 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:02.046\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1750 | Train score: 0.9444 | Val loss: 0.1934 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:03.651\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1935 | Train score: 0.9444 | Val loss: 0.1938 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:05.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.2237 | Train score: 0.9383 | Val loss: 0.1919 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:06.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.2063 | Train score: 0.9444 | Val loss: 0.1916 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:08.085\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1812 | Train score: 0.9444 | Val loss: 0.1913 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:09.554\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1784 | Train score: 0.9444 | Val loss: 0.1922 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:11.086\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1850 | Train score: 0.9444 | Val loss: 0.1927 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:12.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1818 | Train score: 0.9444 | Val loss: 0.1925 | Val score: 0.9455\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:18:14.130\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.2100 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:15.730\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2082 | Train score: 0.9444 | Val loss: 0.2194 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:17.359\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1842 | Train score: 0.9444 | Val loss: 0.2292 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:18.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1858 | Train score: 0.9444 | Val loss: 0.2302 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:20.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1743 | Train score: 0.9444 | Val loss: 0.2243 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:22.358\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1878 | Train score: 0.9444 | Val loss: 0.2202 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:24.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1528 | Train score: 0.9506 | Val loss: 0.2195 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:25.763\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1855 | Train score: 0.9444 | Val loss: 0.2195 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:27.409\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1703 | Train score: 0.9506 | Val loss: 0.2212 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:29.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1788 | Train score: 0.9506 | Val loss: 0.2173 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:30.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1471 | Train score: 0.9568 | Val loss: 0.2230 | Val score: 0.9406\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:18:32.209\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.2082 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:33.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2091 | Train score: 0.9444 | Val loss: 0.1758 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:35.274\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1955 | Train score: 0.9444 | Val loss: 0.1745 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:36.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2037 | Train score: 0.9444 | Val loss: 0.1841 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:38.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.2507 | Train score: 0.9444 | Val loss: 0.1823 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:39.927\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1832 | Train score: 0.9444 | Val loss: 0.1805 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:41.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1989 | Train score: 0.9444 | Val loss: 0.1800 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:43.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.2430 | Train score: 0.9444 | Val loss: 0.1795 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:44.604\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1760 | Train score: 0.9444 | Val loss: 0.1793 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:46.148\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1846 | Train score: 0.9444 | Val loss: 0.1796 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:47.788\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.2019 | Train score: 0.9444 | Val loss: 0.1797 | Val score: 0.9455\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:18:49.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1946 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:51.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1921 | Train score: 0.9444 | Val loss: 0.1940 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:52.672\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1730 | Train score: 0.9444 | Val loss: 0.2001 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:54.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1962 | Train score: 0.9444 | Val loss: 0.2011 | Val score: 0.9307\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:55.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1430 | Train score: 0.9444 | Val loss: 0.2053 | Val score: 0.9257\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:57.498\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1638 | Train score: 0.9444 | Val loss: 0.2101 | Val score: 0.9158\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:59.053\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1965 | Train score: 0.9444 | Val loss: 0.2089 | Val score: 0.9257\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:00.672\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.2279 | Train score: 0.9383 | Val loss: 0.2075 | Val score: 0.9307\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:02.260\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1648 | Train score: 0.9444 | Val loss: 0.2088 | Val score: 0.9307\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:03.808\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1599 | Train score: 0.9506 | Val loss: 0.2146 | Val score: 0.9208\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:05.566\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.2152 | Train score: 0.9444 | Val loss: 0.2165 | Val score: 0.9208\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:07.143\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1966 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:08.601\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1990 | Train score: 0.9444 | Val loss: 0.1998 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:10.229\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2184 | Train score: 0.9383 | Val loss: 0.2052 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:11.886\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1820 | Train score: 0.9506 | Val loss: 0.2041 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:13.317\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.2046 | Train score: 0.9444 | Val loss: 0.2005 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:14.752\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1606 | Train score: 0.9444 | Val loss: 0.2026 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:16.229\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1779 | Train score: 0.9506 | Val loss: 0.2068 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:17.685\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1825 | Train score: 0.9444 | Val loss: 0.2106 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:19.180\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.2103 | Train score: 0.9383 | Val loss: 0.2113 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:20.642\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1855 | Train score: 0.9444 | Val loss: 0.2115 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:22.123\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1815 | Train score: 0.9444 | Val loss: 0.2120 | Val score: 0.9406\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:19:23.702\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.2189 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:25.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2170 | Train score: 0.9444 | Val loss: 0.2090 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:27.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2001 | Train score: 0.9444 | Val loss: 0.2110 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:28.627\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1986 | Train score: 0.9444 | Val loss: 0.2187 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:30.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1972 | Train score: 0.9444 | Val loss: 0.2257 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:31.928\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1731 | Train score: 0.9444 | Val loss: 0.2350 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:33.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1790 | Train score: 0.9383 | Val loss: 0.2431 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:35.103\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1919 | Train score: 0.9383 | Val loss: 0.2495 | Val score: 0.9307\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:36.767\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.2131 | Train score: 0.9444 | Val loss: 0.2535 | Val score: 0.9307\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:38.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1590 | Train score: 0.9444 | Val loss: 0.2592 | Val score: 0.9307\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:39.952\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.2248 | Train score: 0.9321 | Val loss: 0.2604 | Val score: 0.9406\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:19:41.553\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.2041 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:43.103\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2125 | Train score: 0.9444 | Val loss: 0.1716 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:44.670\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2443 | Train score: 0.9444 | Val loss: 0.1774 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:46.226\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2065 | Train score: 0.9444 | Val loss: 0.1852 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:47.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1978 | Train score: 0.9444 | Val loss: 0.1864 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:49.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.2069 | Train score: 0.9444 | Val loss: 0.1852 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:50.904\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.2039 | Train score: 0.9444 | Val loss: 0.1826 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:52.599\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.2005 | Train score: 0.9444 | Val loss: 0.1796 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:54.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1907 | Train score: 0.9444 | Val loss: 0.1764 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:55.777\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.2069 | Train score: 0.9444 | Val loss: 0.1754 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:57.333\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1841 | Train score: 0.9444 | Val loss: 0.1773 | Val score: 0.9406\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " 250 \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.946         0.000           0.000          0.000        0.000       0.000         0.500        0.000    0.000   0.000         0.000        0.000\n",
      "MedPFNClassifier                      0.946         0.000           0.000          0.000        0.000       0.000         0.470        0.080    0.000   0.000         0.254        0.003\n",
      "MedPFNClassifier                      0.946         0.000           0.000          0.000        0.000       0.000         0.751        0.070    0.000   0.000         1.550        0.020\n",
      "MedPFNClassifier                      0.946         0.000           0.000          0.000        0.000       0.000         0.768        0.071    0.000   0.000        10.245        0.089\n",
      "RandomForestClassifier                0.946         0.000           0.000          0.000        0.000       0.000         0.784        0.101    0.000   0.000         0.238        0.007\n",
      "LogisticRegressionClassifier          0.923         0.010           0.067          0.133        0.033       0.067         0.544        0.083    0.044   0.089         0.007        0.001\n",
      "TabPFNClassifier                      0.946         0.000           0.000          0.000        0.000       0.000         0.768        0.086    0.000   0.000         2.393        0.018\n",
      "TabForestPFNClassifier                0.945         0.004           0.000          0.000        0.000       0.000         0.792        0.047    0.000   0.000        17.133        0.626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:22:31.827\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.2119 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:22:33.324\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2148 | Train score: 0.9444 | Val loss: 0.2109 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:22:34.800\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2153 | Train score: 0.9444 | Val loss: 0.2110 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:22:36.234\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2145 | Train score: 0.9444 | Val loss: 0.2105 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:22:37.675\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.2136 | Train score: 0.9444 | Val loss: 0.2101 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:22:39.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.2128 | Train score: 0.9444 | Val loss: 0.2090 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:22:40.575\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.2122 | Train score: 0.9444 | Val loss: 0.2062 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:22:42.181\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.2147 | Train score: 0.9444 | Val loss: 0.2065 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:22:43.663\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.2103 | Train score: 0.9444 | Val loss: 0.2066 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:22:45.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.2117 | Train score: 0.9444 | Val loss: 0.2056 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:22:46.569\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.2087 | Train score: 0.9444 | Val loss: 0.2038 | Val score: 0.9455\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:22:48.109\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.2116 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:22:49.727\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2148 | Train score: 0.9444 | Val loss: 0.2118 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:22:51.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2149 | Train score: 0.9444 | Val loss: 0.2113 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:22:52.946\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2138 | Train score: 0.9444 | Val loss: 0.2112 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:22:54.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.2143 | Train score: 0.9444 | Val loss: 0.2107 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:22:56.222\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.2147 | Train score: 0.9444 | Val loss: 0.2102 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:22:57.680\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.2137 | Train score: 0.9444 | Val loss: 0.2100 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:22:59.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.2133 | Train score: 0.9444 | Val loss: 0.2097 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:00.977\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.2088 | Train score: 0.9444 | Val loss: 0.2092 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:02.415\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.2043 | Train score: 0.9444 | Val loss: 0.2090 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:04.106\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.2026 | Train score: 0.9444 | Val loss: 0.2114 | Val score: 0.9455\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:23:05.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.2108 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:07.160\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2144 | Train score: 0.9444 | Val loss: 0.2103 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:08.625\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2141 | Train score: 0.9444 | Val loss: 0.2087 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:10.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2132 | Train score: 0.9444 | Val loss: 0.2070 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:11.528\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.2135 | Train score: 0.9444 | Val loss: 0.2040 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:12.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.2117 | Train score: 0.9444 | Val loss: 0.1978 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:14.548\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.2082 | Train score: 0.9444 | Val loss: 0.1857 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:16.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.2091 | Train score: 0.9444 | Val loss: 0.1793 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:17.539\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1980 | Train score: 0.9444 | Val loss: 0.1695 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:18.987\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1791 | Train score: 0.9444 | Val loss: 0.1708 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:20.446\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1882 | Train score: 0.9444 | Val loss: 0.1786 | Val score: 0.9455\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:23:22.010\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.2118 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:23.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2153 | Train score: 0.9444 | Val loss: 0.2115 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:24.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2147 | Train score: 0.9444 | Val loss: 0.2113 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:26.332\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2142 | Train score: 0.9444 | Val loss: 0.2109 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:27.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.2145 | Train score: 0.9444 | Val loss: 0.2109 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:29.316\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.2142 | Train score: 0.9444 | Val loss: 0.2112 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:30.771\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.2133 | Train score: 0.9444 | Val loss: 0.2110 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:32.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.2139 | Train score: 0.9444 | Val loss: 0.2106 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:33.728\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.2109 | Train score: 0.9444 | Val loss: 0.2100 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:35.195\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.2120 | Train score: 0.9444 | Val loss: 0.2093 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:36.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.2083 | Train score: 0.9444 | Val loss: 0.2080 | Val score: 0.9455\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:23:38.205\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.2113 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:39.655\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2146 | Train score: 0.9444 | Val loss: 0.2111 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:41.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2115 | Train score: 0.9444 | Val loss: 0.2112 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:42.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2117 | Train score: 0.9444 | Val loss: 0.2122 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:44.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.2067 | Train score: 0.9444 | Val loss: 0.2168 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:45.506\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1910 | Train score: 0.9444 | Val loss: 0.2285 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:46.961\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.2006 | Train score: 0.9506 | Val loss: 0.2359 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:48.389\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1865 | Train score: 0.9444 | Val loss: 0.2436 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:49.842\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.2326 | Train score: 0.9444 | Val loss: 0.2407 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:51.284\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.2042 | Train score: 0.9444 | Val loss: 0.2348 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:52.972\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1999 | Train score: 0.9444 | Val loss: 0.2271 | Val score: 0.9455\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:23:54.520\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.2111 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:56.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2136 | Train score: 0.9444 | Val loss: 0.2094 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:57.638\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2066 | Train score: 0.9444 | Val loss: 0.2058 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:59.290\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2049 | Train score: 0.9444 | Val loss: 0.2037 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:00.756\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1927 | Train score: 0.9444 | Val loss: 0.2033 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:02.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.2238 | Train score: 0.9444 | Val loss: 0.2016 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:04.035\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.2186 | Train score: 0.9444 | Val loss: 0.2038 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:05.635\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.2077 | Train score: 0.9444 | Val loss: 0.2038 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:07.269\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1975 | Train score: 0.9444 | Val loss: 0.2030 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:08.945\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1957 | Train score: 0.9444 | Val loss: 0.2024 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:10.638\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1988 | Train score: 0.9444 | Val loss: 0.2022 | Val score: 0.9455\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:24:12.261\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.2118 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:13.783\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2152 | Train score: 0.9444 | Val loss: 0.2118 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:15.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2150 | Train score: 0.9444 | Val loss: 0.2111 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:16.786\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2139 | Train score: 0.9444 | Val loss: 0.2107 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:18.274\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.2150 | Train score: 0.9444 | Val loss: 0.2107 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:19.763\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.2139 | Train score: 0.9444 | Val loss: 0.2105 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:21.261\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.2152 | Train score: 0.9444 | Val loss: 0.2100 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:22.737\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.2120 | Train score: 0.9444 | Val loss: 0.2092 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:24.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.2145 | Train score: 0.9444 | Val loss: 0.2089 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:25.763\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.2121 | Train score: 0.9444 | Val loss: 0.2083 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:27.219\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.2095 | Train score: 0.9444 | Val loss: 0.2071 | Val score: 0.9455\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:24:28.790\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.2116 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:30.230\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2145 | Train score: 0.9444 | Val loss: 0.2106 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:31.685\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2138 | Train score: 0.9444 | Val loss: 0.2079 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:33.161\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2115 | Train score: 0.9444 | Val loss: 0.2052 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:34.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.2109 | Train score: 0.9444 | Val loss: 0.2048 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:36.101\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.2086 | Train score: 0.9444 | Val loss: 0.2062 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:37.539\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.2008 | Train score: 0.9444 | Val loss: 0.2109 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:39.066\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.2013 | Train score: 0.9444 | Val loss: 0.2187 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:40.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1805 | Train score: 0.9444 | Val loss: 0.2322 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:42.106\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1678 | Train score: 0.9444 | Val loss: 0.2537 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:43.566\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.2122 | Train score: 0.9383 | Val loss: 0.2489 | Val score: 0.9455\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:24:45.143\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.2120 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:46.565\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2138 | Train score: 0.9444 | Val loss: 0.2120 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:48.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2105 | Train score: 0.9444 | Val loss: 0.2141 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:49.457\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2140 | Train score: 0.9444 | Val loss: 0.2162 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:50.930\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.2092 | Train score: 0.9444 | Val loss: 0.2185 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:52.351\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1946 | Train score: 0.9444 | Val loss: 0.2249 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:53.809\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1979 | Train score: 0.9444 | Val loss: 0.2285 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:55.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.2111 | Train score: 0.9444 | Val loss: 0.2271 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:56.730\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1974 | Train score: 0.9444 | Val loss: 0.2252 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:58.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1973 | Train score: 0.9444 | Val loss: 0.2240 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:59.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.2009 | Train score: 0.9444 | Val loss: 0.2179 | Val score: 0.9455\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:25:01.183\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.2110 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:25:02.660\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2141 | Train score: 0.9444 | Val loss: 0.2095 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:25:04.153\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2131 | Train score: 0.9444 | Val loss: 0.2085 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:25:05.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2097 | Train score: 0.9444 | Val loss: 0.2080 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:25:07.149\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.2079 | Train score: 0.9444 | Val loss: 0.2073 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:25:08.602\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1989 | Train score: 0.9444 | Val loss: 0.2091 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:25:10.109\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.2224 | Train score: 0.9444 | Val loss: 0.2066 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:25:11.630\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1964 | Train score: 0.9444 | Val loss: 0.2050 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:25:13.108\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1984 | Train score: 0.9444 | Val loss: 0.2052 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:25:14.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1822 | Train score: 0.9444 | Val loss: 0.2075 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:25:16.124\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1875 | Train score: 0.9444 | Val loss: 0.2140 | Val score: 0.9455\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " 500 \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.946         0.000             0.0            0.0          0.0         0.0         0.500        0.000      0.0     0.0         0.000        0.000\n",
      "MedPFNClassifier                      0.946         0.000             0.0            0.0          0.0         0.0         0.604        0.126      0.0     0.0         0.252        0.012\n",
      "MedPFNClassifier                      0.946         0.000             0.0            0.0          0.0         0.0         0.552        0.128      0.0     0.0         1.589        0.039\n",
      "MedPFNClassifier                      0.946         0.000             0.0            0.0          0.0         0.0         0.641        0.122      0.0     0.0        10.281        0.075\n",
      "RandomForestClassifier                0.946         0.000             0.0            0.0          0.0         0.0         0.645        0.081      0.0     0.0         0.178        0.005\n",
      "LogisticRegressionClassifier          0.945         0.004             0.0            0.0          0.0         0.0         0.435        0.122      0.0     0.0         0.006        0.000\n",
      "TabPFNClassifier                      0.946         0.000             0.0            0.0          0.0         0.0         0.588        0.130      0.0     0.0         2.456        0.074\n",
      "TabForestPFNClassifier                0.946         0.000             0.0            0.0          0.0         0.0         0.625        0.095      0.0     0.0        16.313        0.527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "save = True\n",
    "sampling = None\n",
    "cv = 10\n",
    "best_delete = 0\n",
    "strat_split = True\n",
    "recomp = False\n",
    "n_optim = 1000\n",
    "cat_optim = 10\n",
    "ft_epochs = 20\n",
    "ft_epochs_forest = 10\n",
    "ft_lr = 1e-5\n",
    "max_s = 1024\n",
    "max_q = 128\n",
    "max_samples = 1024\n",
    "no_pre_process = False\n",
    "multi_decoder = \"permutation\"\n",
    "N_ens = 5\n",
    "seed = 42\n",
    "overwrite = True\n",
    "metrics = [\"accuracy\", \"precision\", \"recall\", \"roc_auc\", \"f1\"]\n",
    "dir_path = os.path.abspath(os.getcwd())\n",
    "run_name = \"medium_mlp_var_balance_05weight_anova_bestwithnoisebnn_100\"\n",
    "path = dir_path + f\"/logs/trainrun_{run_name}\"\n",
    "filename = \"model\"\n",
    "\n",
    "\n",
    "models = [\n",
    "    MajorityClass(),\n",
    "    #XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic'),\n",
    "    MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=1, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process),\n",
    "    MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process),\n",
    "    MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process,\n",
    "                    ft_epochs=ft_epochs, ft_lr=ft_lr),\n",
    "    RandomForestClassifier(),\n",
    "    #AutoGluon(),\n",
    "    #CatBoostGrid(),\n",
    "    #XGBoostGrid(),\n",
    "    LogisticRegressionClassifier(), \n",
    "    TabPFNClassifier(device='cpu', N_ensemble_configurations=5, no_preprocess_mode=no_pre_process),\n",
    "    TabForestPFNClassifier(\"saved_models/tabforest/mix600k/tabforestpfn.pt\", \"saved_models/tabforest/mix600k/config_run.yaml\", max_epochs=ft_epochs_forest)\n",
    "]\n",
    "reducer  = AnovaSelect()\n",
    "#for reducer in [AnovaSelect(), RandomSelect(), NonZeroSelect(), MeanSelect(), StdSelect(), MaxSelect(), PCASelect()]:\n",
    "#data = clr(all_data)\n",
    "\n",
    "#all_data = normalize(all_data)\n",
    "to_delete = [0,1,5,10,25,50,100,250,500]\n",
    "for best_delete in to_delete:\n",
    "    results_mean = pd.DataFrame(np.zeros((len(models), len(metrics)+1)),\n",
    "                                index=[m.__class__.__name__ for m in models],\n",
    "                                columns=metrics+[\"runtime\"])\n",
    "    results_std = pd.DataFrame(np.zeros((len(models), len(metrics)+1)), \n",
    "                               index=[m.__class__.__name__ for m in models],\n",
    "                               columns=metrics+[\"runtime\"])\n",
    "    \n",
    "    for ii, model in enumerate(models):\n",
    "        results_mean.iloc[ii,:], results_std.iloc[ii,:] = cross_validate_sample(\n",
    "            model, all_data, labels, metrics, strat_split, cv, sampling, \n",
    "            reducer, max_samples, seed=seed, overwrite=overwrite, n_best_delete=best_delete,\n",
    "            recomp=recomp)\n",
    "    \n",
    "    results_mean = results_mean.add_suffix(\" mean\")\n",
    "    results_std = results_std.add_suffix(\" std\")\n",
    "    results_full = pd.concat((results_mean, results_std), axis=1)\n",
    "    cols = results_full.columns.tolist()\n",
    "    new_cols = []\n",
    "    for i in range(int(len(cols)/2)):\n",
    "        new_cols.append(cols[i])\n",
    "        new_cols.append(cols[i+int(len(cols)/2)])\n",
    "    results_full = results_full[new_cols]\n",
    "    red_name = \"feature_removal\"\n",
    "    if save:\n",
    "        directory = f\"results/{red_name}\"\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        save_path = f'results/{red_name}/best_delete{best_delete}.csv'\n",
    "        results_full.to_csv(save_path)\n",
    "    print(\"\\n\", \"\\n\", best_delete, \"\\n\", results_full.round(3))\n",
    "    #print(results_full.sort_values(\"roc_auc mean\").round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef7a442-b698-44d5-869a-756ec1e70b55",
   "metadata": {},
   "source": [
    "## New data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2ab1872-e271-44ac-b463-9ee4fa7127d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"datasets/external_pdac.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df_data = df.iloc[:,2:-5]\n",
    "data = df_data.to_numpy()\n",
    "labels = df[\"Disease\"].to_numpy()\n",
    "labels[labels==\"Healthy\"] = 0\n",
    "labels[labels==\"PDAC\"] = 1\n",
    "all_data = data\n",
    "data_c0 = data[labels==0]\n",
    "data_c1 = data[labels==1]\n",
    "num_c1 = data_c1.shape[0]\n",
    "num_c0 = int(num_c1*0.05)\n",
    "data = np.concatenate((data_c0[:num_c0], data_c1), axis=0)\n",
    "#labels = np.concatenate((np.zeros(num_c0), np.ones(num_c1)))\n",
    "all_data, labels = unison_shuffled_copies(data, labels)\n",
    "all_data = data_to_comp(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5860c111-1280-470e-a332-3945d589858d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-05 15:24:41.403\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.2916 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:42.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.5151 | Train score: 0.7308 | Val loss: 0.3171 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:42.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.4749 | Train score: 0.7692 | Val loss: 0.3599 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:43.628\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.4746 | Train score: 0.7308 | Val loss: 0.3794 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:44.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.4510 | Train score: 0.7308 | Val loss: 0.3534 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:44.953\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.3663 | Train score: 0.8462 | Val loss: 0.3204 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:45.594\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.3435 | Train score: 0.8077 | Val loss: 0.3064 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:46.206\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.3675 | Train score: 0.8846 | Val loss: 0.2934 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:46.838\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.6610 | Train score: 0.6154 | Val loss: 0.2878 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:47.493\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.3857 | Train score: 0.8077 | Val loss: 0.2834 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:48.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.5030 | Train score: 0.8462 | Val loss: 0.2836 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:48.779\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.3848 | Train score: 0.8846 | Val loss: 0.2847 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:49.743\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.4436 | Train score: 0.8077 | Val loss: 0.2889 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:50.365\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.5059 | Train score: 0.8077 | Val loss: 0.2965 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:50.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.3777 | Train score: 0.8462 | Val loss: 0.2995 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:51.518\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.3292 | Train score: 0.8077 | Val loss: 0.2984 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:52.074\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.3318 | Train score: 0.8462 | Val loss: 0.3038 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:52.701\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.2923 | Train score: 0.9231 | Val loss: 0.2978 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:53.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.2202 | Train score: 0.9615 | Val loss: 0.2981 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:54.726\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.2545 | Train score: 0.8846 | Val loss: 0.2757 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:55.328\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.1457 | Train score: 1.0000 | Val loss: 0.2648 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:56.180\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.3618 | Val score: 0.9091\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:56.943\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2762 | Train score: 0.8846 | Val loss: 0.3630 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:57.530\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.3941 | Train score: 0.8462 | Val loss: 0.3790 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:58.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2477 | Train score: 0.9615 | Val loss: 0.3893 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:58.844\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.2133 | Train score: 0.9615 | Val loss: 0.4065 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:59.418\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.5501 | Train score: 0.8846 | Val loss: 0.4061 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:00.030\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.3449 | Train score: 0.8462 | Val loss: 0.4007 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:00.660\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.3194 | Train score: 0.8077 | Val loss: 0.4048 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:01.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.3465 | Train score: 0.8077 | Val loss: 0.4122 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:01.841\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.2845 | Train score: 0.8846 | Val loss: 0.4116 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:02.457\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.3623 | Train score: 0.8462 | Val loss: 0.4104 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:03.019\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.3654 | Train score: 0.8846 | Val loss: 0.4079 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:03.634\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.2222 | Train score: 0.9231 | Val loss: 0.4117 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:04.226\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.3845 | Train score: 0.8462 | Val loss: 0.4115 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:04.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.3047 | Train score: 0.8077 | Val loss: 0.4074 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:05.629\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.3698 | Train score: 0.7692 | Val loss: 0.4103 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:06.212\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.2180 | Train score: 0.8846 | Val loss: 0.4169 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:06.796\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.2552 | Train score: 0.8846 | Val loss: 0.4307 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:07.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.1518 | Train score: 0.9615 | Val loss: 0.4555 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:08.043\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.3783 | Train score: 0.8077 | Val loss: 0.4630 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:08.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.2206 | Train score: 0.9615 | Val loss: 0.4641 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:09.486\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.4509 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:10.148\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.4866 | Train score: 0.8462 | Val loss: 0.4411 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:10.856\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.3499 | Train score: 0.8462 | Val loss: 0.4398 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:11.567\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.3791 | Train score: 0.7308 | Val loss: 0.4410 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:12.292\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.2894 | Train score: 0.9231 | Val loss: 0.4436 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:12.965\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.3695 | Train score: 0.8846 | Val loss: 0.4433 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:13.721\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.3273 | Train score: 0.8846 | Val loss: 0.4442 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:14.857\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.4324 | Train score: 0.7308 | Val loss: 0.4459 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:15.491\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.2727 | Train score: 0.8077 | Val loss: 0.4486 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:16.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.3162 | Train score: 0.8846 | Val loss: 0.4540 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:16.803\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.3338 | Train score: 0.8077 | Val loss: 0.4587 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:17.581\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.2602 | Train score: 0.8846 | Val loss: 0.4676 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:18.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.2604 | Train score: 0.8462 | Val loss: 0.4831 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:18.853\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.3089 | Train score: 0.8846 | Val loss: 0.4878 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:19.540\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.3011 | Train score: 0.8077 | Val loss: 0.4854 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:20.244\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.1748 | Train score: 0.9231 | Val loss: 0.4850 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:20.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.2639 | Train score: 0.8462 | Val loss: 0.4882 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:21.563\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.1709 | Train score: 0.8846 | Val loss: 0.4997 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:22.248\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.2629 | Train score: 0.8846 | Val loss: 0.5147 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:22.887\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.2203 | Train score: 0.9231 | Val loss: 0.5338 | Val score: 0.6970\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:23.507\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.1109 | Train score: 1.0000 | Val loss: 0.5700 | Val score: 0.6970\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:24.339\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.4728 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:25.010\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.3254 | Train score: 0.8462 | Val loss: 0.4845 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:25.633\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.3499 | Train score: 0.8462 | Val loss: 0.4991 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:26.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.5414 | Train score: 0.8462 | Val loss: 0.4905 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:26.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.5126 | Train score: 0.7692 | Val loss: 0.4918 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:27.447\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.3769 | Train score: 0.8462 | Val loss: 0.4961 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:28.047\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.3712 | Train score: 0.8077 | Val loss: 0.4912 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:28.762\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.2231 | Train score: 0.9615 | Val loss: 0.4961 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:29.457\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.3811 | Train score: 0.8462 | Val loss: 0.4963 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:30.117\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.4140 | Train score: 0.8462 | Val loss: 0.5024 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:30.826\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.2575 | Train score: 0.9231 | Val loss: 0.5106 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:31.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.3902 | Train score: 0.8846 | Val loss: 0.5308 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:32.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.4854 | Train score: 0.8462 | Val loss: 0.5447 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:32.727\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.3552 | Train score: 0.8846 | Val loss: 0.5600 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:33.329\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.4977 | Train score: 0.7308 | Val loss: 0.5725 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:33.927\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.4028 | Train score: 0.8462 | Val loss: 0.5778 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:34.519\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.2044 | Train score: 0.9231 | Val loss: 0.5930 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:35.118\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.3312 | Train score: 0.8846 | Val loss: 0.6044 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:35.758\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.3048 | Train score: 0.8846 | Val loss: 0.6051 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:36.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.2287 | Train score: 0.9231 | Val loss: 0.6170 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:36.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.2951 | Train score: 0.8846 | Val loss: 0.6243 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:37.827\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.3766 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:38.544\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.6770 | Train score: 0.8077 | Val loss: 0.3614 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:39.218\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2983 | Train score: 0.9231 | Val loss: 0.3618 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:39.915\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.3495 | Train score: 0.8462 | Val loss: 0.3616 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:40.549\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.5068 | Train score: 0.8077 | Val loss: 0.3693 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:41.151\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.4319 | Train score: 0.8077 | Val loss: 0.3723 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:41.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.4340 | Train score: 0.8077 | Val loss: 0.3794 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:42.453\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.4123 | Train score: 0.8462 | Val loss: 0.3790 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:43.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.3321 | Train score: 0.8462 | Val loss: 0.3724 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:43.655\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.3558 | Train score: 0.8846 | Val loss: 0.3670 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:44.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.4858 | Train score: 0.7692 | Val loss: 0.3672 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:44.915\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.3800 | Train score: 0.8462 | Val loss: 0.3725 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:45.573\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.4554 | Train score: 0.8077 | Val loss: 0.3771 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:46.177\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.4380 | Train score: 0.7692 | Val loss: 0.3782 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:46.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.2563 | Train score: 0.9231 | Val loss: 0.3801 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:47.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.2003 | Train score: 0.9615 | Val loss: 0.3804 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:48.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.3800 | Train score: 0.8077 | Val loss: 0.3812 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:48.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.3920 | Train score: 0.8462 | Val loss: 0.3836 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:49.357\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.3258 | Train score: 0.8846 | Val loss: 0.3912 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:50.039\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.2638 | Train score: 0.8462 | Val loss: 0.4010 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:50.712\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.1902 | Train score: 0.9231 | Val loss: 0.4078 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:51.587\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.3234 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:52.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.4183 | Train score: 0.8462 | Val loss: 0.3099 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:52.898\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.4690 | Train score: 0.8077 | Val loss: 0.3205 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:53.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.5090 | Train score: 0.8077 | Val loss: 0.3321 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:54.123\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.3021 | Train score: 0.9615 | Val loss: 0.3337 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:54.712\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.4051 | Train score: 0.8462 | Val loss: 0.3377 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:55.337\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.2882 | Train score: 0.8846 | Val loss: 0.3344 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:55.936\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.3410 | Train score: 0.8077 | Val loss: 0.3205 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:56.533\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.3769 | Train score: 0.8077 | Val loss: 0.3113 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:57.110\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.3441 | Train score: 0.8462 | Val loss: 0.3094 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:57.709\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.3317 | Train score: 0.8462 | Val loss: 0.3009 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:58.324\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.3426 | Train score: 0.8462 | Val loss: 0.2898 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:58.968\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.2182 | Train score: 0.8462 | Val loss: 0.2870 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:59.694\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.2917 | Train score: 0.8846 | Val loss: 0.2847 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:00.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.3689 | Train score: 0.8462 | Val loss: 0.2813 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:01.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.1761 | Train score: 0.9231 | Val loss: 0.2789 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:02.284\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.1546 | Train score: 0.9615 | Val loss: 0.2759 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:02.882\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.1661 | Train score: 0.9231 | Val loss: 0.2691 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:03.500\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.2228 | Train score: 0.9231 | Val loss: 0.2691 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:04.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.1785 | Train score: 0.9615 | Val loss: 0.2685 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:04.648\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.1588 | Train score: 0.8846 | Val loss: 0.2689 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:05.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.2940 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:06.011\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.5956 | Train score: 0.8077 | Val loss: 0.3020 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:06.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.3387 | Train score: 0.8077 | Val loss: 0.2924 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:07.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.5447 | Train score: 0.6923 | Val loss: 0.2919 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:08.417\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.4277 | Train score: 0.7692 | Val loss: 0.2968 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:09.191\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.3554 | Train score: 0.8462 | Val loss: 0.2870 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:09.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.3410 | Train score: 0.8462 | Val loss: 0.2753 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:10.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.7439 | Train score: 0.8462 | Val loss: 0.2723 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:11.205\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.3636 | Train score: 0.8462 | Val loss: 0.2725 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:11.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.3278 | Train score: 0.8846 | Val loss: 0.2707 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:12.641\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.3474 | Train score: 0.8462 | Val loss: 0.2656 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:13.215\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.3120 | Train score: 0.8462 | Val loss: 0.2600 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:13.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.2571 | Train score: 0.8846 | Val loss: 0.2553 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:14.417\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.2865 | Train score: 0.8846 | Val loss: 0.2510 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:15.021\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.3719 | Train score: 0.8077 | Val loss: 0.2556 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:15.627\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.2316 | Train score: 0.8846 | Val loss: 0.2607 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:16.242\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.4055 | Train score: 0.8077 | Val loss: 0.2674 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:16.842\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.1855 | Train score: 0.9615 | Val loss: 0.2739 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:17.503\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.1841 | Train score: 0.8846 | Val loss: 0.2779 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:18.125\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.2168 | Train score: 0.9231 | Val loss: 0.2826 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:18.726\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.3553 | Train score: 0.8846 | Val loss: 0.2895 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:19.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.4826 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:20.218\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2636 | Train score: 0.8846 | Val loss: 0.4716 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:20.808\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2857 | Train score: 0.8846 | Val loss: 0.4834 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:21.394\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.3052 | Train score: 0.8462 | Val loss: 0.4923 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:21.984\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.5524 | Train score: 0.7308 | Val loss: 0.4788 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:22.578\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.2625 | Train score: 0.8462 | Val loss: 0.4743 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:23.185\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.3099 | Train score: 0.8846 | Val loss: 0.4714 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:23.775\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.3112 | Train score: 0.9231 | Val loss: 0.4652 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:24.429\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1409 | Train score: 0.9231 | Val loss: 0.4603 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:25.027\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.3570 | Train score: 0.8846 | Val loss: 0.4579 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:25.625\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0949 | Train score: 1.0000 | Val loss: 0.4631 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:26.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.4568 | Train score: 0.8462 | Val loss: 0.4604 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:26.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.4145 | Train score: 0.8462 | Val loss: 0.4598 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:27.539\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.1011 | Train score: 1.0000 | Val loss: 0.4715 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:28.221\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.1570 | Train score: 0.9615 | Val loss: 0.4859 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:28.920\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.2823 | Train score: 0.8846 | Val loss: 0.4813 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:29.531\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.1626 | Train score: 0.9615 | Val loss: 0.4726 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:30.187\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.2607 | Train score: 0.9231 | Val loss: 0.4502 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:30.855\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.2306 | Train score: 0.8846 | Val loss: 0.4309 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:31.526\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.1336 | Train score: 0.9615 | Val loss: 0.4291 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:32.263\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.1435 | Train score: 0.9231 | Val loss: 0.4465 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:33.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.3136 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:33.799\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.4854 | Train score: 0.7692 | Val loss: 0.3248 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:34.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.4365 | Train score: 0.8462 | Val loss: 0.3363 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:35.198\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.7329 | Train score: 0.7692 | Val loss: 0.3513 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:35.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.3351 | Train score: 0.8462 | Val loss: 0.3569 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:36.425\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.5012 | Train score: 0.7308 | Val loss: 0.3547 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:37.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.4093 | Train score: 0.8077 | Val loss: 0.3482 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:37.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.3557 | Train score: 0.9231 | Val loss: 0.3361 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:38.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.4031 | Train score: 0.7692 | Val loss: 0.3226 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:38.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.3834 | Train score: 0.8462 | Val loss: 0.3074 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:39.512\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.3282 | Train score: 0.8846 | Val loss: 0.2882 | Val score: 0.9091\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:40.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.2403 | Train score: 0.9231 | Val loss: 0.2652 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:40.732\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.4139 | Train score: 0.8462 | Val loss: 0.2560 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:41.318\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.4137 | Train score: 0.8077 | Val loss: 0.2620 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:41.916\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.3100 | Train score: 0.8462 | Val loss: 0.2656 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:42.516\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.4191 | Train score: 0.8077 | Val loss: 0.2690 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:43.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.4029 | Train score: 0.8462 | Val loss: 0.2739 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:43.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.2608 | Train score: 0.8846 | Val loss: 0.2756 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:44.447\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.3712 | Train score: 0.8462 | Val loss: 0.2720 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:45.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.2732 | Train score: 0.8462 | Val loss: 0.2703 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:45.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.3718 | Train score: 0.8462 | Val loss: 0.2709 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:46.681\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.3725 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:47.416\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.3899 | Train score: 0.8077 | Val loss: 0.3757 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:48.057\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.3760 | Train score: 0.8462 | Val loss: 0.3773 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:48.660\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.3077 | Train score: 0.8462 | Val loss: 0.3811 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:49.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.3083 | Train score: 0.8462 | Val loss: 0.3847 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:49.839\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.3198 | Train score: 0.8462 | Val loss: 0.3945 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:50.427\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1899 | Train score: 0.9615 | Val loss: 0.4110 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:51.014\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.3111 | Train score: 0.8462 | Val loss: 0.4174 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:51.599\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.3233 | Train score: 0.9615 | Val loss: 0.4179 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:52.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1631 | Train score: 0.9615 | Val loss: 0.4339 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:52.806\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.3688 | Train score: 0.8846 | Val loss: 0.4469 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:53.387\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.5671 | Train score: 0.8462 | Val loss: 0.4279 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:53.970\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.2184 | Train score: 0.9231 | Val loss: 0.4250 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:54.566\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.4199 | Train score: 0.8846 | Val loss: 0.4226 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:55.184\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.2262 | Train score: 0.9231 | Val loss: 0.4227 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:55.795\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.0941 | Train score: 1.0000 | Val loss: 0.4295 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:56.446\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.3090 | Train score: 0.9231 | Val loss: 0.4385 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:57.051\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.2831 | Train score: 0.8846 | Val loss: 0.4501 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:57.820\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.1393 | Train score: 0.9231 | Val loss: 0.4658 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:58.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.1294 | Train score: 1.0000 | Val loss: 0.4837 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:59.293\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.1189 | Train score: 0.9615 | Val loss: 0.5107 | Val score: 0.8788\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " AnovaSelect \n",
      "                         accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                   0.778         0.000           0.778          0.000        1.000       0.000         0.500        0.000    0.875   0.000         0.000        0.000\n",
      "XGBClassifier                   0.733         0.085           0.819          0.048        0.843       0.083         0.657        0.083    0.830   0.060         0.006        0.000\n",
      "MedPFNClassifier                0.744         0.062           0.783          0.027        0.929       0.071         0.602        0.159    0.849   0.041         0.505        0.053\n",
      "MedPFNClassifier                0.750         0.062           0.789          0.037        0.929       0.055         0.609        0.145    0.852   0.038         3.888        0.581\n",
      "MedPFNClassifier                0.711         0.078           0.786          0.046        0.864       0.067         0.629        0.127    0.823   0.050         0.402        0.004\n",
      "MedPFNClassifier                0.700         0.051           0.792          0.036        0.836       0.064         0.607        0.124    0.812   0.035         1.964        0.083\n",
      "RandomForestClassifier          0.744         0.027           0.773          0.014        0.950       0.033         0.567        0.144    0.852   0.017         0.114        0.003\n",
      "LogisticRegression              0.778         0.000           0.778          0.000        1.000       0.000         0.427        0.112    0.875   0.000         0.002        0.000\n",
      "TabPFNClassifier                0.706         0.061           0.802          0.045        0.829       0.080         0.521        0.153    0.813   0.045         0.677        0.040\n",
      "TabForestPFNClassifier          0.706         0.153           0.807          0.104        0.814       0.140         0.621        0.283    0.807   0.116        13.600        0.509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-05 15:28:06.093\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.5224 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:06.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.5411 | Train score: 0.7692 | Val loss: 0.5159 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:07.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.5849 | Train score: 0.7692 | Val loss: 0.5170 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:07.526\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.5409 | Train score: 0.7692 | Val loss: 0.5170 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:07.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.5388 | Train score: 0.7692 | Val loss: 0.5171 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:08.524\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.5403 | Train score: 0.7692 | Val loss: 0.5173 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:08.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.5398 | Train score: 0.7692 | Val loss: 0.5175 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:09.405\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.5381 | Train score: 0.7692 | Val loss: 0.5176 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:09.885\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.5382 | Train score: 0.7692 | Val loss: 0.5176 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:10.356\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.5392 | Train score: 0.7692 | Val loss: 0.5174 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:10.860\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.5407 | Train score: 0.7692 | Val loss: 0.5171 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:11.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.5461 | Train score: 0.7692 | Val loss: 0.5170 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:11.811\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.5395 | Train score: 0.7692 | Val loss: 0.5168 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:12.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.5369 | Train score: 0.7692 | Val loss: 0.5166 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:12.807\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.5418 | Train score: 0.7692 | Val loss: 0.5164 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:13.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.5340 | Train score: 0.7692 | Val loss: 0.5162 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:13.743\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.5280 | Train score: 0.7692 | Val loss: 0.5159 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:14.236\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.5333 | Train score: 0.7692 | Val loss: 0.5155 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:14.731\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.5319 | Train score: 0.7692 | Val loss: 0.5151 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:15.271\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.5419 | Train score: 0.7692 | Val loss: 0.5148 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:15.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.5348 | Train score: 0.7692 | Val loss: 0.5145 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:16.522\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.5107 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:17.007\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.5557 | Train score: 0.7692 | Val loss: 0.5193 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:17.463\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.5380 | Train score: 0.7692 | Val loss: 0.5184 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:17.947\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.5405 | Train score: 0.7692 | Val loss: 0.5177 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:18.431\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.5385 | Train score: 0.7692 | Val loss: 0.5169 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:18.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.5403 | Train score: 0.7692 | Val loss: 0.5165 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:19.447\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.5370 | Train score: 0.7692 | Val loss: 0.5160 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:20.297\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.5394 | Train score: 0.7692 | Val loss: 0.5155 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:21.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.5345 | Train score: 0.7692 | Val loss: 0.5150 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:21.659\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.5347 | Train score: 0.7692 | Val loss: 0.5142 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:22.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.5303 | Train score: 0.7692 | Val loss: 0.5131 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:22.883\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.5355 | Train score: 0.7692 | Val loss: 0.5118 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:23.445\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.5353 | Train score: 0.7692 | Val loss: 0.5104 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:24.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.5376 | Train score: 0.7692 | Val loss: 0.5088 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:24.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.5274 | Train score: 0.7692 | Val loss: 0.5065 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:25.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.5746 | Train score: 0.7692 | Val loss: 0.5068 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:25.849\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.5387 | Train score: 0.7692 | Val loss: 0.5071 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:26.485\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.5203 | Train score: 0.7692 | Val loss: 0.5067 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:27.076\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.5448 | Train score: 0.7692 | Val loss: 0.5067 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:27.719\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.5366 | Train score: 0.7692 | Val loss: 0.5066 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:28.426\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.5243 | Train score: 0.7692 | Val loss: 0.5056 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:29.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.6253 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:30.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.9970 | Train score: 0.6154 | Val loss: 0.5350 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:30.854\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.6666 | Train score: 0.6923 | Val loss: 0.5233 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:31.402\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.5362 | Train score: 0.7692 | Val loss: 0.5223 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:31.967\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.5390 | Train score: 0.7692 | Val loss: 0.5218 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:32.443\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.5401 | Train score: 0.7692 | Val loss: 0.5216 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:33.034\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.5379 | Train score: 0.7692 | Val loss: 0.5214 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:33.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.5295 | Train score: 0.7692 | Val loss: 0.5213 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:33.989\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.5352 | Train score: 0.7692 | Val loss: 0.5213 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:34.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.5337 | Train score: 0.7692 | Val loss: 0.5213 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:34.900\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.5256 | Train score: 0.7692 | Val loss: 0.5214 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:35.359\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.5352 | Train score: 0.7692 | Val loss: 0.5217 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:35.811\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.5412 | Train score: 0.7692 | Val loss: 0.5219 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:36.336\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.5257 | Train score: 0.7692 | Val loss: 0.5223 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:36.812\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.5295 | Train score: 0.7692 | Val loss: 0.5229 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:37.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.5275 | Train score: 0.7692 | Val loss: 0.5236 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:37.700\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.5669 | Train score: 0.7692 | Val loss: 0.5238 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:38.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.5268 | Train score: 0.7692 | Val loss: 0.5243 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:38.850\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.5284 | Train score: 0.7692 | Val loss: 0.5248 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:39.402\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.5096 | Train score: 0.7692 | Val loss: 0.5256 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:39.937\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.5406 | Train score: 0.7692 | Val loss: 0.5263 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:40.665\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.4557 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:41.170\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.6009 | Train score: 0.7308 | Val loss: 0.4955 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:41.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.5398 | Train score: 0.7692 | Val loss: 0.5139 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:42.123\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.5395 | Train score: 0.7692 | Val loss: 0.5171 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:42.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.5372 | Train score: 0.7692 | Val loss: 0.5173 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:43.850\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.5364 | Train score: 0.7692 | Val loss: 0.5169 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:44.467\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.5350 | Train score: 0.7692 | Val loss: 0.5162 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:45.033\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.5384 | Train score: 0.7692 | Val loss: 0.5155 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:45.955\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.5354 | Train score: 0.7692 | Val loss: 0.5145 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:46.429\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.5297 | Train score: 0.7692 | Val loss: 0.5131 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:46.846\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.5378 | Train score: 0.7692 | Val loss: 0.5116 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:47.314\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.5298 | Train score: 0.7692 | Val loss: 0.5095 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:47.883\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.5692 | Train score: 0.7692 | Val loss: 0.5094 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:48.601\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.5111 | Train score: 0.7692 | Val loss: 0.5083 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:49.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.5240 | Train score: 0.7692 | Val loss: 0.5069 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:49.718\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.5209 | Train score: 0.7692 | Val loss: 0.5048 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:50.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.5394 | Train score: 0.7692 | Val loss: 0.5030 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:50.825\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.5002 | Train score: 0.7692 | Val loss: 0.5004 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:51.348\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.5080 | Train score: 0.7692 | Val loss: 0.4977 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:51.956\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.5041 | Train score: 0.7692 | Val loss: 0.4950 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:52.417\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.4900 | Train score: 0.7692 | Val loss: 0.4925 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:53.170\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.5163 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:53.671\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.4352 | Train score: 0.8077 | Val loss: 0.5559 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:54.083\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.6519 | Train score: 0.7692 | Val loss: 0.5264 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:54.524\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.3751 | Train score: 0.7692 | Val loss: 0.5231 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:55.110\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.4630 | Train score: 0.8077 | Val loss: 0.5266 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:55.593\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.4446 | Train score: 0.7692 | Val loss: 0.5266 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:56.015\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.5787 | Train score: 0.7308 | Val loss: 0.5238 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:56.455\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.4119 | Train score: 0.8077 | Val loss: 0.5205 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:57.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.4297 | Train score: 0.8462 | Val loss: 0.5184 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:57.498\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.4475 | Train score: 0.7692 | Val loss: 0.5173 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:57.935\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.3752 | Train score: 0.7692 | Val loss: 0.5194 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:58.402\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.4288 | Train score: 0.8077 | Val loss: 0.5216 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:59.048\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.4588 | Train score: 0.8077 | Val loss: 0.5235 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:59.642\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.4848 | Train score: 0.7692 | Val loss: 0.5159 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:00.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.5077 | Train score: 0.7692 | Val loss: 0.5075 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:00.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.3949 | Train score: 0.8077 | Val loss: 0.5013 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:01.154\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.5028 | Train score: 0.7308 | Val loss: 0.4964 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:01.659\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.4435 | Train score: 0.8077 | Val loss: 0.4898 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:02.131\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.3843 | Train score: 0.8077 | Val loss: 0.4922 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:02.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.2867 | Train score: 0.9231 | Val loss: 0.5098 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:03.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.3240 | Train score: 0.8462 | Val loss: 0.5481 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:03.845\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.5672 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:04.331\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.4804 | Train score: 0.8077 | Val loss: 0.6362 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:04.750\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.4415 | Train score: 0.8077 | Val loss: 0.6531 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:05.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.4076 | Train score: 0.7692 | Val loss: 0.6857 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:05.875\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.4102 | Train score: 0.8462 | Val loss: 0.7199 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:06.370\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.6174 | Train score: 0.7308 | Val loss: 0.7026 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:06.790\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.5248 | Train score: 0.8077 | Val loss: 0.6860 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:07.294\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.5292 | Train score: 0.8077 | Val loss: 0.6497 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:07.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.4319 | Train score: 0.8462 | Val loss: 0.6304 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:08.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.4405 | Train score: 0.8077 | Val loss: 0.6134 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:08.946\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.5832 | Train score: 0.8077 | Val loss: 0.5992 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:09.431\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.4525 | Train score: 0.8077 | Val loss: 0.5885 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:09.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.4528 | Train score: 0.8077 | Val loss: 0.5929 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:10.417\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.4004 | Train score: 0.8462 | Val loss: 0.6061 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:10.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.3933 | Train score: 0.8462 | Val loss: 0.6267 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:11.426\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.4726 | Train score: 0.8077 | Val loss: 0.6443 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:11.913\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.4763 | Train score: 0.8077 | Val loss: 0.6601 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:12.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.4383 | Train score: 0.8077 | Val loss: 0.6775 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:12.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.4579 | Train score: 0.8462 | Val loss: 0.6949 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:13.474\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.4659 | Train score: 0.8462 | Val loss: 0.7083 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:14.052\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.3891 | Train score: 0.8462 | Val loss: 0.7257 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:14.898\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.4922 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:15.503\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.4765 | Train score: 0.7692 | Val loss: 0.6134 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:16.012\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.8006 | Train score: 0.6154 | Val loss: 0.5791 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:16.511\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.4605 | Train score: 0.8077 | Val loss: 0.5425 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:16.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.4631 | Train score: 0.6538 | Val loss: 0.5261 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:17.555\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.4678 | Train score: 0.7308 | Val loss: 0.5231 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:18.047\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.5648 | Train score: 0.7692 | Val loss: 0.5095 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:18.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.5014 | Train score: 0.7692 | Val loss: 0.5043 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:19.169\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.5125 | Train score: 0.7692 | Val loss: 0.5035 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:19.717\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.5966 | Train score: 0.8077 | Val loss: 0.5048 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:20.229\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.5195 | Train score: 0.7308 | Val loss: 0.5089 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:20.719\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.5237 | Train score: 0.7692 | Val loss: 0.5100 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:21.210\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.5261 | Train score: 0.7692 | Val loss: 0.5097 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:21.682\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.5253 | Train score: 0.7692 | Val loss: 0.5085 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:22.169\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.5264 | Train score: 0.7692 | Val loss: 0.5064 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:22.649\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.5361 | Train score: 0.7692 | Val loss: 0.5039 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:23.123\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.4969 | Train score: 0.7692 | Val loss: 0.5000 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:23.597\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.4918 | Train score: 0.7692 | Val loss: 0.4973 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:24.104\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.4799 | Train score: 0.7692 | Val loss: 0.5000 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:24.576\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.4522 | Train score: 0.7692 | Val loss: 0.5080 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:25.021\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.4049 | Train score: 0.7692 | Val loss: 0.5194 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:25.752\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.4801 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:26.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.5324 | Train score: 0.7692 | Val loss: 0.4470 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:26.746\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.6478 | Train score: 0.7308 | Val loss: 0.4760 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:27.195\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.5875 | Train score: 0.7308 | Val loss: 0.5067 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:27.732\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.5335 | Train score: 0.7692 | Val loss: 0.5096 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:28.236\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.5340 | Train score: 0.7692 | Val loss: 0.5092 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:28.778\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.5359 | Train score: 0.7692 | Val loss: 0.5078 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:29.293\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.5326 | Train score: 0.7692 | Val loss: 0.5056 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:29.756\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.5393 | Train score: 0.7692 | Val loss: 0.5038 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:30.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.5298 | Train score: 0.7692 | Val loss: 0.5013 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:30.804\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.5696 | Train score: 0.7692 | Val loss: 0.5010 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:31.289\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.5230 | Train score: 0.7692 | Val loss: 0.4998 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:31.797\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.5534 | Train score: 0.7692 | Val loss: 0.4995 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:32.456\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.5261 | Train score: 0.7692 | Val loss: 0.4983 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:33.225\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.5225 | Train score: 0.7692 | Val loss: 0.4962 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:33.982\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.5504 | Train score: 0.7692 | Val loss: 0.4950 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:34.634\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.5270 | Train score: 0.7692 | Val loss: 0.4932 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:35.192\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.5104 | Train score: 0.7692 | Val loss: 0.4904 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:35.769\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.5376 | Train score: 0.7692 | Val loss: 0.4877 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:36.391\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.5123 | Train score: 0.7692 | Val loss: 0.4838 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:37.128\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.4955 | Train score: 0.7692 | Val loss: 0.4780 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:38.045\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.4495 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:38.671\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.6410 | Train score: 0.8077 | Val loss: 0.4924 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:39.219\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.5762 | Train score: 0.7308 | Val loss: 0.5140 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:39.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.5411 | Train score: 0.7692 | Val loss: 0.5155 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:40.384\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.5379 | Train score: 0.7692 | Val loss: 0.5154 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:40.911\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.5378 | Train score: 0.7692 | Val loss: 0.5148 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:41.438\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.5403 | Train score: 0.7692 | Val loss: 0.5143 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:42.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.5384 | Train score: 0.7692 | Val loss: 0.5137 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:42.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.5366 | Train score: 0.7692 | Val loss: 0.5129 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:43.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.5410 | Train score: 0.7692 | Val loss: 0.5122 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:43.571\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.5387 | Train score: 0.7692 | Val loss: 0.5116 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:44.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.5389 | Train score: 0.7692 | Val loss: 0.5111 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:44.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.5403 | Train score: 0.7692 | Val loss: 0.5107 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:45.208\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.5385 | Train score: 0.7692 | Val loss: 0.5102 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:45.701\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.5334 | Train score: 0.7692 | Val loss: 0.5094 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:46.327\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.5345 | Train score: 0.7692 | Val loss: 0.5085 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:46.873\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.5380 | Train score: 0.7692 | Val loss: 0.5076 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:47.403\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.5379 | Train score: 0.7692 | Val loss: 0.5068 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:47.972\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.5345 | Train score: 0.7692 | Val loss: 0.5058 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:48.586\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.5332 | Train score: 0.7692 | Val loss: 0.5046 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:49.089\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.5264 | Train score: 0.7692 | Val loss: 0.5030 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:49.854\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.5210 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:50.506\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.5540 | Train score: 0.7692 | Val loss: 0.5218 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:51.028\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.5406 | Train score: 0.7692 | Val loss: 0.5191 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:51.526\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.5403 | Train score: 0.7692 | Val loss: 0.5166 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:52.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.5399 | Train score: 0.7692 | Val loss: 0.5146 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:52.704\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.5374 | Train score: 0.7692 | Val loss: 0.5132 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:53.187\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.5402 | Train score: 0.7692 | Val loss: 0.5123 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:53.665\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.5341 | Train score: 0.7692 | Val loss: 0.5111 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:54.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.5278 | Train score: 0.7692 | Val loss: 0.5088 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:54.762\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.5317 | Train score: 0.7692 | Val loss: 0.5052 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:55.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.5344 | Train score: 0.7692 | Val loss: 0.5002 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:55.800\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.5339 | Train score: 0.7692 | Val loss: 0.4954 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:56.539\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.5900 | Train score: 0.7692 | Val loss: 0.4974 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:57.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.5599 | Train score: 0.7692 | Val loss: 0.5001 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:58.403\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.5316 | Train score: 0.7692 | Val loss: 0.5018 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:59.294\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.5270 | Train score: 0.7692 | Val loss: 0.5020 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:30:00.131\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.5191 | Train score: 0.7692 | Val loss: 0.5009 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:30:00.786\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.5065 | Train score: 0.7692 | Val loss: 0.4978 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:30:01.513\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.5375 | Train score: 0.7692 | Val loss: 0.4952 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:30:02.163\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.5233 | Train score: 0.7692 | Val loss: 0.4911 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:30:02.877\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.5179 | Train score: 0.7692 | Val loss: 0.4854 | Val score: 0.7879\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " RandomSelect \n",
      "                         accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                   0.778         0.000           0.778          0.000        1.000       0.000         0.500        0.000    0.875   0.000         0.000        0.000\n",
      "XGBClassifier                   0.656         0.085           0.762          0.038        0.807       0.091         0.569        0.108    0.783   0.061         0.008        0.003\n",
      "MedPFNClassifier                0.628         0.079           0.767          0.057        0.757       0.116         0.462        0.112    0.756   0.062         0.460        0.018\n",
      "MedPFNClassifier                0.722         0.086           0.781          0.042        0.893       0.080         0.521        0.159    0.832   0.055         3.041        0.227\n",
      "MedPFNClassifier                0.694         0.090           0.792          0.046        0.821       0.092         0.579        0.169    0.805   0.064         0.407        0.010\n",
      "MedPFNClassifier                0.689         0.062           0.795          0.051        0.814       0.073         0.543        0.147    0.802   0.042         1.647        0.062\n",
      "RandomForestClassifier          0.733         0.054           0.770          0.020        0.936       0.067         0.584        0.154    0.844   0.037         0.114        0.002\n",
      "LogisticRegression              0.778         0.000           0.778          0.000        1.000       0.000         0.495        0.110    0.875   0.000         0.002        0.000\n",
      "TabPFNClassifier                0.778         0.000           0.778          0.000        1.000       0.000         0.488        0.105    0.875   0.000         0.592        0.021\n",
      "TabForestPFNClassifier          0.767         0.022           0.779          0.008        0.979       0.046         0.616        0.168    0.867   0.017        11.493        1.015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-05 15:31:30.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.5780 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:31.170\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.4803 | Train score: 0.7308 | Val loss: 0.5725 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:31.687\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.4833 | Train score: 0.8077 | Val loss: 0.5627 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:32.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.4398 | Train score: 0.8077 | Val loss: 0.5768 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:32.959\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.4663 | Train score: 0.7692 | Val loss: 0.6151 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:33.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.4590 | Train score: 0.8077 | Val loss: 0.6611 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:34.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.5309 | Train score: 0.8077 | Val loss: 0.6840 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:34.658\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.3834 | Train score: 0.8462 | Val loss: 0.7449 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:35.155\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.2952 | Train score: 0.8846 | Val loss: 0.8276 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:35.637\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.6821 | Train score: 0.8077 | Val loss: 0.8346 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:36.225\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.3496 | Train score: 0.7692 | Val loss: 0.8322 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:36.764\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.3635 | Train score: 0.8846 | Val loss: 0.8139 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:37.248\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.4395 | Train score: 0.8077 | Val loss: 0.8017 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:37.788\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.5695 | Train score: 0.7692 | Val loss: 0.7842 | Val score: 0.6970\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:38.383\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.5696 | Train score: 0.7692 | Val loss: 0.7426 | Val score: 0.6667\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:38.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.4524 | Train score: 0.8462 | Val loss: 0.7336 | Val score: 0.6667\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:39.534\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.5076 | Train score: 0.8462 | Val loss: 0.7201 | Val score: 0.6667\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:40.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.5109 | Train score: 0.8077 | Val loss: 0.7108 | Val score: 0.6667\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:40.774\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.3682 | Train score: 0.8077 | Val loss: 0.7199 | Val score: 0.6364\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:41.270\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.4182 | Train score: 0.8077 | Val loss: 0.7496 | Val score: 0.6364\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:41.794\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.3405 | Train score: 0.8462 | Val loss: 0.7994 | Val score: 0.5758\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:42.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.5293 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:43.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.5475 | Train score: 0.8077 | Val loss: 0.5482 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:43.705\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.4848 | Train score: 0.8077 | Val loss: 0.5514 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:44.333\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.4900 | Train score: 0.8077 | Val loss: 0.5516 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:44.856\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.4881 | Train score: 0.8077 | Val loss: 0.5512 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:45.338\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.5483 | Train score: 0.7692 | Val loss: 0.5520 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:45.868\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.4875 | Train score: 0.8077 | Val loss: 0.5511 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:46.477\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.4804 | Train score: 0.8077 | Val loss: 0.5478 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:46.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.5080 | Train score: 0.8077 | Val loss: 0.5509 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:47.571\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.4831 | Train score: 0.8077 | Val loss: 0.5525 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:48.244\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.4763 | Train score: 0.8077 | Val loss: 0.5546 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:48.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.5355 | Train score: 0.7692 | Val loss: 0.5544 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:49.404\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.4759 | Train score: 0.8077 | Val loss: 0.5536 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:50.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.4732 | Train score: 0.8077 | Val loss: 0.5529 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:50.804\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.4560 | Train score: 0.8077 | Val loss: 0.5534 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:51.332\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.5135 | Train score: 0.7692 | Val loss: 0.5533 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:51.885\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.4809 | Train score: 0.8077 | Val loss: 0.5474 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:52.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.4974 | Train score: 0.8077 | Val loss: 0.5382 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:53.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.5867 | Train score: 0.7692 | Val loss: 0.5300 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:53.640\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.4277 | Train score: 0.8077 | Val loss: 0.5238 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:54.243\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.4165 | Train score: 0.8077 | Val loss: 0.5127 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:55.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.5409 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:55.669\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.5128 | Train score: 0.8077 | Val loss: 0.5546 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:56.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.4922 | Train score: 0.8077 | Val loss: 0.5568 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:56.783\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.4926 | Train score: 0.8077 | Val loss: 0.5581 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:57.310\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.5431 | Train score: 0.7692 | Val loss: 0.5580 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:57.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.4907 | Train score: 0.8077 | Val loss: 0.5584 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:58.495\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.4898 | Train score: 0.8077 | Val loss: 0.5590 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:59.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.5405 | Train score: 0.7692 | Val loss: 0.5588 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:59.497\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.4929 | Train score: 0.8077 | Val loss: 0.5590 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:00.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.4879 | Train score: 0.8077 | Val loss: 0.5592 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:00.668\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.5379 | Train score: 0.7692 | Val loss: 0.5584 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:01.193\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.4884 | Train score: 0.8077 | Val loss: 0.5578 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:01.761\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.4839 | Train score: 0.8077 | Val loss: 0.5571 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:02.379\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.4863 | Train score: 0.8077 | Val loss: 0.5565 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:02.912\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.4853 | Train score: 0.8077 | Val loss: 0.5562 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:03.430\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.4926 | Train score: 0.8077 | Val loss: 0.5577 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:04.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.4815 | Train score: 0.8077 | Val loss: 0.5601 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:04.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.5327 | Train score: 0.7692 | Val loss: 0.5561 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:05.131\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.5015 | Train score: 0.8077 | Val loss: 0.5561 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:05.936\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.4846 | Train score: 0.8077 | Val loss: 0.5569 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:06.568\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.4703 | Train score: 0.8077 | Val loss: 0.5571 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:07.386\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.5546 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:08.114\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.4964 | Train score: 0.7692 | Val loss: 0.5260 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:08.983\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.5427 | Train score: 0.7692 | Val loss: 0.5173 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:09.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.5210 | Train score: 0.7692 | Val loss: 0.5175 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:10.162\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.5188 | Train score: 0.7692 | Val loss: 0.5264 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:10.790\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.5001 | Train score: 0.7692 | Val loss: 0.5630 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:11.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.5016 | Train score: 0.7692 | Val loss: 0.5967 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:11.826\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.3866 | Train score: 0.7692 | Val loss: 0.6277 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:12.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.4325 | Train score: 0.6923 | Val loss: 0.6275 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:12.900\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.5590 | Train score: 0.8462 | Val loss: 0.6316 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:13.375\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.6307 | Train score: 0.6923 | Val loss: 0.6167 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:13.921\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.3354 | Train score: 0.8462 | Val loss: 0.6190 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:14.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.4097 | Train score: 0.6923 | Val loss: 0.6389 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:14.957\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.6172 | Train score: 0.7692 | Val loss: 0.6444 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:15.407\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.4058 | Train score: 0.8462 | Val loss: 0.6454 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:15.915\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.3591 | Train score: 0.8846 | Val loss: 0.6455 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:16.487\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.4169 | Train score: 0.8846 | Val loss: 0.6498 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:16.995\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.3451 | Train score: 0.8077 | Val loss: 0.6503 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:17.474\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.4167 | Train score: 0.8462 | Val loss: 0.6579 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:18.019\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.4104 | Train score: 0.8077 | Val loss: 0.6600 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:18.595\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.3941 | Train score: 0.8462 | Val loss: 0.6759 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:19.348\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.5129 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:19.874\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.5658 | Train score: 0.7692 | Val loss: 0.5086 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:20.443\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.5450 | Train score: 0.7692 | Val loss: 0.5179 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:20.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.5422 | Train score: 0.7692 | Val loss: 0.5191 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:21.398\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.5385 | Train score: 0.7692 | Val loss: 0.5194 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:21.954\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.5427 | Train score: 0.7692 | Val loss: 0.5194 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:22.552\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.5411 | Train score: 0.7692 | Val loss: 0.5192 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:23.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.5398 | Train score: 0.7692 | Val loss: 0.5186 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:23.542\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.5415 | Train score: 0.7692 | Val loss: 0.5180 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:24.097\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.5379 | Train score: 0.7692 | Val loss: 0.5174 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:24.660\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.5398 | Train score: 0.7692 | Val loss: 0.5170 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:25.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.5413 | Train score: 0.7692 | Val loss: 0.5166 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:25.597\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.5385 | Train score: 0.7692 | Val loss: 0.5162 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:26.157\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.5372 | Train score: 0.7692 | Val loss: 0.5158 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:26.686\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.5406 | Train score: 0.7692 | Val loss: 0.5154 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:27.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.5378 | Train score: 0.7692 | Val loss: 0.5151 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:27.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.5356 | Train score: 0.7692 | Val loss: 0.5146 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:28.241\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.5405 | Train score: 0.7692 | Val loss: 0.5142 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:28.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.5375 | Train score: 0.7692 | Val loss: 0.5136 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:29.234\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.5450 | Train score: 0.7692 | Val loss: 0.5132 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:29.771\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.5384 | Train score: 0.7692 | Val loss: 0.5127 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:30.579\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.5345 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:31.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.5019 | Train score: 0.7692 | Val loss: 0.5582 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:31.599\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.4902 | Train score: 0.8077 | Val loss: 0.5429 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:32.157\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.5423 | Train score: 0.7308 | Val loss: 0.5305 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:32.738\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.5557 | Train score: 0.7692 | Val loss: 0.5197 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:33.263\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.6202 | Train score: 0.7308 | Val loss: 0.5163 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:33.762\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.5381 | Train score: 0.7692 | Val loss: 0.5196 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:34.373\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.5422 | Train score: 0.7692 | Val loss: 0.5210 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:34.911\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.5399 | Train score: 0.7692 | Val loss: 0.5211 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:35.388\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.5418 | Train score: 0.7692 | Val loss: 0.5208 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:35.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.5377 | Train score: 0.7692 | Val loss: 0.5202 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:36.515\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.5376 | Train score: 0.7692 | Val loss: 0.5196 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:37.019\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.5456 | Train score: 0.7692 | Val loss: 0.5193 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:37.486\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.5424 | Train score: 0.7692 | Val loss: 0.5191 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:38.029\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.5379 | Train score: 0.7692 | Val loss: 0.5190 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:38.604\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.5389 | Train score: 0.7692 | Val loss: 0.5189 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:39.162\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.5391 | Train score: 0.7692 | Val loss: 0.5188 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:39.685\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.5383 | Train score: 0.7692 | Val loss: 0.5187 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:40.266\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.5381 | Train score: 0.7692 | Val loss: 0.5189 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:40.862\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.5403 | Train score: 0.7692 | Val loss: 0.5191 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:41.370\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.5376 | Train score: 0.7692 | Val loss: 0.5194 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:42.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.5465 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:42.812\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.4783 | Train score: 0.7692 | Val loss: 0.5599 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:43.315\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.5714 | Train score: 0.6923 | Val loss: 0.5450 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:43.822\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.5174 | Train score: 0.7692 | Val loss: 0.5485 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:44.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.5866 | Train score: 0.7692 | Val loss: 0.5382 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:44.933\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.5109 | Train score: 0.7692 | Val loss: 0.5373 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:45.410\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.5066 | Train score: 0.7692 | Val loss: 0.5479 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:45.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.5115 | Train score: 0.7692 | Val loss: 0.5540 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:46.511\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.6099 | Train score: 0.6538 | Val loss: 0.5509 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:46.995\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.4682 | Train score: 0.7692 | Val loss: 0.5500 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:47.503\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.4172 | Train score: 0.8462 | Val loss: 0.5528 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:48.043\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.5124 | Train score: 0.8462 | Val loss: 0.5552 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:48.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.4324 | Train score: 0.7308 | Val loss: 0.5620 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:49.138\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.3780 | Train score: 0.8077 | Val loss: 0.5793 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:49.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.4172 | Train score: 0.8077 | Val loss: 0.6066 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:50.216\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.3815 | Train score: 0.8077 | Val loss: 0.6311 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:50.719\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.4961 | Train score: 0.7692 | Val loss: 0.6495 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:51.202\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.4558 | Train score: 0.7692 | Val loss: 0.6452 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:51.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.3990 | Train score: 0.8462 | Val loss: 0.6535 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:52.234\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.2725 | Train score: 0.8846 | Val loss: 0.6845 | Val score: 0.6970\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:52.741\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.2989 | Train score: 0.8462 | Val loss: 0.7336 | Val score: 0.6667\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:53.480\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.5142 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:54.037\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.5310 | Train score: 0.7692 | Val loss: 0.5074 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:54.580\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.5871 | Train score: 0.7692 | Val loss: 0.5197 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:55.091\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.5344 | Train score: 0.7692 | Val loss: 0.5209 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:55.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.5358 | Train score: 0.7692 | Val loss: 0.5210 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:56.096\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.5357 | Train score: 0.7692 | Val loss: 0.5205 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:56.657\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.5280 | Train score: 0.7692 | Val loss: 0.5177 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:57.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.5167 | Train score: 0.7692 | Val loss: 0.5154 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:57.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.5568 | Train score: 0.7308 | Val loss: 0.5159 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:58.170\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.5277 | Train score: 0.7692 | Val loss: 0.5196 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:58.704\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.5167 | Train score: 0.7692 | Val loss: 0.5210 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:59.175\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.5286 | Train score: 0.7692 | Val loss: 0.5225 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:59.641\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.5089 | Train score: 0.7692 | Val loss: 0.5258 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:00.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.4891 | Train score: 0.7692 | Val loss: 0.5397 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:00.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.4596 | Train score: 0.7692 | Val loss: 0.6103 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:01.356\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.4546 | Train score: 0.7308 | Val loss: 0.6929 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:01.905\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.4048 | Train score: 0.8462 | Val loss: 0.7549 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:02.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.5621 | Train score: 0.8077 | Val loss: 0.7607 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:02.960\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.5592 | Train score: 0.7308 | Val loss: 0.7421 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:03.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.4112 | Train score: 0.7692 | Val loss: 0.7304 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:03.980\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.4429 | Train score: 0.8077 | Val loss: 0.6811 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:04.781\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.5556 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:05.309\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.5005 | Train score: 0.8077 | Val loss: 0.5832 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:05.886\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.6313 | Train score: 0.8077 | Val loss: 0.5311 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:06.485\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.5225 | Train score: 0.7308 | Val loss: 0.5079 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:06.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.5672 | Train score: 0.7692 | Val loss: 0.5059 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:07.413\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.5362 | Train score: 0.7692 | Val loss: 0.5114 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:07.941\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.5419 | Train score: 0.7692 | Val loss: 0.5157 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:08.513\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.5400 | Train score: 0.7692 | Val loss: 0.5181 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:09.068\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.5382 | Train score: 0.7692 | Val loss: 0.5192 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:09.670\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.5410 | Train score: 0.7692 | Val loss: 0.5198 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:10.330\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.5355 | Train score: 0.7692 | Val loss: 0.5201 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:10.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.5365 | Train score: 0.7692 | Val loss: 0.5202 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:11.415\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.5374 | Train score: 0.7692 | Val loss: 0.5202 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:11.940\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.5344 | Train score: 0.7692 | Val loss: 0.5200 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:12.496\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.5366 | Train score: 0.7692 | Val loss: 0.5197 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:12.967\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.5290 | Train score: 0.7692 | Val loss: 0.5190 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:13.433\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.5295 | Train score: 0.7692 | Val loss: 0.5183 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:13.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.5270 | Train score: 0.7692 | Val loss: 0.5177 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:14.540\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.5167 | Train score: 0.7692 | Val loss: 0.5173 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:15.012\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.5512 | Train score: 0.7692 | Val loss: 0.5182 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:15.499\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.4887 | Train score: 0.7692 | Val loss: 0.5210 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:16.306\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.6015 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:16.906\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.4886 | Train score: 0.7692 | Val loss: 0.7183 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:17.412\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.6486 | Train score: 0.6923 | Val loss: 0.6339 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:17.936\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.6495 | Train score: 0.6923 | Val loss: 0.5939 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:18.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.5668 | Train score: 0.7692 | Val loss: 0.5767 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:19.083\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.6965 | Train score: 0.7692 | Val loss: 0.5619 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:19.593\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.5027 | Train score: 0.7692 | Val loss: 0.5533 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:20.176\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.4874 | Train score: 0.7692 | Val loss: 0.5544 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:20.749\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.5358 | Train score: 0.7692 | Val loss: 0.5526 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:21.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.5302 | Train score: 0.7692 | Val loss: 0.5545 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:21.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.5289 | Train score: 0.7692 | Val loss: 0.5559 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:22.351\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.5680 | Train score: 0.7692 | Val loss: 0.5531 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:22.859\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.5230 | Train score: 0.7692 | Val loss: 0.5521 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:23.361\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.5533 | Train score: 0.7692 | Val loss: 0.5487 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:23.907\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.5096 | Train score: 0.7692 | Val loss: 0.5533 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:24.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.5234 | Train score: 0.7692 | Val loss: 0.5581 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:25.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.5010 | Train score: 0.7692 | Val loss: 0.5686 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:25.512\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.4746 | Train score: 0.7692 | Val loss: 0.5791 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:26.054\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.4619 | Train score: 0.7692 | Val loss: 0.5910 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:26.642\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.4634 | Train score: 0.7692 | Val loss: 0.5999 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:27.121\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.4464 | Train score: 0.7692 | Val loss: 0.6072 | Val score: 0.7879\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " NonZeroSelect \n",
      "                         accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                   0.778         0.000           0.778          0.000        1.000       0.000         0.500        0.000    0.875   0.000         0.000        0.000\n",
      "XGBClassifier                   0.756         0.051           0.820          0.060        0.893       0.092         0.579        0.183    0.849   0.036         0.013        0.001\n",
      "MedPFNClassifier                0.783         0.084           0.828          0.057        0.914       0.089         0.620        0.181    0.867   0.056         0.463        0.018\n",
      "MedPFNClassifier                0.789         0.078           0.822          0.059        0.936       0.067         0.620        0.201    0.873   0.048         4.709        2.812\n",
      "MedPFNClassifier                0.728         0.080           0.804          0.041        0.857       0.071         0.595        0.191    0.829   0.054         0.418        0.013\n",
      "MedPFNClassifier                0.733         0.048           0.796          0.031        0.886       0.047         0.593        0.199    0.838   0.031         1.960        0.060\n",
      "RandomForestClassifier          0.778         0.000           0.778          0.000        1.000       0.000         0.555        0.181    0.875   0.000         0.147        0.006\n",
      "LogisticRegression              0.778         0.000           0.778          0.000        1.000       0.000         0.464        0.155    0.875   0.000         0.002        0.000\n",
      "TabPFNClassifier                0.778         0.000           0.778          0.000        1.000       0.000         0.550        0.163    0.875   0.000         0.626        0.035\n",
      "TabForestPFNClassifier          0.733         0.060           0.777          0.012        0.921       0.103         0.462        0.128    0.840   0.047        11.463        0.404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "save = False\n",
    "sampling = None\n",
    "cv = 10\n",
    "best_delete = 0\n",
    "strat_split = True\n",
    "recomp = False\n",
    "n_optim = 1000\n",
    "cat_optim = 10\n",
    "ft_epochs = 20\n",
    "ft_lr = 1e-5\n",
    "max_s = 1024\n",
    "max_q = 128\n",
    "max_samples = 1024\n",
    "no_pre_process = False\n",
    "multi_decoder = \"permutation\"\n",
    "N_ens = 5\n",
    "seed = 42\n",
    "overwrite = True\n",
    "metrics = [\"accuracy\", \"precision\", \"recall\", \"roc_auc\", \"f1\"]\n",
    "dir_path = os.path.abspath(os.getcwd())\n",
    "run_name = \"medium_net_mlp_balance_bsplit_baseline\" ## NO PERM, VERY ROBUST\n",
    "#run_name2 = \"large_mlp_var_balance_05weight_anova\" ## das aller bestigste\n",
    "run_name = \"medium_mlp_var_balance_05weight_anova_bestwithnoisebnn_100\" ## das aller bestigste\n",
    "run_name2 = \"small_mlp_var_balance_05weight_anova_bestwithnoisebnn_100\" ## das aller bestigste ## das aller bestigste\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_200\" ## das aller bestigste\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_longer\" ## das aller bestigste\n",
    "#run_name = \"medium_mlp_balance_lownoisefixparam_anova\"\n",
    "#run_name = \"medium_mlp_0.5static_balance_anova\"\n",
    "#run_name = \"large_mlp_fullbalance\"\n",
    "#run_name = \"small_net_mlp_var_imbalance_05weight\" ## WORKS VERY WELL WITH PERM\n",
    "#run_name = \"small_net_mlp_varbalance_weight_batchunisplit\"\n",
    "#run_name = \"small_net_mlp_variable_balance_weight\"\n",
    "#run_name = \"small_net_mlp_balance_minevalup\"\n",
    "path = dir_path + f\"/logs/trainrun_{run_name}\"\n",
    "path2 = dir_path + f\"/logs/trainrun_{run_name2}\"\n",
    "filename = \"model\"\n",
    "\n",
    "\n",
    "models = [\n",
    "    #CatBoostOptim(n_optim=cat_optim),\n",
    "    MajorityClass(),\n",
    "    XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic'),\n",
    "    MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process),\n",
    "    MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process, ft_epochs=ft_epochs, ft_lr=ft_lr),\n",
    "    MedPFNClassifier(base_path=path2, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process),\n",
    "    MedPFNClassifier(base_path=path2, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process, ft_epochs=ft_epochs, ft_lr=ft_lr),\n",
    "    RandomForestClassifier(),\n",
    "    #AutoGluon(),\n",
    "    #CatBoostGrid(),\n",
    "    #XGBoostGrid(),\n",
    "    #XGBoostOptim(n_optim=n_optim),\n",
    "    LogisticRegression(max_iter=1000), \n",
    "    TabPFNClassifier(device='cpu', N_ensemble_configurations=5, no_preprocess_mode=no_pre_process),\n",
    "    TabForestPFNClassifier(\"saved_models/tabforest/mix600k/tabforestpfn.pt\", \"saved_models/tabforest/mix600k/config_run.yaml\", max_epochs=ft_epochs)\n",
    "]\n",
    "\n",
    "for reducer in [AnovaSelect(), RandomSelect(), NonZeroSelect(), MeanSelect(), StdSelect(), MaxSelect(), PCASelect()]:\n",
    "    results_mean = pd.DataFrame(np.zeros((len(models), len(metrics)+1)),\n",
    "                                index=[m.__class__.__name__ for m in models],\n",
    "                                columns=metrics+[\"runtime\"])\n",
    "    results_std = pd.DataFrame(np.zeros((len(models), len(metrics)+1)), \n",
    "                               index=[m.__class__.__name__ for m in models],\n",
    "                               columns=metrics+[\"runtime\"])\n",
    "    \n",
    "    for ii, model in enumerate(models):\n",
    "        results_mean.iloc[ii,:], results_std.iloc[ii,:] = cross_validate_sample(\n",
    "            model, all_data, labels, metrics, strat_split, cv, sampling, \n",
    "            reducer, max_samples, seed=seed, overwrite=overwrite, n_best_delete=best_delete,\n",
    "            recomp=recomp)\n",
    "\n",
    "    results_mean = results_mean.add_suffix(\" mean\")\n",
    "    results_std = results_std.add_suffix(\" std\")\n",
    "    results_full = pd.concat((results_mean, results_std), axis=1)\n",
    "    cols = results_full.columns.tolist()\n",
    "    new_cols = []\n",
    "    for i in range(int(len(cols)/2)):\n",
    "        new_cols.append(cols[i])\n",
    "        new_cols.append(cols[i+int(len(cols)/2)])\n",
    "    results_full = results_full[new_cols]\n",
    "    red_name = reducer.__class__.__name__\n",
    "    if save:\n",
    "        directory = f\"results/{red_name}\"\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        save_path = f'results/{red_name}/baseline_cv{cv}_mxsamp{max_samples}_sd{seed}_ovrw{int(overwrite)}'\n",
    "        results_full.to_csv(save_path)\n",
    "    print(\"\\n\", \"\\n\", red_name, \"\\n\", results_full.round(3))\n",
    "    #print(results_full.sort_values(\"roc_auc mean\").round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef9e5ef-c542-4525-8e60-6ae0ad51b6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = False\n",
    "sampling = None\n",
    "cv = 10\n",
    "best_delete = 0\n",
    "strat_split = True\n",
    "recomp = False\n",
    "n_optim = 1000\n",
    "cat_optim = 10\n",
    "ft_epochs = 20\n",
    "ft_epochs_forest = 10\n",
    "ft_lr = 1e-5\n",
    "max_s = 1024\n",
    "max_q = 128\n",
    "max_samples = 1024\n",
    "no_pre_process = False\n",
    "multi_decoder = \"permutation\"\n",
    "N_ens = 5\n",
    "seed = 42\n",
    "overwrite = True\n",
    "metrics = [\"accuracy\", \"precision\", \"recall\", \"roc_auc\", \"f1\"]\n",
    "dir_path = os.path.abspath(os.getcwd())\n",
    "#run_name = \"medium_net_mlp_balance_bsplit_baseline\" ## NO PERM, VERY ROBUST\n",
    "#run_name2 = \"large_mlp_var_balance_05weight_anova\" ## das aller bestigste\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_newprior\" ## das aller bestigste\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_newprior\" ## das aller bestigste\n",
    "run_name = \"medium_mlp_var_balance_05weight_anova_bestwithnoisebnn_100\" ## good start, best with ft\n",
    "#run_name3 = \"medium_mlp_var_balance_05weight_anova_bestwithnoisebnn_100_moreweight\" ## best start, ft no so good\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_200\" ## das aller bestigste\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_longer\" ## das aller bestigste\n",
    "#run_name = \"medium_mlp_balance_lownoisefixparam_anova\"\n",
    "#run_name = \"medium_mlp_0.5static_balance_anova\"\n",
    "#run_name = \"large_mlp_fullbalance\"\n",
    "#run_name = \"small_net_mlp_var_imbalance_05weight\" ## WORKS VERY WELL WITH PERM\n",
    "#run_name = \"small_net_mlp_varbalance_weight_batchunisplit\"\n",
    "#run_name = \"small_net_mlp_variable_balance_weight\"\n",
    "#run_name = \"small_net_mlp_balance_minevalup\"\n",
    "path = dir_path + f\"/logs/trainrun_{run_name}\"\n",
    "#path2 = dir_path + f\"/logs/trainrun_{run_name2}\"\n",
    "#path3 = dir_path + f\"/logs/trainrun_{run_name3}\"\n",
    "filename = \"model\"\n",
    "\n",
    "\n",
    "models = [\n",
    "    MajorityClass(),\n",
    "    XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic'),\n",
    "    MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=1, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process),\n",
    "    MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process),\n",
    "    MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process,\n",
    "                    ft_epochs=ft_epochs, ft_lr=ft_lr),\n",
    "    RandomForestClassifier(),\n",
    "    #AutoGluon(),\n",
    "    #CatBoostGrid(),\n",
    "    #XGBoostGrid(),\n",
    "    LogisticRegressionClassifier(), \n",
    "    #TabPFNClassifier(device='cpu', N_ensemble_configurations=5, no_preprocess_mode=no_pre_process),\n",
    "    #TabForestPFNClassifier(\"saved_models/tabforest/mix600k/tabforestpfn.pt\", \"saved_models/tabforest/mix600k/config_run.yaml\", max_epochs=ft_epochs_forest)\n",
    "]\n",
    "reducer  = AnovaSelect()\n",
    "#for reducer in [AnovaSelect(), RandomSelect(), NonZeroSelect(), MeanSelect(), StdSelect(), MaxSelect(), PCASelect()]:\n",
    "#data = clr(all_data)\n",
    "\n",
    "#all_data = normalize(all_data)\n",
    "\n",
    "results_mean = pd.DataFrame(np.zeros((len(models), len(metrics)+1)),\n",
    "                            index=[m.__class__.__name__ for m in models],\n",
    "                            columns=metrics+[\"runtime\"])\n",
    "results_std = pd.DataFrame(np.zeros((len(models), len(metrics)+1)), \n",
    "                           index=[m.__class__.__name__ for m in models],\n",
    "                           columns=metrics+[\"runtime\"])\n",
    "\n",
    "for ii, model in enumerate(models):\n",
    "    results_mean.iloc[ii,:], results_std.iloc[ii,:] = cross_validate_sample(\n",
    "        model, all_data, labels, metrics, strat_split, cv, sampling, \n",
    "        reducer, max_samples, seed=seed, overwrite=overwrite, n_best_delete=best_delete,\n",
    "        recomp=recomp)\n",
    "\n",
    "results_mean = results_mean.add_suffix(\" mean\")\n",
    "results_std = results_std.add_suffix(\" std\")\n",
    "results_full = pd.concat((results_mean, results_std), axis=1)\n",
    "cols = results_full.columns.tolist()\n",
    "new_cols = []\n",
    "for i in range(int(len(cols)/2)):\n",
    "    new_cols.append(cols[i])\n",
    "    new_cols.append(cols[i+int(len(cols)/2)])\n",
    "results_full = results_full[new_cols]\n",
    "red_name = reducer.__class__.__name__\n",
    "if save:\n",
    "    directory = f\"results/{red_name}\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    save_path = f'results/{red_name}/baseline_cv{cv}_mxsamp{max_samples}_sd{seed}_ovrw{int(overwrite)}.csv'\n",
    "    results_full.to_csv(save_path)\n",
    "print(\"\\n\", \"\\n\", red_name, \"\\n\", results_full.round(3))\n",
    "#print(results_full.sort_values(\"roc_auc mean\").round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10eb424e-0b18-471f-9cf6-4b1ce31e88c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save = True\n",
    "sampling = None\n",
    "cv = 7\n",
    "best_delete = 0\n",
    "strat_split = True\n",
    "n_optim = 1000\n",
    "cat_optim = 10\n",
    "ft_epochs = 10\n",
    "ft_lr = 1e-7\n",
    "max_s = 1024\n",
    "max_q = 128\n",
    "max_samples = 1024\n",
    "no_pre_process = False\n",
    "multi_decoder = \"permutation\"\n",
    "N_ens = 7\n",
    "seed = 42\n",
    "overwrite = True\n",
    "metrics = [\"accuracy\", \"precision\", \"recall\", \"roc_auc\", \"f1\"]\n",
    "dir_path = os.path.abspath(os.getcwd())\n",
    "run_name = \"medium_net_mlp_balance_bsplit_baseline\" ## NO PERM, VERY ROBUST\n",
    "run_name = \"medium_mlp_var_balance_05weight_anova\" ### BEST!!!!!! ####\n",
    "#run_name = \"medium_mlp_balance_lownoisefixparam_anova\"\n",
    "#run_name = \"medium_mlp_0.5static_balance_anova\"\n",
    "#run_name = \"large_mlp_fullbalance\"\n",
    "#run_name = \"small_net_mlp_var_imbalance_05weight\" ## WORKS VERY WELL WITH PERM\n",
    "#run_name = \"small_net_mlp_varbalance_weight_batchunisplit\"\n",
    "#run_name = \"small_net_mlp_variable_balance_weight\"\n",
    "#run_name = \"small_net_mlp_balance_minevalup\"\n",
    "path = dir_path + f\"/logs/trainrun_{run_name}\"\n",
    "filename = \"model\"\n",
    "models = [\n",
    "    #CatBoostOptim(n_optim=cat_optim),\n",
    "    XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic'),\n",
    "    MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process),\n",
    "    RandomForestClassifier(),\n",
    "    #XGBoostOptim(n_optim=n_optim),\n",
    "    LogisticRegression(max_iter=1000), \n",
    "    TabPFNClassifier(device='cpu', N_ensemble_configurations=5, no_preprocess_mode=no_pre_process),\n",
    "    TabForestPFNClassifier(\"saved_models/tabforest/mix600k/tabforestpfn.pt\", \"saved_models/tabforest/mix600k/config_run.yaml\", max_epochs=ft_epochs)\n",
    "]\n",
    "\n",
    "#for reducer in [AnovaSelect(), NonZeroSelect(), MeanSelect(), StdSelect(), MaxSelect(), PCASelect()]:\n",
    "reducer = AnovaSelect()\n",
    "#for reduce_data in [top_anova, top_non_zero, top_mean, top_std, top_max, pca_reduce]:\n",
    "    #data = reduce_data(all_data, labels, 100)\n",
    "    #print(all_data.shape)\n",
    "for best_delete in range(0,510,10):\n",
    "    #reducer.k = 100\n",
    "    #reducer = None\n",
    "    results_mean = pd.DataFrame(np.zeros((len(models), len(metrics)+1)),\n",
    "                                index=[m.__class__.__name__ for m in models],\n",
    "                                columns=metrics+[\"runtime\"])\n",
    "    results_std = pd.DataFrame(np.zeros((len(models), len(metrics)+1)), \n",
    "                               index=[m.__class__.__name__ for m in models],\n",
    "                               columns=metrics+[\"runtime\"])\n",
    "    \n",
    "    for ii, model in enumerate(models):\n",
    "        results_mean.iloc[ii,:], results_std.iloc[ii,:] = cross_validate_sample(\n",
    "            model, all_data, labels, metrics, strat_split, cv, sampling, \n",
    "            reducer, max_samples, seed=seed, overwrite=overwrite, n_best_delete=best_delete)\n",
    "\n",
    "    results_mean = results_mean.add_suffix(\" mean\")\n",
    "    results_std = results_std.add_suffix(\" std\")\n",
    "    results_full = pd.concat((results_mean, results_std), axis=1)\n",
    "    cols = results_full.columns.tolist()\n",
    "    new_cols = []\n",
    "    for i in range(int(len(cols)/2)):\n",
    "        new_cols.append(cols[i])\n",
    "        new_cols.append(cols[i+int(len(cols)/2)])\n",
    "    results_full = results_full[new_cols]\n",
    "    red_name = \"feature_select_shift_10step\"\n",
    "    if save:\n",
    "        directory = f\"results/{red_name}\"\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        save_path = f'results/{red_name}/{best_delete}_cv{cv}_mxsamp{max_samples}_sd{seed}_ovrw{int(overwrite)}'\n",
    "        results_full.to_csv(save_path)\n",
    "    print(\"\\n\", \"\\n\", red_name, \"\\n\", results_full.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16f86dc-a1ee-4706-bc17-cbedd58ff3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "all_labels = []\n",
    "for p in [\"datasets/CRC_AUS_LOSO.csv\", \n",
    "          \"datasets/CRC_FRA_LOSO.csv\",\n",
    "         \"datasets/CRC_CHI_LOSO.csv\",\n",
    "         \"datasets/CRC_GER_LOSO.csv\",\n",
    "         #\"datasets/CRC_IND_additional.csv\",\n",
    "         \"datasets/CRC_USA_LOSO.csv\"]:\n",
    "    df = pd.read_csv(p)\n",
    "    df_binary = df.loc[(df[\"disease\"] == \"healthy\") | (df[\"disease\"]==\"CRC\")]\n",
    "    df_data = df_binary.iloc[:,4:]\n",
    "    data = df_data.to_numpy()\n",
    "    labels = df_binary[\"disease\"].to_numpy()\n",
    "    labels[labels==\"healthy\"] = 0\n",
    "    labels[labels==\"CRC\"] = 1\n",
    "    data = (1/np.sum(data, axis=1, keepdims=True))*data\n",
    "    all_data.append(data)\n",
    "    all_labels.append(labels)\n",
    "\n",
    "all_data = np.concatenate(all_data,axis=0)\n",
    "labels = np.concatenate(all_labels)\n",
    "all_data, labels = unison_shuffled_copies(all_data, labels, seed=412)\n",
    "c1_ind = (labels==1).nonzero()[0]\n",
    "c1_del = c1_ind[:int(len(c1_ind)*0.97)]\n",
    "all_data, labels = np.delete(all_data, c1_del, axis=0), np.delete(labels, c1_del, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbafc58-eff4-4b74-b585-52c0a8cf6234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da53d28-57c8-48ba-a1e1-3080b58d3553",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = 20\n",
    "rocs = []\n",
    "f1s = []\n",
    "for i in range(0,510,10):\n",
    "    results = pd.read_csv(f'results/feature_select_shift_10step/{i}_cv{7}_mxsamp{1024}_sd{42}_ovrw{1}')\n",
    "    rocs.append(results[\"roc_auc mean\"].values)\n",
    "    f1s.append(results[\"f1 mean\"].values)\n",
    "rocs = np.array(rocs)\n",
    "f1s = np.array(f1s)\n",
    "labels = results.iloc[:,0].values\n",
    "plt.figure(figsize=(12,3), dpi=200)\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\n",
    "colors = []\n",
    "for cl in range(rocs.shape[1]):\n",
    "    ax1.plot(np.arange(rocs.shape[0]-ws+1)*10, moving_average(rocs[:,cl], ws), label=labels[cl])\n",
    "    ax2.plot(np.arange(rocs.shape[0]-ws+1)*10, moving_average(f1s[:,cl], ws), label=labels[cl])\n",
    "plt.suptitle(\"ROC AUC and F1-Score shifting feature selection\")\n",
    "#ax1.set_title(\"ROC AUC\")\n",
    "ax1.set_ylabel(\"ROC AUC\")\n",
    "#ax2.set_title(\"F1-Score\")\n",
    "ax2.set_xlabel(\"feature shift\")\n",
    "ax2.set_ylabel(\"F1\")\n",
    "ax1.legend(fontsize=7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d448cf5d-91f9-4f84-9477-6fe30540037e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229c531a-d6f8-464b-bb73-476293131bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.count_nonzero(all_data, axis=0)\n",
    "counts = 1-counts/all_data.shape[0]\n",
    "means = np.mean(all_data, axis=0)\n",
    "plt.scatter(counts, means, s=1)\n",
    "plt.show()\n",
    "plt.scatter(counts, np.max(all_data, axis=0), s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e216c8ae-5da2-4b93-bbde-e5bd0009e3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3d2554-f847-48c5-9566-e04693fa8eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = os.path.abspath(os.getcwd())\n",
    "run_name = \"medium_net_mlp_balance_bsplit_baseline\"\n",
    "run_name = \"medium_net_mlp_balance_bsplit_baseline_longer\"\n",
    "path = dir_path + f\"/logs/trainrun_{run_name}\"\n",
    "filename = \"model\"\n",
    "for sampling in [None]:#, undersample]:\n",
    "    cv = 5\n",
    "    strat_split = True\n",
    "    n_optim = 1000\n",
    "    cat_optim = 10\n",
    "    ft_epochs = 10\n",
    "    ft_lr = 1e-8\n",
    "    max_s = 1024\n",
    "    max_q = 128\n",
    "    max_samples = None\n",
    "    no_pre_process = False\n",
    "    multi_decoder = None\n",
    "    N_ens = 5\n",
    "    metrics = [\"accuracy\", \"precision\", \"recall\", \"roc_auc\"]\n",
    "    models = [\n",
    "        #CatBoostOptim(n_optim=cat_optim),\n",
    "        #MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder, ft_epochs=ft_epochs, ft_lr=ft_lr,\n",
    "        #                 max_s=max_s, max_q=max_q, no_preprocess_mode=no_pre_process),\n",
    "        MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process),\n",
    "        #MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=5, no_preprocess_mode=True),\n",
    "        XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic'),\n",
    "        XGBoostOptim(n_optim=n_optim),\n",
    "        LogisticRegression(max_iter=500), \n",
    "        TabPFNClassifier(device='cpu', N_ensemble_configurations=5, no_preprocess_mode=no_pre_process),\n",
    "        TabForestPFNClassifier(\"saved_models/tabforest/mix600k/tabforestpfn.pt\", \"saved_models/tabforest/mix600k/config_run.yaml\", max_epochs=ft_epochs)\n",
    "    ]\n",
    "    results_mean = pd.DataFrame(np.zeros((len(models), len(metrics)+1)),\n",
    "                                index=[m.__class__.__name__ for m in models],\n",
    "                                columns=metrics+[\"runtime\"])\n",
    "    results_std = pd.DataFrame(np.zeros((len(models), len(metrics)+1)), \n",
    "                               index=[m.__class__.__name__ for m in models],\n",
    "                               columns=metrics+[\"runtime\"])\n",
    "    \n",
    "    for ii, model in enumerate(models):\n",
    "        results_mean.iloc[ii,:], results_std.iloc[ii,:] = cross_validate_sample(model, data, labels, metrics, strat_split, cv, sampling, max_samples)\n",
    "    #results_sorted = results.sort_values(\"roc_auc\")\n",
    "    #print(results_sorted)\n",
    "    print(results_mean)\n",
    "    print(results_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04052993-69b3-4c87-9bf8-163357aa9fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = []\n",
    "for m in metrics + \"runtime\":\n",
    "    cols.append(m)\n",
    "    cols.append(m+\" std\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc23d5f-155a-4e3d-b696-1fd6439a0cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dir_path = os.path.abspath(os.getcwd())\n",
    "run_name = \"medium_net_mlp_balance_bsplit_baseline\"\n",
    "path = dir_path + f\"/logs/trainrun_{run_name}\"\n",
    "filename = \"model\"\n",
    "#model, config = load_model(path, filename, device=\"cpu\", eval_positions=None, verbose=0)\n",
    "#pred_model = TabPFNClassifier(model[2], config, device=\"cpu\", N_ensemble_configurations=5, no_preprocess_mode=False)\n",
    "for sampling in [None]:\n",
    "    cv = 3\n",
    "    strat_split = True\n",
    "    n_optim = 10\n",
    "    ft_epochs = 10\n",
    "    max_samples = None\n",
    "    metrics = metrics = [\"accuracy\", \"precision\", \"recall\", \"roc_auc\"]\n",
    "    models = [\n",
    "        RandomForestClassifier()\n",
    "        #CatBoostOptim(n_optim=n_optim),\n",
    "        #pred_model,\n",
    "        #MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=3, no_preprocess_mode=True),\n",
    "        #XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic'),\n",
    "        #XGBoostOptim(n_optim=n_optim),\n",
    "        #LogisticRegression(max_iter=500), \n",
    "        #TabPFNClassifier(device='cpu', N_ensemble_configurations=3, no_preprocess_mode=True),\n",
    "        #TabForestPFNClassifier(\"saved_models/tabforest/mix600k/tabforestpfn.pt\", \"saved_models/tabforest/mix600k/config_run.yaml\", max_epochs=ft_epochs)\n",
    "    ]\n",
    "    results = pd.DataFrame(np.zeros((len(models), len(metrics)+1)), \n",
    "                           index=[m.__class__.__name__ for m in models],\n",
    "                          columns=metrics+[\"runtime\"])\n",
    "    \n",
    "    for ii, model in enumerate(models):\n",
    "        results.iloc[ii,:] = cross_validate_sample(model, data, labels, metrics, strat_split, cv, sampling, max_samples)\n",
    "    results_sorted = results.sort_values(\"roc_auc\")\n",
    "    \n",
    "    print(results_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5983e6a1-a7ce-4694-b775-e83498cd3be9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819f6306-686d-42f1-829c-303890202785",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac970c40-6003-4c24-b454-014ba31f6b26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
