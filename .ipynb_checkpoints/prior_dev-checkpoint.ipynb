{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "806ff5d9-0f3a-4fa1-a089-db69fbe1c925",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "from tabpfn import TabPFNClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from data_prep_utils import *\n",
    "from evaluate import *\n",
    "from load_models import *\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import openml\n",
    "from data_prep_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from tabpfn_new import priors, encoders\n",
    "from tabpfn_new.scripts.model_configs import *\n",
    "from tabpfn_new.scripts.model_builder import get_forest_prior_hyperparameters, get_mlp_prior_hyperparameters, get_model\n",
    "from tabpfn.utils import get_uniform_single_eval_pos_sampler\n",
    "from utils import get_dataloader\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99725f1b-38b4-4188-ba15-49b041341222",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reload_config(prior_type='forest', config_type='causal', task_type='binary', longer=0):\n",
    "    config = get_prior_config(config_type=config_type)\n",
    "    \n",
    "    config['prior_type'] = prior_type\n",
    "    \n",
    "    model_string = ''\n",
    "    \n",
    "    config['epochs'] = 12000\n",
    "    config['recompute_attn'] = True\n",
    "\n",
    "    config['max_num_classes'] = 10\n",
    "    config['num_classes'] = uniform_int_sampler_f(2, config['max_num_classes'])\n",
    "    config['balanced'] = False\n",
    "    model_string = model_string + '_multiclass'\n",
    "    \n",
    "    model_string = model_string + '_'+datetime.now().strftime(\"%m_%d_%Y_%H_%M_%S\")\n",
    "    \n",
    "    return config, model_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ef61611-5810-4471-93f9-82b1f6958f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dl_from_config(config_sample, prior_hyperparameters):\n",
    "    def eval_pos_seq_len_sampler():\n",
    "        single_eval_pos_gen = get_uniform_single_eval_pos_sampler(config.get('max_eval_pos', config['bptt']), min_len=config.get('min_eval_pos', 0))\n",
    "        single_eval_pos = single_eval_pos_gen()\n",
    "        return single_eval_pos, 1024\n",
    "    dl_class, extra_kwargs = get_dataloader(config_sample, device=\"cpu\", should_train=False, verbose=0)\n",
    "    dl = dl_class(num_steps=1, batch_size=1, \n",
    "                                eval_pos_seq_len_sampler=eval_pos_seq_len_sampler, \n",
    "                                seq_len_maximum=None, device=\"cpu\", **extra_kwargs)\n",
    "    dl.model = None\n",
    "    return dl\n",
    "\n",
    "                                     \n",
    "def get_sample(dl):\n",
    "    (style, x, y), _, _ =  next(iter(dl))\n",
    "    return x, y\n",
    "    \n",
    "def plot_grid(dl, hyperparameters, rows=8, cols=6):\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(20,15))\n",
    "    class_assigner = priors.flexible_categorical.BalancedBinarize()#priors.flexible_categorical.MulticlassRank(hyperparameters['num_classes'], ordered_p=hyperparameters['output_multiclass_ordered_p'])\n",
    "    for ax in axes.flatten():\n",
    "        x2, b = get_sample(dl)\n",
    "        #b = class_assigner(b)\n",
    "        i1, i2 = np.random.choice(x2.shape[2], size=(2,), replace=False)\n",
    "        ax.scatter(x2[:, 0, i1], x2[:, 0, i2], c=b, s=1.5, cmap=\"bwr\")\n",
    "\n",
    "def remove_zero_features(x):\n",
    "    x = x[:,:,torch.where(torch.sum(torch.abs(x), dim=0)>0,1,0)]\n",
    "    return x\n",
    "\n",
    "def plot_feature_combinations(dl, hyperparameters, num_plots=10):\n",
    "    fig = plt.figure(figsize=(20,15))\n",
    "    x2, b = get_sample(dl)\n",
    "    #x2 = remove_zero_features(x2)\n",
    "    #class_assigner = priors.flexible_categorical.BalancedBinarize()#MulticlassRank(hyperparameters['num_classes'], ordered_p=hyperparameters['output_multiclass_ordered_p'])\n",
    "    #b = class_assigner(b)\n",
    "    n_feat = num_plots#hyperparameters[\"max_features\"]\n",
    "    for i in range(n_feat-1):\n",
    "        for j in range(n_feat):\n",
    "            if(j>i) :\n",
    "                ax = plt.subplot2grid((n_feat-1, n_feat-1), (i,j-1))\n",
    "                #ax.xaxis.set_ticklabels([]) \n",
    "                #ax.yaxis.set_ticklabels([])\n",
    "                plt.scatter(x2[:,0,i],x2[:,0,j],c=b, s=1.5, cmap=\"bwr\")\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f7f010d-ebbf-4cf7-ba58-8f98ecb7e01b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prior_type = 'mlp'\n",
    "config, model_string = reload_config(prior_type, longer=1)\n",
    "\n",
    "config['differentiable'] = True\n",
    "config['flexible'] = True\n",
    "config['bptt_extra_samples'] = None\n",
    "\n",
    "# diff\n",
    "config['output_multiclass_ordered_p'] = 0.0\n",
    "del config['differentiable_hyperparameters']['output_multiclass_ordered_p']\n",
    "\n",
    "\n",
    "\n",
    "config['sampling'] = 'normal' # vielleicht schlecht?\n",
    "del config['differentiable_hyperparameters']['sampling']\n",
    "\n",
    "config['pre_sample_causes'] = True\n",
    "# end diff\n",
    "\n",
    "config['multiclass_loss_type'] = 'nono' # 'compatible'\n",
    "config['normalize_to_ranking'] = False # False\n",
    "\n",
    "config['categorical_feature_p'] = 0 # diff: .0\n",
    "\n",
    "# turn this back on in a random search!?\n",
    "config['nan_prob_no_reason'] = .0\n",
    "config['nan_prob_unknown_reason'] = .0 # diff: .0\n",
    "config['set_value_to_nan'] = .0 # diff: 1.\n",
    "\n",
    "config['normalize_with_sqrt'] = False\n",
    "\n",
    "config['new_mlp_per_example'] = True\n",
    "config['prior_mlp_scale_weights_sqrt'] = True\n",
    "config['batch_size_per_gp_sample'] = None\n",
    "\n",
    "config['normalize_ignore_label_too'] = False\n",
    "\n",
    "config['differentiable_hps_as_style'] = False\n",
    "config['max_eval_pos'] = 1000\n",
    "\n",
    "config['random_feature_rotation'] = True\n",
    "config['rotate_normalized_labels'] = True\n",
    "\n",
    "config[\"mix_activations\"] = True # False heisst eig True\n",
    "\n",
    "config['n_layers'] = 4\n",
    "config['emsize'] = 128\n",
    "config['nhead'] = config['emsize'] // 32\n",
    "config['bptt'] = 1024+128\n",
    "config['canonical_y_encoder'] = True\n",
    "\n",
    "    \n",
    "config['aggregate_k_gradients'] = 1\n",
    "config['batch_size'] = 1*config['aggregate_k_gradients']\n",
    "config['num_steps'] = 1//config['aggregate_k_gradients']\n",
    "config['epochs'] = 1\n",
    "\n",
    "config['total_available_time_in_s'] = None #60*60*22 # 22 hours for some safety...\n",
    "\n",
    "config['train_mixed_precision'] = True\n",
    "config['efficient_eval_masking'] = True\n",
    "\n",
    "# mlp params\n",
    "config['is_causal'] = True\n",
    "config['num_causes'] = 5\n",
    "config['prior_mlp_hidden_dim'] = 50\n",
    "config['num_layers'] = 4\n",
    "config['noise_std'] = 0.05\n",
    "config['init_std'] = 0.05\n",
    "config['y_is_effect'] = True\n",
    "config['pre_sample_weights'] = True\n",
    "config['prior_mlp_dropout_prob'] = 0\n",
    "config['pre_sample_causes'] = True\n",
    "config[\"prior_mlp_activations\"] = torch.nn.ReLU\n",
    "config[\"block_wise_dropout\"] = True\n",
    "config[\"sort_features\"] = False\n",
    "config[\"in_clique\"] = False\n",
    "\n",
    "# general data params\n",
    "config['balanced'] = True\n",
    "config['max_num_classes'] = 2\n",
    "config['max_features'] = 100\n",
    "config['num_features_used'] = 100\n",
    "\n",
    "config['num_classes'] = 2\n",
    "\n",
    "config['no_encoder'] = False\n",
    "config['normalize_to_ranking'] = False # False\n",
    "config['normalize_with_sqrt'] = False\n",
    "config['normalize_ignore_label_too'] = False\n",
    "config[\"normalize\"] = False\n",
    "config['num_classes'] = 2\n",
    "config[\"balanced\"] = False\n",
    "config['multiclass_type'] = 'imbalanced_binarize'\n",
    "\n",
    "\n",
    "config_sample = evaluate_hypers(config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30030035-1632-47a4-9d32-a560361a8dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dl = dl_from_config(config_sample, prior_hyperparameters)\n",
    "model = get_model(config_sample, device, should_train=False, verbose=0)\n",
    "dl = model[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8825b69a-4d14-4e8f-95ba-1128f5486b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid(dl,config_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb563131-d329-4157-bb05-31fa6a6f0e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_combinations(dl,config_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b700a2b-c26b-44cc-8530-8d1f7650c97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "class MicroDL(DataLoader):\n",
    "    def __init__(self, path=None):\n",
    "        data, labels = get_microbiome(path)\n",
    "        data = top_non_zero(data)\n",
    "        data, labels = unison_shuffled_copies(data, labels)\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return 100\n",
    "        \n",
    "    def get_perm(self):\n",
    "        indices = np.random.permutation(self.data.shape[0])[:1000]\n",
    "        return (None, np.expand_dims(self.data[indices], axis=1), np.expand_dims(self.labels[indices],axis=1)), None, None\n",
    "        \n",
    "    def __iter__(self):\n",
    "        indices = np.random.permutation(self.data.shape[0])[:1000]\n",
    "        return iter(self.get_perm() for _ in range(100))\n",
    "path = \"datasets/data_all.csv\"\n",
    "dl = MicroDL(path)\n",
    "#plot_grid(dl, config_sample)\n",
    "plot_feature_combinations(dl, config_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47342e30-ae92-451b-824d-6db9a19ea2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['differentiable'] = True\n",
    "config['flexible'] = True\n",
    "\n",
    "# forest params\n",
    "config[\"min_features\"] = 100\n",
    "config[\"max_features\"] = 100\n",
    "config[\"n_samples\"] = 1000\n",
    "config[\"max_classes\"] = 2\n",
    "config[\"base_size\"] = 1000\n",
    "config[\"n_estimators\"] = 1\n",
    "config[\"min_depth\"] = 3\n",
    "config[\"max_depth\"] = 15\n",
    "config[\"categorical_x\"] = False\n",
    "config[\"data_sample_func\"] = \"zinb\"\n",
    "config[\"comp\"] = True\n",
    "\n",
    "config['multiclass_type'] = 'balance'\n",
    "del config['differentiable_hyperparameters']['multiclass_type']\n",
    "\n",
    "config[\"prior_type\"] = \"forest\"\n",
    "config[\"microbiome_test\"] = True\n",
    "config[\"weight_classes\"] = False\n",
    "config[\"run_name\"] = \"time\"\n",
    "\n",
    "config[\"prior_type\"] = \"forest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc90518-93eb-4479-980f-3ee7f749c365",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_sample = evaluate_hypers(config)\n",
    "model = get_model(config_sample, device, should_train=False, verbose=0)\n",
    "dl = model[3]\n",
    "plot_grid(dl, config_sample)\n",
    "plot_feature_combinations(dl, config_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540f17f5-7cc3-4fc7-a60c-cfb409cb3513",
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"data_sample_func\"] = \"mnd\"\n",
    "\n",
    "\n",
    "config_sample = evaluate_hypers(config)\n",
    "model = get_model(config_sample, device, should_train=False, verbose=0)\n",
    "dl = model[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4e1075-d1c8-443b-85e6-05216d0367da",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid(dl, config_sample)\n",
    "plot_feature_combinations(dl, config_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b2ca11-0225-4a0d-9c95-796d9eb3ee8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabpfn import TabPFNClassifier\n",
    "model = TabPFNClassifier(device='cpu', N_ensemble_configurations=1)\n",
    "x, y = get_sample(dl)\n",
    "x, y = torch.squeeze(x), torch.squeeze(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, train_size=0.8, test_size=0.2, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "print(torch.tensor(preds)*y_test+(torch.tensor(preds)-1)*(y_test-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecd56e91-d6c5-4163-bf92-a797bb3a8977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "Using cpu:0 device\n",
      "Using a Transformer with 1.64 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "config[\"prior_type\"] = \"mlp\"\n",
    "config[\"data_sample_func\"] = \"mnd\"\n",
    "config['multiclass_type'] = 'balance'\n",
    "config['hist_targets'] = False\n",
    "\n",
    "config[\"align_majority\"] = False\n",
    "config[\"limit_imbalance\"] = False\n",
    "\n",
    "config[\"normalize\"] = True\n",
    "config[\"num_classes\"] = 2\n",
    "config[\"max_num_classes\"] = 2\n",
    "\n",
    "config['min_depth'] = 5\n",
    "config['max_depth'] = 15\n",
    "#del config['differentiable_hyperparameters']['multiclass_type']\n",
    "\n",
    "config_sample = evaluate_hypers(config)\n",
    "model = get_model(config_sample, device, should_train=False, verbose=0)\n",
    "dl = model[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae188bf-91f0-42c2-91b5-96714476a333",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    print(f\"\\n\\n\\nRun #{i}\")\n",
    "    x, y = get_sample(dl)\n",
    "    x, y = torch.squeeze(x), torch.squeeze(y)\n",
    "    print(\"Target mean: \", torch.mean(y))\n",
    "    if len(np.unique(y, return_counts=True)[0])>1 and np.min(np.unique(y, return_counts=True)[1])>20:\n",
    "        #plt.hist(y, bins=100)\n",
    "        #plt.show()\n",
    "        cv = 3\n",
    "        n_optim = 20\n",
    "        ft_epochs = 0\n",
    "        sampling = None\n",
    "        metrics = metrics = [\"accuracy\", \"precision\", \"recall\", \"roc_auc\"]\n",
    "        models = [\n",
    "            #XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic'),\n",
    "            XGBoostOptim(n_optim=n_optim),\n",
    "            #LogisticRegression(max_iter=500), \n",
    "            #TabPFNClassifier(device='cpu', N_ensemble_configurations=3),\n",
    "            #TabForestPFNClassifier(\"saved_models/tabforest/mix600k/tabforestpfn.pt\", \"saved_models/tabforest/mix600k/config_run.yaml\")\n",
    "        ]\n",
    "        results = pd.DataFrame(np.zeros((len(models), len(metrics))), \n",
    "                               index=[m.__class__.__name__ for m in models],\n",
    "                              columns=metrics)\n",
    "        \n",
    "        for ii, model in enumerate(models):\n",
    "            results.iloc[ii,:] = cross_validate_sample(model, x, y, metrics, cv, sampling)\n",
    "        print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b15a5d3-46cc-439c-a324-577e5dda3ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "Using cpu:0 device\n",
      "Using a Transformer with 1.64 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC:  0.7695721008381259 0.1147437013619145\n",
      "Pred avgs:  0.6063131293789907\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config[\"prior_type\"] = \"forest\"\n",
    "config[\"data_sample_func\"] = \"mnd\"\n",
    "config['multiclass_type'] = 'balance'\n",
    "config['hist_targets'] = False\n",
    "config['y_std'] = 1\n",
    "config['min_depth'] = 5\n",
    "config['max_depth'] = 15\n",
    "config['num_classes'] = 2\n",
    "\n",
    "\n",
    "config[\"align_majority\"] = False\n",
    "config[\"limit_imbalance\"] = False\n",
    "\n",
    "\n",
    "\n",
    "config_sample = evaluate_hypers(config)\n",
    "model = get_model(config_sample, device, should_train=False, verbose=0)\n",
    "dl = model[3]\n",
    "rocs = []\n",
    "means = []\n",
    "for i in range(100):\n",
    "    #print(f\"\\n\\n\\nRun #{i}\")\n",
    "    x, y = get_sample(dl)\n",
    "    x, y = torch.squeeze(x).numpy(), torch.squeeze(y).numpy()\n",
    "    #print(np.unique(y, return_counts=True))\n",
    "    if len(np.unique(y, return_counts=True)[0])>1 and np.min(np.unique(y, return_counts=True)[1])>20:\n",
    "        #print(\"Target mean: \", torch.mean(y))\n",
    "        #plt.hist(y, bins=100)\n",
    "        #plt.show()\n",
    "        cv = 3\n",
    "        n_optim = 20\n",
    "        ft_epochs = 0\n",
    "        sampling = None\n",
    "        strat_split=True\n",
    "        metrics = metrics = [\"roc_auc\"]#\"roc_auc_ovr\"]\n",
    "        if config['num_classes'] ==2:\n",
    "            o = 'binary:logistic'\n",
    "        else:\n",
    "            o = 'multi:softmax'\n",
    "        model = XGBClassifier(n_estimators=7, max_depth=7, learning_rate=0.1, objective=o)#\n",
    "        #model = XGBoostOptim(n_optim=n_optim)\n",
    "        results = cross_validate_sample(model, x, y, metrics, strat_split, cv, sampling)\n",
    "        means.append(max(1-np.mean(y),np.mean(y)))\n",
    "        rocs.append(results[0])\n",
    "print(\"ROC: \", np.mean(np.array(rocs)), np.std(np.array(rocs)))\n",
    "print(\"Pred avgs: \", np.mean(np.array(means)))\n",
    "#result_matrix[ii,jj] = np.mean(np.array(rocs))\n",
    "plt.hist(rocs, bins=20)\n",
    "plt.show()\n",
    "plt.hist(means, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebab9f3c-81dc-439f-9a22-6a20a7f4be3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3668474-a2cf-403d-8bb8-4d76ba6063d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5000)\n"
     ]
    }
   ],
   "source": [
    "accs = []\n",
    "for i in range(1000):\n",
    "    #print(f\"\\n\\n\\nRun #{i}\")\n",
    "    x, y = get_sample(dl)\n",
    "    x, y = torch.squeeze(x), torch.squeeze(y)\n",
    "    preds = torch.full(y.shape, torch.argmax(torch.unique(y, return_counts=True)[1]).item())\n",
    "    accuracy = torch.mean((preds==y)[y!=-100].float())\n",
    "    accs.append(accuracy)\n",
    "print(torch.mean(torch.tensor(accs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb27a55-0322-4121-a7ba-f3380dfb2a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50,100,1):\n",
    "    print(f\"ROC sub {i*0.01} pred\",  np.mean(np.array(rocs)[np.array(means)<i*0.01]), len(np.array(rocs)[np.array(means)<i*0.01])/len(means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c363a4-132d-4c4b-9fd2-0f99eb63f4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8a0922-d04c-43e6-a2d5-fd3745858bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(means,rocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff1fee4-f743-4630-b62c-4a02b0880158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358a4488-dda9-43b0-890f-ab7ccd92a306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multinomial_dirichlet(size=(1000,100)):\n",
    "    M = 1000\n",
    "    alphas = np.random.beta(1,1,size[1])\n",
    "    thetas = [np.random.dirichlet(alphas) for i in range(size[0])]\n",
    "    #print(thetas, np.sum(thetas))\n",
    "    X = np.asarray([np.random.multinomial(M, theta)/M for theta in thetas])\n",
    "    return X\n",
    "X = multinomial_dirichlet()\n",
    "print(X[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc87ccf7-5976-483f-9eb4-41036e9d97c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f721f19-7023-4436-b374-886651722f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def get_sample(config_sample, prior_hyperparameters):\n",
    "    def eval_pos_seq_len_sampler():\n",
    "        single_eval_pos_gen = get_uniform_single_eval_pos_sampler(config.get('max_eval_pos', config['bptt']), min_len=config.get('min_eval_pos', 0))\n",
    "        single_eval_pos = single_eval_pos_gen()\n",
    "        return single_eval_pos, 1024\n",
    "    ''extra_prior_kwargs_dict={\n",
    "        'num_features': config['num_features'], \n",
    "        'hyperparameters': prior_hyperparameters\n",
    "    }\n",
    "    extra_kwargs = {}\n",
    "    if 'flexible' in config and config['flexible']:\n",
    "        get_batch_base = make_get_batch(model_proto)\n",
    "        extra_kwargs['get_batch'] = get_batch_base\n",
    "        model_proto = priors.flexible_categorical\n",
    "    if 'differentiable' in prior_hyperparameters and prior_hyperparameters['differentiable']:\n",
    "        get_batch_base = make_get_batch(model_proto, **extra_kwargs)\n",
    "        extra_kwargs = {'get_batch': get_batch_base, 'differentiable_hyperparameters': prior_hyperparameters['differentiable_hyperparameters']}\n",
    "        model_proto = priors.differentiable_prior\n",
    "        use_style = True\n",
    "    \n",
    "    dl = model_proto.DataLoader(num_steps=1, batch_size=1, \n",
    "                                eval_pos_seq_len_sampler=eval_pos_seq_len_sampler, \n",
    "                                seq_len_maximum=None, device=\"cpu\", **extra_prior_kwargs_dict)''\n",
    "    dl_class, extra_kwargs = get_dataloader(config_sample, device=\"cpu\", should_train=False, verbose=2)\n",
    "    dl = model_proto.DataLoader(num_steps=1, batch_size=1, \n",
    "                                eval_pos_seq_len_sampler=eval_pos_seq_len_sampler, \n",
    "                                seq_len_maximum=None, device=\"cpu\", **extra_kwargs)\n",
    "    dl.model = None\n",
    "    return next(iter(dl))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a955c12a-56e9-4895-a9af-07226073cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_sample(config_sample, prior_hyperparameters)\n",
    "print(a[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c161bd-ec80-43ac-b3a9-21011eec1d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['differentiable'] = False\n",
    "config['flexible'] = False\n",
    "\n",
    "# forest params\n",
    "config[\"min_features\"] = 10\n",
    "config[\"max_features\"] = 100\n",
    "config[\"n_samples\"] = 1000\n",
    "config[\"max_classes\"] = 10\n",
    "config[\"base_size\"] = 1000\n",
    "config[\"n_estimators\"] = 1\n",
    "config[\"min_depth\"] = 1\n",
    "config[\"max_depth\"] = 25\n",
    "config[\"categorical_x\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af348aba-7927-4722-829b-2b9067bec073",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "from tabpfn import TabPFNClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from evaluate import scores\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, precision_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from data_prep_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import openml\n",
    "from tabularbench.data.synthetic_generator_forest import synthetic_dataset_generator_forest, synthetic_dataset_function_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5561d98a-122c-46a3-b816-198a5c986552",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabularbench.data.synthetic_generator_tabpfn import synthetic_dataset_generator_tabpfn\n",
    "\n",
    "fig, axes = plt.subplots(8, 6, figsize=(20, 15))\n",
    "generator = synthetic_dataset_generator_tabpfn(n_samples=1000, max_classes=2, min_features=2, max_features=100)\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    x2, b = next(generator)\n",
    "    i1, i2 = np.random.choice(x2.shape[1], size=(2,), replace=False)\n",
    "    ax.scatter(x2[:, i1], x2[:, i2], c=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2a893a-7167-4aa4-a2df-513182935798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabularbench.data.synthetic_generator_forest import synthetic_dataset_generator_forest, synthetic_dataset_function_forest\n",
    "import matplotlib\n",
    "\n",
    "fig, axes = plt.subplots(8, 6, figsize=(20, 15))\n",
    "generator = synthetic_dataset_generator_forest(n_samples=1000, max_classes=2, min_features=2, max_features=2)\n",
    "\n",
    "cmap = matplotlib.colormaps['inferno']\n",
    "colors = cmap(np.linspace(0.0, 0.9, 10))\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    x2, b = synthetic_dataset_function_forest(base_size=1000, min_features=2, max_features=2, max_classes=3, min_depth=1, max_depth=25, categorical_x=True, n_samples=1024)\n",
    "    i1, i2 = np.random.choice(x2.shape[1], size=(2,), replace=False)\n",
    "    random_shuffle = np.random.permutation(np.arange(10))\n",
    "    colors_shuffle = colors[random_shuffle]\n",
    "    #b = np.array([colors_shuffle[i] for i in b])\n",
    "    ax.scatter(x2[:, i1], x2[:, i2], c=b)\n",
    "    ax.tick_params(axis='both', which='both', bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be43c36-ca72-4cb4-9cd4-72a59b27d90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zinb(size=(1000,100)):\n",
    "    pi = 0.25\n",
    "    p = np.random.uniform(0.1,0.9, size=size[1])\n",
    "    p = np.repeat(np.expand_dims(p,axis=0),size[0],axis=0)\n",
    "    #print\n",
    "    #p += 1e-5\n",
    "    X = np.random.negative_binomial(100,p)\n",
    "    X = np.random.binomial(1,1-pi,size)*X\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08769738-e744-49cc-98c2-206e3bb9d5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zinb_comp(size=(1000,100)):\n",
    "    X =  zinb(size)\n",
    "    print(X)\n",
    "    print(np.expand_dims(1/np.sum(X,axis=1),axis=1))\n",
    "    return np.expand_dims(1/np.sum(X,axis=1),axis=1)*X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada8a9e9-6a99-4d92-b869-ae69bdc53cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = zinb_comp((10,10))\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ed9025-1fb0-4732-b3b7-ee311b528e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(out, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c62c558-446d-42bf-a2a3-39ed3b4a9c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prior.synthetic_generator_forest_altdata import synthetic_dataset_generator_forest_altdata, synthetic_dataset_function_forest_altdata\n",
    "\n",
    "fig, axes = plt.subplots(8, 6, figsize=(20, 15))\n",
    "\n",
    "cmap = matplotlib.colormaps['inferno']\n",
    "colors = cmap(np.linspace(0.0, 0.9, 10))\n",
    "\n",
    "\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    x2, b = synthetic_dataset_function_forest_altdata(zinb,base_size=1000, min_features=2, max_features=2, max_classes=3, min_depth=1, max_depth=25, categorical_x=True, n_samples=1024)\n",
    "    i1, i2 = np.random.choice(x2.shape[1], size=(2,), replace=False)\n",
    "    random_shuffle = np.random.permutation(np.arange(10))\n",
    "    colors_shuffle = colors[random_shuffle]\n",
    "    #b = np.array([colors_shuffle[i] for i in b])\n",
    "    ax.scatter(x2[:, i1], x2[:, i2], c=b)\n",
    "    ax.tick_params(axis='both', which='both', bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b35c21-16e3-44e8-80df-dd5de8fc536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_norm, b_norm = synthetic_dataset_function_forest(base_size=1000, min_features=2, max_features=2, max_classes=3, min_depth=1, max_depth=25, categorical_x=True, n_samples=1024)\n",
    "\n",
    "X_zinb, b_zinb = synthetic_dataset_function_forest_altdata(zinb,base_size=1000, min_features=2, max_features=2, max_classes=3, min_depth=1, max_depth=25, categorical_x=True, n_samples=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68200361-d086-41a0-8af3-ad83c009298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, roc_auc_score\n",
    "accuracy = np.zeros((3))\n",
    "runs = 10\n",
    "for ii in range(runs):\n",
    "    X_norm, b_norm = synthetic_dataset_function_forest(base_size=1000, min_features=2, max_features=2, max_classes=3, min_depth=1, max_depth=25, categorical_x=True, n_samples=1024)\n",
    "    models = [XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic'), \n",
    "              LogisticRegression(max_iter=500), \n",
    "              TabPFNClassifier(device='cpu', N_ensemble_configurations=3)]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_norm, b_norm, test_size=0.2, random_state=42)\n",
    "    for mm, model in enumerate(models):\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy[mm] += accuracy_score(y_test,y_pred)\n",
    "print(accuracy/runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248ed978-b1b6-46ee-9233-e91434632ae2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, roc_auc_score\n",
    "accuracy = np.zeros((3))\n",
    "runs = 10\n",
    "for ii in range(runs):\n",
    "    print(ii)\n",
    "    X_zinb, b_zinb = synthetic_dataset_function_forest_altdata(zinb,base_size=1000, min_features=2, max_features=2, max_classes=3, min_depth=1, max_depth=25, categorical_x=True, n_samples=1024)\n",
    "    models = [XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic'), \n",
    "              LogisticRegression(max_iter=500), \n",
    "              TabPFNClassifier(device='cpu', N_ensemble_configurations=3)]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_zinb, b_zinb, test_size=0.2, random_state=42)\n",
    "    for mm, model in enumerate(models):\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy[mm] += accuracy_score(y_test,y_pred)\n",
    "print(accuracy/runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa159333-33a1-4941-9ea3-31ab11dfcca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e818c922-3e6d-4443-884a-9fb01aa1db39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
