{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "806ff5d9-0f3a-4fa1-a089-db69fbe1c925",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "from tabpfn import TabPFNClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from data_prep_utils import *\n",
    "from evaluate import *\n",
    "from load_models import *\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import openml\n",
    "from data_prep_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from tabpfn_new import priors, encoders\n",
    "from tabpfn_new.scripts.model_configs import *\n",
    "from tabpfn_new.scripts.model_builder import get_forest_prior_hyperparameters, get_mlp_prior_hyperparameters, get_model\n",
    "from tabpfn.utils import get_uniform_single_eval_pos_sampler\n",
    "from utils import get_dataloader\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99725f1b-38b4-4188-ba15-49b041341222",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reload_config(prior_type='forest', config_type='causal', task_type='binary', longer=0):\n",
    "    config = get_prior_config(config_type=config_type)\n",
    "    \n",
    "    config['prior_type'] = prior_type\n",
    "    \n",
    "    model_string = ''\n",
    "    \n",
    "    config['epochs'] = 12000\n",
    "    config['recompute_attn'] = True\n",
    "\n",
    "    config['max_num_classes'] = 10\n",
    "    config['num_classes'] = uniform_int_sampler_f(2, config['max_num_classes'])\n",
    "    config['balanced'] = False\n",
    "    model_string = model_string + '_multiclass'\n",
    "    \n",
    "    model_string = model_string + '_'+datetime.now().strftime(\"%m_%d_%Y_%H_%M_%S\")\n",
    "    \n",
    "    return config, model_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ef61611-5810-4471-93f9-82b1f6958f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dl_from_config(config_sample, prior_hyperparameters):\n",
    "    def eval_pos_seq_len_sampler():\n",
    "        single_eval_pos_gen = get_uniform_single_eval_pos_sampler(config.get('max_eval_pos', config['bptt']), min_len=config.get('min_eval_pos', 0))\n",
    "        single_eval_pos = single_eval_pos_gen()\n",
    "        return single_eval_pos, 1024\n",
    "    dl_class, extra_kwargs = get_dataloader(config_sample, device=\"cpu\", should_train=False, verbose=0)\n",
    "    dl = dl_class(num_steps=1, batch_size=1, \n",
    "                                eval_pos_seq_len_sampler=eval_pos_seq_len_sampler, \n",
    "                                seq_len_maximum=None, device=\"cpu\", **extra_kwargs)\n",
    "    dl.model = None\n",
    "    return dl\n",
    "\n",
    "                                     \n",
    "def get_sample(dl):\n",
    "    (style, x, y), _, _ =  next(iter(dl))\n",
    "    return x, y\n",
    "    \n",
    "def plot_grid(dl, hyperparameters, rows=8, cols=6):\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(20,15))\n",
    "    class_assigner = priors.flexible_categorical.BalancedBinarize()#priors.flexible_categorical.MulticlassRank(hyperparameters['num_classes'], ordered_p=hyperparameters['output_multiclass_ordered_p'])\n",
    "    for ax in axes.flatten():\n",
    "        x2, b = get_sample(dl)\n",
    "        #b = class_assigner(b)\n",
    "        i1, i2 = np.random.choice(x2.shape[2], size=(2,), replace=False)\n",
    "        ax.scatter(x2[:, 0, i1], x2[:, 0, i2], c=b, s=1.5, cmap=\"bwr\")\n",
    "\n",
    "def remove_zero_features(x):\n",
    "    x = x[:,:,torch.where(torch.sum(torch.abs(x), dim=0)>0,1,0)]\n",
    "    return x\n",
    "\n",
    "def plot_feature_combinations(dl, hyperparameters, num_plots=10):\n",
    "    fig = plt.figure(figsize=(20,15))\n",
    "    x2, b = get_sample(dl)\n",
    "    #x2 = remove_zero_features(x2)\n",
    "    #class_assigner = priors.flexible_categorical.BalancedBinarize()#MulticlassRank(hyperparameters['num_classes'], ordered_p=hyperparameters['output_multiclass_ordered_p'])\n",
    "    #b = class_assigner(b)\n",
    "    n_feat = num_plots#hyperparameters[\"max_features\"]\n",
    "    for i in range(n_feat-1):\n",
    "        for j in range(n_feat):\n",
    "            if(j>i) :\n",
    "                ax = plt.subplot2grid((n_feat-1, n_feat-1), (i,j-1))\n",
    "                #ax.xaxis.set_ticklabels([]) \n",
    "                #ax.yaxis.set_ticklabels([])\n",
    "                plt.scatter(x2[:,0,i],x2[:,0,j],c=b, s=1.5, cmap=\"bwr\")\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f7f010d-ebbf-4cf7-ba58-8f98ecb7e01b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prior_type = 'mlp'\n",
    "config, model_string = reload_config(prior_type, longer=1)\n",
    "\n",
    "config['differentiable'] = True\n",
    "config['flexible'] = True\n",
    "config['bptt_extra_samples'] = None\n",
    "\n",
    "# diff\n",
    "config['output_multiclass_ordered_p'] = 0.0\n",
    "del config['differentiable_hyperparameters']['output_multiclass_ordered_p']\n",
    "\n",
    "\n",
    "\n",
    "config['sampling'] = 'normal' # vielleicht schlecht?\n",
    "del config['differentiable_hyperparameters']['sampling']\n",
    "\n",
    "config['pre_sample_causes'] = True\n",
    "# end diff\n",
    "\n",
    "config['multiclass_loss_type'] = 'nono' # 'compatible'\n",
    "config['normalize_to_ranking'] = False # False\n",
    "\n",
    "config['categorical_feature_p'] = 0 # diff: .0\n",
    "\n",
    "# turn this back on in a random search!?\n",
    "config['nan_prob_no_reason'] = .0\n",
    "config['nan_prob_unknown_reason'] = .0 # diff: .0\n",
    "config['set_value_to_nan'] = .0 # diff: 1.\n",
    "\n",
    "config['normalize_with_sqrt'] = False\n",
    "\n",
    "config['new_mlp_per_example'] = True\n",
    "config['prior_mlp_scale_weights_sqrt'] = True\n",
    "config['batch_size_per_gp_sample'] = None\n",
    "\n",
    "config['normalize_ignore_label_too'] = False\n",
    "\n",
    "config['differentiable_hps_as_style'] = False\n",
    "config['max_eval_pos'] = 1000\n",
    "\n",
    "config['random_feature_rotation'] = True\n",
    "config['rotate_normalized_labels'] = True\n",
    "\n",
    "config[\"mix_activations\"] = True # False heisst eig True\n",
    "\n",
    "config['n_layers'] = 4\n",
    "config['emsize'] = 128\n",
    "config['nhead'] = config['emsize'] // 32\n",
    "config['bptt'] = 1024+128\n",
    "config['canonical_y_encoder'] = True\n",
    "\n",
    "    \n",
    "config['aggregate_k_gradients'] = 1\n",
    "config['batch_size'] = 1*config['aggregate_k_gradients']\n",
    "config['num_steps'] = 1//config['aggregate_k_gradients']\n",
    "config['epochs'] = 1\n",
    "\n",
    "config['total_available_time_in_s'] = None #60*60*22 # 22 hours for some safety...\n",
    "\n",
    "config['train_mixed_precision'] = True\n",
    "config['efficient_eval_masking'] = True\n",
    "\n",
    "# mlp params\n",
    "config['is_causal'] = True\n",
    "config['num_causes'] = 5\n",
    "config['prior_mlp_hidden_dim'] = 50\n",
    "config['num_layers'] = 4\n",
    "config['noise_std'] = 0.05\n",
    "config['init_std'] = 0.05\n",
    "config['y_is_effect'] = True\n",
    "config['pre_sample_weights'] = True\n",
    "config['prior_mlp_dropout_prob'] = 0\n",
    "config['pre_sample_causes'] = True\n",
    "config[\"prior_mlp_activations\"] = torch.nn.ReLU\n",
    "config[\"block_wise_dropout\"] = True\n",
    "config[\"sort_features\"] = False\n",
    "config[\"in_clique\"] = False\n",
    "\n",
    "# general data params\n",
    "config['balanced'] = True\n",
    "config['max_num_classes'] = 2\n",
    "config['max_features'] = 100\n",
    "config['num_features_used'] = 100\n",
    "\n",
    "config['num_classes'] = 2\n",
    "\n",
    "config['no_encoder'] = False\n",
    "config['normalize_to_ranking'] = False # False\n",
    "config['normalize_with_sqrt'] = False\n",
    "config['normalize_ignore_label_too'] = False\n",
    "config[\"normalize\"] = False\n",
    "config['num_classes'] = 2\n",
    "config[\"balanced\"] = False\n",
    "config['multiclass_type'] = 'imbalanced_binarize'\n",
    "\n",
    "\n",
    "config_sample = evaluate_hypers(config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30030035-1632-47a4-9d32-a560361a8dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dl = dl_from_config(config_sample, prior_hyperparameters)\n",
    "model = get_model(config_sample, device, should_train=False, verbose=0)\n",
    "dl = model[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8825b69a-4d14-4e8f-95ba-1128f5486b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid(dl,config_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb563131-d329-4157-bb05-31fa6a6f0e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_combinations(dl,config_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b700a2b-c26b-44cc-8530-8d1f7650c97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "class MicroDL(DataLoader):\n",
    "    def __init__(self, path=None):\n",
    "        data, labels = get_microbiome(path)\n",
    "        data = top_non_zero(data)\n",
    "        data, labels = unison_shuffled_copies(data, labels)\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return 100\n",
    "        \n",
    "    def get_perm(self):\n",
    "        indices = np.random.permutation(self.data.shape[0])[:1000]\n",
    "        return (None, np.expand_dims(self.data[indices], axis=1), np.expand_dims(self.labels[indices],axis=1)), None, None\n",
    "        \n",
    "    def __iter__(self):\n",
    "        indices = np.random.permutation(self.data.shape[0])[:1000]\n",
    "        return iter(self.get_perm() for _ in range(100))\n",
    "path = \"datasets/data_all.csv\"\n",
    "dl = MicroDL(path)\n",
    "#plot_grid(dl, config_sample)\n",
    "plot_feature_combinations(dl, config_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47342e30-ae92-451b-824d-6db9a19ea2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['differentiable'] = True\n",
    "config['flexible'] = True\n",
    "\n",
    "# forest params\n",
    "config[\"min_features\"] = 100\n",
    "config[\"max_features\"] = 100\n",
    "config[\"n_samples\"] = 1000\n",
    "config[\"max_classes\"] = 2\n",
    "config[\"base_size\"] = 1000\n",
    "config[\"n_estimators\"] = 1\n",
    "config[\"min_depth\"] = 3\n",
    "config[\"max_depth\"] = 15\n",
    "config[\"categorical_x\"] = False\n",
    "config[\"data_sample_func\"] = \"zinb\"\n",
    "config[\"comp\"] = True\n",
    "\n",
    "config['multiclass_type'] = 'balance'\n",
    "del config['differentiable_hyperparameters']['multiclass_type']\n",
    "\n",
    "config[\"prior_type\"] = \"forest\"\n",
    "config[\"microbiome_test\"] = True\n",
    "config[\"weight_classes\"] = False\n",
    "config[\"run_name\"] = \"time\"\n",
    "\n",
    "config[\"prior_type\"] = \"forest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc90518-93eb-4479-980f-3ee7f749c365",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_sample = evaluate_hypers(config)\n",
    "model = get_model(config_sample, device, should_train=False, verbose=0)\n",
    "dl = model[3]\n",
    "plot_grid(dl, config_sample)\n",
    "plot_feature_combinations(dl, config_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540f17f5-7cc3-4fc7-a60c-cfb409cb3513",
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"data_sample_func\"] = \"mnd\"\n",
    "\n",
    "\n",
    "config_sample = evaluate_hypers(config)\n",
    "model = get_model(config_sample, device, should_train=False, verbose=0)\n",
    "dl = model[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4e1075-d1c8-443b-85e6-05216d0367da",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid(dl, config_sample)\n",
    "plot_feature_combinations(dl, config_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b2ca11-0225-4a0d-9c95-796d9eb3ee8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabpfn import TabPFNClassifier\n",
    "model = TabPFNClassifier(device='cpu', N_ensemble_configurations=1)\n",
    "x, y = get_sample(dl)\n",
    "x, y = torch.squeeze(x), torch.squeeze(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, train_size=0.8, test_size=0.2, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "print(torch.tensor(preds)*y_test+(torch.tensor(preds)-1)*(y_test-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ecd56e91-d6c5-4163-bf92-a797bb3a8977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "Using cpu:0 device\n",
      "Using a Transformer with 1.64 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "config[\"prior_type\"] = \"mlp\"\n",
    "config[\"sampling\"] = \"mnd\"\n",
    "config[\"data_sample_func\"] = \"mnd\"\n",
    "config[\"is_causal\"] = False\n",
    "config['multiclass_type'] = 'balance'\n",
    "config['hist_targets'] = False\n",
    "\n",
    "config[\"align_majority\"] = False\n",
    "config[\"limit_imbalance\"] = False\n",
    "\n",
    "config[\"normalize\"] = True\n",
    "config[\"num_classes\"] = 2\n",
    "config[\"max_num_classes\"] = 2\n",
    "\n",
    "config['min_depth'] = 5\n",
    "config['max_depth'] = 15\n",
    "#del config['differentiable_hyperparameters']['multiclass_type']\n",
    "\n",
    "config_sample = evaluate_hypers(config)\n",
    "model = get_model(config_sample, device, should_train=False, verbose=0)\n",
    "dl = model[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ae188bf-91f0-42c2-91b5-96714476a333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Run #0\n",
      "Target mean:  tensor(0.5000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\Desktop\\MT\\TabPFN-medical\\evaluate.py:22: UserWarning: you are shuffling a 'Tensor' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(c0_data)\n",
      "C:\\Users\\lenna\\Desktop\\MT\\TabPFN-medical\\evaluate.py:23: UserWarning: you are shuffling a 'Tensor' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(c1_data)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\master3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:1429\u001b[0m, in \u001b[0;36mBlock.setitem\u001b[1;34m(self, indexer, value, using_cow)\u001b[0m\n\u001b[0;32m   1428\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1429\u001b[0m     \u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m casted\n\u001b[0;32m   1430\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (5,) into shape (4,)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 27\u001b[0m\n\u001b[0;32m     22\u001b[0m results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(models), \u001b[38;5;28mlen\u001b[39m(metrics))), \n\u001b[0;32m     23\u001b[0m                        index\u001b[38;5;241m=\u001b[39m[m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m models],\n\u001b[0;32m     24\u001b[0m                       columns\u001b[38;5;241m=\u001b[39mmetrics)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ii, model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(models):\n\u001b[1;32m---> 27\u001b[0m     \u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mii\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m cross_validate_sample(model, x, y, metrics, strat_split, cv, sampling)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(results)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master3\\Lib\\site-packages\\pandas\\core\\indexing.py:911\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[0;32m    910\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[1;32m--> 911\u001b[0m \u001b[43miloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master3\\Lib\\site-packages\\pandas\\core\\indexing.py:1944\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1942\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_with_indexer_split_path(indexer, value, name)\n\u001b[0;32m   1943\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1944\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_single_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master3\\Lib\\site-packages\\pandas\\core\\indexing.py:2218\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_single_block\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   2215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_check_is_chained_assignment_possible()\n\u001b[0;32m   2217\u001b[0m \u001b[38;5;66;03m# actually do the set\u001b[39;00m\n\u001b[1;32m-> 2218\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2219\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_maybe_update_cacher(clear\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:415\u001b[0m, in \u001b[0;36mBaseBlockManager.setitem\u001b[1;34m(self, indexer, value, warn)\u001b[0m\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;66;03m# No need to split if we either set all columns or on a single block\u001b[39;00m\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;66;03m# manager\u001b[39;00m\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m--> 415\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msetitem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:1432\u001b[0m, in \u001b[0;36mBlock.setitem\u001b[1;34m(self, indexer, value, using_cow)\u001b[0m\n\u001b[0;32m   1430\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1431\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m is_list_like(casted):\n\u001b[1;32m-> 1432\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1433\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msetting an array element with a sequence.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1434\u001b[0m             ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   1435\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m   1436\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print(f\"\\n\\n\\nRun #{i}\")\n",
    "    x, y = get_sample(dl)\n",
    "    x, y = torch.squeeze(x), torch.squeeze(y)\n",
    "    print(\"Target mean: \", torch.mean(y))\n",
    "    if len(np.unique(y, return_counts=True)[0])>1 and np.min(np.unique(y, return_counts=True)[1])>20:\n",
    "        #plt.hist(y, bins=100)\n",
    "        #plt.show()\n",
    "        cv = 3\n",
    "        n_optim = 20\n",
    "        ft_epochs = 0\n",
    "        sampling = None\n",
    "        strat_split=True\n",
    "        metrics = metrics = [\"accuracy\", \"precision\", \"recall\", \"roc_auc\"]\n",
    "        models = [\n",
    "            #XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic'),\n",
    "            XGBoostOptim(n_optim=n_optim),\n",
    "            #LogisticRegression(max_iter=500), \n",
    "            #TabPFNClassifier(device='cpu', N_ensemble_configurations=3),\n",
    "            #TabForestPFNClassifier(\"saved_models/tabforest/mix600k/tabforestpfn.pt\", \"saved_models/tabforest/mix600k/config_run.yaml\")\n",
    "        ]\n",
    "        results = pd.DataFrame(np.zeros((len(models), len(metrics))), \n",
    "                               index=[m.__class__.__name__ for m in models],\n",
    "                              columns=metrics)\n",
    "        \n",
    "        for ii, model in enumerate(models):\n",
    "            results.iloc[ii,:] = cross_validate_sample(model, x, y, metrics, strat_split, cv, sampling)\n",
    "        print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7b15a5d3-46cc-439c-a324-577e5dda3ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "Using cpu:0 device\n",
      "Using a Transformer with 1.64 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC:  0.7360507132182651 0.14917785094406735\n",
      "Pred avgs:  0.6178100018948317\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config[\"prior_type\"] = \"forest\"\n",
    "config[\"sampling\"] = \"mnd\"\n",
    "config[\"data_sample_func\"] = \"mnd\"\n",
    "config[\"is_causal\"] = False\n",
    "config['multiclass_type'] = 'balance'\n",
    "config['hist_targets'] = False\n",
    "config['y_std'] = 1\n",
    "config['min_depth'] = 5\n",
    "config['max_depth'] = 15\n",
    "config['num_classes'] = 2\n",
    "\n",
    "\n",
    "config[\"align_majority\"] = False\n",
    "config[\"limit_imbalance\"] = False\n",
    "\n",
    "\n",
    "\n",
    "config_sample = evaluate_hypers(config)\n",
    "model = get_model(config_sample, device, should_train=False, verbose=0)\n",
    "dl = model[3]\n",
    "rocs = []\n",
    "means = []\n",
    "for i in range(100):\n",
    "    #print(f\"\\n\\n\\nRun #{i}\")\n",
    "    x, y = get_sample(dl)\n",
    "    x, y = torch.squeeze(x).numpy(), torch.squeeze(y).numpy()\n",
    "    #print(np.unique(y, return_counts=True))\n",
    "    if len(np.unique(y, return_counts=True)[0])>1 and np.min(np.unique(y, return_counts=True)[1])>10:\n",
    "        #print(\"Target mean: \", torch.mean(y))\n",
    "        #plt.hist(y, bins=100)\n",
    "        #plt.show()\n",
    "        cv = 3\n",
    "        n_optim = 20\n",
    "        ft_epochs = 0\n",
    "        sampling = None\n",
    "        strat_split=True\n",
    "        metrics = metrics = [\"roc_auc\"]#\"roc_auc_ovr\"]\n",
    "        if config['num_classes'] ==2:\n",
    "            o = 'binary:logistic'\n",
    "        else:\n",
    "            o = 'multi:softmax'\n",
    "        model = XGBClassifier(n_estimators=7, max_depth=7, learning_rate=1, objective=o)#\n",
    "        #model = XGBoostOptim(n_optim=n_optim)\n",
    "        results = cross_validate_sample(model, x, y, metrics, strat_split, cv, sampling)\n",
    "        means.append(max(1-np.mean(y),np.mean(y)))\n",
    "        #print(results[0])\n",
    "        rocs.append(results[0])\n",
    "print(\"ROC: \", np.mean(np.array(rocs)), np.std(np.array(rocs)))\n",
    "print(\"Pred avgs: \", np.mean(np.array(means)))\n",
    "#result_matrix[ii,jj] = np.mean(np.array(rocs))\n",
    "plt.hist(rocs, bins=20)\n",
    "plt.show()\n",
    "plt.hist(means, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3668474-a2cf-403d-8bb8-4d76ba6063d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5005)\n"
     ]
    }
   ],
   "source": [
    "accs = []\n",
    "for i in range(1000):\n",
    "    #print(f\"\\n\\n\\nRun #{i}\")\n",
    "    x, y = get_sample(dl)\n",
    "    x, y = torch.squeeze(x), torch.squeeze(y)\n",
    "    preds = torch.full(y.shape, torch.argmax(torch.unique(y, return_counts=True)[1]).item())\n",
    "    accuracy = torch.mean((preds==y)[y!=-100].float())\n",
    "    accs.append(accuracy)\n",
    "print(torch.mean(torch.tensor(accs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb27a55-0322-4121-a7ba-f3380dfb2a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50,100,1):\n",
    "    print(f\"ROC sub {i*0.01} pred\",  np.mean(np.array(rocs)[np.array(means)<i*0.01]), len(np.array(rocs)[np.array(means)<i*0.01])/len(means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c363a4-132d-4c4b-9fd2-0f99eb63f4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8a0922-d04c-43e6-a2d5-fd3745858bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(means,rocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff1fee4-f743-4630-b62c-4a02b0880158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358a4488-dda9-43b0-890f-ab7ccd92a306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multinomial_dirichlet(size=(1000,100)):\n",
    "    M = 1000\n",
    "    alphas = np.random.beta(1,1,size[1])\n",
    "    thetas = [np.random.dirichlet(alphas) for i in range(size[0])]\n",
    "    #print(thetas, np.sum(thetas))\n",
    "    X = np.asarray([np.random.multinomial(M, theta)/M for theta in thetas])\n",
    "    return X\n",
    "X = multinomial_dirichlet()\n",
    "print(X[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc87ccf7-5976-483f-9eb4-41036e9d97c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f721f19-7023-4436-b374-886651722f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def get_sample(config_sample, prior_hyperparameters):\n",
    "    def eval_pos_seq_len_sampler():\n",
    "        single_eval_pos_gen = get_uniform_single_eval_pos_sampler(config.get('max_eval_pos', config['bptt']), min_len=config.get('min_eval_pos', 0))\n",
    "        single_eval_pos = single_eval_pos_gen()\n",
    "        return single_eval_pos, 1024\n",
    "    ''extra_prior_kwargs_dict={\n",
    "        'num_features': config['num_features'], \n",
    "        'hyperparameters': prior_hyperparameters\n",
    "    }\n",
    "    extra_kwargs = {}\n",
    "    if 'flexible' in config and config['flexible']:\n",
    "        get_batch_base = make_get_batch(model_proto)\n",
    "        extra_kwargs['get_batch'] = get_batch_base\n",
    "        model_proto = priors.flexible_categorical\n",
    "    if 'differentiable' in prior_hyperparameters and prior_hyperparameters['differentiable']:\n",
    "        get_batch_base = make_get_batch(model_proto, **extra_kwargs)\n",
    "        extra_kwargs = {'get_batch': get_batch_base, 'differentiable_hyperparameters': prior_hyperparameters['differentiable_hyperparameters']}\n",
    "        model_proto = priors.differentiable_prior\n",
    "        use_style = True\n",
    "    \n",
    "    dl = model_proto.DataLoader(num_steps=1, batch_size=1, \n",
    "                                eval_pos_seq_len_sampler=eval_pos_seq_len_sampler, \n",
    "                                seq_len_maximum=None, device=\"cpu\", **extra_prior_kwargs_dict)''\n",
    "    dl_class, extra_kwargs = get_dataloader(config_sample, device=\"cpu\", should_train=False, verbose=2)\n",
    "    dl = model_proto.DataLoader(num_steps=1, batch_size=1, \n",
    "                                eval_pos_seq_len_sampler=eval_pos_seq_len_sampler, \n",
    "                                seq_len_maximum=None, device=\"cpu\", **extra_kwargs)\n",
    "    dl.model = None\n",
    "    return next(iter(dl))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a955c12a-56e9-4895-a9af-07226073cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_sample(config_sample, prior_hyperparameters)\n",
    "print(a[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c161bd-ec80-43ac-b3a9-21011eec1d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['differentiable'] = False\n",
    "config['flexible'] = False\n",
    "\n",
    "# forest params\n",
    "config[\"min_features\"] = 10\n",
    "config[\"max_features\"] = 100\n",
    "config[\"n_samples\"] = 1000\n",
    "config[\"max_classes\"] = 10\n",
    "config[\"base_size\"] = 1000\n",
    "config[\"n_estimators\"] = 1\n",
    "config[\"min_depth\"] = 1\n",
    "config[\"max_depth\"] = 25\n",
    "config[\"categorical_x\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af348aba-7927-4722-829b-2b9067bec073",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "from tabpfn import TabPFNClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from evaluate import scores\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, precision_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from data_prep_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import openml\n",
    "from tabularbench.data.synthetic_generator_forest import synthetic_dataset_generator_forest, synthetic_dataset_function_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5561d98a-122c-46a3-b816-198a5c986552",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabularbench.data.synthetic_generator_tabpfn import synthetic_dataset_generator_tabpfn\n",
    "\n",
    "fig, axes = plt.subplots(8, 6, figsize=(20, 15))\n",
    "generator = synthetic_dataset_generator_tabpfn(n_samples=1000, max_classes=2, min_features=2, max_features=100)\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    x2, b = next(generator)\n",
    "    i1, i2 = np.random.choice(x2.shape[1], size=(2,), replace=False)\n",
    "    ax.scatter(x2[:, i1], x2[:, i2], c=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2a893a-7167-4aa4-a2df-513182935798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabularbench.data.synthetic_generator_forest import synthetic_dataset_generator_forest, synthetic_dataset_function_forest\n",
    "import matplotlib\n",
    "\n",
    "fig, axes = plt.subplots(8, 6, figsize=(20, 15))\n",
    "generator = synthetic_dataset_generator_forest(n_samples=1000, max_classes=2, min_features=2, max_features=2)\n",
    "\n",
    "cmap = matplotlib.colormaps['inferno']\n",
    "colors = cmap(np.linspace(0.0, 0.9, 10))\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    x2, b = synthetic_dataset_function_forest(base_size=1000, min_features=2, max_features=2, max_classes=3, min_depth=1, max_depth=25, categorical_x=True, n_samples=1024)\n",
    "    i1, i2 = np.random.choice(x2.shape[1], size=(2,), replace=False)\n",
    "    random_shuffle = np.random.permutation(np.arange(10))\n",
    "    colors_shuffle = colors[random_shuffle]\n",
    "    #b = np.array([colors_shuffle[i] for i in b])\n",
    "    ax.scatter(x2[:, i1], x2[:, i2], c=b)\n",
    "    ax.tick_params(axis='both', which='both', bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be43c36-ca72-4cb4-9cd4-72a59b27d90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zinb(size=(1000,100)):\n",
    "    pi = 0.25\n",
    "    p = np.random.uniform(0.1,0.9, size=size[1])\n",
    "    p = np.repeat(np.expand_dims(p,axis=0),size[0],axis=0)\n",
    "    #print\n",
    "    #p += 1e-5\n",
    "    X = np.random.negative_binomial(100,p)\n",
    "    X = np.random.binomial(1,1-pi,size)*X\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08769738-e744-49cc-98c2-206e3bb9d5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zinb_comp(size=(1000,100)):\n",
    "    X =  zinb(size)\n",
    "    print(X)\n",
    "    print(np.expand_dims(1/np.sum(X,axis=1),axis=1))\n",
    "    return np.expand_dims(1/np.sum(X,axis=1),axis=1)*X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada8a9e9-6a99-4d92-b869-ae69bdc53cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = zinb_comp((10,10))\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ed9025-1fb0-4732-b3b7-ee311b528e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(out, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c62c558-446d-42bf-a2a3-39ed3b4a9c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prior.synthetic_generator_forest_altdata import synthetic_dataset_generator_forest_altdata, synthetic_dataset_function_forest_altdata\n",
    "\n",
    "fig, axes = plt.subplots(8, 6, figsize=(20, 15))\n",
    "\n",
    "cmap = matplotlib.colormaps['inferno']\n",
    "colors = cmap(np.linspace(0.0, 0.9, 10))\n",
    "\n",
    "\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    x2, b = synthetic_dataset_function_forest_altdata(zinb,base_size=1000, min_features=2, max_features=2, max_classes=3, min_depth=1, max_depth=25, categorical_x=True, n_samples=1024)\n",
    "    i1, i2 = np.random.choice(x2.shape[1], size=(2,), replace=False)\n",
    "    random_shuffle = np.random.permutation(np.arange(10))\n",
    "    colors_shuffle = colors[random_shuffle]\n",
    "    #b = np.array([colors_shuffle[i] for i in b])\n",
    "    ax.scatter(x2[:, i1], x2[:, i2], c=b)\n",
    "    ax.tick_params(axis='both', which='both', bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b35c21-16e3-44e8-80df-dd5de8fc536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_norm, b_norm = synthetic_dataset_function_forest(base_size=1000, min_features=2, max_features=2, max_classes=3, min_depth=1, max_depth=25, categorical_x=True, n_samples=1024)\n",
    "\n",
    "X_zinb, b_zinb = synthetic_dataset_function_forest_altdata(zinb,base_size=1000, min_features=2, max_features=2, max_classes=3, min_depth=1, max_depth=25, categorical_x=True, n_samples=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68200361-d086-41a0-8af3-ad83c009298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, roc_auc_score\n",
    "accuracy = np.zeros((3))\n",
    "runs = 10\n",
    "for ii in range(runs):\n",
    "    X_norm, b_norm = synthetic_dataset_function_forest(base_size=1000, min_features=2, max_features=2, max_classes=3, min_depth=1, max_depth=25, categorical_x=True, n_samples=1024)\n",
    "    models = [XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic'), \n",
    "              LogisticRegression(max_iter=500), \n",
    "              TabPFNClassifier(device='cpu', N_ensemble_configurations=3)]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_norm, b_norm, test_size=0.2, random_state=42)\n",
    "    for mm, model in enumerate(models):\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy[mm] += accuracy_score(y_test,y_pred)\n",
    "print(accuracy/runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248ed978-b1b6-46ee-9233-e91434632ae2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, roc_auc_score\n",
    "accuracy = np.zeros((3))\n",
    "runs = 10\n",
    "for ii in range(runs):\n",
    "    print(ii)\n",
    "    X_zinb, b_zinb = synthetic_dataset_function_forest_altdata(zinb,base_size=1000, min_features=2, max_features=2, max_classes=3, min_depth=1, max_depth=25, categorical_x=True, n_samples=1024)\n",
    "    models = [XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic'), \n",
    "              LogisticRegression(max_iter=500), \n",
    "              TabPFNClassifier(device='cpu', N_ensemble_configurations=3)]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_zinb, b_zinb, test_size=0.2, random_state=42)\n",
    "    for mm, model in enumerate(models):\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy[mm] += accuracy_score(y_test,y_pred)\n",
    "print(accuracy/runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa159333-33a1-4941-9ea3-31ab11dfcca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e818c922-3e6d-4443-884a-9fb01aa1db39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
