{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "806ff5d9-0f3a-4fa1-a089-db69fbe1c925",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "from tabpfn_new.scripts.transformer_prediction_interface import TabPFNClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from data_prep_utils import *\n",
    "from evaluate import *\n",
    "from load_models import *\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import openml\n",
    "from data_prep_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from tabpfn_new import priors, encoders\n",
    "from tabpfn_new.scripts.model_configs import *\n",
    "from tabpfn_new.scripts.model_builder import get_forest_prior_hyperparameters, get_mlp_prior_hyperparameters, get_model\n",
    "from tabpfn.utils import get_uniform_single_eval_pos_sampler\n",
    "from utils import get_dataloader\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99725f1b-38b4-4188-ba15-49b041341222",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reload_config(prior_type='forest', config_type='causal', task_type='binary', longer=0):\n",
    "    config = get_prior_config(config_type=config_type)\n",
    "    \n",
    "    config['prior_type'] = prior_type\n",
    "    \n",
    "    model_string = ''\n",
    "    \n",
    "    config['epochs'] = 12000\n",
    "    config['recompute_attn'] = True\n",
    "\n",
    "    config['max_num_classes'] = 10\n",
    "    config['num_classes'] = uniform_int_sampler_f(2, config['max_num_classes'])\n",
    "    config['balanced'] = False\n",
    "    model_string = model_string + '_multiclass'\n",
    "    \n",
    "    model_string = model_string + '_'+datetime.now().strftime(\"%m_%d_%Y_%H_%M_%S\")\n",
    "    \n",
    "    return config, model_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ef61611-5810-4471-93f9-82b1f6958f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dl_from_config(config_sample, prior_hyperparameters):\n",
    "    def eval_pos_seq_len_sampler():\n",
    "        single_eval_pos_gen = get_uniform_single_eval_pos_sampler(config.get('max_eval_pos', config['bptt']), min_len=config.get('min_eval_pos', 0))\n",
    "        single_eval_pos = single_eval_pos_gen()\n",
    "        return single_eval_pos, 1024\n",
    "    dl_class, extra_kwargs = get_dataloader(config_sample, device=\"cpu\", should_train=False, verbose=0)\n",
    "    dl = dl_class(num_steps=1, batch_size=1, \n",
    "                                eval_pos_seq_len_sampler=eval_pos_seq_len_sampler, \n",
    "                                seq_len_maximum=None, device=\"cpu\", **extra_kwargs)\n",
    "    dl.model = None\n",
    "    return dl\n",
    "\n",
    "                                     \n",
    "def get_sample(dl):\n",
    "    (style, x, y), _, _ =  next(iter(dl))\n",
    "    return x, y\n",
    "    \n",
    "def plot_grid(dl, hyperparameters, rows=8, cols=6):\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(20,15))\n",
    "    class_assigner = priors.flexible_categorical.BalancedBinarize()#priors.flexible_categorical.MulticlassRank(hyperparameters['num_classes'], ordered_p=hyperparameters['output_multiclass_ordered_p'])\n",
    "    for ax in axes.flatten():\n",
    "        x2, b = get_sample(dl)\n",
    "        #b = class_assigner(b)\n",
    "        i1, i2 = np.random.choice(x2.shape[2], size=(2,), replace=False)\n",
    "        ax.scatter(x2[:, 0, i1], x2[:, 0, i2], c=b, s=1.5, cmap=\"bwr\")\n",
    "\n",
    "def remove_zero_features(x):\n",
    "    x = x[:,:,torch.where(torch.sum(torch.abs(x), dim=0)>0,1,0)]\n",
    "    return x\n",
    "\n",
    "def plot_feature_combinations(dl, hyperparameters, num_plots=10):\n",
    "    fig = plt.figure(figsize=(20,15))\n",
    "    x2, b = get_sample(dl)\n",
    "    #x2 = remove_zero_features(x2)\n",
    "    #class_assigner = priors.flexible_categorical.BalancedBinarize()#MulticlassRank(hyperparameters['num_classes'], ordered_p=hyperparameters['output_multiclass_ordered_p'])\n",
    "    #b = class_assigner(b)\n",
    "    n_feat = num_plots#hyperparameters[\"max_features\"]\n",
    "    for i in range(n_feat-1):\n",
    "        for j in range(n_feat):\n",
    "            if(j>i) :\n",
    "                ax = plt.subplot2grid((n_feat-1, n_feat-1), (i,j-1))\n",
    "                #ax.xaxis.set_ticklabels([]) \n",
    "                #ax.yaxis.set_ticklabels([])\n",
    "                plt.scatter(x2[:,0,i],x2[:,0,j],c=b, s=1.5, cmap=\"bwr\")\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f7f010d-ebbf-4cf7-ba58-8f98ecb7e01b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prior_type = 'mlp'\n",
    "config, model_string = reload_config(prior_type, longer=1)\n",
    "\n",
    "config['differentiable'] = True\n",
    "config['flexible'] = True\n",
    "config['bptt_extra_samples'] = None\n",
    "\n",
    "# diff\n",
    "config['output_multiclass_ordered_p'] = 0.0\n",
    "del config['differentiable_hyperparameters']['output_multiclass_ordered_p']\n",
    "\n",
    "\n",
    "\n",
    "config['sampling'] = 'normal' # vielleicht schlecht?\n",
    "del config['differentiable_hyperparameters']['sampling']\n",
    "\n",
    "config['pre_sample_causes'] = True\n",
    "# end diff\n",
    "\n",
    "config['multiclass_loss_type'] = 'nono' # 'compatible'\n",
    "config['normalize_to_ranking'] = False # False\n",
    "\n",
    "config['categorical_feature_p'] = 0 # diff: .0\n",
    "\n",
    "# turn this back on in a random search!?\n",
    "config['nan_prob_no_reason'] = .0\n",
    "config['nan_prob_unknown_reason'] = .0 # diff: .0\n",
    "config['set_value_to_nan'] = .0 # diff: 1.\n",
    "\n",
    "config['normalize_with_sqrt'] = False\n",
    "\n",
    "config['new_mlp_per_example'] = True\n",
    "config['prior_mlp_scale_weights_sqrt'] = True\n",
    "config['batch_size_per_gp_sample'] = None\n",
    "\n",
    "config['normalize_ignore_label_too'] = False\n",
    "\n",
    "config['differentiable_hps_as_style'] = False\n",
    "config['max_eval_pos'] = 1000\n",
    "\n",
    "config['random_feature_rotation'] = True\n",
    "config['rotate_normalized_labels'] = True\n",
    "\n",
    "config[\"mix_activations\"] = True # False heisst eig True\n",
    "\n",
    "config['n_layers'] = 4\n",
    "config['emsize'] = 128\n",
    "config['nhead'] = config['emsize'] // 32\n",
    "config['bptt'] = 1024+128\n",
    "config['canonical_y_encoder'] = True\n",
    "\n",
    "    \n",
    "config['aggregate_k_gradients'] = 1\n",
    "config['batch_size'] = 1*config['aggregate_k_gradients']\n",
    "config['num_steps'] = 1//config['aggregate_k_gradients']\n",
    "config['epochs'] = 1\n",
    "\n",
    "config['total_available_time_in_s'] = None #60*60*22 # 22 hours for some safety...\n",
    "\n",
    "config['train_mixed_precision'] = True\n",
    "config['efficient_eval_masking'] = True\n",
    "\n",
    "# mlp params\n",
    "config['is_causal'] = True\n",
    "config['num_causes'] = 5\n",
    "config['prior_mlp_hidden_dim'] = 50\n",
    "config['num_layers'] = 4\n",
    "config['noise_std'] = 0.05\n",
    "config['init_std'] = 0.05\n",
    "config['y_is_effect'] = True\n",
    "config['pre_sample_weights'] = True\n",
    "config['prior_mlp_dropout_prob'] = 0\n",
    "config['pre_sample_causes'] = True\n",
    "config[\"prior_mlp_activations\"] = torch.nn.ReLU()\n",
    "config[\"block_wise_dropout\"] = True\n",
    "config[\"sort_features\"] = False\n",
    "config[\"in_clique\"] = False\n",
    "\n",
    "# general data params\n",
    "config['balanced'] = True\n",
    "config['max_num_classes'] = 2\n",
    "config['max_features'] = 100\n",
    "config['num_features_used'] = 100\n",
    "\n",
    "config['num_classes'] = 2\n",
    "\n",
    "config['no_encoder'] = False\n",
    "config['normalize_to_ranking'] = False # False\n",
    "config['normalize_with_sqrt'] = False\n",
    "config['normalize_ignore_label_too'] = False\n",
    "config[\"normalize\"] = False\n",
    "config['num_classes'] = 2\n",
    "config[\"balanced\"] = False\n",
    "config['multiclass_type'] = 'imbalanced_binarize'\n",
    "\n",
    "\n",
    "config_sample = evaluate_hypers(config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30030035-1632-47a4-9d32-a560361a8dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "Using cpu:0 device\n",
      "Using a Transformer with 1.64 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#dl = dl_from_config(config_sample, prior_hyperparameters)\n",
    "model = get_model(config_sample, device, should_train=False, verbose=0)\n",
    "dl = model[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8825b69a-4d14-4e8f-95ba-1128f5486b99",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'limit_imbalance'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplot_grid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdl\u001b[49m\u001b[43m,\u001b[49m\u001b[43mconfig_sample\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 22\u001b[0m, in \u001b[0;36mplot_grid\u001b[1;34m(dl, hyperparameters, rows, cols)\u001b[0m\n\u001b[0;32m     20\u001b[0m class_assigner \u001b[38;5;241m=\u001b[39m priors\u001b[38;5;241m.\u001b[39mflexible_categorical\u001b[38;5;241m.\u001b[39mBalancedBinarize()\u001b[38;5;66;03m#priors.flexible_categorical.MulticlassRank(hyperparameters['num_classes'], ordered_p=hyperparameters['output_multiclass_ordered_p'])\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mflatten():\n\u001b[1;32m---> 22\u001b[0m     x2, b \u001b[38;5;241m=\u001b[39m \u001b[43mget_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m#b = class_assigner(b)\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     i1, i2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(x2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m], size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m,), replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[3], line 15\u001b[0m, in \u001b[0;36mget_sample\u001b[1;34m(dl)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_sample\u001b[39m(dl):\n\u001b[1;32m---> 15\u001b[0m     (style, x, y), _, _ \u001b[38;5;241m=\u001b[39m  \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x, y\n",
      "File \u001b[1;32m~\\Desktop\\MT\\TabPFN-medical\\tabpfn_new\\priors\\utils.py:45\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease assign model with `dl.model = ...` before training.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgbm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_batch_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_count\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_steps))\n",
      "File \u001b[1;32m~\\Desktop\\MT\\TabPFN-medical\\tabpfn_new\\priors\\utils.py:32\u001b[0m, in \u001b[0;36mget_batch_to_dataloader.<locals>.DL.gbm\u001b[1;34m(eval_pos_seq_len_sampler, *args, **kwargs)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic_batch_size\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic_batch_size\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic_batch_size\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m     31\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39mfloor(math\u001b[38;5;241m.\u001b[39mpow(kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseq_len_maximum\u001b[39m\u001b[38;5;124m'\u001b[39m], kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic_batch_size\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39mpow(kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseq_len\u001b[39m\u001b[38;5;124m'\u001b[39m], kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic_batch_size\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m---> 32\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[43mget_batch_method_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m x, y, target_y, style \u001b[38;5;241m=\u001b[39m batch \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batch) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m (batch[\u001b[38;5;241m0\u001b[39m], batch[\u001b[38;5;241m1\u001b[39m], batch[\u001b[38;5;241m2\u001b[39m], \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (style, x, y), target_y, kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msingle_eval_pos\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master3\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\MT\\TabPFN-medical\\tabpfn_new\\priors\\differentiable_prior.py:237\u001b[0m, in \u001b[0;36mget_batch\u001b[1;34m(batch_size, seq_len, num_features, get_batch, device, differentiable_hyperparameters, hyperparameters, batch_size_per_gp_sample, **kwargs)\u001b[0m\n\u001b[0;32m    234\u001b[0m args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs}\n\u001b[0;32m    236\u001b[0m models \u001b[38;5;241m=\u001b[39m [DifferentiablePrior(get_batch, hyperparameters, differentiable_hyperparameters, args) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_models)]\n\u001b[1;32m--> 237\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m]\u001b[49m, [])\n\u001b[0;32m    239\u001b[0m x, y, y_, hyperparameter_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39msample)\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m hyperparameters \u001b[38;5;129;01mand\u001b[39;00m hyperparameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[1;32m~\\Desktop\\MT\\TabPFN-medical\\tabpfn_new\\priors\\differentiable_prior.py:237\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    234\u001b[0m args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs}\n\u001b[0;32m    236\u001b[0m models \u001b[38;5;241m=\u001b[39m [DifferentiablePrior(get_batch, hyperparameters, differentiable_hyperparameters, args) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_models)]\n\u001b[1;32m--> 237\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m([[\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m] \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m models], [])\n\u001b[0;32m    239\u001b[0m x, y, y_, hyperparameter_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39msample)\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m hyperparameters \u001b[38;5;129;01mand\u001b[39;00m hyperparameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\MT\\TabPFN-medical\\tabpfn_new\\priors\\differentiable_prior.py:219\u001b[0m, in \u001b[0;36mDifferentiablePrior.forward\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    216\u001b[0m sampled_hyperparameters_passed, sampled_hyperparameters_indicators \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdifferentiable_hyperparameters\u001b[38;5;241m.\u001b[39msample_parameter_object()\n\u001b[0;32m    218\u001b[0m hyperparameters \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msampled_hyperparameters_passed}\n\u001b[1;32m--> 219\u001b[0m x, y, y_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyperparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x, y, y_, sampled_hyperparameters_indicators\n",
      "File \u001b[1;32m~\\Desktop\\MT\\TabPFN-medical\\tabpfn_new\\scripts\\model_builder.py:221\u001b[0m, in \u001b[0;36mget_model.<locals>.make_get_batch.<locals>.new_get_batch\u001b[1;34m(batch_size, seq_len, num_features, hyperparameters, device, model_proto, **kwargs)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_get_batch\u001b[39m(batch_size, seq_len, num_features, hyperparameters\n\u001b[0;32m    218\u001b[0m         , device, model_proto\u001b[38;5;241m=\u001b[39mmodel_proto\n\u001b[0;32m    219\u001b[0m         , \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    220\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs} \u001b[38;5;66;03m# new args overwrite pre-specified args\u001b[39;00m\n\u001b[1;32m--> 221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_proto\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseq_len\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyperparameters\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master3\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\MT\\TabPFN-medical\\tabpfn_new\\priors\\flexible_categorical.py:348\u001b[0m, in \u001b[0;36mget_batch\u001b[1;34m(batch_size, seq_len, num_features, get_batch, device, hyperparameters, batch_size_per_gp_sample, **kwargs)\u001b[0m\n\u001b[0;32m    344\u001b[0m args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m: device, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseq_len\u001b[39m\u001b[38;5;124m'\u001b[39m: seq_len, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_features\u001b[39m\u001b[38;5;124m'\u001b[39m: num_features, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m: batch_size_per_gp_sample, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m    346\u001b[0m models \u001b[38;5;241m=\u001b[39m [FlexibleCategorical(get_batch, hyperparameters, args)\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_models)]\n\u001b[1;32m--> 348\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size_per_gp_sample\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    350\u001b[0m x, y, y_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39msample)\n\u001b[0;32m    351\u001b[0m x, y, y_ \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(x, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach(), torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach(), torch\u001b[38;5;241m.\u001b[39mcat(y_, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[1;32m~\\Desktop\\MT\\TabPFN-medical\\tabpfn_new\\priors\\flexible_categorical.py:348\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    344\u001b[0m args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m: device, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseq_len\u001b[39m\u001b[38;5;124m'\u001b[39m: seq_len, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_features\u001b[39m\u001b[38;5;124m'\u001b[39m: num_features, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m: batch_size_per_gp_sample, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m    346\u001b[0m models \u001b[38;5;241m=\u001b[39m [FlexibleCategorical(get_batch, hyperparameters, args)\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_models)]\n\u001b[1;32m--> 348\u001b[0m sample \u001b[38;5;241m=\u001b[39m [\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size_per_gp_sample\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m models]\n\u001b[0;32m    350\u001b[0m x, y, y_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39msample)\n\u001b[0;32m    351\u001b[0m x, y, y_ \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(x, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach(), torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach(), torch\u001b[38;5;241m.\u001b[39mcat(y_, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\MT\\TabPFN-medical\\tabpfn_new\\priors\\flexible_categorical.py:218\u001b[0m, in \u001b[0;36mFlexibleCategorical.forward\u001b[1;34m(self, batch_size)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;66;03m#print(self.args_passed[\"num_features\"])\u001b[39;00m\n\u001b[0;32m    217\u001b[0m x, y, y_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_batch(hyperparameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs_passed)\n\u001b[1;32m--> 218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlimit_imbalance\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39mmax(torch\u001b[38;5;241m.\u001b[39munique(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_assigner(y), return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m/\u001b[39m\n\u001b[0;32m    220\u001b[0m            torch\u001b[38;5;241m.\u001b[39msum(torch\u001b[38;5;241m.\u001b[39munique(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_assigner(y), return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m1\u001b[39m]))\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0.7\u001b[39m:\n\u001b[0;32m    221\u001b[0m         x, y, y_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_batch(hyperparameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs_passed)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'limit_imbalance'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function flush_figures at 0x00000137304B6D40> (for post_execute), with arguments args (),kwargs {}:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "plot_grid(dl,config_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb563131-d329-4157-bb05-31fa6a6f0e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_combinations(dl,config_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b700a2b-c26b-44cc-8530-8d1f7650c97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "class MicroDL(DataLoader):\n",
    "    def __init__(self, path=None):\n",
    "        data, labels = get_microbiome(path)\n",
    "        data = top_non_zero(data)\n",
    "        data, labels = unison_shuffled_copies(data, labels)\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return 100\n",
    "        \n",
    "    def get_perm(self):\n",
    "        indices = np.random.permutation(self.data.shape[0])[:1000]\n",
    "        return (None, np.expand_dims(self.data[indices], axis=1), np.expand_dims(self.labels[indices],axis=1)), None, None\n",
    "        \n",
    "    def __iter__(self):\n",
    "        indices = np.random.permutation(self.data.shape[0])[:1000]\n",
    "        return iter(self.get_perm() for _ in range(100))\n",
    "path = \"datasets/data_all.csv\"\n",
    "dl = MicroDL(path)\n",
    "#plot_grid(dl, config_sample)\n",
    "plot_feature_combinations(dl, config_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47342e30-ae92-451b-824d-6db9a19ea2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['differentiable'] = True\n",
    "config['flexible'] = True\n",
    "\n",
    "# forest params\n",
    "config[\"min_features\"] = 100\n",
    "config[\"max_features\"] = 100\n",
    "config[\"n_samples\"] = 1000\n",
    "config[\"max_classes\"] = 2\n",
    "config[\"base_size\"] = 1000\n",
    "config[\"n_estimators\"] = 1\n",
    "config[\"min_depth\"] = 3\n",
    "config[\"max_depth\"] = 15\n",
    "config[\"categorical_x\"] = False\n",
    "config[\"data_sample_func\"] = \"zinb\"\n",
    "config[\"comp\"] = True\n",
    "\n",
    "config['multiclass_type'] = 'balance'\n",
    "del config['differentiable_hyperparameters']['multiclass_type']\n",
    "\n",
    "config[\"prior_type\"] = \"forest\"\n",
    "config[\"microbiome_test\"] = True\n",
    "config[\"weight_classes\"] = False\n",
    "config[\"run_name\"] = \"time\"\n",
    "\n",
    "config[\"prior_type\"] = \"forest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc90518-93eb-4479-980f-3ee7f749c365",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_sample = evaluate_hypers(config)\n",
    "model = get_model(config_sample, device, should_train=False, verbose=0)\n",
    "dl = model[3]\n",
    "plot_grid(dl, config_sample)\n",
    "plot_feature_combinations(dl, config_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540f17f5-7cc3-4fc7-a60c-cfb409cb3513",
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"data_sample_func\"] = \"mnd\"\n",
    "\n",
    "\n",
    "config_sample = evaluate_hypers(config)\n",
    "model = get_model(config_sample, device, should_train=False, verbose=0)\n",
    "dl = model[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4e1075-d1c8-443b-85e6-05216d0367da",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid(dl, config_sample)\n",
    "plot_feature_combinations(dl, config_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b2ca11-0225-4a0d-9c95-796d9eb3ee8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabpfn import TabPFNClassifier\n",
    "model = TabPFNClassifier(device='cpu', N_ensemble_configurations=1)\n",
    "x, y = get_sample(dl)\n",
    "x, y = torch.squeeze(x), torch.squeeze(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, train_size=0.8, test_size=0.2, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "print(torch.tensor(preds)*y_test+(torch.tensor(preds)-1)*(y_test-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecd56e91-d6c5-4163-bf92-a797bb3a8977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "Using cpu:0 device\n",
      "Using a Transformer with 1.64 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "config['differentiable'] = True\n",
    "config['flexible'] = True\n",
    "config[\"prior_type\"] = \"forest\"\n",
    "config[\"sampling\"] = \"mnd\"\n",
    "#del config['differentiable_hyperparameters']['sampling']\n",
    "config[\"data_sample_func\"] = \"mnd\"\n",
    "config[\"is_causal\"] = False\n",
    "#del config['differentiable_hyperparameters']['is_causal']\n",
    "config['multiclass_type'] = 'balance'\n",
    "config['hist_targets'] = False\n",
    "\n",
    "config[\"align_majority\"] = False\n",
    "config[\"limit_imbalance\"] = False\n",
    "\n",
    "config[\"normalize\"] = True\n",
    "config[\"num_classes\"] = 2\n",
    "config[\"max_num_classes\"] = 2\n",
    "\n",
    "config['min_depth'] = 5\n",
    "config['max_depth'] = 15\n",
    "#del config['differentiable_hyperparameters']['multiclass_type']\n",
    "\n",
    "config_sample = evaluate_hypers(config)\n",
    "model = get_model(config_sample, device, should_train=False, verbose=0)\n",
    "dl = model[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae188bf-91f0-42c2-91b5-96714476a333",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    print(f\"\\n\\n\\nRun #{i}\")\n",
    "    x, y = get_sample(dl)\n",
    "    x, y = torch.squeeze(x), torch.squeeze(y)\n",
    "    print(\"Target mean: \", torch.mean(y))\n",
    "    if len(np.unique(y, return_counts=True)[0])>1 and np.min(np.unique(y, return_counts=True)[1])>20:\n",
    "        #plt.hist(y, bins=100)\n",
    "        #plt.show()\n",
    "        cv = 3\n",
    "        n_optim = 20\n",
    "        ft_epochs = 0\n",
    "        sampling = None\n",
    "        strat_split=True\n",
    "        max_samples = 1000\n",
    "        metrics = metrics = [\"accuracy\", \"precision\", \"recall\", \"roc_auc\"]\n",
    "        models = [\n",
    "            #XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic'),\n",
    "            XGBoostOptim(n_optim=n_optim),\n",
    "            #LogisticRegression(max_iter=500), \n",
    "            #TabPFNClassifier(device='cpu', N_ensemble_configurations=3),\n",
    "            #TabForestPFNClassifier(\"saved_models/tabforest/mix600k/tabforestpfn.pt\", \"saved_models/tabforest/mix600k/config_run.yaml\")\n",
    "        ]\n",
    "        results = pd.DataFrame(np.zeros((len(models), len(metrics))), \n",
    "                               index=[m.__class__.__name__ for m in models],\n",
    "                              columns=metrics)\n",
    "        \n",
    "        for ii, model in enumerate(models):\n",
    "            results.iloc[ii,:] = cross_validate_sample(model, x, y, metrics, strat_split, cv, sampling)\n",
    "        print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b15a5d3-46cc-439c-a324-577e5dda3ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "Using cpu:0 device\n",
      "Using a Transformer with 1.64 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC:  0.8792731947143999 0.07063145544966512\n",
      "Pred avgs:  0.49938366\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "Using cpu:0 device\n",
      "Using a Transformer with 1.64 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC:  0.6663975694444444 0.15865475373554\n",
      "Pred avgs:  0.5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config['differentiable'] = True\n",
    "config['flexible'] = True\n",
    "config[\"prior_type\"] = \"mlp\"\n",
    "config[\"sampling\"] = \"mnd\"\n",
    "#del config['differentiable_hyperparameters']['sampling']\n",
    "config[\"data_sample_func\"] = \"mnd\"\n",
    "\n",
    "config['multiclass_type'] = 'balance'\n",
    "config[\"is_causal\"] = False\n",
    "if \"is_causal\" in config['differentiable_hyperparameters']:\n",
    "    del config['differentiable_hyperparameters']['is_causal']\n",
    "if 'multiclass_type' in config['differentiable_hyperparameters']:\n",
    "    del config['differentiable_hyperparameters']['multiclass_type']\n",
    "\n",
    "if \"block_wise_dropout\" in config['differentiable_hyperparameters']:\n",
    "    del config['differentiable_hyperparameters']['block_wise_dropout']\n",
    "config[\"block_wise_dropout\"] = True\n",
    "\n",
    "\n",
    "\n",
    "config['hist_targets'] = False\n",
    "config['y_std'] = 1\n",
    "config['min_depth'] = 5\n",
    "config['max_depth'] = 15\n",
    "config['num_classes'] = 2\n",
    "config[\"max_num_classes\"] = 2\n",
    "\n",
    "\n",
    "config[\"align_majority\"] = False\n",
    "config[\"limit_imbalance\"] = False\n",
    "\n",
    "\n",
    "for noi in [False, True]:\n",
    "    config[\"mlp_noise\"] = noi\n",
    "    \n",
    "    #config['differentiable_hyperparameters']['noise_std'] = {'distribution': 'meta_trunc_norm_log_scaled', 'max_mean': al, 'min_mean': 0.00001, 'round': False, 'lower_bound': 0.0}\n",
    "    \n",
    "    \n",
    "    #config[\"epoch_frac\"] = e/maxepo\n",
    "    config_sample = evaluate_hypers(config)\n",
    "    model = get_model(config_sample, device, should_train=False, verbose=0)\n",
    "    dl = model[3]\n",
    "    rocs = []\n",
    "    means = []\n",
    "    for i in range(100):\n",
    "        #print(f\"\\n\\n\\nRun #{i}\")\n",
    "        x, y = get_sample(dl)\n",
    "        x, y = torch.squeeze(x).numpy(), torch.squeeze(y).numpy()\n",
    "        #print(np.unique(y, return_counts=True))\n",
    "        #if len(np.unique(y, return_counts=True)[0])<2: print(\"HERE FUZCKSNDKSHFKHSFG!!!!!!!!!###########################################################################################################################################\\n\\n\")\n",
    "        means.append(np.mean(y))\n",
    "        if len(np.unique(y, return_counts=True)[0])>1 and np.min(np.unique(y, return_counts=True)[1])>1:\n",
    "            #print(\"Target mean: \", torch.mean(y))\n",
    "            #plt.hist(y, bins=100)\n",
    "            #plt.show()\n",
    "            cv = 3\n",
    "            n_optim = 100\n",
    "            ft_epochs = 0\n",
    "            sampling = None\n",
    "            strat_split=True\n",
    "            max_samples = None\n",
    "            metrics = metrics = [\"roc_auc\"]#\"roc_auc_ovr\"]\n",
    "            if config['num_classes'] ==2:\n",
    "                o = 'binary:logistic'\n",
    "            else:\n",
    "                o = 'multi:softmax'\n",
    "            #model = XGBClassifier(n_estimators=10, max_depth=10, learning_rate=1, objective=o)#\n",
    "            #model = XGBoostOptim(n_optim=n_optim)\n",
    "            model = TabPFNClassifier(device='cpu', N_ensemble_configurations=3)\n",
    "            results = cross_validate_sample(model, x, y, metrics, strat_split, cv, sampling, max_samples)\n",
    "            #print(results[0])\n",
    "            rocs.append(results[0])\n",
    "            #print(\"ROC: \", results[0])\n",
    "    print(\"ROC: \", np.mean(np.array(rocs)), np.std(np.array(rocs)))\n",
    "    print(\"Pred avgs: \", np.mean(np.array(means)))\n",
    "    #result_matrix[ii,jj] = np.mean(np.array(rocs))\n",
    "    plt.hist(rocs, bins=20)\n",
    "    plt.show()\n",
    "    bins = np.arange(0,102,3)*1e-2\n",
    "    plt.hist(means, bins=bins)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3668474-a2cf-403d-8bb8-4d76ba6063d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = []\n",
    "means = []\n",
    "for i in range(1000):\n",
    "    #print(f\"\\n\\n\\nRun #{i}\")\n",
    "    x, y = get_sample(dl)\n",
    "    #print(x[0])\n",
    "    #print(np.unique(y, return_counts=True))\n",
    "    x, y = torch.squeeze(x), torch.squeeze(y)\n",
    "    preds = torch.full(y.shape, torch.argmax(torch.unique(y, return_counts=True)[1]).item())\n",
    "    accuracy = torch.mean((preds==y)[y!=-100].float())\n",
    "    means.append(max(1-np.mean(y),np.mean(y)))\n",
    "    accs.append(accuracy)\n",
    "print(torch.mean(torch.tensor(accs)))\n",
    "print(torch.mean(torch.tensor(means)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb27a55-0322-4121-a7ba-f3380dfb2a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50,100,1):\n",
    "    print(f\"ROC sub {i*0.01} pred\",  np.mean(np.array(rocs)[np.array(means)<i*0.01]), len(np.array(rocs)[np.array(means)<i*0.01])/len(means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c363a4-132d-4c4b-9fd2-0f99eb63f4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8a0922-d04c-43e6-a2d5-fd3745858bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(means,rocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff1fee4-f743-4630-b62c-4a02b0880158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358a4488-dda9-43b0-890f-ab7ccd92a306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multinomial_dirichlet(size=(1000,100)):\n",
    "    M = 1000\n",
    "    alphas = np.random.beta(1,1,size[1])\n",
    "    thetas = [np.random.dirichlet(alphas) for i in range(size[0])]\n",
    "    #print(thetas, np.sum(thetas))\n",
    "    X = np.asarray([np.random.multinomial(M, theta)/M for theta in thetas])\n",
    "    return X\n",
    "X = multinomial_dirichlet()\n",
    "print(X[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc87ccf7-5976-483f-9eb4-41036e9d97c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f721f19-7023-4436-b374-886651722f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def get_sample(config_sample, prior_hyperparameters):\n",
    "    def eval_pos_seq_len_sampler():\n",
    "        single_eval_pos_gen = get_uniform_single_eval_pos_sampler(config.get('max_eval_pos', config['bptt']), min_len=config.get('min_eval_pos', 0))\n",
    "        single_eval_pos = single_eval_pos_gen()\n",
    "        return single_eval_pos, 1024\n",
    "    ''extra_prior_kwargs_dict={\n",
    "        'num_features': config['num_features'], \n",
    "        'hyperparameters': prior_hyperparameters\n",
    "    }\n",
    "    extra_kwargs = {}\n",
    "    if 'flexible' in config and config['flexible']:\n",
    "        get_batch_base = make_get_batch(model_proto)\n",
    "        extra_kwargs['get_batch'] = get_batch_base\n",
    "        model_proto = priors.flexible_categorical\n",
    "    if 'differentiable' in prior_hyperparameters and prior_hyperparameters['differentiable']:\n",
    "        get_batch_base = make_get_batch(model_proto, **extra_kwargs)\n",
    "        extra_kwargs = {'get_batch': get_batch_base, 'differentiable_hyperparameters': prior_hyperparameters['differentiable_hyperparameters']}\n",
    "        model_proto = priors.differentiable_prior\n",
    "        use_style = True\n",
    "    \n",
    "    dl = model_proto.DataLoader(num_steps=1, batch_size=1, \n",
    "                                eval_pos_seq_len_sampler=eval_pos_seq_len_sampler, \n",
    "                                seq_len_maximum=None, device=\"cpu\", **extra_prior_kwargs_dict)''\n",
    "    dl_class, extra_kwargs = get_dataloader(config_sample, device=\"cpu\", should_train=False, verbose=2)\n",
    "    dl = model_proto.DataLoader(num_steps=1, batch_size=1, \n",
    "                                eval_pos_seq_len_sampler=eval_pos_seq_len_sampler, \n",
    "                                seq_len_maximum=None, device=\"cpu\", **extra_kwargs)\n",
    "    dl.model = None\n",
    "    return next(iter(dl))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a955c12a-56e9-4895-a9af-07226073cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_sample(config_sample, prior_hyperparameters)\n",
    "print(a[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c161bd-ec80-43ac-b3a9-21011eec1d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['differentiable'] = False\n",
    "config['flexible'] = False\n",
    "\n",
    "# forest params\n",
    "config[\"min_features\"] = 10\n",
    "config[\"max_features\"] = 100\n",
    "config[\"n_samples\"] = 1000\n",
    "config[\"max_classes\"] = 10\n",
    "config[\"base_size\"] = 1000\n",
    "config[\"n_estimators\"] = 1\n",
    "config[\"min_depth\"] = 1\n",
    "config[\"max_depth\"] = 25\n",
    "config[\"categorical_x\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af348aba-7927-4722-829b-2b9067bec073",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "from tabpfn import TabPFNClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from evaluate import scores\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, precision_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from data_prep_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import openml\n",
    "from tabularbench.data.synthetic_generator_forest import synthetic_dataset_generator_forest, synthetic_dataset_function_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5561d98a-122c-46a3-b816-198a5c986552",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabularbench.data.synthetic_generator_tabpfn import synthetic_dataset_generator_tabpfn\n",
    "\n",
    "fig, axes = plt.subplots(8, 6, figsize=(20, 15))\n",
    "generator = synthetic_dataset_generator_tabpfn(n_samples=1000, max_classes=2, min_features=2, max_features=100)\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    x2, b = next(generator)\n",
    "    i1, i2 = np.random.choice(x2.shape[1], size=(2,), replace=False)\n",
    "    ax.scatter(x2[:, i1], x2[:, i2], c=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2a893a-7167-4aa4-a2df-513182935798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabularbench.data.synthetic_generator_forest import synthetic_dataset_generator_forest, synthetic_dataset_function_forest\n",
    "import matplotlib\n",
    "\n",
    "fig, axes = plt.subplots(8, 6, figsize=(20, 15))\n",
    "generator = synthetic_dataset_generator_forest(n_samples=1000, max_classes=2, min_features=2, max_features=2)\n",
    "\n",
    "cmap = matplotlib.colormaps['inferno']\n",
    "colors = cmap(np.linspace(0.0, 0.9, 10))\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    x2, b = synthetic_dataset_function_forest(base_size=1000, min_features=2, max_features=2, max_classes=3, min_depth=1, max_depth=25, categorical_x=True, n_samples=1024)\n",
    "    i1, i2 = np.random.choice(x2.shape[1], size=(2,), replace=False)\n",
    "    random_shuffle = np.random.permutation(np.arange(10))\n",
    "    colors_shuffle = colors[random_shuffle]\n",
    "    #b = np.array([colors_shuffle[i] for i in b])\n",
    "    ax.scatter(x2[:, i1], x2[:, i2], c=b)\n",
    "    ax.tick_params(axis='both', which='both', bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be43c36-ca72-4cb4-9cd4-72a59b27d90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zinb(size=(1000,100)):\n",
    "    pi = 0.25\n",
    "    p = np.random.uniform(0.1,0.9, size=size[1])\n",
    "    p = np.repeat(np.expand_dims(p,axis=0),size[0],axis=0)\n",
    "    #print\n",
    "    #p += 1e-5\n",
    "    X = np.random.negative_binomial(100,p)\n",
    "    X = np.random.binomial(1,1-pi,size)*X\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08769738-e744-49cc-98c2-206e3bb9d5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zinb_comp(size=(1000,100)):\n",
    "    X =  zinb(size)\n",
    "    print(X)\n",
    "    print(np.expand_dims(1/np.sum(X,axis=1),axis=1))\n",
    "    return np.expand_dims(1/np.sum(X,axis=1),axis=1)*X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada8a9e9-6a99-4d92-b869-ae69bdc53cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = zinb_comp((10,10))\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ed9025-1fb0-4732-b3b7-ee311b528e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(out, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c62c558-446d-42bf-a2a3-39ed3b4a9c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prior.synthetic_generator_forest_altdata import synthetic_dataset_generator_forest_altdata, synthetic_dataset_function_forest_altdata\n",
    "\n",
    "fig, axes = plt.subplots(8, 6, figsize=(20, 15))\n",
    "\n",
    "cmap = matplotlib.colormaps['inferno']\n",
    "colors = cmap(np.linspace(0.0, 0.9, 10))\n",
    "\n",
    "\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    x2, b = synthetic_dataset_function_forest_altdata(zinb,base_size=1000, min_features=2, max_features=2, max_classes=3, min_depth=1, max_depth=25, categorical_x=True, n_samples=1024)\n",
    "    i1, i2 = np.random.choice(x2.shape[1], size=(2,), replace=False)\n",
    "    random_shuffle = np.random.permutation(np.arange(10))\n",
    "    colors_shuffle = colors[random_shuffle]\n",
    "    #b = np.array([colors_shuffle[i] for i in b])\n",
    "    ax.scatter(x2[:, i1], x2[:, i2], c=b)\n",
    "    ax.tick_params(axis='both', which='both', bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b35c21-16e3-44e8-80df-dd5de8fc536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_norm, b_norm = synthetic_dataset_function_forest(base_size=1000, min_features=2, max_features=2, max_classes=3, min_depth=1, max_depth=25, categorical_x=True, n_samples=1024)\n",
    "\n",
    "X_zinb, b_zinb = synthetic_dataset_function_forest_altdata(zinb,base_size=1000, min_features=2, max_features=2, max_classes=3, min_depth=1, max_depth=25, categorical_x=True, n_samples=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68200361-d086-41a0-8af3-ad83c009298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, roc_auc_score\n",
    "accuracy = np.zeros((3))\n",
    "runs = 10\n",
    "for ii in range(runs):\n",
    "    X_norm, b_norm = synthetic_dataset_function_forest(base_size=1000, min_features=2, max_features=2, max_classes=3, min_depth=1, max_depth=25, categorical_x=True, n_samples=1024)\n",
    "    models = [XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic'), \n",
    "              LogisticRegression(max_iter=500), \n",
    "              TabPFNClassifier(device='cpu', N_ensemble_configurations=3)]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_norm, b_norm, test_size=0.2, random_state=42)\n",
    "    for mm, model in enumerate(models):\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy[mm] += accuracy_score(y_test,y_pred)\n",
    "print(accuracy/runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248ed978-b1b6-46ee-9233-e91434632ae2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, roc_auc_score\n",
    "accuracy = np.zeros((3))\n",
    "runs = 10\n",
    "for ii in range(runs):\n",
    "    print(ii)\n",
    "    X_zinb, b_zinb = synthetic_dataset_function_forest_altdata(zinb,base_size=1000, min_features=2, max_features=2, max_classes=3, min_depth=1, max_depth=25, categorical_x=True, n_samples=1024)\n",
    "    models = [XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic'), \n",
    "              LogisticRegression(max_iter=500), \n",
    "              TabPFNClassifier(device='cpu', N_ensemble_configurations=3)]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_zinb, b_zinb, test_size=0.2, random_state=42)\n",
    "    for mm, model in enumerate(models):\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy[mm] += accuracy_score(y_test,y_pred)\n",
    "print(accuracy/runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa159333-33a1-4941-9ea3-31ab11dfcca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e818c922-3e6d-4443-884a-9fb01aa1db39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
