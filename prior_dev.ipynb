{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "806ff5d9-0f3a-4fa1-a089-db69fbe1c925",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "from tabpfn_new.scripts.transformer_prediction_interface import TabPFNClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from data_prep_utils import *\n",
    "from evaluate import *\n",
    "from load_models import *\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import openml\n",
    "from data_prep_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from tabpfn_new import priors, encoders\n",
    "from tabpfn_new.scripts.model_configs import *\n",
    "from tabpfn_new.scripts.model_builder import get_forest_prior_hyperparameters, get_mlp_prior_hyperparameters, get_model\n",
    "from tabpfn.utils import get_uniform_single_eval_pos_sampler\n",
    "from utils import get_dataloader\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99725f1b-38b4-4188-ba15-49b041341222",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reload_config(prior_type='forest', config_type='causal', task_type='binary', longer=0):\n",
    "    config = get_prior_config(config_type=config_type)\n",
    "    \n",
    "    config['prior_type'] = prior_type\n",
    "    \n",
    "    model_string = ''\n",
    "    \n",
    "    config['epochs'] = 12000\n",
    "    config['recompute_attn'] = True\n",
    "\n",
    "    config['max_num_classes'] = 10\n",
    "    config['num_classes'] = uniform_int_sampler_f(2, config['max_num_classes'])\n",
    "    config['balanced'] = False\n",
    "    model_string = model_string + '_multiclass'\n",
    "    \n",
    "    model_string = model_string + '_'+datetime.now().strftime(\"%m_%d_%Y_%H_%M_%S\")\n",
    "    \n",
    "    return config, model_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ef61611-5810-4471-93f9-82b1f6958f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dl_from_config(config_sample, prior_hyperparameters):\n",
    "    def eval_pos_seq_len_sampler():\n",
    "        single_eval_pos_gen = get_uniform_single_eval_pos_sampler(config.get('max_eval_pos', config['bptt']), min_len=config.get('min_eval_pos', 0))\n",
    "        single_eval_pos = single_eval_pos_gen()\n",
    "        return single_eval_pos, 1024\n",
    "    dl_class, extra_kwargs = get_dataloader(config_sample, device=\"cpu\", should_train=False, verbose=0)\n",
    "    dl = dl_class(num_steps=1, batch_size=1, \n",
    "                                eval_pos_seq_len_sampler=eval_pos_seq_len_sampler, \n",
    "                                seq_len_maximum=None, device=\"cpu\", **extra_kwargs)\n",
    "    dl.model = None\n",
    "    return dl\n",
    "\n",
    "                                     \n",
    "def get_sample(dl):\n",
    "    (style, x, y), _, _ =  next(iter(dl))\n",
    "    return x, y\n",
    "    \n",
    "def plot_grid(dl, hyperparameters, rows=8, cols=6):\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(20,15))\n",
    "    class_assigner = priors.flexible_categorical.BalancedBinarize()#priors.flexible_categorical.MulticlassRank(hyperparameters['num_classes'], ordered_p=hyperparameters['output_multiclass_ordered_p'])\n",
    "    for ax in axes.flatten():\n",
    "        x2, b = get_sample(dl)\n",
    "        #b = class_assigner(b)\n",
    "        i1, i2 = np.random.choice(x2.shape[2], size=(2,), replace=False)\n",
    "        ax.scatter(x2[:, 0, i1], x2[:, 0, i2], c=b, s=1.5, cmap=\"bwr\")\n",
    "\n",
    "def remove_zero_features(x):\n",
    "    x = x[:,:,torch.where(torch.sum(torch.abs(x), dim=0)>0,1,0)]\n",
    "    return x\n",
    "\n",
    "def plot_feature_combinations(dl, hyperparameters, num_plots=10):\n",
    "    fig = plt.figure(figsize=(20,15))\n",
    "    x2, b = get_sample(dl)\n",
    "    #x2 = remove_zero_features(x2)\n",
    "    #class_assigner = priors.flexible_categorical.BalancedBinarize()#MulticlassRank(hyperparameters['num_classes'], ordered_p=hyperparameters['output_multiclass_ordered_p'])\n",
    "    #b = class_assigner(b)\n",
    "    n_feat = num_plots#hyperparameters[\"max_features\"]\n",
    "    for i in range(n_feat-1):\n",
    "        for j in range(n_feat):\n",
    "            if(j>i) :\n",
    "                ax = plt.subplot2grid((n_feat-1, n_feat-1), (i,j-1))\n",
    "                #ax.xaxis.set_ticklabels([]) \n",
    "                #ax.yaxis.set_ticklabels([])\n",
    "                plt.scatter(x2[:,0,i],x2[:,0,j],c=b, s=1.5, cmap=\"bwr\")\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f7f010d-ebbf-4cf7-ba58-8f98ecb7e01b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prior_type = 'mlp'\n",
    "config, model_string = reload_config(prior_type, longer=1)\n",
    "\n",
    "config['differentiable'] = True\n",
    "config['flexible'] = True\n",
    "config['bptt_extra_samples'] = None\n",
    "\n",
    "# diff\n",
    "config['output_multiclass_ordered_p'] = 0.0\n",
    "del config['differentiable_hyperparameters']['output_multiclass_ordered_p']\n",
    "\n",
    "\n",
    "\n",
    "config['sampling'] = 'normal' # vielleicht schlecht?\n",
    "del config['differentiable_hyperparameters']['sampling']\n",
    "\n",
    "config['pre_sample_causes'] = True\n",
    "# end diff\n",
    "\n",
    "config['multiclass_loss_type'] = 'nono' # 'compatible'\n",
    "config['normalize_to_ranking'] = False # False\n",
    "\n",
    "config['categorical_feature_p'] = 0 # diff: .0\n",
    "\n",
    "# turn this back on in a random search!?\n",
    "config['nan_prob_no_reason'] = .0\n",
    "config['nan_prob_unknown_reason'] = .0 # diff: .0\n",
    "config['set_value_to_nan'] = .0 # diff: 1.\n",
    "\n",
    "config['normalize_with_sqrt'] = False\n",
    "\n",
    "config['new_mlp_per_example'] = True\n",
    "config['prior_mlp_scale_weights_sqrt'] = True\n",
    "config['batch_size_per_gp_sample'] = None\n",
    "\n",
    "config['normalize_ignore_label_too'] = False\n",
    "\n",
    "config['differentiable_hps_as_style'] = False\n",
    "config['max_eval_pos'] = 1000\n",
    "\n",
    "config['random_feature_rotation'] = True\n",
    "config['rotate_normalized_labels'] = True\n",
    "\n",
    "config[\"mix_activations\"] = True # False heisst eig True\n",
    "\n",
    "config['n_layers'] = 4\n",
    "config['emsize'] = 128\n",
    "config['nhead'] = config['emsize'] // 32\n",
    "config['bptt'] = 1024+128\n",
    "config['canonical_y_encoder'] = True\n",
    "\n",
    "    \n",
    "config['aggregate_k_gradients'] = 1\n",
    "config['batch_size'] = 1*config['aggregate_k_gradients']\n",
    "config['num_steps'] = 1//config['aggregate_k_gradients']\n",
    "config['epochs'] = 1\n",
    "\n",
    "config['total_available_time_in_s'] = None #60*60*22 # 22 hours for some safety...\n",
    "\n",
    "config['train_mixed_precision'] = True\n",
    "config['efficient_eval_masking'] = True\n",
    "\n",
    "# mlp params\n",
    "config['is_causal'] = True\n",
    "config['num_causes'] = 5\n",
    "config['prior_mlp_hidden_dim'] = 50\n",
    "config['num_layers'] = 4\n",
    "config['noise_std'] = 0.05\n",
    "config['init_std'] = 0.05\n",
    "config['y_is_effect'] = True\n",
    "config['pre_sample_weights'] = True\n",
    "config['prior_mlp_dropout_prob'] = 0\n",
    "config['pre_sample_causes'] = True\n",
    "config[\"prior_mlp_activations\"] = torch.nn.ReLU()\n",
    "config[\"block_wise_dropout\"] = True\n",
    "config[\"sort_features\"] = False\n",
    "config[\"in_clique\"] = False\n",
    "\n",
    "# general data params\n",
    "config['balanced'] = True\n",
    "config['max_num_classes'] = 2\n",
    "config['max_features'] = 100\n",
    "config['num_features_used'] = 100\n",
    "\n",
    "config['num_classes'] = 2\n",
    "\n",
    "config['no_encoder'] = False\n",
    "config['normalize_to_ranking'] = False # False\n",
    "config['normalize_with_sqrt'] = False\n",
    "config['normalize_ignore_label_too'] = False\n",
    "config[\"normalize\"] = False\n",
    "config['num_classes'] = 2\n",
    "config[\"balanced\"] = False\n",
    "config['multiclass_type'] = 'imbalanced_binarize'\n",
    "\n",
    "\n",
    "config_sample = evaluate_hypers(config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30030035-1632-47a4-9d32-a560361a8dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dl = dl_from_config(config_sample, prior_hyperparameters)\n",
    "model = get_model(config_sample, device, should_train=False, verbose=0)\n",
    "dl = model[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8825b69a-4d14-4e8f-95ba-1128f5486b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid(dl,config_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb563131-d329-4157-bb05-31fa6a6f0e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_combinations(dl,config_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b700a2b-c26b-44cc-8530-8d1f7650c97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "class MicroDL(DataLoader):\n",
    "    def __init__(self, path=None):\n",
    "        data, labels = get_microbiome(path)\n",
    "        data = top_non_zero(data)\n",
    "        data, labels = unison_shuffled_copies(data, labels)\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return 100\n",
    "        \n",
    "    def get_perm(self):\n",
    "        indices = np.random.permutation(self.data.shape[0])[:1000]\n",
    "        return (None, np.expand_dims(self.data[indices], axis=1), np.expand_dims(self.labels[indices],axis=1)), None, None\n",
    "        \n",
    "    def __iter__(self):\n",
    "        indices = np.random.permutation(self.data.shape[0])[:1000]\n",
    "        return iter(self.get_perm() for _ in range(100))\n",
    "path = \"datasets/data_all.csv\"\n",
    "dl = MicroDL(path)\n",
    "#plot_grid(dl, config_sample)\n",
    "plot_feature_combinations(dl, config_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47342e30-ae92-451b-824d-6db9a19ea2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['differentiable'] = True\n",
    "config['flexible'] = True\n",
    "\n",
    "# forest params\n",
    "config[\"min_features\"] = 100\n",
    "config[\"max_features\"] = 100\n",
    "config[\"n_samples\"] = 1000\n",
    "config[\"max_classes\"] = 2\n",
    "config[\"base_size\"] = 1000\n",
    "config[\"n_estimators\"] = 1\n",
    "config[\"min_depth\"] = 3\n",
    "config[\"max_depth\"] = 15\n",
    "config[\"categorical_x\"] = False\n",
    "config[\"data_sample_func\"] = \"zinb\"\n",
    "config[\"comp\"] = True\n",
    "\n",
    "config['multiclass_type'] = 'balance'\n",
    "del config['differentiable_hyperparameters']['multiclass_type']\n",
    "\n",
    "config[\"prior_type\"] = \"forest\"\n",
    "config[\"microbiome_test\"] = True\n",
    "config[\"weight_classes\"] = False\n",
    "config[\"run_name\"] = \"time\"\n",
    "\n",
    "config[\"prior_type\"] = \"forest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc90518-93eb-4479-980f-3ee7f749c365",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_sample = evaluate_hypers(config)\n",
    "model = get_model(config_sample, device, should_train=False, verbose=0)\n",
    "dl = model[3]\n",
    "plot_grid(dl, config_sample)\n",
    "plot_feature_combinations(dl, config_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540f17f5-7cc3-4fc7-a60c-cfb409cb3513",
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"data_sample_func\"] = \"mnd\"\n",
    "\n",
    "\n",
    "config_sample = evaluate_hypers(config)\n",
    "model = get_model(config_sample, device, should_train=False, verbose=0)\n",
    "dl = model[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4e1075-d1c8-443b-85e6-05216d0367da",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid(dl, config_sample)\n",
    "plot_feature_combinations(dl, config_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b2ca11-0225-4a0d-9c95-796d9eb3ee8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabpfn import TabPFNClassifier\n",
    "model = TabPFNClassifier(device='cpu', N_ensemble_configurations=1)\n",
    "x, y = get_sample(dl)\n",
    "x, y = torch.squeeze(x), torch.squeeze(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, train_size=0.8, test_size=0.2, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "print(torch.tensor(preds)*y_test+(torch.tensor(preds)-1)*(y_test-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd56e91-d6c5-4163-bf92-a797bb3a8977",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['differentiable'] = True\n",
    "config['flexible'] = True\n",
    "config[\"prior_type\"] = \"forest\"\n",
    "config[\"sampling\"] = \"mnd\"\n",
    "#del config['differentiable_hyperparameters']['sampling']\n",
    "config[\"data_sample_func\"] = \"mnd\"\n",
    "config[\"is_causal\"] = False\n",
    "#del config['differentiable_hyperparameters']['is_causal']\n",
    "config['multiclass_type'] = 'balance'\n",
    "config['hist_targets'] = False\n",
    "\n",
    "config[\"align_majority\"] = False\n",
    "config[\"limit_imbalance\"] = False\n",
    "\n",
    "config[\"normalize\"] = True\n",
    "config[\"num_classes\"] = 2\n",
    "config[\"max_num_classes\"] = 2\n",
    "\n",
    "config['min_depth'] = 5\n",
    "config['max_depth'] = 15\n",
    "#del config['differentiable_hyperparameters']['multiclass_type']\n",
    "\n",
    "config_sample = evaluate_hypers(config)\n",
    "model = get_model(config_sample, device, should_train=False, verbose=0)\n",
    "dl = model[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae188bf-91f0-42c2-91b5-96714476a333",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    print(f\"\\n\\n\\nRun #{i}\")\n",
    "    x, y = get_sample(dl)\n",
    "    x, y = torch.squeeze(x), torch.squeeze(y)\n",
    "    print(\"Target mean: \", torch.mean(y))\n",
    "    if len(np.unique(y, return_counts=True)[0])>1 and np.min(np.unique(y, return_counts=True)[1])>20:\n",
    "        #plt.hist(y, bins=100)\n",
    "        #plt.show()\n",
    "        cv = 3\n",
    "        n_optim = 20\n",
    "        ft_epochs = 0\n",
    "        sampling = None\n",
    "        strat_split=True\n",
    "        max_samples = 1000\n",
    "        metrics = metrics = [\"accuracy\", \"precision\", \"recall\", \"roc_auc\"]\n",
    "        models = [\n",
    "            #XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic'),\n",
    "            XGBoostOptim(n_optim=n_optim),\n",
    "            #LogisticRegression(max_iter=500), \n",
    "            #TabPFNClassifier(device='cpu', N_ensemble_configurations=3),\n",
    "            #TabForestPFNClassifier(\"saved_models/tabforest/mix600k/tabforestpfn.pt\", \"saved_models/tabforest/mix600k/config_run.yaml\")\n",
    "        ]\n",
    "        results = pd.DataFrame(np.zeros((len(models), len(metrics))), \n",
    "                               index=[m.__class__.__name__ for m in models],\n",
    "                              columns=metrics)\n",
    "        \n",
    "        for ii, model in enumerate(models):\n",
    "            results.iloc[ii,:] = cross_validate_sample(model, x, y, metrics, strat_split, cv, sampling)\n",
    "        print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b15a5d3-46cc-439c-a324-577e5dda3ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "Using cpu:0 device\n",
      "Using a Transformer with 1.64 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC:  0.7595833333333334 0.1606144369965561\n",
      "Pred avgs:  0.5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAiG0lEQVR4nO3dfVCVdf7/8dcR5WANYCVyUxRq3qZi0cpitmqyITmu2q4Za0GmNtPiTMV0I5X3fsPdJrVdSWtHpMYKc3OxCYcyWnQdNFeN2XQ3VxBFVw6FmyA0ggvX74/fdHbPCtTRc3E+HJ+PmWumc12f6/J9rsXlOYeDx2FZliUAAACD9fD3AAAAAN+HYAEAAMYjWAAAgPEIFgAAYDyCBQAAGI9gAQAAxiNYAACA8QgWAABgvJ7+HsAX2tradObMGYWGhsrhcPh7HAAA8ANYlqXz588rJiZGPXp0/hpKQATLmTNnFBsb6+8xAADAZTh16pRuuummTtcERLCEhoZK+v9POCwszM/TAACAH6KhoUGxsbHu7+OdCYhg+e7HQGFhYQQLAADdzA95OwdvugUAAMYjWAAAgPEIFgAAYDyCBQAAGI9gAQAAxiNYAACA8QgWAABgPIIFAAAYj2ABAADGI1gAAIDxCBYAAGA8ggUAABiPYAEAAMYjWAAAgPF6+nsAAADgG3ELi2y79olVU2y79g/BKywAAMB4BAsAADAewQIAAIxHsAAAAOMRLAAAwHheB8vu3bs1depUxcTEyOFwqLCw0OO4w+Fod3v55Zc7vObSpUsvWT906FCvnwwAAAhMXgdLU1OT4uPjlZub2+7xmpoajy0vL08Oh0M///nPO73ubbfd5nHenj17vB0NAAAEKK//HZbU1FSlpqZ2eDwqKsrj8fbt2zVx4kQNGDCg80F69rzkXAAAAMnm97DU1taqqKhIc+fO/d61x44dU0xMjAYMGKDZs2erurq6w7XNzc1qaGjw2AAAQOCyNVjefPNNhYaG6v777+90XWJiovLz81VcXKz169erqqpKd999t86fP9/u+pycHIWHh7u32NhYO8YHAACGsDVY8vLyNHv2bIWEhHS6LjU1VTNnztSoUaOUkpKiHTt26Ny5c3rvvffaXZ+dna36+nr3durUKTvGBwAAhrDts4T+/Oc/6+jRo9qyZYvX5/bp00eDBw9WRUVFu8edTqecTueVjggAALoJ215h2bhxoxISEhQfH+/1uY2NjaqsrFR0dLQNkwEAgO7G62BpbGxUeXm5ysvLJUlVVVUqLy/3eJNsQ0ODtm7dqnnz5rV7jUmTJmndunXux08//bR27dqlEydOqKysTDNmzFBQUJDS0tK8HQ8AAAQgr38kdODAAU2cONH9OCsrS5KUkZGh/Px8SVJBQYEsy+owOCorK1VXV+d+fPr0aaWlpens2bOKiIjQuHHjtG/fPkVERHg7HgAACEAOy7Isfw9xpRoaGhQeHq76+nqFhYX5exwAAPwibmGRbdc+sWqKz6/pzfdvPksIAAAYj2ABAADGI1gAAIDxCBYAAGA8ggUAABiPYAEAAMYjWAAAgPEIFgAAYDyCBQAAGI9gAQAAxiNYAACA8QgWAABgPIIFAAAYj2ABAADGI1gAAIDxCBYAAGA8ggUAABiPYAEAAMYjWAAAgPEIFgAAYDyCBQAAGI9gAQAAxiNYAACA8QgWAABgPIIFAAAYj2ABAADGI1gAAIDxCBYAAGA8ggUAABiPYAEAAMYjWAAAgPEIFgAAYDyCBQAAGI9gAQAAxiNYAACA8QgWAABgPIIFAAAYj2ABAADG8zpYdu/eralTpyomJkYOh0OFhYUexx955BE5HA6PbfLkyd973dzcXMXFxSkkJESJiYnav3+/t6MBAIAA5XWwNDU1KT4+Xrm5uR2umTx5smpqatzbu+++2+k1t2zZoqysLC1ZskSHDh1SfHy8UlJS9NVXX3k7HgAACEA9vT0hNTVVqampna5xOp2Kior6wddcvXq15s+frzlz5kiSNmzYoKKiIuXl5WnhwoXejggAAAKMLe9hKS0tVb9+/TRkyBA9/vjjOnv2bIdrW1padPDgQSUnJ/9nqB49lJycrL1797Z7TnNzsxoaGjw2AAAQuHweLJMnT9Zbb72lkpIS/frXv9auXbuUmpqq1tbWdtfX1dWptbVVkZGRHvsjIyPlcrnaPScnJ0fh4eHuLTY21tdPAwAAGMTrHwl9nwcffND93yNHjtSoUaM0cOBAlZaWatKkST75M7Kzs5WVleV+3NDQQLQAABDAbP+15gEDBqhv376qqKho93jfvn0VFBSk2tpaj/21tbUdvg/G6XQqLCzMYwMAAIHL9mA5ffq0zp49q+jo6HaPBwcHKyEhQSUlJe59bW1tKikpUVJSkt3jAQCAbsDrYGlsbFR5ebnKy8slSVVVVSovL1d1dbUaGxv1zDPPaN++fTpx4oRKSko0bdo03XrrrUpJSXFfY9KkSVq3bp37cVZWln7/+9/rzTff1N///nc9/vjjampqcv/WEAAAuLp5/R6WAwcOaOLEie7H372XJCMjQ+vXr9df//pXvfnmmzp37pxiYmJ07733asWKFXI6ne5zKisrVVdX5348a9Ysff3111q8eLFcLpdGjx6t4uLiS96ICwAArk4Oy7Isfw9xpRoaGhQeHq76+nrezwIAuGrFLSyy7donVk3x+TW9+f7NZwkBAADjESwAAMB4BAsAADAewQIAAIxHsAAAAOMRLAAAwHgECwAAMB7BAgAAjEewAAAA4xEsAADAeAQLAAAwHsECAACMR7AAAADjESwAAMB4BAsAADAewQIAAIxHsAAAAOMRLAAAwHgECwAAMB7BAgAAjEewAAAA4xEsAADAeAQLAAAwHsECAACMR7AAAADjESwAAMB4BAsAADAewQIAAIxHsAAAAOMRLAAAwHgECwAAMB7BAgAAjEewAAAA4xEsAADAeAQLAAAwHsECAACMR7AAAADjESwAAMB4XgfL7t27NXXqVMXExMjhcKiwsNB97OLFi3ruuec0cuRIXXvttYqJiVF6errOnDnT6TWXLl0qh8PhsQ0dOtTrJwMAAAKT18HS1NSk+Ph45ebmXnLs22+/1aFDh7Ro0SIdOnRI27Zt09GjR/Wzn/3se6972223qaamxr3t2bPH29EAAECA6untCampqUpNTW33WHh4uHbu3Omxb926dRozZoyqq6t18803dzxIz56KiorydhwAAHAVsP09LPX19XI4HOrTp0+n644dO6aYmBgNGDBAs2fPVnV1dYdrm5ub1dDQ4LEBAIDAZWuwXLhwQc8995zS0tIUFhbW4brExETl5+eruLhY69evV1VVle6++26dP3++3fU5OTkKDw93b7GxsXY9BQAAYADbguXixYt64IEHZFmW1q9f3+na1NRUzZw5U6NGjVJKSop27Nihc+fO6b333mt3fXZ2turr693bqVOn7HgKAADAEF6/h+WH+C5WTp48qU8//bTTV1fa06dPHw0ePFgVFRXtHnc6nXI6nb4YFQAAdAM+f4Xlu1g5duyYPvnkE91www1eX6OxsVGVlZWKjo729XgAAKAb8jpYGhsbVV5ervLycklSVVWVysvLVV1drYsXL+oXv/iFDhw4oLffflutra1yuVxyuVxqaWlxX2PSpElat26d+/HTTz+tXbt26cSJEyorK9OMGTMUFBSktLS0K3+GAACg2/P6R0IHDhzQxIkT3Y+zsrIkSRkZGVq6dKk++OADSdLo0aM9zvvTn/6kCRMmSJIqKytVV1fnPnb69GmlpaXp7NmzioiI0Lhx47Rv3z5FRER4Ox4AAAhAXgfLhAkTZFlWh8c7O/adEydOeDwuKCjwdgwAAHAV4bOEAACA8QgWAABgPIIFAAAYz5Z/hwU/XNzCIluue2LVFFuuCwCAP/AKCwAAMB7BAgAAjEewAAAA4xEsAADAeAQLAAAwHsECAACMR7AAAADjESwAAMB4BAsAADAewQIAAIxHsAAAAOMRLAAAwHgECwAAMB7BAgAAjEewAAAA4xEsAADAeAQLAAAwHsECAACM19PfAwAAcLWJW1jk7xG6HV5hAQAAxiNYAACA8QgWAABgPIIFAAAYj2ABAADGI1gAAIDxCBYAAGA8ggUAABiPYAEAAMYjWAAAgPEIFgAAYDyCBQAAGI9gAQAAxiNYAACA8QgWAABgPK+DZffu3Zo6dapiYmLkcDhUWFjocdyyLC1evFjR0dHq3bu3kpOTdezYse+9bm5uruLi4hQSEqLExETt37/f29EAAECA8jpYmpqaFB8fr9zc3HaP/+Y3v9Fvf/tbbdiwQZ999pmuvfZapaSk6MKFCx1ec8uWLcrKytKSJUt06NAhxcfHKyUlRV999ZW34wEAgADkdbCkpqZq5cqVmjFjxiXHLMvS2rVr9eKLL2ratGkaNWqU3nrrLZ05c+aSV2L+2+rVqzV//nzNmTNHw4cP14YNG3TNNdcoLy/P2/EAAEAA8ul7WKqqquRyuZScnOzeFx4ersTERO3du7fdc1paWnTw4EGPc3r06KHk5OQOz2lublZDQ4PHBgAAApdPg8XlckmSIiMjPfZHRka6j/2vuro6tba2enVOTk6OwsPD3VtsbKwPpgcAAKbqlr8llJ2drfr6evd26tQpf48EAABs5NNgiYqKkiTV1tZ67K+trXUf+199+/ZVUFCQV+c4nU6FhYV5bAAAIHD5NFj69++vqKgolZSUuPc1NDTos88+U1JSUrvnBAcHKyEhweOctrY2lZSUdHgOAAC4uvT09oTGxkZVVFS4H1dVVam8vFzXX3+9br75Zj355JNauXKlBg0apP79+2vRokWKiYnR9OnT3edMmjRJM2bM0IIFCyRJWVlZysjI0J133qkxY8Zo7dq1ampq0pw5c678GQIAgG7P62A5cOCAJk6c6H6clZUlScrIyFB+fr6effZZNTU16bHHHtO5c+c0btw4FRcXKyQkxH1OZWWl6urq3I9nzZqlr7/+WosXL5bL5dLo0aNVXFx8yRtxAQDA1clhWZbl7yGuVENDg8LDw1VfX9/t3s8St7DIluueWDXFlusCAK6cXf/fbyc7vq948/27W/6WEAAAuLoQLAAAwHgECwAAMB7BAgAAjEewAAAA4xEsAADAeAQLAAAwHsECAACMR7AAAADjESwAAMB4BAsAADAewQIAAIxHsAAAAOMRLAAAwHgECwAAMB7BAgAAjEewAAAA4xEsAADAeAQLAAAwHsECAACMR7AAAADjESwAAMB4BAsAADAewQIAAIxHsAAAAOMRLAAAwHgECwAAMB7BAgAAjEewAAAA4xEsAADAeAQLAAAwHsECAACM19PfAwAAvBO3sMi2a59YNcW2a9vFrvvRHe9FIOMVFgAAYDyCBQAAGI9gAQAAxiNYAACA8XweLHFxcXI4HJdsmZmZ7a7Pz8+/ZG1ISIivxwIAAN2Yz39L6C9/+YtaW1vdjw8fPqyf/vSnmjlzZofnhIWF6ejRo+7HDofD12MBAIBuzOfBEhER4fF41apVGjhwoMaPH9/hOQ6HQ1FRUb4eBQAABAhb38PS0tKizZs369FHH+30VZPGxkbdcsstio2N1bRp03TkyBE7xwIAAN2MrcFSWFioc+fO6ZFHHulwzZAhQ5SXl6ft27dr8+bNamtr09ixY3X69OkOz2lublZDQ4PHBgAAApetwbJx40alpqYqJiamwzVJSUlKT0/X6NGjNX78eG3btk0RERF6/fXXOzwnJydH4eHh7i02NtaO8QEAgCFsC5aTJ0/qk08+0bx587w6r1evXrr99ttVUVHR4Zrs7GzV19e7t1OnTl3puAAAwGC2BcumTZvUr18/TZni3WcxtLa26osvvlB0dHSHa5xOp8LCwjw2AAAQuGwJlra2Nm3atEkZGRnq2dPzF5HS09OVnZ3tfrx8+XJ9/PHHOn78uA4dOqSHHnpIJ0+e9PqVGQAAELhs+bTmTz75RNXV1Xr00UcvOVZdXa0ePf7TSd98843mz58vl8ul6667TgkJCSorK9Pw4cPtGA0AAHRDtgTLvffeK8uy2j1WWlrq8XjNmjVas2aNHWMAAIAAwWcJAQAA4xEsAADAeAQLAAAwHsECAACMR7AAAADjESwAAMB4BAsAADAewQIAAIxHsAAAAOMRLAAAwHgECwAAMB7BAgAAjEewAAAA4xEsAADAeAQLAAAwHsECAACMR7AAAADjESwAAMB4BAsAADAewQIAAIxHsAAAAOMRLAAAwHgECwAAMF5Pfw8AAAh8cQuL/D2C17rjzIGMV1gAAIDxCBYAAGA8ggUAABiPYAEAAMYjWAAAgPEIFgAAYDyCBQAAGI9gAQAAxiNYAACA8QgWAABgPIIFAAAYj2ABAADGI1gAAIDxCBYAAGA8nwfL0qVL5XA4PLahQ4d2es7WrVs1dOhQhYSEaOTIkdqxY4evxwIAAN2YLa+w3HbbbaqpqXFve/bs6XBtWVmZ0tLSNHfuXH3++eeaPn26pk+frsOHD9sxGgAA6IZsCZaePXsqKirKvfXt27fDta+++qomT56sZ555RsOGDdOKFSt0xx13aN26dXaMBgAAuiFbguXYsWOKiYnRgAEDNHv2bFVXV3e4du/evUpOTvbYl5KSor1799oxGgAA6IZ6+vqCiYmJys/P15AhQ1RTU6Nly5bp7rvv1uHDhxUaGnrJepfLpcjISI99kZGRcrlcHf4Zzc3Nam5udj9uaGjw3RMAAADG8XmwpKamuv971KhRSkxM1C233KL33ntPc+fO9cmfkZOTo2XLlvnkWj9E3MKiLvuzgO7Mrr8rJ1ZNseW6ALoP23+tuU+fPho8eLAqKiraPR4VFaXa2lqPfbW1tYqKiurwmtnZ2aqvr3dvp06d8unMAADALLYHS2NjoyorKxUdHd3u8aSkJJWUlHjs27lzp5KSkjq8ptPpVFhYmMcGAAACl8+D5emnn9auXbt04sQJlZWVacaMGQoKClJaWpokKT09XdnZ2e71TzzxhIqLi/XKK6/oyy+/1NKlS3XgwAEtWLDA16MBAIBuyufvYTl9+rTS0tJ09uxZRUREaNy4cdq3b58iIiIkSdXV1erR4z+dNHbsWL3zzjt68cUX9fzzz2vQoEEqLCzUiBEjfD0aAADopnweLAUFBZ0eLy0tvWTfzJkzNXPmTF+PAgAAAgSfJQQAAIxHsAAAAOMRLAAAwHgECwAAMB7BAgAAjEewAAAA4xEsAADAeAQLAAAwHsECAACMR7AAAADjESwAAMB4BAsAADAewQIAAIxHsAAAAOMRLAAAwHgECwAAMB7BAgAAjEewAAAA4xEsAADAeAQLAAAwHsECAACMR7AAAADjESwAAMB4BAsAADAewQIAAIxHsAAAAOMRLAAAwHgECwAAMB7BAgAAjEewAAAA4xEsAADAeAQLAAAwHsECAACM19PfA8AecQuLbLv2iVVTbLs27Gfn10Z3xN8VT3x9wFS8wgIAAIxHsAAAAOMRLAAAwHgECwAAMJ7PgyUnJ0c/+tGPFBoaqn79+mn69Ok6evRop+fk5+fL4XB4bCEhIb4eDQAAdFM+D5Zdu3YpMzNT+/bt086dO3Xx4kXde++9ampq6vS8sLAw1dTUuLeTJ0/6ejQAANBN+fzXmouLiz0e5+fnq1+/fjp48KB+8pOfdHiew+FQVFSUr8cBAAABwPb3sNTX10uSrr/++k7XNTY26pZbblFsbKymTZumI0eOdLi2ublZDQ0NHhsAAAhctgZLW1ubnnzySd11110aMWJEh+uGDBmivLw8bd++XZs3b1ZbW5vGjh2r06dPt7s+JydH4eHh7i02NtaupwAAAAxga7BkZmbq8OHDKigo6HRdUlKS0tPTNXr0aI0fP17btm1TRESEXn/99XbXZ2dnq76+3r2dOnXKjvEBAIAhbPun+RcsWKAPP/xQu3fv1k033eTVub169dLtt9+uioqKdo87nU45nU5fjAkAALoBn7/CYlmWFixYoD/+8Y/69NNP1b9/f6+v0draqi+++ELR0dG+Hg8AAHRDPn+FJTMzU++88462b9+u0NBQuVwuSVJ4eLh69+4tSUpPT9eNN96onJwcSdLy5cv14x//WLfeeqvOnTunl19+WSdPntS8efN8PR4AAOiGfB4s69evlyRNmDDBY/+mTZv0yCOPSJKqq6vVo8d/Xtz55ptvNH/+fLlcLl133XVKSEhQWVmZhg8f7uvxAABAN+TzYLEs63vXlJaWejxes2aN1qxZ4+tRAABAgOCzhAAAgPEIFgAAYDyCBQAAGM+2f4cFgStuYZEt1z2xaoot15WYGf7B/4aA7/AKCwAAMB7BAgAAjEewAAAA4xEsAADAeAQLAAAwHsECAACMR7AAAADjESwAAMB4BAsAADAewQIAAIxHsAAAAOMRLAAAwHgECwAAMB7BAgAAjEewAAAA4xEsAADAeAQLAAAwHsECAACMR7AAAADj9fT3AMB34hYW+XsEAICheIUFAAAYj2ABAADGI1gAAIDxCBYAAGA8ggUAABiPYAEAAMYjWAAAgPEIFgAAYDyCBQAAGI9gAQAAxiNYAACA8QgWAABgPIIFAAAYj2ABAADGsy1YcnNzFRcXp5CQECUmJmr//v2drt+6dauGDh2qkJAQjRw5Ujt27LBrNAAA0M3YEixbtmxRVlaWlixZokOHDik+Pl4pKSn66quv2l1fVlamtLQ0zZ07V59//rmmT5+u6dOn6/Dhw3aMBwAAuhlbgmX16tWaP3++5syZo+HDh2vDhg265pprlJeX1+76V199VZMnT9YzzzyjYcOGacWKFbrjjju0bt06O8YDAADdTE9fX7ClpUUHDx5Udna2e1+PHj2UnJysvXv3tnvO3r17lZWV5bEvJSVFhYWF7a5vbm5Wc3Oz+3F9fb0kqaGh4Qqnb19b87e2XBfdn11fcxJfd/+N+wz4nx1/D7+7pmVZ37vW58FSV1en1tZWRUZGeuyPjIzUl19+2e45Lper3fUul6vd9Tk5OVq2bNkl+2NjYy9zauDyhK/19wRXB+4z4H92/j08f/68wsPDO13j82DpCtnZ2R6vyLS1telf//qXbrjhBjkcDj9O5lsNDQ2KjY3VqVOnFBYW5u9xrirce//h3vsX999/rsZ7b1mWzp8/r5iYmO9d6/Ng6du3r4KCglRbW+uxv7a2VlFRUe2eExUV5dV6p9Mpp9Ppsa9Pnz6XP7ThwsLCrpovXtNw7/2He+9f3H//udru/fe9svIdn7/pNjg4WAkJCSopKXHva2trU0lJiZKSkto9JykpyWO9JO3cubPD9QAA4Opiy4+EsrKylJGRoTvvvFNjxozR2rVr1dTUpDlz5kiS0tPTdeONNyonJ0eS9MQTT2j8+PF65ZVXNGXKFBUUFOjAgQN644037BgPAAB0M7YEy6xZs/T1119r8eLFcrlcGj16tIqLi91vrK2urlaPHv95cWfs2LF655139OKLL+r555/XoEGDVFhYqBEjRtgxXrfhdDq1ZMmSS378Bftx7/2He+9f3H//4d53zmH9kN8lAgAA8CM+SwgAABiPYAEAAMYjWAAAgPEIFgAAYDyCxc9yc3MVFxenkJAQJSYmav/+/R2uzc/Pl8Ph8NhCQkK6cNrA4s29l6Rz584pMzNT0dHRcjqdGjx4sHbs2NFF0wYWb+79hAkTLvm6dzgcmjJlShdOHDi8/bpfu3athgwZot69eys2NlZPPfWULly40EXTBh5v7v/Fixe1fPlyDRw4UCEhIYqPj1dxcXEXTmsYC35TUFBgBQcHW3l5edaRI0es+fPnW3369LFqa2vbXb9p0yYrLCzMqqmpcW8ul6uLpw4M3t775uZm684777Tuu+8+a8+ePVZVVZVVWlpqlZeXd/Hk3Z+39/7s2bMeX/OHDx+2goKCrE2bNnXt4AHA23v/9ttvW06n03r77betqqoq66OPPrKio6Otp556qosnDwze3v9nn33WiomJsYqKiqzKykrrtddes0JCQqxDhw518eRmIFj8aMyYMVZmZqb7cWtrqxUTE2Pl5OS0u37Tpk1WeHh4F00X2Ly99+vXr7cGDBhgtbS0dNWIAcvbe/+/1qxZY4WGhlqNjY12jRiwvL33mZmZ1j333OOxLysry7rrrrtsnTNQeXv/o6OjrXXr1nnsu//++63Zs2fbOqep+JGQn7S0tOjgwYNKTk527+vRo4eSk5O1d+/eDs9rbGzULbfcotjYWE2bNk1HjhzpinEDyuXc+w8++EBJSUnKzMxUZGSkRowYoZdeekmtra1dNXZAuNyv+/+2ceNGPfjgg7r22mvtGjMgXc69Hzt2rA4ePOj+scXx48e1Y8cO3XfffV0ycyC5nPvf3Nx8yY/9e/furT179tg6q6kIFj+pq6tTa2ur+1///U5kZKRcLle75wwZMkR5eXnavn27Nm/erLa2No0dO1anT5/uipEDxuXc++PHj+sPf/iDWltbtWPHDi1atEivvPKKVq5c2RUjB4zLuff/bf/+/Tp8+LDmzZtn14gB63Lu/S9/+UstX75c48aNU69evTRw4EBNmDBBzz//fFeMHFAu5/6npKRo9erVOnbsmNra2rRz505t27ZNNTU1XTGycQiWbiQpKUnp6ekaPXq0xo8fr23btikiIkKvv/66v0cLeG1tberXr5/eeOMNJSQkaNasWXrhhRe0YcMGf492Vdm4caNGjhypMWPG+HuUq0Jpaaleeuklvfbaazp06JC2bdumoqIirVixwt+jXRVeffVVDRo0SEOHDlVwcLAWLFigOXPmeHy0zdXEls8Swvfr27evgoKCVFtb67G/trZWUVFRP+gavXr10u23366Kigo7RgxYl3Pvo6Oj1atXLwUFBbn3DRs2TC6XSy0tLQoODrZ15kBxJV/3TU1NKigo0PLly+0cMWBdzr1ftGiRHn74YfcrWiNHjlRTU5Mee+wxvfDCC1ftN87LcTn3PyIiQoWFhbpw4YLOnj2rmJgYLVy4UAMGDOiKkY3DV5ufBAcHKyEhQSUlJe59bW1tKikpUVJS0g+6Rmtrq7744gtFR0fbNWZAupx7f9ddd6miokJtbW3uff/4xz8UHR1NrHjhSr7ut27dqubmZj300EN2jxmQLufef/vtt5dEyXfRbvExdF65kq/9kJAQ3Xjjjfr3v/+t999/X9OmTbN7XDP5+12/V7OCggLL6XRa+fn51t/+9jfrscces/r06eP+VeWHH37YWrhwoXv9smXLrI8++siqrKy0Dh48aD344INWSEiIdeTIEX89hW7L23tfXV1thYaGWgsWLLCOHj1qffjhh1a/fv2slStX+uspdFve3vvvjBs3zpo1a1ZXjxtQvL33S5YssUJDQ613333XOn78uPXxxx9bAwcOtB544AF/PYVuzdv7v2/fPuv999+3Kisrrd27d1v33HOP1b9/f+ubb77x0zPwL4LFz373u99ZN998sxUcHGyNGTPG2rdvn/vY+PHjrYyMDPfjJ5980r02MjLSuu+++67a38f3BW/uvWVZVllZmZWYmGg5nU5rwIAB1v/93/9Z//73v7t46sDg7b3/8ssvLUnWxx9/3MWTBh5v7v3FixetpUuXWgMHDrRCQkKs2NhY61e/+tVV+w3TF7y5/6WlpdawYcMsp9Np3XDDDdbDDz9s/fOf//TD1GZwWBav6wEAALPxHhYAAGA8ggUAABiPYAEAAMYjWAAAgPEIFgAAYDyCBQAAGI9gAQAAxiNYAACA8QgWAABgPIIFAAAYj2ABAADGI1gAAIDx/h/9UsW6KtcQGAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "Using cpu:0 device\n",
      "Using a Transformer with 1.64 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config['differentiable'] = True\n",
    "config['flexible'] = True\n",
    "config[\"prior_type\"] = \"mlp\"\n",
    "config[\"sampling\"] = \"mnd\"\n",
    "#del config['differentiable_hyperparameters']['sampling']\n",
    "config[\"data_sample_func\"] = \"mnd\"\n",
    "\n",
    "config['multiclass_type'] = 'balance'\n",
    "config[\"is_causal\"] = False\n",
    "if \"is_causal\" in config['differentiable_hyperparameters']:\n",
    "    del config['differentiable_hyperparameters']['is_causal']\n",
    "if 'multiclass_type' in config['differentiable_hyperparameters']:\n",
    "    del config['differentiable_hyperparameters']['multiclass_type']\n",
    "\n",
    "if \"block_wise_dropout\" in config['differentiable_hyperparameters']:\n",
    "    del config['differentiable_hyperparameters']['block_wise_dropout']\n",
    "config[\"block_wise_dropout\"] = True\n",
    "\n",
    "\n",
    "\n",
    "config['hist_targets'] = False\n",
    "config['y_std'] = 1\n",
    "config['min_depth'] = 5\n",
    "config['max_depth'] = 15\n",
    "config['num_classes'] = 2\n",
    "config[\"max_num_classes\"] = 2\n",
    "\n",
    "\n",
    "config[\"align_majority\"] = False\n",
    "config[\"limit_imbalance\"] = False\n",
    "\n",
    "\n",
    "config[\"mlp_noise\"] = True\n",
    "for noi in [0.3,0.001,0.01,0.1]:\n",
    "    \n",
    "    config['differentiable_hyperparameters']['noise_std'] = {'distribution': 'meta_trunc_norm_log_scaled', 'max_mean': noi, 'min_mean': 0.00001, 'round': False, 'lower_bound': 0.0}\n",
    "    \n",
    "    \n",
    "    #config[\"epoch_frac\"] = e/maxepo\n",
    "    config_sample = evaluate_hypers(config)\n",
    "    model = get_model(config_sample, device, should_train=False, verbose=0)\n",
    "    dl = model[3]\n",
    "    rocs = []\n",
    "    means = []\n",
    "    for i in range(100):\n",
    "        #print(f\"\\n\\n\\nRun #{i}\")\n",
    "        x, y = get_sample(dl)\n",
    "        x, y = torch.squeeze(x).numpy(), torch.squeeze(y).numpy()\n",
    "        #print(np.unique(y, return_counts=True))\n",
    "        #if len(np.unique(y, return_counts=True)[0])<2: print(\"HERE FUZCKSNDKSHFKHSFG!!!!!!!!!###########################################################################################################################################\\n\\n\")\n",
    "        means.append(np.mean(y))\n",
    "        if len(np.unique(y, return_counts=True)[0])>1 and np.min(np.unique(y, return_counts=True)[1])>1:\n",
    "            #print(\"Target mean: \", torch.mean(y))\n",
    "            #plt.hist(y, bins=100)\n",
    "            #plt.show()\n",
    "            cv = 3\n",
    "            n_optim = 100\n",
    "            ft_epochs = 0\n",
    "            sampling = None\n",
    "            strat_split=True\n",
    "            max_samples = None\n",
    "            metrics = metrics = [\"roc_auc\"]#\"roc_auc_ovr\"]\n",
    "            if config['num_classes'] ==2:\n",
    "                o = 'binary:logistic'\n",
    "            else:\n",
    "                o = 'multi:softmax'\n",
    "            #model = XGBClassifier(n_estimators=10, max_depth=10, learning_rate=1, objective=o)#\n",
    "            #model = XGBoostOptim(n_optim=n_optim)\n",
    "            model = TabPFNClassifier(device='cpu', N_ensemble_configurations=3)\n",
    "            results = cross_validate_sample(model, x, y, metrics, strat_split, cv, sampling, max_samples)\n",
    "            #print(results[0])\n",
    "            rocs.append(results[0])\n",
    "            #print(\"ROC: \", results[0])\n",
    "    print(\"ROC: \", np.mean(np.array(rocs)), np.std(np.array(rocs)))\n",
    "    print(\"Pred avgs: \", np.mean(np.array(means)))\n",
    "    #result_matrix[ii,jj] = np.mean(np.array(rocs))\n",
    "    plt.hist(rocs, bins=20)\n",
    "    plt.show()\n",
    "    bins = np.arange(0,102,3)*1e-2\n",
    "    plt.hist(means, bins=bins)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3668474-a2cf-403d-8bb8-4d76ba6063d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = []\n",
    "means = []\n",
    "for i in range(1000):\n",
    "    #print(f\"\\n\\n\\nRun #{i}\")\n",
    "    x, y = get_sample(dl)\n",
    "    #print(x[0])\n",
    "    #print(np.unique(y, return_counts=True))\n",
    "    x, y = torch.squeeze(x), torch.squeeze(y)\n",
    "    preds = torch.full(y.shape, torch.argmax(torch.unique(y, return_counts=True)[1]).item())\n",
    "    accuracy = torch.mean((preds==y)[y!=-100].float())\n",
    "    means.append(max(1-np.mean(y),np.mean(y)))\n",
    "    accs.append(accuracy)\n",
    "print(torch.mean(torch.tensor(accs)))\n",
    "print(torch.mean(torch.tensor(means)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb27a55-0322-4121-a7ba-f3380dfb2a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50,100,1):\n",
    "    print(f\"ROC sub {i*0.01} pred\",  np.mean(np.array(rocs)[np.array(means)<i*0.01]), len(np.array(rocs)[np.array(means)<i*0.01])/len(means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c363a4-132d-4c4b-9fd2-0f99eb63f4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8a0922-d04c-43e6-a2d5-fd3745858bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(means,rocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff1fee4-f743-4630-b62c-4a02b0880158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358a4488-dda9-43b0-890f-ab7ccd92a306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multinomial_dirichlet(size=(1000,100)):\n",
    "    M = 1000\n",
    "    alphas = np.random.beta(1,1,size[1])\n",
    "    thetas = [np.random.dirichlet(alphas) for i in range(size[0])]\n",
    "    #print(thetas, np.sum(thetas))\n",
    "    X = np.asarray([np.random.multinomial(M, theta)/M for theta in thetas])\n",
    "    return X\n",
    "X = multinomial_dirichlet()\n",
    "print(X[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc87ccf7-5976-483f-9eb4-41036e9d97c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f721f19-7023-4436-b374-886651722f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def get_sample(config_sample, prior_hyperparameters):\n",
    "    def eval_pos_seq_len_sampler():\n",
    "        single_eval_pos_gen = get_uniform_single_eval_pos_sampler(config.get('max_eval_pos', config['bptt']), min_len=config.get('min_eval_pos', 0))\n",
    "        single_eval_pos = single_eval_pos_gen()\n",
    "        return single_eval_pos, 1024\n",
    "    ''extra_prior_kwargs_dict={\n",
    "        'num_features': config['num_features'], \n",
    "        'hyperparameters': prior_hyperparameters\n",
    "    }\n",
    "    extra_kwargs = {}\n",
    "    if 'flexible' in config and config['flexible']:\n",
    "        get_batch_base = make_get_batch(model_proto)\n",
    "        extra_kwargs['get_batch'] = get_batch_base\n",
    "        model_proto = priors.flexible_categorical\n",
    "    if 'differentiable' in prior_hyperparameters and prior_hyperparameters['differentiable']:\n",
    "        get_batch_base = make_get_batch(model_proto, **extra_kwargs)\n",
    "        extra_kwargs = {'get_batch': get_batch_base, 'differentiable_hyperparameters': prior_hyperparameters['differentiable_hyperparameters']}\n",
    "        model_proto = priors.differentiable_prior\n",
    "        use_style = True\n",
    "    \n",
    "    dl = model_proto.DataLoader(num_steps=1, batch_size=1, \n",
    "                                eval_pos_seq_len_sampler=eval_pos_seq_len_sampler, \n",
    "                                seq_len_maximum=None, device=\"cpu\", **extra_prior_kwargs_dict)''\n",
    "    dl_class, extra_kwargs = get_dataloader(config_sample, device=\"cpu\", should_train=False, verbose=2)\n",
    "    dl = model_proto.DataLoader(num_steps=1, batch_size=1, \n",
    "                                eval_pos_seq_len_sampler=eval_pos_seq_len_sampler, \n",
    "                                seq_len_maximum=None, device=\"cpu\", **extra_kwargs)\n",
    "    dl.model = None\n",
    "    return next(iter(dl))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a955c12a-56e9-4895-a9af-07226073cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_sample(config_sample, prior_hyperparameters)\n",
    "print(a[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c161bd-ec80-43ac-b3a9-21011eec1d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['differentiable'] = False\n",
    "config['flexible'] = False\n",
    "\n",
    "# forest params\n",
    "config[\"min_features\"] = 10\n",
    "config[\"max_features\"] = 100\n",
    "config[\"n_samples\"] = 1000\n",
    "config[\"max_classes\"] = 10\n",
    "config[\"base_size\"] = 1000\n",
    "config[\"n_estimators\"] = 1\n",
    "config[\"min_depth\"] = 1\n",
    "config[\"max_depth\"] = 25\n",
    "config[\"categorical_x\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af348aba-7927-4722-829b-2b9067bec073",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "from tabpfn import TabPFNClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from evaluate import scores\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, precision_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from data_prep_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import openml\n",
    "from tabularbench.data.synthetic_generator_forest import synthetic_dataset_generator_forest, synthetic_dataset_function_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5561d98a-122c-46a3-b816-198a5c986552",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabularbench.data.synthetic_generator_tabpfn import synthetic_dataset_generator_tabpfn\n",
    "\n",
    "fig, axes = plt.subplots(8, 6, figsize=(20, 15))\n",
    "generator = synthetic_dataset_generator_tabpfn(n_samples=1000, max_classes=2, min_features=2, max_features=100)\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    x2, b = next(generator)\n",
    "    i1, i2 = np.random.choice(x2.shape[1], size=(2,), replace=False)\n",
    "    ax.scatter(x2[:, i1], x2[:, i2], c=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2a893a-7167-4aa4-a2df-513182935798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabularbench.data.synthetic_generator_forest import synthetic_dataset_generator_forest, synthetic_dataset_function_forest\n",
    "import matplotlib\n",
    "\n",
    "fig, axes = plt.subplots(8, 6, figsize=(20, 15))\n",
    "generator = synthetic_dataset_generator_forest(n_samples=1000, max_classes=2, min_features=2, max_features=2)\n",
    "\n",
    "cmap = matplotlib.colormaps['inferno']\n",
    "colors = cmap(np.linspace(0.0, 0.9, 10))\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    x2, b = synthetic_dataset_function_forest(base_size=1000, min_features=2, max_features=2, max_classes=3, min_depth=1, max_depth=25, categorical_x=True, n_samples=1024)\n",
    "    i1, i2 = np.random.choice(x2.shape[1], size=(2,), replace=False)\n",
    "    random_shuffle = np.random.permutation(np.arange(10))\n",
    "    colors_shuffle = colors[random_shuffle]\n",
    "    #b = np.array([colors_shuffle[i] for i in b])\n",
    "    ax.scatter(x2[:, i1], x2[:, i2], c=b)\n",
    "    ax.tick_params(axis='both', which='both', bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be43c36-ca72-4cb4-9cd4-72a59b27d90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zinb(size=(1000,100)):\n",
    "    pi = 0.25\n",
    "    p = np.random.uniform(0.1,0.9, size=size[1])\n",
    "    p = np.repeat(np.expand_dims(p,axis=0),size[0],axis=0)\n",
    "    #print\n",
    "    #p += 1e-5\n",
    "    X = np.random.negative_binomial(100,p)\n",
    "    X = np.random.binomial(1,1-pi,size)*X\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08769738-e744-49cc-98c2-206e3bb9d5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zinb_comp(size=(1000,100)):\n",
    "    X =  zinb(size)\n",
    "    print(X)\n",
    "    print(np.expand_dims(1/np.sum(X,axis=1),axis=1))\n",
    "    return np.expand_dims(1/np.sum(X,axis=1),axis=1)*X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada8a9e9-6a99-4d92-b869-ae69bdc53cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = zinb_comp((10,10))\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ed9025-1fb0-4732-b3b7-ee311b528e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(out, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c62c558-446d-42bf-a2a3-39ed3b4a9c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prior.synthetic_generator_forest_altdata import synthetic_dataset_generator_forest_altdata, synthetic_dataset_function_forest_altdata\n",
    "\n",
    "fig, axes = plt.subplots(8, 6, figsize=(20, 15))\n",
    "\n",
    "cmap = matplotlib.colormaps['inferno']\n",
    "colors = cmap(np.linspace(0.0, 0.9, 10))\n",
    "\n",
    "\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    x2, b = synthetic_dataset_function_forest_altdata(zinb,base_size=1000, min_features=2, max_features=2, max_classes=3, min_depth=1, max_depth=25, categorical_x=True, n_samples=1024)\n",
    "    i1, i2 = np.random.choice(x2.shape[1], size=(2,), replace=False)\n",
    "    random_shuffle = np.random.permutation(np.arange(10))\n",
    "    colors_shuffle = colors[random_shuffle]\n",
    "    #b = np.array([colors_shuffle[i] for i in b])\n",
    "    ax.scatter(x2[:, i1], x2[:, i2], c=b)\n",
    "    ax.tick_params(axis='both', which='both', bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b35c21-16e3-44e8-80df-dd5de8fc536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_norm, b_norm = synthetic_dataset_function_forest(base_size=1000, min_features=2, max_features=2, max_classes=3, min_depth=1, max_depth=25, categorical_x=True, n_samples=1024)\n",
    "\n",
    "X_zinb, b_zinb = synthetic_dataset_function_forest_altdata(zinb,base_size=1000, min_features=2, max_features=2, max_classes=3, min_depth=1, max_depth=25, categorical_x=True, n_samples=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68200361-d086-41a0-8af3-ad83c009298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, roc_auc_score\n",
    "accuracy = np.zeros((3))\n",
    "runs = 10\n",
    "for ii in range(runs):\n",
    "    X_norm, b_norm = synthetic_dataset_function_forest(base_size=1000, min_features=2, max_features=2, max_classes=3, min_depth=1, max_depth=25, categorical_x=True, n_samples=1024)\n",
    "    models = [XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic'), \n",
    "              LogisticRegression(max_iter=500), \n",
    "              TabPFNClassifier(device='cpu', N_ensemble_configurations=3)]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_norm, b_norm, test_size=0.2, random_state=42)\n",
    "    for mm, model in enumerate(models):\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy[mm] += accuracy_score(y_test,y_pred)\n",
    "print(accuracy/runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248ed978-b1b6-46ee-9233-e91434632ae2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, roc_auc_score\n",
    "accuracy = np.zeros((3))\n",
    "runs = 10\n",
    "for ii in range(runs):\n",
    "    print(ii)\n",
    "    X_zinb, b_zinb = synthetic_dataset_function_forest_altdata(zinb,base_size=1000, min_features=2, max_features=2, max_classes=3, min_depth=1, max_depth=25, categorical_x=True, n_samples=1024)\n",
    "    models = [XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic'), \n",
    "              LogisticRegression(max_iter=500), \n",
    "              TabPFNClassifier(device='cpu', N_ensemble_configurations=3)]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_zinb, b_zinb, test_size=0.2, random_state=42)\n",
    "    for mm, model in enumerate(models):\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy[mm] += accuracy_score(y_test,y_pred)\n",
    "print(accuracy/runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa159333-33a1-4941-9ea3-31ab11dfcca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e818c922-3e6d-4443-884a-9fb01aa1db39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
