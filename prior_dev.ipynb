{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "806ff5d9-0f3a-4fa1-a089-db69fbe1c925",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "from tabpfn_new.scripts.transformer_prediction_interface import TabPFNClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from data_prep_utils import *\n",
    "from evaluate import *\n",
    "from load_models import *\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import openml\n",
    "from data_prep_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from tabpfn_new import priors, encoders\n",
    "from tabpfn_new.scripts.model_configs import *\n",
    "from tabpfn_new.scripts.model_builder import get_forest_prior_hyperparameters, get_mlp_prior_hyperparameters, get_model\n",
    "from tabpfn.utils import get_uniform_single_eval_pos_sampler\n",
    "from utils import get_dataloader\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99725f1b-38b4-4188-ba15-49b041341222",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reload_config(prior_type='forest', config_type='causal', task_type='binary', longer=0):\n",
    "    config = get_prior_config(config_type=config_type)\n",
    "    \n",
    "    config['prior_type'] = prior_type\n",
    "    \n",
    "    model_string = ''\n",
    "    \n",
    "    config['epochs'] = 12000\n",
    "    config['recompute_attn'] = True\n",
    "\n",
    "    config['max_num_classes'] = 10\n",
    "    config['num_classes'] = uniform_int_sampler_f(2, config['max_num_classes'])\n",
    "    config['balanced'] = False\n",
    "    model_string = model_string + '_multiclass'\n",
    "    \n",
    "    model_string = model_string + '_'+datetime.now().strftime(\"%m_%d_%Y_%H_%M_%S\")\n",
    "    \n",
    "    return config, model_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ef61611-5810-4471-93f9-82b1f6958f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dl_from_config(config_sample, prior_hyperparameters):\n",
    "    def eval_pos_seq_len_sampler():\n",
    "        single_eval_pos_gen = get_uniform_single_eval_pos_sampler(config.get('max_eval_pos', config['bptt']), min_len=config.get('min_eval_pos', 0))\n",
    "        single_eval_pos = single_eval_pos_gen()\n",
    "        return single_eval_pos, 1024\n",
    "    dl_class, extra_kwargs = get_dataloader(config_sample, device=\"cpu\", should_train=False, verbose=0)\n",
    "    dl = dl_class(num_steps=1, batch_size=1, \n",
    "                                eval_pos_seq_len_sampler=eval_pos_seq_len_sampler, \n",
    "                                seq_len_maximum=None, device=\"cpu\", **extra_kwargs)\n",
    "    dl.model = None\n",
    "    return dl\n",
    "\n",
    "                                     \n",
    "def get_sample(dl):\n",
    "    (style, x, y), _, _ =  next(iter(dl))\n",
    "    return x, y\n",
    "    \n",
    "def plot_grid(dl, hyperparameters, rows=8, cols=6):\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(20,15))\n",
    "    class_assigner = priors.flexible_categorical.BalancedBinarize()#priors.flexible_categorical.MulticlassRank(hyperparameters['num_classes'], ordered_p=hyperparameters['output_multiclass_ordered_p'])\n",
    "    for ax in axes.flatten():\n",
    "        x2, b = get_sample(dl)\n",
    "        #b = class_assigner(b)\n",
    "        i1, i2 = np.random.choice(x2.shape[2], size=(2,), replace=False)\n",
    "        ax.scatter(x2[:, 0, i1], x2[:, 0, i2], c=b, s=1.5, cmap=\"bwr\")\n",
    "\n",
    "def remove_zero_features(x):\n",
    "    x = x[:,:,torch.where(torch.sum(torch.abs(x), dim=0)>0,1,0)]\n",
    "    return x\n",
    "\n",
    "def plot_feature_combinations(dl, hyperparameters, num_plots=10):\n",
    "    fig = plt.figure(figsize=(20,15))\n",
    "    x2, b = get_sample(dl)\n",
    "    #x2 = remove_zero_features(x2)\n",
    "    #class_assigner = priors.flexible_categorical.BalancedBinarize()#MulticlassRank(hyperparameters['num_classes'], ordered_p=hyperparameters['output_multiclass_ordered_p'])\n",
    "    #b = class_assigner(b)\n",
    "    n_feat = num_plots#hyperparameters[\"max_features\"]\n",
    "    for i in range(n_feat-1):\n",
    "        for j in range(n_feat):\n",
    "            if(j>i) :\n",
    "                ax = plt.subplot2grid((n_feat-1, n_feat-1), (i,j-1))\n",
    "                #ax.xaxis.set_ticklabels([]) \n",
    "                #ax.yaxis.set_ticklabels([])\n",
    "                plt.scatter(x2[:,0,i],x2[:,0,j],c=b, s=1.5, cmap=\"bwr\")\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f7f010d-ebbf-4cf7-ba58-8f98ecb7e01b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prior_type = 'mlp'\n",
    "config, model_string = reload_config(prior_type, longer=1)\n",
    "\n",
    "config['differentiable'] = True\n",
    "config['flexible'] = True\n",
    "config['bptt_extra_samples'] = None\n",
    "\n",
    "# diff\n",
    "config['output_multiclass_ordered_p'] = 0.0\n",
    "del config['differentiable_hyperparameters']['output_multiclass_ordered_p']\n",
    "\n",
    "\n",
    "\n",
    "config['sampling'] = 'normal' # vielleicht schlecht?\n",
    "del config['differentiable_hyperparameters']['sampling']\n",
    "\n",
    "config['pre_sample_causes'] = True\n",
    "# end diff\n",
    "\n",
    "config['multiclass_loss_type'] = 'nono' # 'compatible'\n",
    "config['normalize_to_ranking'] = False # False\n",
    "\n",
    "config['categorical_feature_p'] = 0 # diff: .0\n",
    "\n",
    "# turn this back on in a random search!?\n",
    "config['nan_prob_no_reason'] = .0\n",
    "config['nan_prob_unknown_reason'] = .0 # diff: .0\n",
    "config['set_value_to_nan'] = .0 # diff: 1.\n",
    "\n",
    "config['normalize_with_sqrt'] = False\n",
    "\n",
    "config['new_mlp_per_example'] = True\n",
    "config['prior_mlp_scale_weights_sqrt'] = True\n",
    "config['batch_size_per_gp_sample'] = None\n",
    "\n",
    "config['normalize_ignore_label_too'] = False\n",
    "\n",
    "config['differentiable_hps_as_style'] = False\n",
    "config['max_eval_pos'] = 1000\n",
    "\n",
    "config['random_feature_rotation'] = True\n",
    "config['rotate_normalized_labels'] = True\n",
    "\n",
    "config[\"mix_activations\"] = True # False heisst eig True\n",
    "\n",
    "config['n_layers'] = 4\n",
    "config['emsize'] = 128\n",
    "config['nhead'] = config['emsize'] // 32\n",
    "config['bptt'] = 1024+128\n",
    "config['canonical_y_encoder'] = True\n",
    "\n",
    "    \n",
    "config['aggregate_k_gradients'] = 1\n",
    "config['batch_size'] = 1*config['aggregate_k_gradients']\n",
    "config['num_steps'] = 1//config['aggregate_k_gradients']\n",
    "config['epochs'] = 1\n",
    "\n",
    "config['total_available_time_in_s'] = None #60*60*22 # 22 hours for some safety...\n",
    "\n",
    "config['train_mixed_precision'] = True\n",
    "config['efficient_eval_masking'] = True\n",
    "\n",
    "# mlp params\n",
    "config['is_causal'] = True\n",
    "config['num_causes'] = 5\n",
    "config['prior_mlp_hidden_dim'] = 50\n",
    "config['num_layers'] = 4\n",
    "config['noise_std'] = 0.05\n",
    "config['init_std'] = 0.05\n",
    "config['y_is_effect'] = True\n",
    "config['pre_sample_weights'] = True\n",
    "config['prior_mlp_dropout_prob'] = 0\n",
    "config['pre_sample_causes'] = True\n",
    "config[\"prior_mlp_activations\"] = torch.nn.ReLU()\n",
    "config[\"block_wise_dropout\"] = True\n",
    "config[\"sort_features\"] = False\n",
    "config[\"in_clique\"] = False\n",
    "\n",
    "# general data params\n",
    "config['balanced'] = True\n",
    "config['max_num_classes'] = 2\n",
    "config['max_features'] = 100\n",
    "config['num_features_used'] = 100\n",
    "\n",
    "config['num_classes'] = 2\n",
    "\n",
    "config['no_encoder'] = False\n",
    "config['normalize_to_ranking'] = False # False\n",
    "config['normalize_with_sqrt'] = False\n",
    "config['normalize_ignore_label_too'] = False\n",
    "config[\"normalize\"] = False\n",
    "config['num_classes'] = 2\n",
    "config[\"balanced\"] = False\n",
    "config['multiclass_type'] = 'imbalanced_binarize'\n",
    "\n",
    "\n",
    "config_sample = evaluate_hypers(config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30030035-1632-47a4-9d32-a560361a8dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dl = dl_from_config(config_sample, prior_hyperparameters)\n",
    "model = get_model(config_sample, device, should_train=False, verbose=0)\n",
    "dl = model[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8825b69a-4d14-4e8f-95ba-1128f5486b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid(dl,config_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb563131-d329-4157-bb05-31fa6a6f0e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_combinations(dl,config_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b700a2b-c26b-44cc-8530-8d1f7650c97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "class MicroDL(DataLoader):\n",
    "    def __init__(self, path=None):\n",
    "        data, labels = get_microbiome(path)\n",
    "        data = top_non_zero(data)\n",
    "        data, labels = unison_shuffled_copies(data, labels)\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return 100\n",
    "        \n",
    "    def get_perm(self):\n",
    "        indices = np.random.permutation(self.data.shape[0])[:1000]\n",
    "        return (None, np.expand_dims(self.data[indices], axis=1), np.expand_dims(self.labels[indices],axis=1)), None, None\n",
    "        \n",
    "    def __iter__(self):\n",
    "        indices = np.random.permutation(self.data.shape[0])[:1000]\n",
    "        return iter(self.get_perm() for _ in range(100))\n",
    "path = \"datasets/data_all.csv\"\n",
    "dl = MicroDL(path)\n",
    "#plot_grid(dl, config_sample)\n",
    "plot_feature_combinations(dl, config_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47342e30-ae92-451b-824d-6db9a19ea2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['differentiable'] = True\n",
    "config['flexible'] = True\n",
    "\n",
    "# forest params\n",
    "config[\"min_features\"] = 100\n",
    "config[\"max_features\"] = 100\n",
    "config[\"n_samples\"] = 1000\n",
    "config[\"max_classes\"] = 2\n",
    "config[\"base_size\"] = 1000\n",
    "config[\"n_estimators\"] = 1\n",
    "config[\"min_depth\"] = 3\n",
    "config[\"max_depth\"] = 15\n",
    "config[\"categorical_x\"] = False\n",
    "config[\"data_sample_func\"] = \"zinb\"\n",
    "config[\"comp\"] = True\n",
    "\n",
    "config['multiclass_type'] = 'balance'\n",
    "del config['differentiable_hyperparameters']['multiclass_type']\n",
    "\n",
    "config[\"prior_type\"] = \"forest\"\n",
    "config[\"microbiome_test\"] = True\n",
    "config[\"weight_classes\"] = False\n",
    "config[\"run_name\"] = \"time\"\n",
    "\n",
    "config[\"prior_type\"] = \"forest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc90518-93eb-4479-980f-3ee7f749c365",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_sample = evaluate_hypers(config)\n",
    "model = get_model(config_sample, device, should_train=False, verbose=0)\n",
    "dl = model[3]\n",
    "plot_grid(dl, config_sample)\n",
    "plot_feature_combinations(dl, config_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540f17f5-7cc3-4fc7-a60c-cfb409cb3513",
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"data_sample_func\"] = \"mnd\"\n",
    "\n",
    "\n",
    "config_sample = evaluate_hypers(config)\n",
    "model = get_model(config_sample, device, should_train=False, verbose=0)\n",
    "dl = model[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4e1075-d1c8-443b-85e6-05216d0367da",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid(dl, config_sample)\n",
    "plot_feature_combinations(dl, config_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b2ca11-0225-4a0d-9c95-796d9eb3ee8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabpfn import TabPFNClassifier\n",
    "model = TabPFNClassifier(device='cpu', N_ensemble_configurations=1)\n",
    "x, y = get_sample(dl)\n",
    "x, y = torch.squeeze(x), torch.squeeze(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, train_size=0.8, test_size=0.2, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "print(torch.tensor(preds)*y_test+(torch.tensor(preds)-1)*(y_test-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd56e91-d6c5-4163-bf92-a797bb3a8977",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['differentiable'] = True\n",
    "config['flexible'] = True\n",
    "config[\"prior_type\"] = \"forest\"\n",
    "config[\"sampling\"] = \"mnd\"\n",
    "#del config['differentiable_hyperparameters']['sampling']\n",
    "config[\"data_sample_func\"] = \"mnd\"\n",
    "config[\"is_causal\"] = False\n",
    "#del config['differentiable_hyperparameters']['is_causal']\n",
    "config['multiclass_type'] = 'balance'\n",
    "config['hist_targets'] = False\n",
    "\n",
    "config[\"align_majority\"] = False\n",
    "config[\"limit_imbalance\"] = False\n",
    "\n",
    "config[\"normalize\"] = True\n",
    "config[\"num_classes\"] = 2\n",
    "config[\"max_num_classes\"] = 2\n",
    "\n",
    "config['min_depth'] = 5\n",
    "config['max_depth'] = 15\n",
    "#del config['differentiable_hyperparameters']['multiclass_type']\n",
    "\n",
    "config_sample = evaluate_hypers(config)\n",
    "model = get_model(config_sample, device, should_train=False, verbose=0)\n",
    "dl = model[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae188bf-91f0-42c2-91b5-96714476a333",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    print(f\"\\n\\n\\nRun #{i}\")\n",
    "    x, y = get_sample(dl)\n",
    "    x, y = torch.squeeze(x), torch.squeeze(y)\n",
    "    print(\"Target mean: \", torch.mean(y))\n",
    "    if len(np.unique(y, return_counts=True)[0])>1 and np.min(np.unique(y, return_counts=True)[1])>20:\n",
    "        #plt.hist(y, bins=100)\n",
    "        #plt.show()\n",
    "        cv = 3\n",
    "        n_optim = 20\n",
    "        ft_epochs = 0\n",
    "        sampling = None\n",
    "        strat_split=True\n",
    "        max_samples = 1000\n",
    "        metrics = metrics = [\"accuracy\", \"precision\", \"recall\", \"roc_auc\"]\n",
    "        models = [\n",
    "            #XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic'),\n",
    "            XGBoostOptim(n_optim=n_optim),\n",
    "            #LogisticRegression(max_iter=500), \n",
    "            #TabPFNClassifier(device='cpu', N_ensemble_configurations=3),\n",
    "            #TabForestPFNClassifier(\"saved_models/tabforest/mix600k/tabforestpfn.pt\", \"saved_models/tabforest/mix600k/config_run.yaml\")\n",
    "        ]\n",
    "        results = pd.DataFrame(np.zeros((len(models), len(metrics))), \n",
    "                               index=[m.__class__.__name__ for m in models],\n",
    "                              columns=metrics)\n",
    "        \n",
    "        for ii, model in enumerate(models):\n",
    "            results.iloc[ii,:] = cross_validate_sample(model, x, y, metrics, strat_split, cv, sampling)\n",
    "        print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b15a5d3-46cc-439c-a324-577e5dda3ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\Desktop\\MT\\TabPFN-medical\\tabpfn_new\\scripts\\model_configs.py:260: DeprecationWarning: Please use `space.add(hyperparameter)`\n",
      "  cs.add_hyperparameter(hp)\n",
      "C:\\Users\\lenna\\Desktop\\MT\\TabPFN-medical\\tabpfn_new\\train.py:130: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler() if train_mixed_precision else None\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master4\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "Using cpu:0 device\n",
      "Using a Transformer with 1.64 M parameters\n",
      "{'is_causal': False, 'num_causes': 5, 'prior_mlp_hidden_dim': 17, 'num_layers': 3, 'noise_std': 0.00031978730398937673, 'y_is_effect': True, 'pre_sample_weights': True, 'prior_mlp_dropout_prob': 0.2882227693093149, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n",
      "ROC:  0.777777777777778\n",
      "{'is_causal': False, 'num_causes': 2, 'prior_mlp_hidden_dim': 11, 'num_layers': 5, 'noise_std': 0.00019869609416407253, 'y_is_effect': False, 'pre_sample_weights': False, 'prior_mlp_dropout_prob': 0.47146684043530074, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n",
      "ROC:  0.7699652777777777\n",
      "{'is_causal': False, 'num_causes': 6, 'prior_mlp_hidden_dim': 45, 'num_layers': 4, 'noise_std': 0.0003980926797131955, 'y_is_effect': False, 'pre_sample_weights': True, 'prior_mlp_dropout_prob': 0.1426821045991925, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n",
      "ROC:  0.7682291666666666\n",
      "{'is_causal': False, 'num_causes': 4, 'prior_mlp_hidden_dim': 48, 'num_layers': 3, 'noise_std': 0.0009740933602815879, 'y_is_effect': False, 'pre_sample_weights': False, 'prior_mlp_dropout_prob': 0.3239013689804392, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n",
      "ROC:  0.6362847222222222\n",
      "{'is_causal': False, 'num_causes': 4, 'prior_mlp_hidden_dim': 27, 'num_layers': 3, 'noise_std': 0.0009704388790977103, 'y_is_effect': False, 'pre_sample_weights': False, 'prior_mlp_dropout_prob': 0.2262669743502683, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n",
      "ROC:  0.7690972222222223\n",
      "{'is_causal': False, 'num_causes': 10, 'prior_mlp_hidden_dim': 11, 'num_layers': 5, 'noise_std': 0.00010224208357724842, 'y_is_effect': False, 'pre_sample_weights': False, 'prior_mlp_dropout_prob': 0.49708497686827136, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n",
      "ROC:  0.5720486111111112\n",
      "{'is_causal': False, 'num_causes': 4, 'prior_mlp_hidden_dim': 49, 'num_layers': 4, 'noise_std': 0.0008149029511177947, 'y_is_effect': False, 'pre_sample_weights': False, 'prior_mlp_dropout_prob': 0.27187967571439753, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n",
      "ROC:  0.75\n",
      "{'is_causal': False, 'num_causes': 4, 'prior_mlp_hidden_dim': 28, 'num_layers': 4, 'noise_std': 0.00034585510703231926, 'y_is_effect': False, 'pre_sample_weights': False, 'prior_mlp_dropout_prob': 0.12411357346652836, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n",
      "ROC:  0.5416666666666666\n",
      "{'is_causal': False, 'num_causes': 3, 'prior_mlp_hidden_dim': 11, 'num_layers': 4, 'noise_std': 0.0008973915969175977, 'y_is_effect': False, 'pre_sample_weights': True, 'prior_mlp_dropout_prob': 0.1123477302055048, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n",
      "ROC:  0.5434027777777778\n",
      "{'is_causal': False, 'num_causes': 2, 'prior_mlp_hidden_dim': 38, 'num_layers': 4, 'noise_std': 0.0003338709858192485, 'y_is_effect': False, 'pre_sample_weights': True, 'prior_mlp_dropout_prob': 0.3641242514333526, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n",
      "ROC:  0.5824652777777779\n",
      "{'is_causal': False, 'num_causes': 4, 'prior_mlp_hidden_dim': 46, 'num_layers': 4, 'noise_std': 0.0008386876249131772, 'y_is_effect': False, 'pre_sample_weights': False, 'prior_mlp_dropout_prob': 0.13708134585668616, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n",
      "ROC:  0.6883680555555557\n",
      "{'is_causal': False, 'num_causes': 8, 'prior_mlp_hidden_dim': 19, 'num_layers': 4, 'noise_std': 0.0007193947076744712, 'y_is_effect': False, 'pre_sample_weights': False, 'prior_mlp_dropout_prob': 0.2791195021819165, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n",
      "ROC:  0.6710069444444445\n",
      "{'is_causal': False, 'num_causes': 4, 'prior_mlp_hidden_dim': 15, 'num_layers': 4, 'noise_std': 0.00011822881548697911, 'y_is_effect': False, 'pre_sample_weights': False, 'prior_mlp_dropout_prob': 0.4148179462749012, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n",
      "ROC:  0.7421875\n",
      "{'is_causal': False, 'num_causes': 5, 'prior_mlp_hidden_dim': 17, 'num_layers': 4, 'noise_std': 0.0007994898406376183, 'y_is_effect': False, 'pre_sample_weights': False, 'prior_mlp_dropout_prob': 0.1290234424364937, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n",
      "{'is_causal': False, 'num_causes': 6, 'prior_mlp_hidden_dim': 31, 'num_layers': 4, 'noise_std': 0.0009908527897995272, 'y_is_effect': True, 'pre_sample_weights': False, 'prior_mlp_dropout_prob': 0.38891886278279064, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n",
      "ROC:  0.7144097222222222\n",
      "{'is_causal': False, 'num_causes': 9, 'prior_mlp_hidden_dim': 23, 'num_layers': 4, 'noise_std': 0.00039937447451442567, 'y_is_effect': False, 'pre_sample_weights': False, 'prior_mlp_dropout_prob': 0.3753345043539994, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n",
      "ROC:  0.6336805555555556\n",
      "{'is_causal': False, 'num_causes': 4, 'prior_mlp_hidden_dim': 45, 'num_layers': 4, 'noise_std': 0.0005448237095515426, 'y_is_effect': False, 'pre_sample_weights': True, 'prior_mlp_dropout_prob': 0.2965662219056302, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n",
      "ROC:  0.7256944444444445\n",
      "{'is_causal': False, 'num_causes': 2, 'prior_mlp_hidden_dim': 20, 'num_layers': 4, 'noise_std': 0.0002762904071087718, 'y_is_effect': False, 'pre_sample_weights': True, 'prior_mlp_dropout_prob': 0.446400756943246, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n",
      "ROC:  0.707465277777778\n",
      "{'is_causal': False, 'num_causes': 4, 'prior_mlp_hidden_dim': 49, 'num_layers': 4, 'noise_std': 0.0009894426443548484, 'y_is_effect': False, 'pre_sample_weights': False, 'prior_mlp_dropout_prob': 0.14519223542664675, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n",
      "ROC:  0.4704861111111111\n",
      "{'is_causal': False, 'num_causes': 2, 'prior_mlp_hidden_dim': 16, 'num_layers': 3, 'noise_std': 0.0007581328024983409, 'y_is_effect': False, 'pre_sample_weights': False, 'prior_mlp_dropout_prob': 0.4304538260209273, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n",
      "ROC:  0.65625\n",
      "{'is_causal': False, 'num_causes': 10, 'prior_mlp_hidden_dim': 24, 'num_layers': 4, 'noise_std': 0.00020085555324746694, 'y_is_effect': False, 'pre_sample_weights': True, 'prior_mlp_dropout_prob': 0.30575659207853423, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n",
      "ROC:  0.7612847222222222\n",
      "{'is_causal': False, 'num_causes': 5, 'prior_mlp_hidden_dim': 42, 'num_layers': 4, 'noise_std': 0.0007802877050196931, 'y_is_effect': False, 'pre_sample_weights': False, 'prior_mlp_dropout_prob': 0.3960089660542966, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n",
      "ROC:  0.4947916666666667\n",
      "{'is_causal': False, 'num_causes': 6, 'prior_mlp_hidden_dim': 34, 'num_layers': 4, 'noise_std': 0.0007839956062234468, 'y_is_effect': False, 'pre_sample_weights': False, 'prior_mlp_dropout_prob': 0.23766421005352834, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n",
      "ROC:  0.8159722222222223\n",
      "{'is_causal': False, 'num_causes': 2, 'prior_mlp_hidden_dim': 30, 'num_layers': 4, 'noise_std': 0.00059269797902031, 'y_is_effect': False, 'pre_sample_weights': True, 'prior_mlp_dropout_prob': 0.3455360849178767, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n",
      "ROC:  0.6536458333333333\n",
      "{'is_causal': False, 'num_causes': 4, 'prior_mlp_hidden_dim': 26, 'num_layers': 4, 'noise_std': 0.0007515900000241273, 'y_is_effect': False, 'pre_sample_weights': False, 'prior_mlp_dropout_prob': 0.2609601083498066, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n",
      "ROC:  0.7838541666666666\n",
      "{'is_causal': False, 'num_causes': 3, 'prior_mlp_hidden_dim': 26, 'num_layers': 4, 'noise_std': 0.0001198268561794694, 'y_is_effect': True, 'pre_sample_weights': False, 'prior_mlp_dropout_prob': 0.20506857929808914, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n",
      "ROC:  0.7005208333333334\n",
      "{'is_causal': False, 'num_causes': 9, 'prior_mlp_hidden_dim': 21, 'num_layers': 3, 'noise_std': 0.0002135282859691487, 'y_is_effect': False, 'pre_sample_weights': False, 'prior_mlp_dropout_prob': 0.250687804354685, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n",
      "ROC:  0.7855902777777778\n",
      "{'is_causal': False, 'num_causes': 12, 'prior_mlp_hidden_dim': 35, 'num_layers': 4, 'noise_std': 0.00023495002114296796, 'y_is_effect': False, 'pre_sample_weights': True, 'prior_mlp_dropout_prob': 0.14738435608891623, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n",
      "ROC:  0.7248263888888888\n",
      "{'is_causal': False, 'num_causes': 2, 'prior_mlp_hidden_dim': 22, 'num_layers': 4, 'noise_std': 0.0009347105952546631, 'y_is_effect': False, 'pre_sample_weights': True, 'prior_mlp_dropout_prob': 0.49789630533939844, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n",
      "ROC:  0.6189236111111112\n",
      "{'is_causal': False, 'num_causes': 8, 'prior_mlp_hidden_dim': 40, 'num_layers': 3, 'noise_std': 0.00047277611777545925, 'y_is_effect': False, 'pre_sample_weights': False, 'prior_mlp_dropout_prob': 0.3734901051693639, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n",
      "ROC:  0.6154513888888891\n",
      "{'is_causal': False, 'num_causes': 4, 'prior_mlp_hidden_dim': 23, 'num_layers': 4, 'noise_std': 0.0009670490790144646, 'y_is_effect': False, 'pre_sample_weights': False, 'prior_mlp_dropout_prob': 0.3137011658141554, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n",
      "ROC:  0.8038194444444445\n",
      "{'is_causal': False, 'num_causes': 11, 'prior_mlp_hidden_dim': 39, 'num_layers': 4, 'noise_std': 0.0003074718822248363, 'y_is_effect': False, 'pre_sample_weights': True, 'prior_mlp_dropout_prob': 0.3410429739860533, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n",
      "ROC:  0.717013888888889\n",
      "{'is_causal': False, 'num_causes': 16, 'prior_mlp_hidden_dim': 47, 'num_layers': 4, 'noise_std': 0.0002989769238989237, 'y_is_effect': True, 'pre_sample_weights': False, 'prior_mlp_dropout_prob': 0.4163239848493615, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n",
      "ROC:  0.49131944444444436\n",
      "{'is_causal': False, 'num_causes': 3, 'prior_mlp_hidden_dim': 18, 'num_layers': 5, 'noise_std': 0.0004523926829907971, 'y_is_effect': True, 'pre_sample_weights': False, 'prior_mlp_dropout_prob': 0.3263555186782423, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n",
      "ROC:  0.7421875000000001\n",
      "{'is_causal': False, 'num_causes': 3, 'prior_mlp_hidden_dim': 20, 'num_layers': 3, 'noise_std': 0.0006457401435596298, 'y_is_effect': False, 'pre_sample_weights': False, 'prior_mlp_dropout_prob': 0.22552379412619544, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n",
      "ROC:  0.8151041666666666\n",
      "{'is_causal': False, 'num_causes': 6, 'prior_mlp_hidden_dim': 48, 'num_layers': 4, 'noise_std': 0.00025709325632537554, 'y_is_effect': False, 'pre_sample_weights': True, 'prior_mlp_dropout_prob': 0.20108143983794738, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n",
      "ROC:  0.685763888888889\n",
      "{'is_causal': False, 'num_causes': 5, 'prior_mlp_hidden_dim': 39, 'num_layers': 4, 'noise_std': 0.00036145069282906173, 'y_is_effect': False, 'pre_sample_weights': False, 'prior_mlp_dropout_prob': 0.28667246180369604, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n",
      "ROC:  0.4618055555555556\n",
      "{'is_causal': False, 'num_causes': 10, 'prior_mlp_hidden_dim': 38, 'num_layers': 5, 'noise_std': 0.0007078960876658767, 'y_is_effect': False, 'pre_sample_weights': True, 'prior_mlp_dropout_prob': 0.4259757234865038, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n",
      "ROC:  0.642361111111111\n",
      "{'is_causal': False, 'num_causes': 7, 'prior_mlp_hidden_dim': 38, 'num_layers': 3, 'noise_std': 0.0009417574209642923, 'y_is_effect': False, 'pre_sample_weights': True, 'prior_mlp_dropout_prob': 0.4078462579455565, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n",
      "ROC:  0.5963541666666666\n",
      "{'is_causal': False, 'num_causes': 5, 'prior_mlp_hidden_dim': 28, 'num_layers': 5, 'noise_std': 0.0001389975894663905, 'y_is_effect': False, 'pre_sample_weights': False, 'prior_mlp_dropout_prob': 0.24504598542968542, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n",
      "ROC:  0.7135416666666666\n",
      "{'is_causal': False, 'num_causes': 6, 'prior_mlp_hidden_dim': 21, 'num_layers': 4, 'noise_std': 0.0008658142641806796, 'y_is_effect': False, 'pre_sample_weights': False, 'prior_mlp_dropout_prob': 0.14414990264229638, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n",
      "ROC:  0.8055555555555557\n",
      "{'is_causal': False, 'num_causes': 2, 'prior_mlp_hidden_dim': 44, 'num_layers': 5, 'noise_std': 0.0004049228923740279, 'y_is_effect': False, 'pre_sample_weights': False, 'prior_mlp_dropout_prob': 0.44562194239231656, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n",
      "ROC:  0.7890625\n",
      "{'is_causal': False, 'num_causes': 15, 'prior_mlp_hidden_dim': 41, 'num_layers': 4, 'noise_std': 0.0006182802660622772, 'y_is_effect': False, 'pre_sample_weights': True, 'prior_mlp_dropout_prob': 0.13526685345574918, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n",
      "ROC:  0.7682291666666666\n",
      "{'is_causal': False, 'num_causes': 5, 'prior_mlp_hidden_dim': 40, 'num_layers': 4, 'noise_std': 0.0006601331029727885, 'y_is_effect': False, 'pre_sample_weights': True, 'prior_mlp_dropout_prob': 0.2838327743524608, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n",
      "ROC:  0.5972222222222222\n",
      "{'is_causal': False, 'num_causes': 7, 'prior_mlp_hidden_dim': 41, 'num_layers': 5, 'noise_std': 0.0005754992371665092, 'y_is_effect': False, 'pre_sample_weights': True, 'prior_mlp_dropout_prob': 0.3717902352146587, 'pre_sample_causes': True}\n",
      "Hparams dict_keys(['prior_bag_exp_weights_1', 'num_layers', 'prior_mlp_hidden_dim', 'prior_mlp_dropout_prob', 'noise_std', 'init_std_log_mean', 'init_std_log_std', 'num_causes_alpha', 'num_causes_scale', 'pre_sample_weights_choice_1_weight', 'y_is_effect_choice_1_weight', 'prior_mlp_activations_choice_1_weight', 'prior_mlp_activations_choice_2_weight', 'sort_features_choice_1_weight', 'in_clique_choice_1_weight', 'outputscale_log_mean', 'outputscale_log_std', 'lengthscale_log_mean', 'lengthscale_log_std', 'noise_choice_1_weight', 'noise_choice_2_weight'])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 72\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m#model = XGBClassifier(n_estimators=10, max_depth=10, learning_rate=1, objective=o)#\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m#model = XGBoostOptim(n_optim=n_optim)\u001b[39;00m\n\u001b[0;32m     71\u001b[0m model \u001b[38;5;241m=\u001b[39m TabPFNClassifier(device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m, N_ensemble_configurations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m---> 72\u001b[0m results,_ \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrat_split\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m#print(results[0])\u001b[39;00m\n\u001b[0;32m     74\u001b[0m rocs\u001b[38;5;241m.\u001b[39mappend(results[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32m~\\Desktop\\MT\\TabPFN-medical\\evaluate.py:75\u001b[0m, in \u001b[0;36mcross_validate_sample\u001b[1;34m(model, X, y, metrics, strat_split, cv, sampling, reducer, max_samples, seed, overwrite, n_best_delete)\u001b[0m\n\u001b[0;32m     73\u001b[0m     model_clean\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 75\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_clean\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m results[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(metrics):\n",
      "File \u001b[1;32m~\\Desktop\\MT\\TabPFN-medical\\tabpfn_new\\scripts\\transformer_prediction_interface.py:303\u001b[0m, in \u001b[0;36mTabPFNClassifier.predict\u001b[1;34m(self, X, return_winning_probability, normalize_with_test)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, return_winning_probability\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, normalize_with_test\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 303\u001b[0m     p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize_with_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalize_with_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    304\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(p, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    305\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39masarray(y, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp))\n",
      "File \u001b[1;32m~\\Desktop\\MT\\TabPFN-medical\\tabpfn_new\\scripts\\transformer_prediction_interface.py:282\u001b[0m, in \u001b[0;36mTabPFNClassifier.predict_proba\u001b[1;34m(self, X, normalize_with_test, return_logits)\u001b[0m\n\u001b[0;32m    278\u001b[0m y_full \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(y_full, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    280\u001b[0m eval_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 282\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_full\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_full\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mstyle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstyle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43minference_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mpreprocess_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnone\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_preprocess_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmix\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mnormalize_with_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalize_with_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mN_ensemble_configurations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mN_ensemble_configurations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43msoftmax_temperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mmulticlass_decoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulticlass_decoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mfeature_shift_decoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_shift_decoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mdifferentiable_hps_as_style\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdifferentiable_hps_as_style\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mreturn_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mno_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mbatch_size_inference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size_inference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m                                 \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mget_params_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    298\u001b[0m prediction_, y_ \u001b[38;5;241m=\u001b[39m prediction\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m), y_full\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mlong()[eval_pos:]\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prediction_\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad \u001b[38;5;28;01melse\u001b[39;00m prediction_\n",
      "File \u001b[1;32m~\\Desktop\\MT\\TabPFN-medical\\tabpfn_new\\scripts\\transformer_prediction_interface.py:535\u001b[0m, in \u001b[0;36mtransformer_predict\u001b[1;34m(model, eval_xs, eval_ys, eval_position, device, max_features, style, inference_mode, num_classes, extend_features, normalize_with_test, normalize_to_ranking, softmax_temperature, multiclass_decoder, preprocess_transform, categorical_feats, feature_shift_decoder, N_ensemble_configurations, batch_size_inference, differentiable_hps_as_style, average_logits, fp16_inference, normalize_with_sqrt, seed, no_grad, return_logits, **kwargs)\u001b[0m\n\u001b[0;32m    531\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    532\u001b[0m                             message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of the inputs have requires_grad=True. Gradients will be None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    533\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    534\u001b[0m                             message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 535\u001b[0m     output_batch \u001b[38;5;241m=\u001b[39m \u001b[43mcheckpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msoftmax_temperature_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_reentrant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''if device == 'cpu':\u001b[39;00m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;124;03m        output_batch = checkpoint(predict, batch_input, batch_label, style_, softmax_temperature_, True, use_reentrant=False)\u001b[39;00m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;124;03m    else:\u001b[39;00m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;124;03m        with torch.cuda.amp.autocast(enabled=fp16_inference):\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;124;03m            output_batch = checkpoint(predict, batch_input, batch_label, style_, softmax_temperature_, True, use_reentrant=False)'''\u001b[39;00m\n\u001b[0;32m    541\u001b[0m outputs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [output_batch]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master4\\Lib\\site-packages\\torch\\_compile.py:31\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     28\u001b[0m     disable_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)\n\u001b[0;32m     29\u001b[0m     fn\u001b[38;5;241m.\u001b[39m__dynamo_disable \u001b[38;5;241m=\u001b[39m disable_fn\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master4\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600\u001b[0m, in \u001b[0;36mDisableContext.__call__.<locals>._fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    598\u001b[0m prior \u001b[38;5;241m=\u001b[39m set_eval_frame(callback)\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 600\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    602\u001b[0m     set_eval_frame(prior)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master4\\Lib\\site-packages\\torch\\utils\\checkpoint.py:488\u001b[0m, in \u001b[0;36mcheckpoint\u001b[1;34m(function, use_reentrant, context_fn, determinism_check, debug, *args, **kwargs)\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# Runs pre-forward logic\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28mnext\u001b[39m(gen)\n\u001b[1;32m--> 488\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[38;5;66;03m# Runs post-forward logic\u001b[39;00m\n\u001b[0;32m    490\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Desktop\\MT\\TabPFN-medical\\tabpfn_new\\scripts\\transformer_prediction_interface.py:369\u001b[0m, in \u001b[0;36mtransformer_predict.<locals>.predict\u001b[1;34m(eval_xs, eval_ys, used_style, softmax_temperature, return_logits)\u001b[0m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m inference_mode_call:\n\u001b[0;32m    368\u001b[0m     start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 369\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    370\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[43mused_style\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_xs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mused_style\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_xs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_ys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m            \u001b[49m\u001b[43msingle_eval_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_position\u001b[49m\u001b[43m)\u001b[49m[:, :, \u001b[38;5;241m0\u001b[39m:num_classes]\n\u001b[0;32m    372\u001b[0m     output \u001b[38;5;241m=\u001b[39m output[:, :, \u001b[38;5;241m0\u001b[39m:num_classes] \u001b[38;5;241m/\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(softmax_temperature)\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_logits:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master4\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master4\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master4\\Lib\\site-packages\\tabpfn\\transformer.py:141\u001b[0m, in \u001b[0;36mTransformerModel.forward\u001b[1;34m(self, src, src_mask, single_eval_pos)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_encoder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m     src \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_encoder(src)\n\u001b[1;32m--> 141\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(output)\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output[single_eval_pos\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mlen\u001b[39m(style_src)\u001b[38;5;241m+\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_att_embeddings\u001b[38;5;241m.\u001b[39mnum_embeddings \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_att_embeddings \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m):]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master4\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master4\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master4\\Lib\\site-packages\\tabpfn\\transformer.py:227\u001b[0m, in \u001b[0;36mTransformerEncoderDiffInit.forward\u001b[1;34m(self, src, mask, src_key_padding_mask)\u001b[0m\n\u001b[0;32m    224\u001b[0m output \u001b[38;5;241m=\u001b[39m src\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m--> 227\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    230\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(output)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master4\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master4\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master4\\Lib\\site-packages\\tabpfn\\layer.py:109\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[1;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[0;32m    107\u001b[0m     single_eval_position \u001b[38;5;241m=\u001b[39m src_mask\n\u001b[0;32m    108\u001b[0m     src_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn(src_[:single_eval_position], src_[:single_eval_position], src_[:single_eval_position])[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 109\u001b[0m     src_right \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_\u001b[49m\u001b[43m[\u001b[49m\u001b[43msingle_eval_position\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43msingle_eval_position\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43msingle_eval_position\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    110\u001b[0m     src2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([src_left, src_right], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master4\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master4\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master4\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:1275\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[1;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m   1261\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[0;32m   1262\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[0;32m   1263\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1272\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[0;32m   1273\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[0;32m   1274\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1275\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1277\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1278\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1279\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1284\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[0;32m   1287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master4\\Lib\\site-packages\\torch\\nn\\functional.py:5533\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[1;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m   5530\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbmm(attn_output_weights, v)\n\u001b[0;32m   5532\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(tgt_len \u001b[38;5;241m*\u001b[39m bsz, embed_dim)\n\u001b[1;32m-> 5533\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_proj_bias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5534\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mview(tgt_len, bsz, attn_output\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m   5536\u001b[0m \u001b[38;5;66;03m# optionally average attention weights over heads\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "config['differentiable'] = True\n",
    "config['flexible'] = True\n",
    "config[\"prior_type\"] = \"mlp\"\n",
    "config[\"sampling\"] = \"mnd\"\n",
    "#del config['differentiable_hyperparameters']['sampling']\n",
    "config[\"data_sample_func\"] = \"mnd\"\n",
    "\n",
    "config['multiclass_type'] = 'balance'\n",
    "config[\"is_causal\"] = False\n",
    "if \"is_causal\" in config['differentiable_hyperparameters']:\n",
    "    del config['differentiable_hyperparameters']['is_causal']\n",
    "if 'multiclass_type' in config['differentiable_hyperparameters']:\n",
    "    del config['differentiable_hyperparameters']['multiclass_type']\n",
    "\n",
    "if \"block_wise_dropout\" in config['differentiable_hyperparameters']:\n",
    "    del config['differentiable_hyperparameters']['block_wise_dropout']\n",
    "config[\"block_wise_dropout\"] = False\n",
    "\n",
    "\n",
    "\n",
    "config['hist_targets'] = False\n",
    "config['y_std'] = 1\n",
    "config['min_depth'] = 5\n",
    "config['max_depth'] = 15\n",
    "config['num_classes'] = 2\n",
    "config[\"max_num_classes\"] = 2\n",
    "\n",
    "\n",
    "config[\"align_majority\"] = False\n",
    "config[\"limit_imbalance\"] = False\n",
    "config[\"verbose\"] = True\n",
    "\n",
    "config[\"mlp_noise\"] = True\n",
    "for scale in [3,1,0.1]:\n",
    "    \n",
    "    config['differentiable_hyperparameters']['noise_std'] = {'distribution': 'uniform', 'min': 0.001, 'max': 0.0001}#{'distribution': 'meta_trunc_norm_log_scaled', 'max_mean': 0.0001, 'min_mean': 0.00001, 'round': False, 'lower_bound': 0.0}\n",
    "    config['differentiable_hyperparameters'][\"prior_mlp_dropout_prob\"] = {'distribution': 'uniform', 'min': 0.1, 'max': 0.5} #{'distribution': 'meta_beta', 'scale': scale, 'min': 0.01, 'max': 0.1}\n",
    "    config['differentiable_hyperparameters'][\"prior_mlp_hidden_dim\"] = {'distribution': 'uniform_int', 'min': 10, 'max': 50}#{'distribution': 'meta_gamma', 'max_alpha': 3, 'max_scale': 100, 'round': True, 'lower_bound': 25}\n",
    "    config['differentiable_hyperparameters'][\"num_layers\"] = {'distribution': 'uniform_int', 'min': 3, 'max': 5}\n",
    "    #config[\"epoch_frac\"] = e/maxepo\n",
    "    config_sample = evaluate_hypers(config)\n",
    "    model = get_model(config_sample, device, should_train=False, verbose=2)\n",
    "    dl = model[3]\n",
    "    rocs = []\n",
    "    means = []\n",
    "    for i in range(100):\n",
    "        #print(f\"\\n\\n\\nRun #{i}\")\n",
    "        x, y = get_sample(dl)\n",
    "        x, y = torch.squeeze(x).numpy(), torch.squeeze(y).numpy()\n",
    "        #print((x[:,np.sum(np.abs(x), axis=0)==0]).shape)\n",
    "        #print(np.unique(y, return_counts=True))\n",
    "        #if len(np.unique(y, return_counts=True)[0])<2: print(\"HERE FUZCKSNDKSHFKHSFG!!!!!!!!!###########################################################################################################################################\\n\\n\")\n",
    "        means.append(np.mean(y))\n",
    "        if len(np.unique(y, return_counts=True)[0])>1 and np.min(np.unique(y, return_counts=True)[1])>1:\n",
    "            #print(\"Target mean: \", torch.mean(y))\n",
    "            #plt.hist(y, bins=100)\n",
    "            #plt.show()\n",
    "            cv = 3\n",
    "            n_optim = 100\n",
    "            ft_epochs = 0\n",
    "            sampling = None\n",
    "            strat_split=True\n",
    "            max_samples = 1024\n",
    "            metrics = metrics = [\"roc_auc\"]#\"roc_auc_ovr\"]\n",
    "            if config['num_classes'] ==2:\n",
    "                o = 'binary:logistic'\n",
    "            else:\n",
    "                o = 'multi:softmax'\n",
    "            #model = XGBClassifier(n_estimators=10, max_depth=10, learning_rate=1, objective=o)#\n",
    "            #model = XGBoostOptim(n_optim=n_optim)\n",
    "            model = TabPFNClassifier(device='cpu', N_ensemble_configurations=3)\n",
    "            results,_ = cross_validate_sample(model, x, y, metrics, strat_split, cv, sampling, max_samples=max_samples)\n",
    "            #print(results[0])\n",
    "            rocs.append(results[0])\n",
    "            print(\"ROC: \", results[0])\n",
    "    print(\"ROC: \", np.mean(np.array(rocs)), np.std(np.array(rocs)))\n",
    "    print(\"Pred avgs: \", np.mean(np.array(means)))\n",
    "    #result_matrix[ii,jj] = np.mean(np.array(rocs))\n",
    "    plt.hist(rocs, bins=20)\n",
    "    plt.show()\n",
    "    bins = np.arange(0,102,3)*1e-2\n",
    "    plt.hist(means, bins=bins)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3668474-a2cf-403d-8bb8-4d76ba6063d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = []\n",
    "means = []\n",
    "for i in range(1000):\n",
    "    #print(f\"\\n\\n\\nRun #{i}\")\n",
    "    x, y = get_sample(dl)\n",
    "    #print(x[0])\n",
    "    #print(np.unique(y, return_counts=True))\n",
    "    x, y = torch.squeeze(x), torch.squeeze(y)\n",
    "    preds = torch.full(y.shape, torch.argmax(torch.unique(y, return_counts=True)[1]).item())\n",
    "    accuracy = torch.mean((preds==y)[y!=-100].float())\n",
    "    means.append(max(1-np.mean(y),np.mean(y)))\n",
    "    accs.append(accuracy)\n",
    "print(torch.mean(torch.tensor(accs)))\n",
    "print(torch.mean(torch.tensor(means)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb27a55-0322-4121-a7ba-f3380dfb2a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50,100,1):\n",
    "    print(f\"ROC sub {i*0.01} pred\",  np.mean(np.array(rocs)[np.array(means)<i*0.01]), len(np.array(rocs)[np.array(means)<i*0.01])/len(means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c363a4-132d-4c4b-9fd2-0f99eb63f4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8a0922-d04c-43e6-a2d5-fd3745858bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(means,rocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff1fee4-f743-4630-b62c-4a02b0880158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358a4488-dda9-43b0-890f-ab7ccd92a306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multinomial_dirichlet(size=(1000,100)):\n",
    "    M = 1000\n",
    "    alphas = np.random.beta(1,1,size[1])\n",
    "    thetas = [np.random.dirichlet(alphas) for i in range(size[0])]\n",
    "    #print(thetas, np.sum(thetas))\n",
    "    X = np.asarray([np.random.multinomial(M, theta)/M for theta in thetas])\n",
    "    return X\n",
    "X = multinomial_dirichlet()\n",
    "print(X[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc87ccf7-5976-483f-9eb4-41036e9d97c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f721f19-7023-4436-b374-886651722f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def get_sample(config_sample, prior_hyperparameters):\n",
    "    def eval_pos_seq_len_sampler():\n",
    "        single_eval_pos_gen = get_uniform_single_eval_pos_sampler(config.get('max_eval_pos', config['bptt']), min_len=config.get('min_eval_pos', 0))\n",
    "        single_eval_pos = single_eval_pos_gen()\n",
    "        return single_eval_pos, 1024\n",
    "    ''extra_prior_kwargs_dict={\n",
    "        'num_features': config['num_features'], \n",
    "        'hyperparameters': prior_hyperparameters\n",
    "    }\n",
    "    extra_kwargs = {}\n",
    "    if 'flexible' in config and config['flexible']:\n",
    "        get_batch_base = make_get_batch(model_proto)\n",
    "        extra_kwargs['get_batch'] = get_batch_base\n",
    "        model_proto = priors.flexible_categorical\n",
    "    if 'differentiable' in prior_hyperparameters and prior_hyperparameters['differentiable']:\n",
    "        get_batch_base = make_get_batch(model_proto, **extra_kwargs)\n",
    "        extra_kwargs = {'get_batch': get_batch_base, 'differentiable_hyperparameters': prior_hyperparameters['differentiable_hyperparameters']}\n",
    "        model_proto = priors.differentiable_prior\n",
    "        use_style = True\n",
    "    \n",
    "    dl = model_proto.DataLoader(num_steps=1, batch_size=1, \n",
    "                                eval_pos_seq_len_sampler=eval_pos_seq_len_sampler, \n",
    "                                seq_len_maximum=None, device=\"cpu\", **extra_prior_kwargs_dict)''\n",
    "    dl_class, extra_kwargs = get_dataloader(config_sample, device=\"cpu\", should_train=False, verbose=2)\n",
    "    dl = model_proto.DataLoader(num_steps=1, batch_size=1, \n",
    "                                eval_pos_seq_len_sampler=eval_pos_seq_len_sampler, \n",
    "                                seq_len_maximum=None, device=\"cpu\", **extra_kwargs)\n",
    "    dl.model = None\n",
    "    return next(iter(dl))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a955c12a-56e9-4895-a9af-07226073cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_sample(config_sample, prior_hyperparameters)\n",
    "print(a[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c161bd-ec80-43ac-b3a9-21011eec1d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['differentiable'] = False\n",
    "config['flexible'] = False\n",
    "\n",
    "# forest params\n",
    "config[\"min_features\"] = 10\n",
    "config[\"max_features\"] = 100\n",
    "config[\"n_samples\"] = 1000\n",
    "config[\"max_classes\"] = 10\n",
    "config[\"base_size\"] = 1000\n",
    "config[\"n_estimators\"] = 1\n",
    "config[\"min_depth\"] = 1\n",
    "config[\"max_depth\"] = 25\n",
    "config[\"categorical_x\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af348aba-7927-4722-829b-2b9067bec073",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "from tabpfn import TabPFNClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from evaluate import scores\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, precision_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from data_prep_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import openml\n",
    "from tabularbench.data.synthetic_generator_forest import synthetic_dataset_generator_forest, synthetic_dataset_function_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5561d98a-122c-46a3-b816-198a5c986552",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabularbench.data.synthetic_generator_tabpfn import synthetic_dataset_generator_tabpfn\n",
    "\n",
    "fig, axes = plt.subplots(8, 6, figsize=(20, 15))\n",
    "generator = synthetic_dataset_generator_tabpfn(n_samples=1000, max_classes=2, min_features=2, max_features=100)\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    x2, b = next(generator)\n",
    "    i1, i2 = np.random.choice(x2.shape[1], size=(2,), replace=False)\n",
    "    ax.scatter(x2[:, i1], x2[:, i2], c=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2a893a-7167-4aa4-a2df-513182935798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabularbench.data.synthetic_generator_forest import synthetic_dataset_generator_forest, synthetic_dataset_function_forest\n",
    "import matplotlib\n",
    "\n",
    "fig, axes = plt.subplots(8, 6, figsize=(20, 15))\n",
    "generator = synthetic_dataset_generator_forest(n_samples=1000, max_classes=2, min_features=2, max_features=2)\n",
    "\n",
    "cmap = matplotlib.colormaps['inferno']\n",
    "colors = cmap(np.linspace(0.0, 0.9, 10))\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    x2, b = synthetic_dataset_function_forest(base_size=1000, min_features=2, max_features=2, max_classes=3, min_depth=1, max_depth=25, categorical_x=True, n_samples=1024)\n",
    "    i1, i2 = np.random.choice(x2.shape[1], size=(2,), replace=False)\n",
    "    random_shuffle = np.random.permutation(np.arange(10))\n",
    "    colors_shuffle = colors[random_shuffle]\n",
    "    #b = np.array([colors_shuffle[i] for i in b])\n",
    "    ax.scatter(x2[:, i1], x2[:, i2], c=b)\n",
    "    ax.tick_params(axis='both', which='both', bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be43c36-ca72-4cb4-9cd4-72a59b27d90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zinb(size=(1000,100)):\n",
    "    pi = 0.25\n",
    "    p = np.random.uniform(0.1,0.9, size=size[1])\n",
    "    p = np.repeat(np.expand_dims(p,axis=0),size[0],axis=0)\n",
    "    #print\n",
    "    #p += 1e-5\n",
    "    X = np.random.negative_binomial(100,p)\n",
    "    X = np.random.binomial(1,1-pi,size)*X\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08769738-e744-49cc-98c2-206e3bb9d5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zinb_comp(size=(1000,100)):\n",
    "    X =  zinb(size)\n",
    "    print(X)\n",
    "    print(np.expand_dims(1/np.sum(X,axis=1),axis=1))\n",
    "    return np.expand_dims(1/np.sum(X,axis=1),axis=1)*X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada8a9e9-6a99-4d92-b869-ae69bdc53cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = zinb_comp((10,10))\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ed9025-1fb0-4732-b3b7-ee311b528e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(out, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c62c558-446d-42bf-a2a3-39ed3b4a9c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prior.synthetic_generator_forest_altdata import synthetic_dataset_generator_forest_altdata, synthetic_dataset_function_forest_altdata\n",
    "\n",
    "fig, axes = plt.subplots(8, 6, figsize=(20, 15))\n",
    "\n",
    "cmap = matplotlib.colormaps['inferno']\n",
    "colors = cmap(np.linspace(0.0, 0.9, 10))\n",
    "\n",
    "\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    x2, b = synthetic_dataset_function_forest_altdata(zinb,base_size=1000, min_features=2, max_features=2, max_classes=3, min_depth=1, max_depth=25, categorical_x=True, n_samples=1024)\n",
    "    i1, i2 = np.random.choice(x2.shape[1], size=(2,), replace=False)\n",
    "    random_shuffle = np.random.permutation(np.arange(10))\n",
    "    colors_shuffle = colors[random_shuffle]\n",
    "    #b = np.array([colors_shuffle[i] for i in b])\n",
    "    ax.scatter(x2[:, i1], x2[:, i2], c=b)\n",
    "    ax.tick_params(axis='both', which='both', bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b35c21-16e3-44e8-80df-dd5de8fc536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_norm, b_norm = synthetic_dataset_function_forest(base_size=1000, min_features=2, max_features=2, max_classes=3, min_depth=1, max_depth=25, categorical_x=True, n_samples=1024)\n",
    "\n",
    "X_zinb, b_zinb = synthetic_dataset_function_forest_altdata(zinb,base_size=1000, min_features=2, max_features=2, max_classes=3, min_depth=1, max_depth=25, categorical_x=True, n_samples=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68200361-d086-41a0-8af3-ad83c009298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, roc_auc_score\n",
    "accuracy = np.zeros((3))\n",
    "runs = 10\n",
    "for ii in range(runs):\n",
    "    X_norm, b_norm = synthetic_dataset_function_forest(base_size=1000, min_features=2, max_features=2, max_classes=3, min_depth=1, max_depth=25, categorical_x=True, n_samples=1024)\n",
    "    models = [XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic'), \n",
    "              LogisticRegression(max_iter=500), \n",
    "              TabPFNClassifier(device='cpu', N_ensemble_configurations=3)]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_norm, b_norm, test_size=0.2, random_state=42)\n",
    "    for mm, model in enumerate(models):\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy[mm] += accuracy_score(y_test,y_pred)\n",
    "print(accuracy/runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248ed978-b1b6-46ee-9233-e91434632ae2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, roc_auc_score\n",
    "accuracy = np.zeros((3))\n",
    "runs = 10\n",
    "for ii in range(runs):\n",
    "    print(ii)\n",
    "    X_zinb, b_zinb = synthetic_dataset_function_forest_altdata(zinb,base_size=1000, min_features=2, max_features=2, max_classes=3, min_depth=1, max_depth=25, categorical_x=True, n_samples=1024)\n",
    "    models = [XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic'), \n",
    "              LogisticRegression(max_iter=500), \n",
    "              TabPFNClassifier(device='cpu', N_ensemble_configurations=3)]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_zinb, b_zinb, test_size=0.2, random_state=42)\n",
    "    for mm, model in enumerate(models):\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy[mm] += accuracy_score(y_test,y_pred)\n",
    "print(accuracy/runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa159333-33a1-4941-9ea3-31ab11dfcca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e818c922-3e6d-4443-884a-9fb01aa1db39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
