{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "716a0985-a3e5-47be-acc6-d58fb95fa8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from tabpfn_new.scripts.transformer_prediction_interface import TabPFNClassifier, MedPFNClassifier\n",
    "from tabpfn_new.scripts.model_builder import load_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from data_prep_utils import *\n",
    "from evaluate import *\n",
    "from load_models import *\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import openml\n",
    "import time\n",
    "import matplotlib as mpl\n",
    "#from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "pd.set_option('display.expand_frame_repr', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0e72742-f9d3-4748-939e-0aee908e04c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"datasets/data_all.csv\"\n",
    "all_data, labels = get_microbiome(path)\n",
    "all_data = remove_zero_features(all_data)\n",
    "all_data, labels = unison_shuffled_copies(all_data, labels, seed=42)\n",
    "#all_data = top_anova(all_data, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10a5130-cda2-47ab-a5c2-70a2840cfa1d",
   "metadata": {},
   "source": [
    "## Baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "adae1ec9-3ead-4f70-8f11-8936c9783725",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " AnovaSelect \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.946         0.000           0.000          0.000        0.000       0.000         0.500        0.000    0.000   0.000         0.000        0.000\n",
      "XGBClassifier                         0.948         0.010           0.463          0.206        0.317       0.203         0.848        0.081    0.364   0.195         0.027        0.032\n",
      "MedPFNClassifier                      0.955         0.013           0.679          0.225        0.433       0.111         0.919        0.052    0.511   0.125         3.083        0.237\n",
      "RandomForestClassifier                0.951         0.012           0.347          0.372        0.200       0.233         0.902        0.059    0.249   0.278         0.184        0.011\n",
      "LogisticRegressionClassifier          0.939         0.014           0.393          0.245        0.217       0.150         0.825        0.096    0.269   0.169         0.006        0.001\n",
      "TabPFNClassifier                      0.946         0.018           0.373          0.397        0.200       0.194         0.906        0.057    0.259   0.261         2.557        0.140\n"
     ]
    }
   ],
   "source": [
    "save = False\n",
    "sampling = None\n",
    "cv = 10\n",
    "best_delete = 0\n",
    "strat_split = True\n",
    "recomp = False\n",
    "n_optim = 1000\n",
    "cat_optim = 10\n",
    "ft_epochs = 5\n",
    "ft_epochs_forest = 10\n",
    "ft_lr = 1e-5\n",
    "max_s = 1024\n",
    "max_q = 128\n",
    "max_samples = 1024\n",
    "no_pre_process = False\n",
    "multi_decoder = \"permutation\"\n",
    "N_ens = 10\n",
    "seed = 42\n",
    "overwrite = True\n",
    "metrics = [\"accuracy\", \"precision\", \"recall\", \"roc_auc\", \"f1\"]\n",
    "dir_path = os.path.abspath(os.getcwd())\n",
    "#run_name = \"medium_net_mlp_balance_bsplit_baseline\" ## NO PERM, VERY ROBUST\n",
    "#run_name2 = \"large_mlp_var_balance_05weight_anova\" ## das aller bestigste\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_newprior\" ## das aller bestigste\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_newprior\" ## das aller bestigste\n",
    "run_name = \"small_mlp_var_balance_05weight_anova_bestwithnoisebnn_100\" ## good start, best with ft\n",
    "#run_name = \"large_mlp_var_balance_05weight_anova_bestwithnoisebnn_100_moreweight\" ## best start, ft no so good\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_200\" ## das aller bestigste\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_longer\" ## das aller bestigste\n",
    "#run_name = \"medium_mlp_balance_lownoisefixparam_anova\"\n",
    "#run_name = \"medium_mlp_0.5static_balance_anova\"\n",
    "#run_name = \"large_mlp_fullbalance\"\n",
    "#run_name = \"small_net_mlp_var_imbalance_05weight\" ## WORKS VERY WELL WITH PERM\n",
    "#run_name = \"small_net_mlp_varbalance_weight_batchunisplit\"\n",
    "#run_name = \"small_net_mlp_variable_balance_weight\"\n",
    "#run_name = \"small_net_mlp_balance_minevalup\"\n",
    "path = dir_path + f\"/logs/trainrun_{run_name}\"\n",
    "#path2 = dir_path + f\"/logs/trainrun_{run_name2}\"\n",
    "#path3 = dir_path + f\"/logs/trainrun_{run_name3}\"\n",
    "filename = \"model\"\n",
    "\n",
    "\n",
    "\n",
    "models = [\n",
    "    MajorityClass(),\n",
    "    XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic'),\n",
    "    #MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=1, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process),\n",
    "    #MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process),\n",
    "    MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process,\n",
    "                    ft_epochs=ft_epochs, ft_lr=ft_lr),\n",
    "    RandomForestClassifier(),\n",
    "    #AutoGluon(),\n",
    "    #CatBoostGrid(),\n",
    "    #XGBoostGrid(),\n",
    "    LogisticRegressionClassifier(), \n",
    "    TabPFNClassifier(device='cpu', N_ensemble_configurations=5, no_preprocess_mode=no_pre_process),\n",
    "    #TabForestPFNClassifier(\"saved_models/tabforest/mix600k/tabforestpfn.pt\", \"saved_models/tabforest/mix600k/config_run.yaml\", max_epochs=ft_epochs_forest)\n",
    "]\n",
    "reducer  = AnovaSelect()\n",
    "\n",
    "\n",
    "results_mean = pd.DataFrame(np.zeros((len(models), len(metrics)+1)),\n",
    "                            index=[m.__class__.__name__ for m in models],\n",
    "                            columns=metrics+[\"runtime\"])\n",
    "results_std = pd.DataFrame(np.zeros((len(models), len(metrics)+1)), \n",
    "                           index=[m.__class__.__name__ for m in models],\n",
    "                           columns=metrics+[\"runtime\"])\n",
    "\n",
    "for ii, model in enumerate(models):\n",
    "    results_mean.iloc[ii,:], results_std.iloc[ii,:] = cross_validate_sample(\n",
    "        model, all_data, labels, metrics, strat_split, cv, sampling, \n",
    "        reducer, max_samples, seed=seed, overwrite=overwrite, n_best_delete=best_delete,\n",
    "        recomp=recomp)\n",
    "\n",
    "results_mean = results_mean.add_suffix(\" mean\")\n",
    "results_std = results_std.add_suffix(\" std\")\n",
    "results_full = pd.concat((results_mean, results_std), axis=1)\n",
    "cols = results_full.columns.tolist()\n",
    "new_cols = []\n",
    "for i in range(int(len(cols)/2)):\n",
    "    new_cols.append(cols[i])\n",
    "    new_cols.append(cols[i+int(len(cols)/2)])\n",
    "results_full = results_full[new_cols]\n",
    "red_name = reducer.__class__.__name__\n",
    "if save:\n",
    "    directory = f\"results/{red_name}\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    save_path = f'results/{red_name}/baseline_cv{cv}_mxsamp{max_samples}_sd{seed}_ovrw{int(overwrite)}.csv'\n",
    "    results_full.to_csv(save_path)\n",
    "print(\"\\n\", \"\\n\", red_name, \"\\n\", results_full.round(3))\n",
    "#print(results_full.sort_values(\"roc_auc mean\").round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6c7211-581b-426c-b21f-eaa6988627f1",
   "metadata": {},
   "source": [
    "## Baseline Repeated cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c2cbf3b4-c737-4652-a371-ec8d3608a1e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1145, 1391) 1137.0\n",
      "Step:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "save = False\n",
    "sampling = None\n",
    "cv = 10\n",
    "best_delete = 0\n",
    "strat_split = True\n",
    "recomp = False\n",
    "n_optim = 1000\n",
    "cat_optim = 10\n",
    "ft_epochs = 10\n",
    "ft_epochs_forest = 10\n",
    "ft_lr = 1e-5\n",
    "max_s = 1024\n",
    "max_q = 128\n",
    "max_samples = 1024\n",
    "no_pre_process = False\n",
    "multi_decoder = \"permutation\"\n",
    "N_ens = 10\n",
    "seed = 42\n",
    "overwrite = True\n",
    "metrics = [\"accuracy\", \"precision\", \"recall\", \"roc_auc\", \"f1\"]\n",
    "dir_path = os.path.abspath(os.getcwd())\n",
    "#run_name = \"medium_net_mlp_balance_bsplit_baseline\" ## NO PERM, VERY ROBUST\n",
    "#run_name2 = \"large_mlp_var_balance_05weight_anova\" ## das aller bestigste\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_newprior\" ## das aller bestigste\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_newprior\" ## das aller bestigste\n",
    "run_name = \"small_mlp_var_balance_05weight_anova_bestwithnoisebnn_100\" ## good start, best with ft\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_bestwithnoisebnn_100\" ## good start, best with ft\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_bestwithnoisebnn_100_moreweight\" ## best start, ft no so good\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_200\" ## das aller bestigste\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_longer\" ## das aller bestigste\n",
    "#run_name = \"medium_mlp_balance_lownoisefixparam_anova\"\n",
    "#run_name = \"medium_mlp_0.5static_balance_anova\"\n",
    "#run_name = \"large_mlp_fullbalance\"\n",
    "#run_name = \"small_net_mlp_var_imbalance_05weight\" ## WORKS VERY WELL WITH PERM\n",
    "#run_name = \"small_net_mlp_varbalance_weight_batchunisplit\"\n",
    "#run_name = \"small_net_mlp_variable_balance_weight\"\n",
    "#run_name = \"small_net_mlp_balance_minevalup\"\n",
    "path = dir_path + f\"/logs/trainrun_{run_name}\"\n",
    "#path2 = dir_path + f\"/logs/trainrun_{run_name2}\"\n",
    "#path3 = dir_path + f\"/logs/trainrun_{run_name3}\"\n",
    "filename = \"model\"\n",
    "\n",
    "\n",
    "\n",
    "models = [\n",
    "    #MajorityClass(),\n",
    "    #XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic'),\n",
    "    #MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=1, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process),\n",
    "    #MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process),\n",
    "    #MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process,\n",
    "    #                ft_epochs=ft_epochs, ft_lr=ft_lr),\n",
    "    #RandomForestClassifier(),\n",
    "    #AutoGluon(),\n",
    "    CatBoostGrid(),\n",
    "    XGBoostGrid(),\n",
    "    #LogisticRegressionClassifier(), \n",
    "    #TabPFNClassifier(device='cpu', N_ensemble_configurations=5, no_preprocess_mode=no_pre_process),\n",
    "    #TabForestPFNClassifier(\"saved_models/tabforest/mix600k/tabforestpfn.pt\", \"saved_models/tabforest/mix600k/config_run.yaml\", max_epochs=ft_epochs_forest)\n",
    "]\n",
    "reducer  = AnovaSelect()\n",
    "\n",
    "\n",
    "results_mean = pd.DataFrame(np.zeros((len(models), len(metrics)+1)),\n",
    "                            index=[m.__class__.__name__ for m in models],\n",
    "                            columns=metrics+[\"runtime\"])\n",
    "results_std = pd.DataFrame(np.zeros((len(models), len(metrics)+1)), \n",
    "                           index=[m.__class__.__name__ for m in models],\n",
    "                           columns=metrics+[\"runtime\"])\n",
    "\n",
    "size = min(labels.shape[0],np.floor(max_samples*(cv/(cv-1))))\n",
    "runs = int(all_data.shape[0]//size)\n",
    "data_sections, label_sections = stratified_split(all_data, labels,cv=runs)\n",
    "print(np.array(data_sections).shape, size)\n",
    "\n",
    "for section in range(runs):\n",
    "    print(\"Step: \", section)\n",
    "    for ii, model in enumerate(models):\n",
    "        out_mean, out_std = cross_validate_sample(\n",
    "            model, data_sections[section], label_sections[section], metrics, strat_split, cv, sampling, \n",
    "            reducer, max_samples, seed=seed, overwrite=overwrite, n_best_delete=best_delete,\n",
    "            recomp=recomp)\n",
    "        results_mean.iloc[ii,:] += out_mean\n",
    "        results_std.iloc[ii,:] += out_std \n",
    "    \n",
    "results_mean = results_mean.add_suffix(\" mean\")\n",
    "results_std = results_std.add_suffix(\" std\")\n",
    "results_full = pd.concat((results_mean, results_std), axis=1)\n",
    "cols = results_full.columns.tolist()\n",
    "new_cols = []\n",
    "for i in range(int(len(cols)/2)):\n",
    "    new_cols.append(cols[i])\n",
    "    new_cols.append(cols[i+int(len(cols)/2)])\n",
    "results_full = results_full[new_cols]\n",
    "results_full = results_full/runs\n",
    "red_name = \"repeated_cv\"\n",
    "if save:\n",
    "    directory = f\"results/{red_name}\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    save_path = f'results/{red_name}/baseline_cv{cv}_mxsamp{max_samples}_sd{seed}_ovrw{int(overwrite)}.csv'\n",
    "    results_full.to_csv(save_path)\n",
    "print(\"\\n\", \"\\n\", red_name, \"\\n\", results_full.round(3))\n",
    "#print(results_full.sort_values(\"roc_auc mean\").round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "4a6a78a6-8bac-461d-b9e3-8f2ad2a2fb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['MedPFNClassifier' 'MedPFNClassifier' 'MedPFNClassifier'\n",
      " 'RandomForestClassifier' 'LogisticRegressionClassifier'\n",
      " 'TabPFNClassifier' 'TabForestPFNClassifier']\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_path = f'results/repeated_cv/baseline_cv10_mxsamp1024_sd42_ovrw1.csv'\n",
    "data = pd.read_csv(save_path)\n",
    "fig, axs = plt.subplots(3, 1, figsize=(8, 5), dpi=100, sharex=True)\n",
    "print()\n",
    "# Plot error bar plots in each subplot\n",
    "models = data.iloc[:,0].values\n",
    "colors = [\"gold\", \"darkorange\", \"crimson\", \"yellowgreen\", \"teal\", \"royalblue\", \"purple\"]\n",
    "print(models)\n",
    "x = np.arange(len(data.iloc[:,1].values))\n",
    "for i in range(7):\n",
    "    axs[0].set_xticks([])\n",
    "    axs[0].set_xlim(-1,7)\n",
    "    axs[0].errorbar(x[i], data.iloc[i,1], yerr=data.iloc[i,2], fmt='+', mew=2, lw=2, markersize=12, capsize=0, color=colors[i], label=models[i])\n",
    "    axs[0].set_ylabel(\"Accuracy\")\n",
    "    \n",
    "    axs[1].errorbar(x[i], data.iloc[i,7], yerr=data.iloc[i,8], fmt='+', mew=2, lw=2, markersize=12, capsize=0, color=colors[i])\n",
    "    axs[1].set_ylabel(\"ROC AUC\")\n",
    "    #axs[1].legend()\n",
    "    \n",
    "    axs[2].errorbar(x[i], data.iloc[i,9], yerr=data.iloc[i,10], fmt='+', mew=2, lw=2, markersize=12, capsize=0, color=colors[i])\n",
    "    axs[2].set_ylabel(r\"$F_1$-score\")\n",
    "    #axs[2].legend()\n",
    "    \n",
    "    #axs[3].errorbar(x[i], data.iloc[i,7], yerr=data.iloc[i,8], fmt='+', mew=2, lw=2, markersize=12, capsize=0, color=colors[i])\n",
    "    #axs[3].set_ylabel(\"\")\n",
    "    #axs[3].legend()\n",
    "    \n",
    "    # Set common x-axis label\n",
    "    #axs[3].set_xlabel(\"X-axis\")\n",
    "\n",
    "inds = [1,7,9]\n",
    "for j in range(3):\n",
    "    axs[j].hlines(np.max(data.iloc[:,inds[j]].values),-1,7, lw=1, colors=colors[np.argmax(data.iloc[:,1+2*j].values)], linestyles=\"dashed\")\n",
    "    #axs[j].grid()\n",
    "axs[j].hlines(0,0,0,linestyles=\"dashed\", colors=[\"gray\"], label=\"Highest (color of winner)\")\n",
    "axs[0].set_ylim(0.9,0.97)\n",
    "fig.legend(loc='upper center', bbox_to_anchor=(0.5, 1.1),\n",
    "          ncol=3, fancybox=True, shadow=True)\n",
    "# Adjust layout to prevent overlap\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4906d353-1d35-4139-babd-0a320b4bc376",
   "metadata": {},
   "source": [
    "## Mine vs static vs normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31180d61-b1bb-4e55-a0ad-c1b64197bb49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " nomethodscompare \n",
      "                   accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MedPFNClassifier          0.956         0.008           0.663          0.143        0.400       0.153         0.917        0.061    0.485   0.111         7.780        0.467\n",
      "MedPFNClassifier          0.875         0.024           0.267          0.058        0.733       0.133         0.890        0.055    0.389   0.074         8.428        0.954\n",
      "MedPFNClassifier          0.930         0.012           0.404          0.089        0.617       0.198         0.908        0.048    0.475   0.108         7.840        0.623\n"
     ]
    }
   ],
   "source": [
    "save = True\n",
    "sampling = None\n",
    "cv = 10\n",
    "best_delete = 0\n",
    "strat_split = True\n",
    "recomp = False\n",
    "n_optim = 1000\n",
    "cat_optim = 10\n",
    "ft_epochs = 20\n",
    "ft_epochs_forest = 10\n",
    "ft_lr = 1e-5\n",
    "max_s = 1024\n",
    "max_q = 128\n",
    "max_samples = 1024\n",
    "no_pre_process = False\n",
    "multi_decoder = \"permutation\"\n",
    "N_ens = 5\n",
    "seed = 42\n",
    "overwrite = True\n",
    "metrics = [\"accuracy\", \"precision\", \"recall\", \"roc_auc\", \"f1\"]\n",
    "dir_path = os.path.abspath(os.getcwd())\n",
    "run_name = \"medium_mlp_var_balance_05weight_anova_bestwithnoisebnn_100\" \n",
    "run_name2 = \"medium_mlp_static_balance_05weight_anova_bestwithnoisebnn_100\" \n",
    "run_name3 = \"medium_mlp_var_balance_05weight_anova_bestwithnoisebnn_100_normalprior\" \n",
    "path = dir_path + f\"/logs/trainrun_{run_name}\"\n",
    "path2 = dir_path + f\"/logs/trainrun_{run_name2}\"\n",
    "path3 = dir_path + f\"/logs/trainrun_{run_name3}\"\n",
    "filename = \"model\"\n",
    "\n",
    "\n",
    "models = [\n",
    "    \n",
    "    #MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process),\n",
    "    #MedPFNClassifier(base_path=path2, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process),\n",
    "    #MedPFNClassifier(base_path=path3, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process),\n",
    "    MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process, ft_epochs=ft_epochs, ft_lr=ft_lr),\n",
    "    MedPFNClassifier(base_path=path2, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process,ft_epochs=ft_epochs, ft_lr=ft_lr),\n",
    "    MedPFNClassifier(base_path=path3, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process,ft_epochs=ft_epochs, ft_lr=ft_lr),\n",
    "]\n",
    "reducer  = AnovaSelect()\n",
    "#for reducer in [AnovaSelect(), RandomSelect(), NonZeroSelect(), MeanSelect(), StdSelect(), MaxSelect(), PCASelect()]:\n",
    "#data = clr(all_data)\n",
    "\n",
    "#all_data = normalize(all_data)\n",
    "\n",
    "results_mean = pd.DataFrame(np.zeros((len(models), len(metrics)+1)),\n",
    "                            index=[m.__class__.__name__ for m in models],\n",
    "                            columns=metrics+[\"runtime\"])\n",
    "results_std = pd.DataFrame(np.zeros((len(models), len(metrics)+1)), \n",
    "                           index=[m.__class__.__name__ for m in models],\n",
    "                           columns=metrics+[\"runtime\"])\n",
    "\n",
    "for ii, model in enumerate(models):\n",
    "    results_mean.iloc[ii,:], results_std.iloc[ii,:] = cross_validate_sample(\n",
    "        model, all_data, labels, metrics, strat_split, cv, sampling, \n",
    "        reducer, max_samples, seed=seed, overwrite=overwrite, n_best_delete=best_delete,\n",
    "        recomp=recomp)\n",
    "\n",
    "results_mean = results_mean.add_suffix(\" mean\")\n",
    "results_std = results_std.add_suffix(\" std\")\n",
    "results_full = pd.concat((results_mean, results_std), axis=1)\n",
    "cols = results_full.columns.tolist()\n",
    "new_cols = []\n",
    "for i in range(int(len(cols)/2)):\n",
    "    new_cols.append(cols[i])\n",
    "    new_cols.append(cols[i+int(len(cols)/2)])\n",
    "results_full = results_full[new_cols]\n",
    "red_name = \"nomethodscompare\"\n",
    "if save:\n",
    "    directory = f\"results/{red_name}\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    save_path = f'results/{red_name}/results_1mine_2staticbal_3normalprior.csv'\n",
    "    results_full.to_csv(save_path)\n",
    "print(\"\\n\", \"\\n\", red_name, \"\\n\", results_full.round(3))\n",
    "#print(results_full.sort_values(\"roc_auc mean\").round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c65c8e1-8f50-4735-bb45-352f0fb9f1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(save_path)\n",
    "df.round(3).to_csv(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b718491-a7e4-46c1-aeb7-c443398e4379",
   "metadata": {},
   "source": [
    "## Context length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "604773e7-27c7-4417-93a3-204f30d38e5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-03 12:50:52.145\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0856 | Val score: 0.9899\u001b[0m\n",
      "\u001b[32m2024-11-03 12:50:53.350\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1143 | Train score: 0.9625 | Val loss: 0.0760 | Val score: 0.9798\u001b[0m\n",
      "\u001b[32m2024-11-03 12:50:54.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2287 | Train score: 0.9500 | Val loss: 0.0777 | Val score: 0.9798\u001b[0m\n",
      "\u001b[32m2024-11-03 12:50:55.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0535 | Train score: 0.9875 | Val loss: 0.0791 | Val score: 0.9798\u001b[0m\n",
      "\u001b[32m2024-11-03 12:50:57.045\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1063 | Train score: 0.9625 | Val loss: 0.0797 | Val score: 0.9798\u001b[0m\n",
      "\u001b[32m2024-11-03 12:50:58.178\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0825 | Train score: 0.9625 | Val loss: 0.0783 | Val score: 0.9798\u001b[0m\n",
      "\u001b[32m2024-11-03 12:50:59.371\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0773 | Train score: 0.9625 | Val loss: 0.0760 | Val score: 0.9798\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:00.628\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1248 | Train score: 0.9500 | Val loss: 0.0746 | Val score: 0.9798\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:01.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1030 | Train score: 0.9875 | Val loss: 0.0739 | Val score: 0.9798\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:02.997\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0452 | Train score: 1.0000 | Val loss: 0.0740 | Val score: 0.9798\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:04.216\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1260 | Train score: 0.9625 | Val loss: 0.0749 | Val score: 0.9798\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:05.400\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1245 | Val score: 0.9394\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:06.532\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0982 | Train score: 0.9500 | Val loss: 0.1304 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:07.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1129 | Train score: 0.9500 | Val loss: 0.1298 | Val score: 0.9394\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:08.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0775 | Train score: 0.9750 | Val loss: 0.1294 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:09.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0730 | Train score: 0.9750 | Val loss: 0.1294 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:10.878\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1630 | Train score: 0.9625 | Val loss: 0.1233 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:12.007\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1099 | Train score: 0.9750 | Val loss: 0.1182 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:13.148\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0531 | Train score: 0.9875 | Val loss: 0.1174 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:14.703\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0552 | Train score: 1.0000 | Val loss: 0.1186 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:16.194\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0662 | Train score: 0.9750 | Val loss: 0.1201 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:17.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0317 | Train score: 0.9875 | Val loss: 0.1206 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:18.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1438 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:20.437\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2175 | Train score: 0.9125 | Val loss: 0.1423 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:22.048\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1295 | Train score: 0.9625 | Val loss: 0.1390 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:23.648\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1223 | Train score: 0.9500 | Val loss: 0.1343 | Val score: 0.9596\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:25.372\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1126 | Train score: 0.9375 | Val loss: 0.1315 | Val score: 0.9596\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:26.916\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0534 | Train score: 0.9750 | Val loss: 0.1308 | Val score: 0.9596\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:27.915\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1496 | Train score: 0.9625 | Val loss: 0.1296 | Val score: 0.9596\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:29.094\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0785 | Train score: 0.9750 | Val loss: 0.1288 | Val score: 0.9596\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:30.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0791 | Train score: 0.9375 | Val loss: 0.1290 | Val score: 0.9596\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:31.879\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0765 | Train score: 0.9625 | Val loss: 0.1294 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:33.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0874 | Train score: 0.9875 | Val loss: 0.1298 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:34.757\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1932 | Val score: 0.9293\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:35.910\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0661 | Train score: 0.9625 | Val loss: 0.2173 | Val score: 0.9394\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:36.965\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0932 | Train score: 0.9375 | Val loss: 0.2246 | Val score: 0.9394\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:38.348\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1297 | Train score: 0.9500 | Val loss: 0.2126 | Val score: 0.9394\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:39.402\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1242 | Train score: 0.9750 | Val loss: 0.1979 | Val score: 0.9394\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:40.537\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1150 | Train score: 0.9375 | Val loss: 0.1892 | Val score: 0.9293\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:41.799\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0696 | Train score: 0.9500 | Val loss: 0.1825 | Val score: 0.9394\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:42.847\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0947 | Train score: 0.9625 | Val loss: 0.1746 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:44.349\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0826 | Train score: 0.9750 | Val loss: 0.1711 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:45.773\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0595 | Train score: 1.0000 | Val loss: 0.1726 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:47.174\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0849 | Train score: 0.9625 | Val loss: 0.1734 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:48.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0846 | Val score: 0.9596\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:49.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1933 | Train score: 0.9625 | Val loss: 0.1014 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:51.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1237 | Train score: 0.9375 | Val loss: 0.0884 | Val score: 0.9596\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:52.079\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1338 | Train score: 0.9250 | Val loss: 0.0830 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:53.525\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0745 | Train score: 0.9625 | Val loss: 0.0794 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:54.716\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0975 | Train score: 0.9625 | Val loss: 0.0792 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:55.710\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1549 | Train score: 0.9625 | Val loss: 0.0759 | Val score: 0.9798\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:56.782\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1516 | Train score: 0.9625 | Val loss: 0.0757 | Val score: 0.9798\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:57.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0761 | Train score: 0.9875 | Val loss: 0.0744 | Val score: 0.9798\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:58.779\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1757 | Train score: 0.9625 | Val loss: 0.0731 | Val score: 0.9798\u001b[0m\n",
      "\u001b[32m2024-11-03 12:51:59.839\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0929 | Train score: 0.9625 | Val loss: 0.0719 | Val score: 0.9798\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:00.994\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1358 | Val score: 0.9596\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:02.033\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1084 | Train score: 0.9625 | Val loss: 0.1354 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:03.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0828 | Train score: 0.9500 | Val loss: 0.1401 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:04.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1849 | Train score: 0.9500 | Val loss: 0.1352 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:05.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0742 | Train score: 0.9625 | Val loss: 0.1300 | Val score: 0.9596\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:06.840\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0389 | Train score: 1.0000 | Val loss: 0.1268 | Val score: 0.9596\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:08.215\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1307 | Train score: 0.9125 | Val loss: 0.1218 | Val score: 0.9596\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:09.602\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0568 | Train score: 0.9750 | Val loss: 0.1198 | Val score: 0.9596\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:10.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0664 | Train score: 0.9625 | Val loss: 0.1195 | Val score: 0.9596\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:11.864\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0863 | Train score: 0.9625 | Val loss: 0.1209 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:12.853\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0963 | Train score: 0.9375 | Val loss: 0.1202 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:14.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1258 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:15.624\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1025 | Train score: 0.9500 | Val loss: 0.1273 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:16.970\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1661 | Train score: 0.9500 | Val loss: 0.1235 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:18.400\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0898 | Train score: 0.9500 | Val loss: 0.1210 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:19.459\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1644 | Train score: 0.9750 | Val loss: 0.1206 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:20.503\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0692 | Train score: 0.9750 | Val loss: 0.1211 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:21.603\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0749 | Train score: 0.9875 | Val loss: 0.1220 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:22.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1140 | Train score: 0.9500 | Val loss: 0.1230 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:24.180\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0645 | Train score: 0.9875 | Val loss: 0.1261 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:25.326\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1402 | Train score: 0.9500 | Val loss: 0.1272 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:26.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0536 | Train score: 0.9750 | Val loss: 0.1279 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:27.495\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1959 | Val score: 0.9394\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:28.688\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1255 | Train score: 0.9375 | Val loss: 0.1737 | Val score: 0.9394\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:29.759\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0895 | Train score: 0.9500 | Val loss: 0.1652 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:30.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0777 | Train score: 0.9500 | Val loss: 0.1693 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:32.062\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0476 | Train score: 0.9500 | Val loss: 0.1800 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:33.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0383 | Train score: 1.0000 | Val loss: 0.2019 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:35.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0348 | Train score: 1.0000 | Val loss: 0.2300 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:36.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0800 | Train score: 0.9750 | Val loss: 0.2297 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:38.067\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0913 | Train score: 0.9625 | Val loss: 0.2331 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:39.542\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0860 | Train score: 0.9500 | Val loss: 0.2464 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:40.877\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0186 | Train score: 1.0000 | Val loss: 0.2640 | Val score: 0.9495\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:42.367\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0964 | Val score: 0.9596\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:43.749\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1828 | Train score: 0.9375 | Val loss: 0.0952 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:45.530\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1804 | Train score: 0.9500 | Val loss: 0.1097 | Val score: 0.9596\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:47.376\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1603 | Train score: 0.9125 | Val loss: 0.1175 | Val score: 0.9394\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:49.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1311 | Train score: 0.9250 | Val loss: 0.1150 | Val score: 0.9394\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:50.886\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1296 | Train score: 0.9375 | Val loss: 0.1010 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:52.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1741 | Train score: 0.9375 | Val loss: 0.0987 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:53.425\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0959 | Train score: 0.9500 | Val loss: 0.0944 | Val score: 0.9798\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:54.590\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1215 | Train score: 0.9625 | Val loss: 0.0910 | Val score: 0.9798\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:55.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0866 | Train score: 0.9625 | Val loss: 0.0881 | Val score: 0.9798\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:57.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0749 | Train score: 0.9625 | Val loss: 0.0857 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:52:58.824\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0996 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:53:00.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1868 | Train score: 0.9250 | Val loss: 0.0964 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:53:01.341\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1241 | Train score: 0.9500 | Val loss: 0.0949 | Val score: 0.9596\u001b[0m\n",
      "\u001b[32m2024-11-03 12:53:02.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1513 | Train score: 0.9375 | Val loss: 0.0969 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:53:03.883\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0936 | Train score: 0.9500 | Val loss: 0.0946 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:53:05.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1587 | Train score: 0.9500 | Val loss: 0.0944 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:53:07.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0611 | Train score: 0.9875 | Val loss: 0.0911 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:53:08.945\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0842 | Train score: 0.9750 | Val loss: 0.0872 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:53:10.412\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1225 | Train score: 0.9500 | Val loss: 0.0864 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:53:11.671\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0696 | Train score: 0.9625 | Val loss: 0.0856 | Val score: 0.9697\u001b[0m\n",
      "\u001b[32m2024-11-03 12:53:13.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0634 | Train score: 0.9625 | Val loss: 0.0855 | Val score: 0.9697\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " context_length \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.945         0.000           0.000          0.000        0.000       0.000         0.500        0.000    0.000   0.000         0.000        0.000\n",
      "XGBClassifier                         0.945         0.011           0.333          0.325        0.233       0.213         0.896        0.080    0.263   0.233         0.009        0.001\n",
      "MedPFNClassifier                      0.942         0.021           0.583          0.298        0.367       0.100         0.909        0.030    0.420   0.115         0.138        0.017\n",
      "MedPFNClassifier                      0.945         0.014           0.400          0.436        0.167       0.167         0.940        0.033    0.230   0.233         1.044        0.067\n",
      "MedPFNClassifier                      0.945         0.018           0.600          0.416        0.267       0.133         0.931        0.035    0.350   0.189         7.296        1.174\n",
      "RandomForestClassifier                0.951         0.008           0.350          0.450        0.133       0.163         0.895        0.074    0.190   0.234         0.152        0.010\n",
      "CatBoostGrid                          0.945         0.016           0.500          0.447        0.200       0.163         0.881        0.102    0.280   0.232        44.723        9.455\n",
      "XGBoostGrid                           0.951         0.008           0.300          0.458        0.100       0.153         0.852        0.123    0.150   0.229        29.868        3.425\n",
      "LogisticRegressionClassifier          0.947         0.013           0.450          0.415        0.200       0.163         0.887        0.045    0.270   0.224         0.006        0.002\n",
      "TabPFNClassifier                      0.947         0.019           0.533          0.400        0.300       0.180         0.915        0.040    0.363   0.227         1.666        0.194\n",
      "TabForestPFNClassifier                0.942         0.031           0.587          0.427        0.333       0.211         0.883        0.057    0.402   0.265        13.905        1.244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-03 13:11:59.030\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1159 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:01.402\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1374 | Train score: 0.9444 | Val loss: 0.0941 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:03.759\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1526 | Train score: 0.9444 | Val loss: 0.0937 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:06.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2114 | Train score: 0.9444 | Val loss: 0.0986 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:08.452\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1302 | Train score: 0.9444 | Val loss: 0.1002 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:10.770\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1429 | Train score: 0.9568 | Val loss: 0.1011 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:13.412\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1022 | Train score: 0.9753 | Val loss: 0.0986 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:16.454\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1277 | Train score: 0.9568 | Val loss: 0.0963 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:19.041\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0922 | Train score: 0.9630 | Val loss: 0.0939 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:21.399\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1067 | Train score: 0.9568 | Val loss: 0.0916 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:23.802\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0877 | Train score: 0.9815 | Val loss: 0.0893 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:25.947\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0907 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:28.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1061 | Train score: 0.9691 | Val loss: 0.0800 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:30.899\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1183 | Train score: 0.9568 | Val loss: 0.0796 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:33.565\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1391 | Train score: 0.9630 | Val loss: 0.0849 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:36.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1282 | Train score: 0.9691 | Val loss: 0.0876 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:38.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1369 | Train score: 0.9630 | Val loss: 0.0905 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:41.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1241 | Train score: 0.9630 | Val loss: 0.0926 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:43.911\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1133 | Train score: 0.9630 | Val loss: 0.0917 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:47.789\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1088 | Train score: 0.9691 | Val loss: 0.0868 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:50.651\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0900 | Train score: 0.9815 | Val loss: 0.0819 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:53.305\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1095 | Train score: 0.9691 | Val loss: 0.0797 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:55.501\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1126 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-03 13:12:57.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1556 | Train score: 0.9568 | Val loss: 0.1187 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:00.553\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1461 | Train score: 0.9444 | Val loss: 0.1130 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:03.282\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1176 | Train score: 0.9568 | Val loss: 0.1059 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:05.816\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1491 | Train score: 0.9506 | Val loss: 0.1065 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:08.383\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1220 | Train score: 0.9568 | Val loss: 0.1053 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:10.926\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1106 | Train score: 0.9568 | Val loss: 0.1056 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:13.373\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0937 | Train score: 0.9568 | Val loss: 0.1042 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:16.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1819 | Train score: 0.9568 | Val loss: 0.1074 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:19.597\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0973 | Train score: 0.9568 | Val loss: 0.1036 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:22.079\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1359 | Train score: 0.9506 | Val loss: 0.1020 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:24.627\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1471 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:27.917\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1095 | Train score: 0.9568 | Val loss: 0.1631 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:30.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1284 | Train score: 0.9444 | Val loss: 0.1700 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:33.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0955 | Train score: 0.9506 | Val loss: 0.1735 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:35.596\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1766 | Train score: 0.9444 | Val loss: 0.1631 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:38.067\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1351 | Train score: 0.9630 | Val loss: 0.1538 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:40.589\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1207 | Train score: 0.9568 | Val loss: 0.1477 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:43.214\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1725 | Train score: 0.9506 | Val loss: 0.1428 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:46.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1552 | Train score: 0.9568 | Val loss: 0.1397 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:49.225\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1048 | Train score: 0.9568 | Val loss: 0.1389 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:51.963\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0963 | Train score: 0.9815 | Val loss: 0.1388 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:54.285\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1318 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:56.906\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1159 | Train score: 0.9506 | Val loss: 0.1326 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:13:59.578\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0868 | Train score: 0.9630 | Val loss: 0.1464 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:02.195\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1801 | Train score: 0.9568 | Val loss: 0.1392 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:04.803\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1288 | Train score: 0.9630 | Val loss: 0.1322 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:07.358\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1449 | Train score: 0.9691 | Val loss: 0.1286 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:09.956\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1079 | Train score: 0.9568 | Val loss: 0.1273 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:12.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0914 | Train score: 0.9444 | Val loss: 0.1258 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:15.627\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1434 | Train score: 0.9568 | Val loss: 0.1239 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:18.755\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0978 | Train score: 0.9753 | Val loss: 0.1225 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:21.295\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1440 | Train score: 0.9630 | Val loss: 0.1216 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:23.562\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1185 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:26.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1196 | Train score: 0.9506 | Val loss: 0.1040 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:28.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1178 | Train score: 0.9444 | Val loss: 0.0981 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:31.407\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1341 | Train score: 0.9630 | Val loss: 0.0967 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:33.851\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1560 | Train score: 0.9753 | Val loss: 0.0990 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:36.261\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0555 | Train score: 0.9815 | Val loss: 0.0993 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:38.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0639 | Train score: 0.9753 | Val loss: 0.1001 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:41.324\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1215 | Train score: 0.9630 | Val loss: 0.1011 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:44.034\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0690 | Train score: 0.9877 | Val loss: 0.1033 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:47.283\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0731 | Train score: 0.9877 | Val loss: 0.1068 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:50.014\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0740 | Train score: 0.9630 | Val loss: 0.1136 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:52.265\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1005 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:54.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1323 | Train score: 0.9568 | Val loss: 0.0931 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:57.283\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0963 | Train score: 0.9568 | Val loss: 0.0904 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-03 13:14:59.776\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1400 | Train score: 0.9630 | Val loss: 0.0912 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:02.298\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1098 | Train score: 0.9506 | Val loss: 0.0940 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:04.780\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1045 | Train score: 0.9568 | Val loss: 0.0977 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:07.384\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0779 | Train score: 0.9691 | Val loss: 0.1041 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:09.880\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1553 | Train score: 0.9506 | Val loss: 0.1021 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:12.395\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1189 | Train score: 0.9568 | Val loss: 0.1012 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:15.272\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1382 | Train score: 0.9506 | Val loss: 0.1489 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:18.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1537 | Train score: 0.9753 | Val loss: 0.1003 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:20.634\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1001 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:23.177\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1232 | Train score: 0.9444 | Val loss: 0.0894 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:25.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1276 | Train score: 0.9506 | Val loss: 0.0898 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:28.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0976 | Train score: 0.9444 | Val loss: 0.0946 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:30.791\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1643 | Train score: 0.9506 | Val loss: 0.0917 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:33.381\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0826 | Train score: 0.9630 | Val loss: 0.0909 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:35.907\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1775 | Train score: 0.9444 | Val loss: 0.0923 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:38.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1494 | Train score: 0.9568 | Val loss: 0.0949 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:40.930\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1000 | Train score: 0.9630 | Val loss: 0.0957 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:43.381\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1283 | Train score: 0.9568 | Val loss: 0.0974 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:46.444\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0951 | Train score: 0.9630 | Val loss: 0.0970 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:49.102\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1564 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:51.739\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1597 | Train score: 0.9321 | Val loss: 0.1573 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:54.298\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1122 | Train score: 0.9691 | Val loss: 0.1583 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:56.846\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0946 | Train score: 0.9506 | Val loss: 0.1633 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-03 13:15:59.351\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1132 | Train score: 0.9506 | Val loss: 0.1667 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-03 13:16:01.933\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1057 | Train score: 0.9630 | Val loss: 0.1636 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-03 13:16:04.535\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0938 | Train score: 0.9753 | Val loss: 0.1653 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-03 13:16:07.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0709 | Train score: 0.9815 | Val loss: 0.1758 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-03 13:16:09.697\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1691 | Train score: 0.9568 | Val loss: 0.1693 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-03 13:16:12.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1551 | Train score: 0.9506 | Val loss: 0.1610 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-03 13:16:15.363\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0988 | Train score: 0.9753 | Val loss: 0.1561 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-03 13:16:18.045\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1282 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-03 13:16:20.759\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1033 | Train score: 0.9568 | Val loss: 0.1350 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:16:23.507\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0685 | Train score: 0.9753 | Val loss: 0.1652 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:16:26.358\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1151 | Train score: 0.9691 | Val loss: 0.1559 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 13:16:28.853\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1949 | Train score: 0.9444 | Val loss: 0.1426 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:16:31.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1724 | Train score: 0.9568 | Val loss: 0.1381 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:16:34.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1522 | Train score: 0.9568 | Val loss: 0.1356 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-03 13:16:36.847\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1032 | Train score: 0.9568 | Val loss: 0.1224 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-03 13:16:39.395\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0910 | Train score: 0.9691 | Val loss: 0.1193 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-03 13:16:41.861\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1376 | Train score: 0.9691 | Val loss: 0.1185 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-03 13:16:44.873\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1126 | Train score: 0.9568 | Val loss: 0.1177 | Val score: 0.9653\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " context_length \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.946         0.000           0.000          0.000        0.000       0.000         0.500        0.000    0.000   0.000         0.000        0.000\n",
      "XGBClassifier                         0.948         0.010           0.463          0.206        0.317       0.203         0.848        0.081    0.364   0.195         0.012        0.001\n",
      "MedPFNClassifier                      0.947         0.006           0.400          0.436        0.117       0.130         0.870        0.071    0.166   0.170         0.371        0.047\n",
      "MedPFNClassifier                      0.950         0.008           0.533          0.393        0.200       0.145         0.919        0.055    0.276   0.191         2.034        0.129\n",
      "MedPFNClassifier                      0.951         0.011           0.560          0.115        0.500       0.258         0.916        0.061    0.499   0.137        15.587        1.777\n",
      "RandomForestClassifier                0.952         0.012           0.417          0.443        0.183       0.203         0.903        0.056    0.246   0.269         0.239        0.018\n",
      "CatBoostGrid                          0.949         0.006           0.500          0.447        0.133       0.125         0.901        0.061    0.194   0.164        49.480        5.812\n",
      "XGBoostGrid                           0.946         0.000           0.000          0.000        0.000       0.000         0.871        0.054    0.000   0.000        40.350        5.466\n",
      "LogisticRegressionClassifier          0.939         0.014           0.393          0.245        0.217       0.150         0.825        0.096    0.269   0.169         0.010        0.002\n",
      "TabPFNClassifier                      0.946         0.018           0.373          0.397        0.200       0.194         0.906        0.057    0.259   0.261         3.630        0.183\n",
      "TabForestPFNClassifier                0.939         0.023           0.484          0.311        0.333       0.183         0.886        0.036    0.371   0.206        28.517        0.803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-03 13:53:12.988\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1215 | Val score: 0.9631\u001b[0m\n",
      "\u001b[32m2024-11-03 13:53:19.486\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1317 | Train score: 0.9571 | Val loss: 0.1234 | Val score: 0.9631\u001b[0m\n",
      "\u001b[32m2024-11-03 13:53:24.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1247 | Train score: 0.9571 | Val loss: 0.1260 | Val score: 0.9631\u001b[0m\n",
      "\u001b[32m2024-11-03 13:53:30.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1209 | Train score: 0.9632 | Val loss: 0.1182 | Val score: 0.9656\u001b[0m\n",
      "\u001b[32m2024-11-03 13:53:36.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0861 | Train score: 0.9663 | Val loss: 0.1180 | Val score: 0.9631\u001b[0m\n",
      "\u001b[32m2024-11-03 13:53:41.603\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1200 | Train score: 0.9632 | Val loss: 0.1198 | Val score: 0.9631\u001b[0m\n",
      "\u001b[32m2024-11-03 13:53:48.086\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0946 | Train score: 0.9693 | Val loss: 0.1240 | Val score: 0.9656\u001b[0m\n",
      "\u001b[32m2024-11-03 13:53:53.522\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1213 | Train score: 0.9632 | Val loss: 0.1217 | Val score: 0.9656\u001b[0m\n",
      "\u001b[32m2024-11-03 13:53:59.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1178 | Train score: 0.9632 | Val loss: 0.1176 | Val score: 0.9681\u001b[0m\n",
      "\u001b[32m2024-11-03 13:54:04.442\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1314 | Train score: 0.9540 | Val loss: 0.1175 | Val score: 0.9754\u001b[0m\n",
      "\u001b[32m2024-11-03 13:54:09.878\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0881 | Train score: 0.9724 | Val loss: 0.1155 | Val score: 0.9705\u001b[0m\n",
      "\u001b[32m2024-11-03 13:54:14.979\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1460 | Val score: 0.9459\u001b[0m\n",
      "\u001b[32m2024-11-03 13:54:20.773\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1003 | Train score: 0.9724 | Val loss: 0.1542 | Val score: 0.9484\u001b[0m\n",
      "\u001b[32m2024-11-03 13:54:26.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1353 | Train score: 0.9601 | Val loss: 0.1574 | Val score: 0.9484\u001b[0m\n",
      "\u001b[32m2024-11-03 13:54:31.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1044 | Train score: 0.9663 | Val loss: 0.1584 | Val score: 0.9459\u001b[0m\n",
      "\u001b[32m2024-11-03 13:54:36.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1072 | Train score: 0.9693 | Val loss: 0.1564 | Val score: 0.9459\u001b[0m\n",
      "\u001b[32m2024-11-03 13:54:42.229\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1208 | Train score: 0.9601 | Val loss: 0.1543 | Val score: 0.9459\u001b[0m\n",
      "\u001b[32m2024-11-03 13:54:48.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1684 | Train score: 0.9540 | Val loss: 0.1506 | Val score: 0.9459\u001b[0m\n",
      "\u001b[32m2024-11-03 13:54:54.037\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1018 | Train score: 0.9663 | Val loss: 0.1485 | Val score: 0.9484\u001b[0m\n",
      "\u001b[32m2024-11-03 13:54:59.412\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1048 | Train score: 0.9693 | Val loss: 0.1478 | Val score: 0.9484\u001b[0m\n",
      "\u001b[32m2024-11-03 13:55:04.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0994 | Train score: 0.9663 | Val loss: 0.1487 | Val score: 0.9459\u001b[0m\n",
      "\u001b[32m2024-11-03 13:55:10.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0753 | Train score: 0.9785 | Val loss: 0.1518 | Val score: 0.9459\u001b[0m\n",
      "\u001b[32m2024-11-03 13:55:15.350\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1098 | Val score: 0.9705\u001b[0m\n",
      "\u001b[32m2024-11-03 13:55:21.459\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1135 | Train score: 0.9724 | Val loss: 0.1075 | Val score: 0.9681\u001b[0m\n",
      "\u001b[32m2024-11-03 13:55:27.074\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0996 | Train score: 0.9632 | Val loss: 0.1101 | Val score: 0.9631\u001b[0m\n",
      "\u001b[32m2024-11-03 13:55:32.796\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1426 | Train score: 0.9601 | Val loss: 0.1114 | Val score: 0.9656\u001b[0m\n",
      "\u001b[32m2024-11-03 13:55:38.054\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1365 | Train score: 0.9601 | Val loss: 0.1187 | Val score: 0.9681\u001b[0m\n",
      "\u001b[32m2024-11-03 13:55:43.571\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1029 | Train score: 0.9724 | Val loss: 0.1066 | Val score: 0.9681\u001b[0m\n",
      "\u001b[32m2024-11-03 13:55:49.916\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1377 | Train score: 0.9540 | Val loss: 0.1034 | Val score: 0.9681\u001b[0m\n",
      "\u001b[32m2024-11-03 13:55:55.727\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1113 | Train score: 0.9663 | Val loss: 0.1023 | Val score: 0.9681\u001b[0m\n",
      "\u001b[32m2024-11-03 13:56:01.184\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1615 | Train score: 0.9479 | Val loss: 0.1032 | Val score: 0.9681\u001b[0m\n",
      "\u001b[32m2024-11-03 13:56:06.863\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1512 | Train score: 0.9509 | Val loss: 0.1049 | Val score: 0.9656\u001b[0m\n",
      "\u001b[32m2024-11-03 13:56:12.490\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1405 | Train score: 0.9571 | Val loss: 0.1069 | Val score: 0.9656\u001b[0m\n",
      "\u001b[32m2024-11-03 13:56:18.046\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1253 | Val score: 0.9533\u001b[0m\n",
      "\u001b[32m2024-11-03 13:56:23.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1081 | Train score: 0.9632 | Val loss: 0.1229 | Val score: 0.9459\u001b[0m\n",
      "\u001b[32m2024-11-03 13:56:29.972\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1113 | Train score: 0.9663 | Val loss: 0.1231 | Val score: 0.9435\u001b[0m\n",
      "\u001b[32m2024-11-03 13:56:35.848\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0814 | Train score: 0.9724 | Val loss: 0.1259 | Val score: 0.9459\u001b[0m\n",
      "\u001b[32m2024-11-03 13:56:41.269\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1038 | Train score: 0.9571 | Val loss: 0.1331 | Val score: 0.9484\u001b[0m\n",
      "\u001b[32m2024-11-03 13:56:48.098\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0811 | Train score: 0.9663 | Val loss: 0.1398 | Val score: 0.9459\u001b[0m\n",
      "\u001b[32m2024-11-03 13:56:53.950\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0933 | Train score: 0.9571 | Val loss: 0.1438 | Val score: 0.9484\u001b[0m\n",
      "\u001b[32m2024-11-03 13:56:59.488\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1178 | Train score: 0.9571 | Val loss: 0.1384 | Val score: 0.9435\u001b[0m\n",
      "\u001b[32m2024-11-03 13:57:05.296\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0932 | Train score: 0.9601 | Val loss: 0.1348 | Val score: 0.9459\u001b[0m\n",
      "\u001b[32m2024-11-03 13:57:11.092\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1011 | Train score: 0.9663 | Val loss: 0.1315 | Val score: 0.9459\u001b[0m\n",
      "\u001b[32m2024-11-03 13:57:17.850\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1090 | Train score: 0.9632 | Val loss: 0.1291 | Val score: 0.9459\u001b[0m\n",
      "\u001b[32m2024-11-03 13:57:22.717\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1280 | Val score: 0.9582\u001b[0m\n",
      "\u001b[32m2024-11-03 13:57:27.915\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1494 | Train score: 0.9540 | Val loss: 0.1277 | Val score: 0.9582\u001b[0m\n",
      "\u001b[32m2024-11-03 13:57:33.196\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1447 | Train score: 0.9509 | Val loss: 0.1274 | Val score: 0.9558\u001b[0m\n",
      "\u001b[32m2024-11-03 13:57:38.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1388 | Train score: 0.9601 | Val loss: 0.1258 | Val score: 0.9533\u001b[0m\n",
      "\u001b[32m2024-11-03 13:57:44.048\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1501 | Train score: 0.9601 | Val loss: 0.1265 | Val score: 0.9558\u001b[0m\n",
      "\u001b[32m2024-11-03 13:57:50.217\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1051 | Train score: 0.9663 | Val loss: 0.1254 | Val score: 0.9558\u001b[0m\n",
      "\u001b[32m2024-11-03 13:57:55.590\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1053 | Train score: 0.9663 | Val loss: 0.1253 | Val score: 0.9558\u001b[0m\n",
      "\u001b[32m2024-11-03 13:58:00.951\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1038 | Train score: 0.9663 | Val loss: 0.1269 | Val score: 0.9582\u001b[0m\n",
      "\u001b[32m2024-11-03 13:58:06.365\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1076 | Train score: 0.9724 | Val loss: 0.1302 | Val score: 0.9558\u001b[0m\n",
      "\u001b[32m2024-11-03 13:58:11.746\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1016 | Train score: 0.9663 | Val loss: 0.1329 | Val score: 0.9558\u001b[0m\n",
      "\u001b[32m2024-11-03 13:58:17.952\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1003 | Train score: 0.9601 | Val loss: 0.1351 | Val score: 0.9558\u001b[0m\n",
      "\u001b[32m2024-11-03 13:58:22.945\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1116 | Val score: 0.9607\u001b[0m\n",
      "\u001b[32m2024-11-03 13:58:28.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1388 | Train score: 0.9540 | Val loss: 0.1037 | Val score: 0.9656\u001b[0m\n",
      "\u001b[32m2024-11-03 13:58:33.879\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1205 | Train score: 0.9601 | Val loss: 0.1047 | Val score: 0.9656\u001b[0m\n",
      "\u001b[32m2024-11-03 13:58:39.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0995 | Train score: 0.9632 | Val loss: 0.1081 | Val score: 0.9681\u001b[0m\n",
      "\u001b[32m2024-11-03 13:58:45.378\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1201 | Train score: 0.9632 | Val loss: 0.1071 | Val score: 0.9681\u001b[0m\n",
      "\u001b[32m2024-11-03 13:58:51.329\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1158 | Train score: 0.9693 | Val loss: 0.1081 | Val score: 0.9705\u001b[0m\n",
      "\u001b[32m2024-11-03 13:58:56.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0929 | Train score: 0.9724 | Val loss: 0.1058 | Val score: 0.9705\u001b[0m\n",
      "\u001b[32m2024-11-03 13:59:02.122\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1453 | Train score: 0.9571 | Val loss: 0.1048 | Val score: 0.9705\u001b[0m\n",
      "\u001b[32m2024-11-03 13:59:07.514\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1127 | Train score: 0.9601 | Val loss: 0.1058 | Val score: 0.9705\u001b[0m\n",
      "\u001b[32m2024-11-03 13:59:13.165\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1155 | Train score: 0.9632 | Val loss: 0.1102 | Val score: 0.9656\u001b[0m\n",
      "\u001b[32m2024-11-03 13:59:19.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1102 | Train score: 0.9632 | Val loss: 0.1124 | Val score: 0.9607\u001b[0m\n",
      "\u001b[32m2024-11-03 13:59:24.555\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1272 | Val score: 0.9533\u001b[0m\n",
      "\u001b[32m2024-11-03 13:59:30.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1364 | Train score: 0.9601 | Val loss: 0.1217 | Val score: 0.9656\u001b[0m\n",
      "\u001b[32m2024-11-03 13:59:35.795\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1205 | Train score: 0.9571 | Val loss: 0.1202 | Val score: 0.9558\u001b[0m\n",
      "\u001b[32m2024-11-03 13:59:41.590\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0949 | Train score: 0.9693 | Val loss: 0.1210 | Val score: 0.9582\u001b[0m\n",
      "\u001b[32m2024-11-03 13:59:47.875\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1177 | Train score: 0.9571 | Val loss: 0.1227 | Val score: 0.9533\u001b[0m\n",
      "\u001b[32m2024-11-03 13:59:53.960\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0999 | Train score: 0.9693 | Val loss: 0.1234 | Val score: 0.9533\u001b[0m\n",
      "\u001b[32m2024-11-03 14:00:00.138\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1348 | Train score: 0.9663 | Val loss: 0.1237 | Val score: 0.9509\u001b[0m\n",
      "\u001b[32m2024-11-03 14:00:05.925\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1377 | Train score: 0.9632 | Val loss: 0.1252 | Val score: 0.9484\u001b[0m\n",
      "\u001b[32m2024-11-03 14:00:11.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1085 | Train score: 0.9724 | Val loss: 0.1268 | Val score: 0.9484\u001b[0m\n",
      "\u001b[32m2024-11-03 14:00:18.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1090 | Train score: 0.9693 | Val loss: 0.1272 | Val score: 0.9484\u001b[0m\n",
      "\u001b[32m2024-11-03 14:00:23.800\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0987 | Train score: 0.9785 | Val loss: 0.1274 | Val score: 0.9459\u001b[0m\n",
      "\u001b[32m2024-11-03 14:00:28.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1626 | Val score: 0.9459\u001b[0m\n",
      "\u001b[32m2024-11-03 14:00:34.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1152 | Train score: 0.9571 | Val loss: 0.1664 | Val score: 0.9509\u001b[0m\n",
      "\u001b[32m2024-11-03 14:00:39.604\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1147 | Train score: 0.9540 | Val loss: 0.1641 | Val score: 0.9484\u001b[0m\n",
      "\u001b[32m2024-11-03 14:00:45.624\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1239 | Train score: 0.9632 | Val loss: 0.1568 | Val score: 0.9484\u001b[0m\n",
      "\u001b[32m2024-11-03 14:00:51.890\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1476 | Train score: 0.9479 | Val loss: 0.1533 | Val score: 0.9484\u001b[0m\n",
      "\u001b[32m2024-11-03 14:00:57.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0954 | Train score: 0.9724 | Val loss: 0.1535 | Val score: 0.9484\u001b[0m\n",
      "\u001b[32m2024-11-03 14:01:03.385\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1029 | Train score: 0.9663 | Val loss: 0.1563 | Val score: 0.9484\u001b[0m\n",
      "\u001b[32m2024-11-03 14:01:09.013\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0731 | Train score: 0.9663 | Val loss: 0.1638 | Val score: 0.9484\u001b[0m\n",
      "\u001b[32m2024-11-03 14:01:15.180\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0845 | Train score: 0.9785 | Val loss: 0.1733 | Val score: 0.9509\u001b[0m\n",
      "\u001b[32m2024-11-03 14:01:21.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1180 | Train score: 0.9571 | Val loss: 0.1789 | Val score: 0.9509\u001b[0m\n",
      "\u001b[32m2024-11-03 14:01:27.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1538 | Train score: 0.9601 | Val loss: 0.1741 | Val score: 0.9509\u001b[0m\n",
      "\u001b[32m2024-11-03 14:01:32.162\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1421 | Val score: 0.9509\u001b[0m\n",
      "\u001b[32m2024-11-03 14:01:37.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1298 | Train score: 0.9540 | Val loss: 0.1380 | Val score: 0.9509\u001b[0m\n",
      "\u001b[32m2024-11-03 14:01:43.402\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0868 | Train score: 0.9755 | Val loss: 0.1415 | Val score: 0.9484\u001b[0m\n",
      "\u001b[32m2024-11-03 14:01:50.222\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1214 | Train score: 0.9632 | Val loss: 0.1402 | Val score: 0.9484\u001b[0m\n",
      "\u001b[32m2024-11-03 14:01:55.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0941 | Train score: 0.9632 | Val loss: 0.1414 | Val score: 0.9435\u001b[0m\n",
      "\u001b[32m2024-11-03 14:02:01.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1487 | Train score: 0.9540 | Val loss: 0.1423 | Val score: 0.9410\u001b[0m\n",
      "\u001b[32m2024-11-03 14:02:06.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1265 | Train score: 0.9663 | Val loss: 0.1413 | Val score: 0.9435\u001b[0m\n",
      "\u001b[32m2024-11-03 14:02:12.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1106 | Train score: 0.9571 | Val loss: 0.1415 | Val score: 0.9361\u001b[0m\n",
      "\u001b[32m2024-11-03 14:02:18.528\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1062 | Train score: 0.9571 | Val loss: 0.1409 | Val score: 0.9410\u001b[0m\n",
      "\u001b[32m2024-11-03 14:02:23.894\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1031 | Train score: 0.9571 | Val loss: 0.1392 | Val score: 0.9435\u001b[0m\n",
      "\u001b[32m2024-11-03 14:02:29.716\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0818 | Train score: 0.9785 | Val loss: 0.1381 | Val score: 0.9435\u001b[0m\n",
      "\u001b[32m2024-11-03 14:02:34.341\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1293 | Val score: 0.9582\u001b[0m\n",
      "\u001b[32m2024-11-03 14:02:39.785\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1364 | Train score: 0.9571 | Val loss: 0.1221 | Val score: 0.9582\u001b[0m\n",
      "\u001b[32m2024-11-03 14:02:45.782\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1413 | Train score: 0.9509 | Val loss: 0.1273 | Val score: 0.9607\u001b[0m\n",
      "\u001b[32m2024-11-03 14:02:51.891\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1253 | Train score: 0.9571 | Val loss: 0.1304 | Val score: 0.9607\u001b[0m\n",
      "\u001b[32m2024-11-03 14:02:58.165\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1038 | Train score: 0.9632 | Val loss: 0.1302 | Val score: 0.9582\u001b[0m\n",
      "\u001b[32m2024-11-03 14:03:04.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1359 | Train score: 0.9663 | Val loss: 0.1302 | Val score: 0.9533\u001b[0m\n",
      "\u001b[32m2024-11-03 14:03:11.804\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0955 | Train score: 0.9724 | Val loss: 0.1305 | Val score: 0.9509\u001b[0m\n",
      "\u001b[32m2024-11-03 14:03:19.013\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0925 | Train score: 0.9724 | Val loss: 0.1313 | Val score: 0.9533\u001b[0m\n",
      "\u001b[32m2024-11-03 14:03:26.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1048 | Train score: 0.9693 | Val loss: 0.1311 | Val score: 0.9558\u001b[0m\n",
      "\u001b[32m2024-11-03 14:03:33.222\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1294 | Train score: 0.9632 | Val loss: 0.1305 | Val score: 0.9558\u001b[0m\n",
      "\u001b[32m2024-11-03 14:03:40.408\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1481 | Train score: 0.9479 | Val loss: 0.1308 | Val score: 0.9558\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " context_length \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.942         0.000           0.000          0.000        0.000       0.000         0.500        0.000    0.000   0.000         0.000        0.000\n",
      "XGBClassifier                         0.949         0.008           0.701          0.195        0.338       0.138         0.813        0.041    0.414   0.142         0.019        0.001\n",
      "MedPFNClassifier                      0.944         0.007           0.613          0.350        0.123       0.051         0.839        0.062    0.201   0.085         1.205        0.027\n",
      "MedPFNClassifier                      0.954         0.009           0.787          0.174        0.292       0.191         0.885        0.040    0.392   0.202         6.306        0.297\n",
      "MedPFNClassifier                      0.950         0.007           0.716          0.188        0.369       0.181         0.884        0.041    0.433   0.159        26.488        0.915\n",
      "RandomForestClassifier                0.955         0.011           0.663          0.371        0.269       0.198         0.874        0.050    0.371   0.250         0.363        0.023\n",
      "CatBoostGrid                          0.953         0.011           0.582          0.321        0.277       0.198         0.888        0.039    0.365   0.241        94.159        7.885\n",
      "XGBoostGrid                           0.950         0.007           0.497          0.419        0.192       0.169         0.871        0.054    0.269   0.225        78.125        4.646\n",
      "LogisticRegressionClassifier          0.935         0.011           0.427          0.099        0.346       0.062         0.805        0.068    0.380   0.075         0.018        0.003\n",
      "TabPFNClassifier                      0.954         0.008           0.715          0.084        0.300       0.170         0.885        0.049    0.404   0.163        10.582        0.342\n",
      "TabForestPFNClassifier                0.949         0.005           0.599          0.062        0.354       0.086         0.880        0.038    0.439   0.077        62.915        3.063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-03 15:08:42.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1405 | Val score: 0.9499\u001b[0m\n",
      "\u001b[32m2024-11-03 15:09:01.289\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1178 | Train score: 0.9570 | Val loss: 0.1335 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 15:09:20.857\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1232 | Train score: 0.9668 | Val loss: 0.1321 | Val score: 0.9597\u001b[0m\n",
      "\u001b[32m2024-11-03 15:09:39.970\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1079 | Train score: 0.9668 | Val loss: 0.1322 | Val score: 0.9597\u001b[0m\n",
      "\u001b[32m2024-11-03 15:10:00.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1557 | Train score: 0.9492 | Val loss: 0.1305 | Val score: 0.9584\u001b[0m\n",
      "\u001b[32m2024-11-03 15:10:20.980\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1985 | Train score: 0.9512 | Val loss: 0.1298 | Val score: 0.9584\u001b[0m\n",
      "\u001b[32m2024-11-03 15:10:40.244\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1221 | Train score: 0.9570 | Val loss: 0.1308 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 15:11:01.717\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1424 | Train score: 0.9531 | Val loss: 0.1314 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 15:11:24.289\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1399 | Train score: 0.9570 | Val loss: 0.1324 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 15:11:45.192\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1336 | Train score: 0.9609 | Val loss: 0.1315 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 15:12:06.829\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1250 | Train score: 0.9590 | Val loss: 0.1305 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 15:12:27.377\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1489 | Val score: 0.9462\u001b[0m\n",
      "\u001b[32m2024-11-03 15:12:48.573\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1299 | Train score: 0.9551 | Val loss: 0.1451 | Val score: 0.9535\u001b[0m\n",
      "\u001b[32m2024-11-03 15:13:09.147\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1220 | Train score: 0.9629 | Val loss: 0.1441 | Val score: 0.9535\u001b[0m\n",
      "\u001b[32m2024-11-03 15:13:31.854\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1148 | Train score: 0.9590 | Val loss: 0.1446 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 15:13:54.777\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0816 | Train score: 0.9668 | Val loss: 0.1461 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 15:14:17.347\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1165 | Train score: 0.9609 | Val loss: 0.1478 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 15:14:39.341\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1215 | Train score: 0.9668 | Val loss: 0.1465 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 15:14:57.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1500 | Train score: 0.9629 | Val loss: 0.1439 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 15:15:16.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0964 | Train score: 0.9785 | Val loss: 0.1431 | Val score: 0.9548\u001b[0m\n",
      "\u001b[32m2024-11-03 15:15:34.519\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1214 | Train score: 0.9590 | Val loss: 0.1424 | Val score: 0.9548\u001b[0m\n",
      "\u001b[32m2024-11-03 15:15:51.236\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1105 | Train score: 0.9590 | Val loss: 0.1424 | Val score: 0.9548\u001b[0m\n",
      "\u001b[32m2024-11-03 15:16:08.039\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1270 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 15:16:24.410\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1190 | Train score: 0.9648 | Val loss: 0.1210 | Val score: 0.9584\u001b[0m\n",
      "\u001b[32m2024-11-03 15:16:42.554\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1647 | Train score: 0.9512 | Val loss: 0.1220 | Val score: 0.9584\u001b[0m\n",
      "\u001b[32m2024-11-03 15:17:01.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1232 | Train score: 0.9609 | Val loss: 0.1206 | Val score: 0.9645\u001b[0m\n",
      "\u001b[32m2024-11-03 15:17:19.118\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1326 | Train score: 0.9609 | Val loss: 0.1198 | Val score: 0.9645\u001b[0m\n",
      "\u001b[32m2024-11-03 15:17:36.286\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1160 | Train score: 0.9648 | Val loss: 0.1194 | Val score: 0.9645\u001b[0m\n",
      "\u001b[32m2024-11-03 15:17:53.527\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1321 | Train score: 0.9648 | Val loss: 0.1195 | Val score: 0.9633\u001b[0m\n",
      "\u001b[32m2024-11-03 15:18:10.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1428 | Train score: 0.9453 | Val loss: 0.1189 | Val score: 0.9658\u001b[0m\n",
      "\u001b[32m2024-11-03 15:18:27.756\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1512 | Train score: 0.9512 | Val loss: 0.1183 | Val score: 0.9633\u001b[0m\n",
      "\u001b[32m2024-11-03 15:18:45.215\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1269 | Train score: 0.9492 | Val loss: 0.1174 | Val score: 0.9633\u001b[0m\n",
      "\u001b[32m2024-11-03 15:19:02.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1467 | Train score: 0.9531 | Val loss: 0.1165 | Val score: 0.9645\u001b[0m\n",
      "\u001b[32m2024-11-03 15:19:18.927\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1616 | Val score: 0.9511\u001b[0m\n",
      "\u001b[32m2024-11-03 15:19:36.329\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1411 | Train score: 0.9512 | Val loss: 0.1698 | Val score: 0.9548\u001b[0m\n",
      "\u001b[32m2024-11-03 15:19:53.266\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1109 | Train score: 0.9707 | Val loss: 0.1804 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 15:20:11.382\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1784 | Train score: 0.9531 | Val loss: 0.1712 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 15:20:28.596\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1411 | Train score: 0.9551 | Val loss: 0.1665 | Val score: 0.9548\u001b[0m\n",
      "\u001b[32m2024-11-03 15:20:49.938\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0953 | Train score: 0.9688 | Val loss: 0.1664 | Val score: 0.9535\u001b[0m\n",
      "\u001b[32m2024-11-03 15:21:08.323\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1255 | Train score: 0.9570 | Val loss: 0.1648 | Val score: 0.9535\u001b[0m\n",
      "\u001b[32m2024-11-03 15:21:24.272\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1141 | Train score: 0.9590 | Val loss: 0.1663 | Val score: 0.9511\u001b[0m\n",
      "\u001b[32m2024-11-03 15:21:40.475\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1201 | Train score: 0.9590 | Val loss: 0.1674 | Val score: 0.9523\u001b[0m\n",
      "\u001b[32m2024-11-03 15:22:02.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1264 | Train score: 0.9570 | Val loss: 0.1690 | Val score: 0.9548\u001b[0m\n",
      "\u001b[32m2024-11-03 15:22:24.966\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1301 | Train score: 0.9531 | Val loss: 0.1698 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 15:22:44.422\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1312 | Val score: 0.9535\u001b[0m\n",
      "\u001b[32m2024-11-03 15:23:04.457\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1546 | Train score: 0.9395 | Val loss: 0.1254 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 15:23:24.788\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1536 | Train score: 0.9453 | Val loss: 0.1282 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 15:23:43.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1586 | Train score: 0.9570 | Val loss: 0.1295 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 15:24:03.627\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1263 | Train score: 0.9609 | Val loss: 0.1252 | Val score: 0.9584\u001b[0m\n",
      "\u001b[32m2024-11-03 15:24:23.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1487 | Train score: 0.9492 | Val loss: 0.1231 | Val score: 0.9584\u001b[0m\n",
      "\u001b[32m2024-11-03 15:24:42.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1434 | Train score: 0.9551 | Val loss: 0.1231 | Val score: 0.9621\u001b[0m\n",
      "\u001b[32m2024-11-03 15:25:03.304\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1564 | Train score: 0.9453 | Val loss: 0.1263 | Val score: 0.9609\u001b[0m\n",
      "\u001b[32m2024-11-03 15:25:23.520\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1427 | Train score: 0.9492 | Val loss: 0.1231 | Val score: 0.9621\u001b[0m\n",
      "\u001b[32m2024-11-03 15:25:42.372\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1438 | Train score: 0.9551 | Val loss: 0.1185 | Val score: 0.9621\u001b[0m\n",
      "\u001b[32m2024-11-03 15:26:02.096\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1195 | Train score: 0.9648 | Val loss: 0.1177 | Val score: 0.9621\u001b[0m\n",
      "\u001b[32m2024-11-03 15:26:21.466\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1362 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 15:26:41.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1413 | Train score: 0.9492 | Val loss: 0.1331 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 15:27:01.396\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1500 | Train score: 0.9492 | Val loss: 0.1326 | Val score: 0.9584\u001b[0m\n",
      "\u001b[32m2024-11-03 15:27:21.651\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1266 | Train score: 0.9492 | Val loss: 0.1330 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 15:27:40.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1213 | Train score: 0.9570 | Val loss: 0.1341 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 15:28:01.499\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1349 | Train score: 0.9531 | Val loss: 0.1359 | Val score: 0.9584\u001b[0m\n",
      "\u001b[32m2024-11-03 15:28:26.945\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0990 | Train score: 0.9648 | Val loss: 0.1373 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 15:28:47.320\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1419 | Train score: 0.9590 | Val loss: 0.1379 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 15:29:13.497\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1425 | Train score: 0.9453 | Val loss: 0.1378 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 15:29:36.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1264 | Train score: 0.9609 | Val loss: 0.1371 | Val score: 0.9584\u001b[0m\n",
      "\u001b[32m2024-11-03 15:29:58.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1304 | Train score: 0.9590 | Val loss: 0.1360 | Val score: 0.9584\u001b[0m\n",
      "\u001b[32m2024-11-03 15:30:21.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1576 | Val score: 0.9511\u001b[0m\n",
      "\u001b[32m2024-11-03 15:30:44.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1364 | Train score: 0.9551 | Val loss: 0.1521 | Val score: 0.9487\u001b[0m\n",
      "\u001b[32m2024-11-03 15:31:03.525\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1040 | Train score: 0.9688 | Val loss: 0.1578 | Val score: 0.9474\u001b[0m\n",
      "\u001b[32m2024-11-03 15:31:25.224\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1150 | Train score: 0.9629 | Val loss: 0.1572 | Val score: 0.9511\u001b[0m\n",
      "\u001b[32m2024-11-03 15:31:46.026\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1094 | Train score: 0.9648 | Val loss: 0.1558 | Val score: 0.9487\u001b[0m\n",
      "\u001b[32m2024-11-03 15:32:05.891\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0999 | Train score: 0.9668 | Val loss: 0.1549 | Val score: 0.9487\u001b[0m\n",
      "\u001b[32m2024-11-03 15:32:26.881\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1619 | Train score: 0.9492 | Val loss: 0.1518 | Val score: 0.9487\u001b[0m\n",
      "\u001b[32m2024-11-03 15:32:48.386\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1028 | Train score: 0.9629 | Val loss: 0.1511 | Val score: 0.9474\u001b[0m\n",
      "\u001b[32m2024-11-03 15:33:09.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1073 | Train score: 0.9688 | Val loss: 0.1510 | Val score: 0.9511\u001b[0m\n",
      "\u001b[32m2024-11-03 15:33:29.730\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1087 | Train score: 0.9648 | Val loss: 0.1512 | Val score: 0.9523\u001b[0m\n",
      "\u001b[32m2024-11-03 15:33:50.574\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1068 | Train score: 0.9688 | Val loss: 0.1507 | Val score: 0.9523\u001b[0m\n",
      "\u001b[32m2024-11-03 15:34:10.100\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1552 | Val score: 0.9523\u001b[0m\n",
      "\u001b[32m2024-11-03 15:34:31.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1375 | Train score: 0.9551 | Val loss: 0.1452 | Val score: 0.9535\u001b[0m\n",
      "\u001b[32m2024-11-03 15:34:54.822\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1363 | Train score: 0.9570 | Val loss: 0.1437 | Val score: 0.9523\u001b[0m\n",
      "\u001b[32m2024-11-03 15:35:15.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1266 | Train score: 0.9629 | Val loss: 0.1428 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 15:35:35.843\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1427 | Train score: 0.9492 | Val loss: 0.1416 | Val score: 0.9548\u001b[0m\n",
      "\u001b[32m2024-11-03 15:35:56.145\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1251 | Train score: 0.9609 | Val loss: 0.1419 | Val score: 0.9535\u001b[0m\n",
      "\u001b[32m2024-11-03 15:36:16.293\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1475 | Train score: 0.9570 | Val loss: 0.1404 | Val score: 0.9548\u001b[0m\n",
      "\u001b[32m2024-11-03 15:36:36.881\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1122 | Train score: 0.9590 | Val loss: 0.1385 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 15:36:56.533\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1407 | Train score: 0.9492 | Val loss: 0.1377 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 15:37:17.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1161 | Train score: 0.9629 | Val loss: 0.1377 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 15:37:37.539\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1205 | Train score: 0.9590 | Val loss: 0.1387 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 15:37:58.024\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1382 | Val score: 0.9548\u001b[0m\n",
      "\u001b[32m2024-11-03 15:38:18.154\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1497 | Train score: 0.9414 | Val loss: 0.1409 | Val score: 0.9548\u001b[0m\n",
      "\u001b[32m2024-11-03 15:38:37.861\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1232 | Train score: 0.9531 | Val loss: 0.1449 | Val score: 0.9548\u001b[0m\n",
      "\u001b[32m2024-11-03 15:38:58.920\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1801 | Train score: 0.9336 | Val loss: 0.1432 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 15:39:19.269\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1402 | Train score: 0.9473 | Val loss: 0.1424 | Val score: 0.9609\u001b[0m\n",
      "\u001b[32m2024-11-03 15:39:38.855\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1303 | Train score: 0.9531 | Val loss: 0.1424 | Val score: 0.9609\u001b[0m\n",
      "\u001b[32m2024-11-03 15:39:59.858\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1230 | Train score: 0.9609 | Val loss: 0.1424 | Val score: 0.9584\u001b[0m\n",
      "\u001b[32m2024-11-03 15:40:23.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1364 | Train score: 0.9570 | Val loss: 0.1405 | Val score: 0.9584\u001b[0m\n",
      "\u001b[32m2024-11-03 15:40:44.377\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1102 | Train score: 0.9629 | Val loss: 0.1394 | Val score: 0.9597\u001b[0m\n",
      "\u001b[32m2024-11-03 15:41:06.040\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1059 | Train score: 0.9590 | Val loss: 0.1375 | Val score: 0.9597\u001b[0m\n",
      "\u001b[32m2024-11-03 15:41:27.483\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1252 | Train score: 0.9512 | Val loss: 0.1356 | Val score: 0.9621\u001b[0m\n",
      "\u001b[32m2024-11-03 15:41:44.801\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1269 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 15:42:02.751\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1328 | Train score: 0.9551 | Val loss: 0.1144 | Val score: 0.9548\u001b[0m\n",
      "\u001b[32m2024-11-03 15:42:26.032\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1410 | Train score: 0.9531 | Val loss: 0.1138 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 15:42:43.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1315 | Train score: 0.9551 | Val loss: 0.1152 | Val score: 0.9584\u001b[0m\n",
      "\u001b[32m2024-11-03 15:43:02.074\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1444 | Train score: 0.9473 | Val loss: 0.1174 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 15:43:21.600\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1767 | Train score: 0.9434 | Val loss: 0.1181 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 15:43:44.942\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1516 | Train score: 0.9473 | Val loss: 0.1218 | Val score: 0.9597\u001b[0m\n",
      "\u001b[32m2024-11-03 15:44:07.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1141 | Train score: 0.9727 | Val loss: 0.1217 | Val score: 0.9597\u001b[0m\n",
      "\u001b[32m2024-11-03 15:44:30.395\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1271 | Train score: 0.9531 | Val loss: 0.1190 | Val score: 0.9597\u001b[0m\n",
      "\u001b[32m2024-11-03 15:45:01.804\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1713 | Train score: 0.9492 | Val loss: 0.1164 | Val score: 0.9609\u001b[0m\n",
      "\u001b[32m2024-11-03 15:45:23.482\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1307 | Train score: 0.9590 | Val loss: 0.1153 | Val score: 0.9609\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " context_length \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.941         0.000           0.000          0.000        0.000       0.000         0.500        0.000    0.000   0.000         0.000        0.000\n",
      "XGBClassifier                         0.946         0.009           0.563          0.100        0.419       0.095         0.843        0.055    0.479   0.097         0.046        0.004\n",
      "MedPFNClassifier                      0.948         0.006           0.678          0.142        0.233       0.072         0.856        0.045    0.345   0.096         5.033        0.103\n",
      "MedPFNClassifier                      0.953         0.006           0.735          0.107        0.322       0.086         0.896        0.038    0.443   0.094        28.414        0.407\n",
      "MedPFNClassifier                      0.952         0.008           0.652          0.125        0.470       0.102         0.898        0.036    0.537   0.086        43.367        5.062\n",
      "RandomForestClassifier                0.959         0.004           0.859          0.094        0.374       0.075         0.896        0.040    0.515   0.076         1.055        0.054\n",
      "CatBoostGrid                          0.959         0.005           0.836          0.118        0.389       0.082         0.907        0.028    0.523   0.077       147.728        7.182\n",
      "XGBoostGrid                           0.949         0.005           0.598          0.311        0.222       0.112         0.893        0.035    0.324   0.164       130.904       14.342\n",
      "LogisticRegressionClassifier          0.937         0.007           0.474          0.087        0.385       0.071         0.820        0.051    0.421   0.061         0.030        0.007\n",
      "TabPFNClassifier                      0.954         0.003           0.846          0.049        0.267       0.046         0.911        0.034    0.404   0.057        30.063        3.129\n",
      "TabForestPFNClassifier                0.953         0.006           0.684          0.097        0.422       0.076         0.900        0.028    0.515   0.062       221.526       14.168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-03 17:36:11.437\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1477 | Val score: 0.9481\u001b[0m\n",
      "\u001b[32m2024-11-03 17:36:48.056\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1270 | Train score: 0.9551 | Val loss: 0.1428 | Val score: 0.9469\u001b[0m\n",
      "\u001b[32m2024-11-03 17:37:23.515\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1626 | Train score: 0.9473 | Val loss: 0.1438 | Val score: 0.9481\u001b[0m\n",
      "\u001b[32m2024-11-03 17:38:01.730\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1412 | Train score: 0.9531 | Val loss: 0.1425 | Val score: 0.9524\u001b[0m\n",
      "\u001b[32m2024-11-03 17:38:38.276\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1375 | Train score: 0.9609 | Val loss: 0.1461 | Val score: 0.9481\u001b[0m\n",
      "\u001b[32m2024-11-03 17:39:15.798\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1553 | Train score: 0.9531 | Val loss: 0.1421 | Val score: 0.9530\u001b[0m\n",
      "\u001b[32m2024-11-03 17:39:54.320\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1095 | Train score: 0.9688 | Val loss: 0.1434 | Val score: 0.9517\u001b[0m\n",
      "\u001b[32m2024-11-03 17:40:37.051\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1245 | Train score: 0.9590 | Val loss: 0.1416 | Val score: 0.9524\u001b[0m\n",
      "\u001b[32m2024-11-03 17:41:17.716\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1422 | Train score: 0.9590 | Val loss: 0.1436 | Val score: 0.9517\u001b[0m\n",
      "\u001b[32m2024-11-03 17:41:56.720\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1382 | Train score: 0.9570 | Val loss: 0.1423 | Val score: 0.9524\u001b[0m\n",
      "\u001b[32m2024-11-03 17:42:37.502\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1608 | Train score: 0.9473 | Val loss: 0.1392 | Val score: 0.9511\u001b[0m\n",
      "\u001b[32m2024-11-03 17:43:15.705\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1382 | Val score: 0.9542\u001b[0m\n",
      "\u001b[32m2024-11-03 17:43:53.416\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1480 | Train score: 0.9512 | Val loss: 0.1306 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 17:44:30.130\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1217 | Train score: 0.9590 | Val loss: 0.1279 | Val score: 0.9597\u001b[0m\n",
      "\u001b[32m2024-11-03 17:45:06.829\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1496 | Train score: 0.9551 | Val loss: 0.1227 | Val score: 0.9597\u001b[0m\n",
      "\u001b[32m2024-11-03 17:45:44.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1564 | Train score: 0.9512 | Val loss: 0.1285 | Val score: 0.9585\u001b[0m\n",
      "\u001b[32m2024-11-03 17:46:21.379\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1340 | Train score: 0.9609 | Val loss: 0.1280 | Val score: 0.9566\u001b[0m\n",
      "\u001b[32m2024-11-03 17:46:56.939\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1189 | Train score: 0.9590 | Val loss: 0.1325 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 17:47:33.773\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1279 | Train score: 0.9531 | Val loss: 0.1269 | Val score: 0.9585\u001b[0m\n",
      "\u001b[32m2024-11-03 17:48:08.559\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1481 | Train score: 0.9609 | Val loss: 0.1292 | Val score: 0.9578\u001b[0m\n",
      "\u001b[32m2024-11-03 17:48:43.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1119 | Train score: 0.9648 | Val loss: 0.1286 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 17:49:18.499\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1795 | Train score: 0.9414 | Val loss: 0.1293 | Val score: 0.9585\u001b[0m\n",
      "\u001b[32m2024-11-03 17:49:54.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1415 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-03 17:50:31.575\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1446 | Train score: 0.9512 | Val loss: 0.1273 | Val score: 0.9597\u001b[0m\n",
      "\u001b[32m2024-11-03 17:51:07.910\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1615 | Train score: 0.9473 | Val loss: 0.1262 | Val score: 0.9597\u001b[0m\n",
      "\u001b[32m2024-11-03 17:51:45.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1147 | Train score: 0.9668 | Val loss: 0.1286 | Val score: 0.9578\u001b[0m\n",
      "\u001b[32m2024-11-03 17:52:21.758\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1223 | Train score: 0.9531 | Val loss: 0.1287 | Val score: 0.9609\u001b[0m\n",
      "\u001b[32m2024-11-03 17:52:57.759\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1070 | Train score: 0.9668 | Val loss: 0.1258 | Val score: 0.9578\u001b[0m\n",
      "\u001b[32m2024-11-03 17:53:33.571\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1333 | Train score: 0.9473 | Val loss: 0.1272 | Val score: 0.9597\u001b[0m\n",
      "\u001b[32m2024-11-03 17:54:10.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1429 | Train score: 0.9551 | Val loss: 0.1250 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 17:54:44.806\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1183 | Train score: 0.9590 | Val loss: 0.1266 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 17:55:22.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1548 | Train score: 0.9570 | Val loss: 0.1274 | Val score: 0.9591\u001b[0m\n",
      "\u001b[32m2024-11-03 17:56:00.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1155 | Train score: 0.9570 | Val loss: 0.1269 | Val score: 0.9578\u001b[0m\n",
      "\u001b[32m2024-11-03 17:56:36.588\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1427 | Val score: 0.9456\u001b[0m\n",
      "\u001b[32m2024-11-03 17:57:28.577\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1765 | Train score: 0.9355 | Val loss: 0.1348 | Val score: 0.9524\u001b[0m\n",
      "\u001b[32m2024-11-03 17:58:16.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1581 | Train score: 0.9336 | Val loss: 0.1286 | Val score: 0.9530\u001b[0m\n",
      "\u001b[32m2024-11-03 17:58:55.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1282 | Train score: 0.9551 | Val loss: 0.1307 | Val score: 0.9548\u001b[0m\n",
      "\u001b[32m2024-11-03 17:59:31.939\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1445 | Train score: 0.9570 | Val loss: 0.1325 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 18:00:07.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0969 | Train score: 0.9590 | Val loss: 0.1336 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 18:00:44.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1307 | Train score: 0.9551 | Val loss: 0.1299 | Val score: 0.9524\u001b[0m\n",
      "\u001b[32m2024-11-03 18:01:21.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1111 | Train score: 0.9707 | Val loss: 0.1355 | Val score: 0.9585\u001b[0m\n",
      "\u001b[32m2024-11-03 18:01:57.915\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1728 | Train score: 0.9512 | Val loss: 0.1341 | Val score: 0.9530\u001b[0m\n",
      "\u001b[32m2024-11-03 18:02:39.033\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1211 | Train score: 0.9590 | Val loss: 0.1312 | Val score: 0.9511\u001b[0m\n",
      "\u001b[32m2024-11-03 18:03:25.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1086 | Train score: 0.9590 | Val loss: 0.1342 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 18:04:06.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1411 | Val score: 0.9530\u001b[0m\n",
      "\u001b[32m2024-11-03 18:04:48.945\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1353 | Train score: 0.9531 | Val loss: 0.1390 | Val score: 0.9530\u001b[0m\n",
      "\u001b[32m2024-11-03 18:05:31.241\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1433 | Train score: 0.9512 | Val loss: 0.1405 | Val score: 0.9517\u001b[0m\n",
      "\u001b[32m2024-11-03 18:06:09.637\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1027 | Train score: 0.9551 | Val loss: 0.1374 | Val score: 0.9536\u001b[0m\n",
      "\u001b[32m2024-11-03 18:06:45.355\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1779 | Train score: 0.9570 | Val loss: 0.1375 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 18:07:24.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1786 | Train score: 0.9316 | Val loss: 0.1339 | Val score: 0.9566\u001b[0m\n",
      "\u001b[32m2024-11-03 18:08:03.192\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1129 | Train score: 0.9609 | Val loss: 0.1341 | Val score: 0.9524\u001b[0m\n",
      "\u001b[32m2024-11-03 18:08:38.698\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1204 | Train score: 0.9668 | Val loss: 0.1372 | Val score: 0.9517\u001b[0m\n",
      "\u001b[32m2024-11-03 18:09:14.328\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1075 | Train score: 0.9688 | Val loss: 0.1380 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-03 18:09:52.019\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1353 | Train score: 0.9609 | Val loss: 0.1331 | Val score: 0.9548\u001b[0m\n",
      "\u001b[32m2024-11-03 18:10:29.563\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1099 | Train score: 0.9727 | Val loss: 0.1338 | Val score: 0.9566\u001b[0m\n",
      "\u001b[32m2024-11-03 18:11:04.390\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1366 | Val score: 0.9511\u001b[0m\n",
      "\u001b[32m2024-11-03 18:11:41.126\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1491 | Train score: 0.9512 | Val loss: 0.1292 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 18:12:18.204\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1264 | Train score: 0.9668 | Val loss: 0.1344 | Val score: 0.9542\u001b[0m\n",
      "\u001b[32m2024-11-03 18:12:54.975\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1823 | Train score: 0.9434 | Val loss: 0.1330 | Val score: 0.9536\u001b[0m\n",
      "\u001b[32m2024-11-03 18:13:29.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1091 | Train score: 0.9629 | Val loss: 0.1292 | Val score: 0.9542\u001b[0m\n",
      "\u001b[32m2024-11-03 18:14:04.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1438 | Train score: 0.9551 | Val loss: 0.1331 | Val score: 0.9542\u001b[0m\n",
      "\u001b[32m2024-11-03 18:14:39.525\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1365 | Train score: 0.9531 | Val loss: 0.1325 | Val score: 0.9536\u001b[0m\n",
      "\u001b[32m2024-11-03 18:15:17.542\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1306 | Train score: 0.9590 | Val loss: 0.1341 | Val score: 0.9542\u001b[0m\n",
      "\u001b[32m2024-11-03 18:15:52.845\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1836 | Train score: 0.9473 | Val loss: 0.1277 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 18:16:30.648\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1944 | Train score: 0.9375 | Val loss: 0.1287 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 18:17:05.802\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1022 | Train score: 0.9648 | Val loss: 0.1275 | Val score: 0.9548\u001b[0m\n",
      "\u001b[32m2024-11-03 18:17:42.422\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1368 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 18:18:17.898\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1418 | Train score: 0.9492 | Val loss: 0.1279 | Val score: 0.9566\u001b[0m\n",
      "\u001b[32m2024-11-03 18:18:51.890\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1459 | Train score: 0.9492 | Val loss: 0.1243 | Val score: 0.9597\u001b[0m\n",
      "\u001b[32m2024-11-03 18:19:28.091\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1533 | Train score: 0.9434 | Val loss: 0.1250 | Val score: 0.9621\u001b[0m\n",
      "\u001b[32m2024-11-03 18:20:05.373\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1541 | Train score: 0.9512 | Val loss: 0.1253 | Val score: 0.9621\u001b[0m\n",
      "\u001b[32m2024-11-03 18:20:40.117\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1317 | Train score: 0.9570 | Val loss: 0.1272 | Val score: 0.9627\u001b[0m\n",
      "\u001b[32m2024-11-03 18:21:18.719\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1202 | Train score: 0.9609 | Val loss: 0.1232 | Val score: 0.9603\u001b[0m\n",
      "\u001b[32m2024-11-03 18:21:56.459\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1233 | Train score: 0.9707 | Val loss: 0.1191 | Val score: 0.9633\u001b[0m\n",
      "\u001b[32m2024-11-03 18:22:31.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1338 | Train score: 0.9590 | Val loss: 0.1218 | Val score: 0.9646\u001b[0m\n",
      "\u001b[32m2024-11-03 18:23:06.480\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1614 | Train score: 0.9473 | Val loss: 0.1237 | Val score: 0.9646\u001b[0m\n",
      "\u001b[32m2024-11-03 18:23:40.725\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1371 | Train score: 0.9531 | Val loss: 0.1247 | Val score: 0.9640\u001b[0m\n",
      "\u001b[32m2024-11-03 18:24:16.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1510 | Val score: 0.9487\u001b[0m\n",
      "\u001b[32m2024-11-03 18:24:53.320\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1316 | Train score: 0.9531 | Val loss: 0.1504 | Val score: 0.9487\u001b[0m\n",
      "\u001b[32m2024-11-03 18:25:30.733\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1481 | Train score: 0.9492 | Val loss: 0.1481 | Val score: 0.9462\u001b[0m\n",
      "\u001b[32m2024-11-03 18:26:09.805\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1654 | Train score: 0.9512 | Val loss: 0.1469 | Val score: 0.9493\u001b[0m\n",
      "\u001b[32m2024-11-03 18:26:45.034\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1501 | Train score: 0.9531 | Val loss: 0.1472 | Val score: 0.9499\u001b[0m\n",
      "\u001b[32m2024-11-03 18:27:20.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1191 | Train score: 0.9609 | Val loss: 0.1467 | Val score: 0.9487\u001b[0m\n",
      "\u001b[32m2024-11-03 18:27:57.762\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1379 | Train score: 0.9473 | Val loss: 0.1453 | Val score: 0.9493\u001b[0m\n",
      "\u001b[32m2024-11-03 18:28:33.800\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1141 | Train score: 0.9629 | Val loss: 0.1440 | Val score: 0.9524\u001b[0m\n",
      "\u001b[32m2024-11-03 18:29:10.076\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1296 | Train score: 0.9570 | Val loss: 0.1439 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-03 18:29:44.123\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1238 | Train score: 0.9688 | Val loss: 0.1481 | Val score: 0.9511\u001b[0m\n",
      "\u001b[32m2024-11-03 18:30:19.054\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1182 | Train score: 0.9570 | Val loss: 0.1483 | Val score: 0.9487\u001b[0m\n",
      "\u001b[32m2024-11-03 18:30:54.853\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1338 | Val score: 0.9511\u001b[0m\n",
      "\u001b[32m2024-11-03 18:31:30.790\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1466 | Train score: 0.9512 | Val loss: 0.1218 | Val score: 0.9536\u001b[0m\n",
      "\u001b[32m2024-11-03 18:32:05.347\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1508 | Train score: 0.9531 | Val loss: 0.1176 | Val score: 0.9585\u001b[0m\n",
      "\u001b[32m2024-11-03 18:32:41.027\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1514 | Train score: 0.9492 | Val loss: 0.1199 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 18:33:15.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1461 | Train score: 0.9531 | Val loss: 0.1191 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 18:33:50.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1514 | Train score: 0.9570 | Val loss: 0.1229 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 18:34:27.850\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1483 | Train score: 0.9434 | Val loss: 0.1191 | Val score: 0.9560\u001b[0m\n",
      "\u001b[32m2024-11-03 18:35:03.030\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1899 | Train score: 0.9355 | Val loss: 0.1218 | Val score: 0.9603\u001b[0m\n",
      "\u001b[32m2024-11-03 18:35:37.403\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1632 | Train score: 0.9414 | Val loss: 0.1204 | Val score: 0.9578\u001b[0m\n",
      "\u001b[32m2024-11-03 18:36:12.287\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1295 | Train score: 0.9551 | Val loss: 0.1203 | Val score: 0.9572\u001b[0m\n",
      "\u001b[32m2024-11-03 18:36:50.455\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1420 | Train score: 0.9492 | Val loss: 0.1174 | Val score: 0.9585\u001b[0m\n",
      "\u001b[32m2024-11-03 18:37:29.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1470 | Val score: 0.9499\u001b[0m\n",
      "\u001b[32m2024-11-03 18:38:02.453\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1158 | Train score: 0.9648 | Val loss: 0.1480 | Val score: 0.9511\u001b[0m\n",
      "\u001b[32m2024-11-03 18:38:37.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1255 | Train score: 0.9512 | Val loss: 0.1500 | Val score: 0.9536\u001b[0m\n",
      "\u001b[32m2024-11-03 18:39:12.411\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2037 | Train score: 0.9395 | Val loss: 0.1473 | Val score: 0.9548\u001b[0m\n",
      "\u001b[32m2024-11-03 18:39:49.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1565 | Train score: 0.9434 | Val loss: 0.1465 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-03 18:40:26.751\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1620 | Train score: 0.9492 | Val loss: 0.1481 | Val score: 0.9536\u001b[0m\n",
      "\u001b[32m2024-11-03 18:41:05.171\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1186 | Train score: 0.9727 | Val loss: 0.1475 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-03 18:41:40.045\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1489 | Train score: 0.9414 | Val loss: 0.1472 | Val score: 0.9511\u001b[0m\n",
      "\u001b[32m2024-11-03 18:42:15.294\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1030 | Train score: 0.9668 | Val loss: 0.1474 | Val score: 0.9499\u001b[0m\n",
      "\u001b[32m2024-11-03 18:42:50.883\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1489 | Train score: 0.9453 | Val loss: 0.1473 | Val score: 0.9517\u001b[0m\n",
      "\u001b[32m2024-11-03 18:43:31.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1529 | Train score: 0.9570 | Val loss: 0.1459 | Val score: 0.9542\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " context_length \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.939         0.000           0.000          0.000        0.000       0.000         0.500        0.000    0.000   0.000         0.000        0.000\n",
      "XGBClassifier                         0.944         0.006           0.563          0.072        0.375       0.052         0.865        0.014    0.449   0.058         0.053        0.005\n",
      "MedPFNClassifier                      0.943         0.003           0.739          0.189        0.093       0.071         0.850        0.018    0.155   0.108        20.498        2.235\n",
      "MedPFNClassifier                      0.951         0.003           0.837          0.096        0.238       0.035         0.894        0.020    0.369   0.047        83.616       12.374\n",
      "MedPFNClassifier                      0.951         0.006           0.694          0.109        0.353       0.060         0.892        0.022    0.462   0.061        92.291        4.785\n",
      "RandomForestClassifier                0.955         0.004           0.795          0.075        0.344       0.058         0.908        0.021    0.477   0.060         2.385        0.049\n",
      "CatBoostGrid                          0.957         0.005           0.789          0.088        0.389       0.043         0.900        0.027    0.520   0.052       160.159       10.800\n",
      "XGBoostGrid                           0.955         0.004           0.788          0.061        0.362       0.044         0.916        0.018    0.495   0.048       185.743       14.649\n",
      "LogisticRegressionClassifier          0.945         0.004           0.577          0.057        0.333       0.039         0.842        0.026    0.421   0.038         0.053        0.011\n",
      "TabPFNClassifier                      0.951         0.005           0.817          0.116        0.253       0.050         0.906        0.020    0.384   0.067        96.494        3.199\n",
      "TabForestPFNClassifier                0.954         0.006           0.725          0.102        0.380       0.060         0.895        0.024    0.497   0.068       406.890       16.181\n"
     ]
    }
   ],
   "source": [
    "save = True\n",
    "sampling = None\n",
    "cv = 10\n",
    "best_delete = 0\n",
    "strat_split = True\n",
    "recomp = False\n",
    "n_optim = 1000\n",
    "cat_optim = 10\n",
    "ft_epochs = 20\n",
    "ft_epochs_forest = 10\n",
    "ft_lr = 1e-5\n",
    "max_s = 1024\n",
    "max_q = 128\n",
    "max_samples = 1024\n",
    "no_pre_process = False\n",
    "multi_decoder = \"permutation\"\n",
    "N_ens = 5\n",
    "seed = 42\n",
    "overwrite = True\n",
    "metrics = [\"accuracy\", \"precision\", \"recall\", \"roc_auc\", \"f1\"]\n",
    "dir_path = os.path.abspath(os.getcwd())\n",
    "#run_name = \"medium_net_mlp_balance_bsplit_baseline\" ## NO PERM, VERY ROBUST\n",
    "#run_name2 = \"large_mlp_var_balance_05weight_anova\" ## das aller bestigste\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_newprior\" ## das aller bestigste\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_newprior\" ## das aller bestigste\n",
    "run_name = \"medium_mlp_var_balance_05weight_anova_bestwithnoisebnn_100\" ## good start, best with ft\n",
    "#run_name3 = \"medium_mlp_var_balance_05weight_anova_bestwithnoisebnn_100_moreweight\" ## best start, ft no so good\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_200\" ## das aller bestigste\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_longer\" ## das aller bestigste\n",
    "#run_name = \"medium_mlp_balance_lownoisefixparam_anova\"\n",
    "#run_name = \"medium_mlp_0.5static_balance_anova\"\n",
    "#run_name = \"large_mlp_fullbalance\"\n",
    "#run_name = \"small_net_mlp_var_imbalance_05weight\" ## WORKS VERY WELL WITH PERM\n",
    "#run_name = \"small_net_mlp_varbalance_weight_batchunisplit\"\n",
    "#run_name = \"small_net_mlp_variable_balance_weight\"\n",
    "#run_name = \"small_net_mlp_balance_minevalup\"\n",
    "path = dir_path + f\"/logs/trainrun_{run_name}\"\n",
    "#path2 = dir_path + f\"/logs/trainrun_{run_name2}\"\n",
    "#path3 = dir_path + f\"/logs/trainrun_{run_name3}\"\n",
    "filename = \"model\"\n",
    "\n",
    "lengths = [512,1024,2048,4096,8192]\n",
    "\n",
    "models = [\n",
    "    MajorityClass(),\n",
    "    XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic'),\n",
    "    MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=1, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process),\n",
    "    MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process),\n",
    "    MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process,\n",
    "                    ft_epochs=ft_epochs, ft_lr=ft_lr),\n",
    "    RandomForestClassifier(),\n",
    "    #AutoGluon(),\n",
    "    CatBoostGrid(),\n",
    "    XGBoostGrid(),\n",
    "    LogisticRegressionClassifier(), \n",
    "    TabPFNClassifier(device='cpu', N_ensemble_configurations=5, no_preprocess_mode=no_pre_process),\n",
    "    TabForestPFNClassifier(\"saved_models/tabforest/mix600k/tabforestpfn.pt\", \"saved_models/tabforest/mix600k/config_run.yaml\", max_epochs=ft_epochs_forest)\n",
    "]\n",
    "reducer  = AnovaSelect()\n",
    "#for reducer in [AnovaSelect(), RandomSelect(), NonZeroSelect(), MeanSelect(), StdSelect(), MaxSelect(), PCASelect()]:\n",
    "#data = clr(all_data)\n",
    "\n",
    "#all_data = normalize(all_data)\n",
    "\n",
    "for cl in lengths:\n",
    "    results_mean = pd.DataFrame(np.zeros((len(models), len(metrics)+1)),\n",
    "                                index=[m.__class__.__name__ for m in models],\n",
    "                                columns=metrics+[\"runtime\"])\n",
    "    results_std = pd.DataFrame(np.zeros((len(models), len(metrics)+1)), \n",
    "                               index=[m.__class__.__name__ for m in models],\n",
    "                               columns=metrics+[\"runtime\"])\n",
    "    \n",
    "    for ii, model in enumerate(models):\n",
    "        results_mean.iloc[ii,:], results_std.iloc[ii,:] = cross_validate_sample(\n",
    "            model, all_data, labels, metrics, strat_split, cv, sampling, \n",
    "            reducer, cl, seed=seed, overwrite=overwrite, n_best_delete=best_delete,\n",
    "            recomp=recomp)\n",
    "    \n",
    "    results_mean = results_mean.add_suffix(\" mean\")\n",
    "    results_std = results_std.add_suffix(\" std\")\n",
    "    results_full = pd.concat((results_mean, results_std), axis=1)\n",
    "    cols = results_full.columns.tolist()\n",
    "    new_cols = []\n",
    "    for i in range(int(len(cols)/2)):\n",
    "        new_cols.append(cols[i])\n",
    "        new_cols.append(cols[i+int(len(cols)/2)])\n",
    "    results_full = results_full[new_cols]\n",
    "    red_name = \"context_length\"\n",
    "    if save:\n",
    "        directory = f\"results/{red_name}\"\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        save_path = f'results/{red_name}/context_length_{cl}.csv'\n",
    "        results_full.to_csv(save_path)\n",
    "    print(\"\\n\", \"\\n\", red_name, \"\\n\", results_full.round(3))\n",
    "    #print(results_full.sort_values(\"roc_auc mean\").round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "03b4b8c5-0c53-43b5-96a7-3eec013f6415",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\AppData\\Local\\Temp\\ipykernel_8164\\550965774.py:41: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  fig.show()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'df = pd.read_csv(path)\\n        accuracies.append(df.iloc[m,1])\\n        rocs.append(df.iloc[m,7])\\n        f1s.append(df.iloc[m,9])\\n    axs[0].plot(lengths, accuracies)\\n    axs[1].plot(lengths, rocs, label = models[m])\\n    axs[2].plot(lengths, f1s)\\n    \\naxs[1].legend(fontsize=12)\\nfig.show()'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "models = [\"Majclass\", \"MedPFN-1\", \"MedPFN-7\", \"MedPFN-7FT\", \"RandomForest\", \"CatBoost\", \"XGBoost\", \"Logistic Regression\", \"TabPFN\", \"TabForestPFN\"]\n",
    "fig, axs = plt.subplots(1,1,figsize=(10,5))#plt.subplots(1, 3, figsize=(25, 5))\n",
    "all_accuracies = []\n",
    "all_rocs = []\n",
    "all_f1s = []\n",
    "lengths = [512,1024,2048,4096,8192]\n",
    "for m in range(1,len(models)):\n",
    "    accuracies = []\n",
    "    rocs = []\n",
    "    f1s = []\n",
    "    for cl in lengths:\n",
    "    \n",
    "        path = f'results/context_length/context_length_{cl}.csv'\n",
    "        df = pd.read_csv(path)\n",
    "        accuracies.append(df.iloc[m,1])\n",
    "        rocs.append(df.iloc[m,7])\n",
    "        f1s.append(df.iloc[m,9])\n",
    "    all_accuracies.append(accuracies)\n",
    "    all_rocs.append(rocs)\n",
    "    all_f1s.append(f1s)\n",
    "    \n",
    "#axs[0].plot(all_accuracies[3])\n",
    "#axs[1].plot(all_rocs[3])\n",
    "#axs[2].plot(all_f1s[2])\n",
    "mean_accuracies = all_accuracies[3]-np.max(np.array(all_accuracies)[4:],axis=0)\n",
    "#axs.plot(fracs, mean_accuracies)\n",
    "mean_rocs = all_rocs[3]-np.max(np.array(all_rocs)[4:],axis=0)\n",
    "#axs.plot(fracs, mean_rocs)\n",
    "mean_f1s = all_f1s[3]-np.max(np.array(all_f1s)[4:],axis=0)\n",
    "#axs.plot(fracs, mean_f1s)\n",
    "axs.plot(lengths, np.zeros(len(lengths)), linestyle='--', c=\"black\", label=\"Win threshhold\")\n",
    "axs.plot(lengths, mean_rocs, marker=\"v\", linewidth=2.5, markersize=7.0, label='ROC AUC', c=\"darkviolet\")\n",
    "axs.plot(lengths, mean_accuracies, marker=\"v\", linewidth=2.5, markersize=7.0, label='Accuracy', c=\"crimson\")\n",
    "axs.plot(lengths, mean_f1s, marker=\"v\", linewidth=2.5, markersize=7.0, label='F1-score', c=\"limegreen\")\n",
    "#axs.set_yticks([-0.05,0,0.05,0.1])\n",
    "#axs.set_xlim(0.5,0.94)\n",
    "axs.set_xlabel(\"Fraction of class 0 in data\")\n",
    "axs.set_ylabel(\"MedPFN - mean[baselines]\")\n",
    "axs.grid()\n",
    "axs.legend(fontsize=12)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "'''df = pd.read_csv(path)\n",
    "        accuracies.append(df.iloc[m,1])\n",
    "        rocs.append(df.iloc[m,7])\n",
    "        f1s.append(df.iloc[m,9])\n",
    "    axs[0].plot(lengths, accuracies)\n",
    "    axs[1].plot(lengths, rocs, label = models[m])\n",
    "    axs[2].plot(lengths, f1s)\n",
    "    \n",
    "axs[1].legend(fontsize=12)\n",
    "fig.show()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc866d4c-75ed-4715-a25d-b0cb8caf5d63",
   "metadata": {},
   "source": [
    "## Imbalance anaysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2d2fcae7-9f0c-4d93-a6a2-b2b6bf4bcf8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700 7087\n",
      "(7787, 1391)\n",
      "0.9101065879029151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 12:29:22.635\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1850 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:24.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2190 | Train score: 0.9383 | Val loss: 0.1841 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:25.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2080 | Train score: 0.9383 | Val loss: 0.1781 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:27.430\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2253 | Train score: 0.9259 | Val loss: 0.1775 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:29.024\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1605 | Train score: 0.9815 | Val loss: 0.1739 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:30.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1880 | Train score: 0.9383 | Val loss: 0.1726 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:32.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1869 | Train score: 0.9321 | Val loss: 0.1719 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:33.977\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.2066 | Train score: 0.9321 | Val loss: 0.1705 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:35.483\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1986 | Train score: 0.9444 | Val loss: 0.1695 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:37.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1860 | Train score: 0.9568 | Val loss: 0.1690 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:38.702\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1524 | Train score: 0.9568 | Val loss: 0.1687 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:40.310\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1837 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:42.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1991 | Train score: 0.9321 | Val loss: 0.1793 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:43.768\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1918 | Train score: 0.9321 | Val loss: 0.1758 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:45.360\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2105 | Train score: 0.9259 | Val loss: 0.1764 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:47.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.2111 | Train score: 0.9136 | Val loss: 0.1791 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:48.581\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1609 | Train score: 0.9321 | Val loss: 0.1817 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:50.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1383 | Train score: 0.9506 | Val loss: 0.1815 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:51.728\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1482 | Train score: 0.9383 | Val loss: 0.1807 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:53.279\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1466 | Train score: 0.9506 | Val loss: 0.1796 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:54.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1410 | Train score: 0.9630 | Val loss: 0.1795 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:56.665\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1334 | Train score: 0.9506 | Val loss: 0.1813 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:58.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1677 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:29:59.917\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1767 | Train score: 0.9444 | Val loss: 0.1614 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:01.489\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1885 | Train score: 0.9259 | Val loss: 0.1654 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:03.123\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1464 | Train score: 0.9259 | Val loss: 0.1713 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:04.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1640 | Train score: 0.9383 | Val loss: 0.1777 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:06.497\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.2146 | Train score: 0.9383 | Val loss: 0.1633 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:08.234\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.2237 | Train score: 0.9136 | Val loss: 0.1576 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:09.737\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1705 | Train score: 0.9259 | Val loss: 0.1562 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:11.426\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1258 | Train score: 0.9506 | Val loss: 0.1554 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:13.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1676 | Train score: 0.9444 | Val loss: 0.1547 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:14.839\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1716 | Train score: 0.9630 | Val loss: 0.1534 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:16.497\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1651 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:18.150\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2029 | Train score: 0.9321 | Val loss: 0.1605 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:19.887\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2150 | Train score: 0.9383 | Val loss: 0.1575 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:21.448\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1691 | Train score: 0.9506 | Val loss: 0.1552 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:23.042\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1710 | Train score: 0.9321 | Val loss: 0.1567 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:24.664\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.2064 | Train score: 0.9383 | Val loss: 0.1582 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:26.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.2034 | Train score: 0.9444 | Val loss: 0.1576 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:27.862\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1738 | Train score: 0.9444 | Val loss: 0.1578 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:29.463\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1563 | Train score: 0.9568 | Val loss: 0.1575 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:31.015\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1616 | Train score: 0.9506 | Val loss: 0.1571 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:32.548\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1855 | Train score: 0.9506 | Val loss: 0.1559 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:34.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1768 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:35.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1663 | Train score: 0.9568 | Val loss: 0.1705 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:37.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2004 | Train score: 0.9259 | Val loss: 0.1682 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:38.889\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1724 | Train score: 0.9506 | Val loss: 0.1670 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:40.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1616 | Train score: 0.9506 | Val loss: 0.1669 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:42.189\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1559 | Train score: 0.9568 | Val loss: 0.1680 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:43.847\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.2419 | Train score: 0.9321 | Val loss: 0.1703 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:45.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1903 | Train score: 0.9259 | Val loss: 0.1712 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:47.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1416 | Train score: 0.9506 | Val loss: 0.1691 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:48.586\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1717 | Train score: 0.9444 | Val loss: 0.1676 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:50.227\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1674 | Train score: 0.9568 | Val loss: 0.1665 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:51.816\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1563 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:53.755\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2477 | Train score: 0.9259 | Val loss: 0.1748 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:55.428\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2037 | Train score: 0.9444 | Val loss: 0.1611 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:57.300\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1925 | Train score: 0.9259 | Val loss: 0.1502 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 12:30:59.161\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1647 | Train score: 0.9568 | Val loss: 0.1438 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:00.943\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1733 | Train score: 0.9383 | Val loss: 0.1370 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:02.595\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1756 | Train score: 0.9383 | Val loss: 0.1298 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:04.243\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1958 | Train score: 0.9321 | Val loss: 0.1268 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:06.049\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1898 | Train score: 0.9506 | Val loss: 0.1249 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:07.860\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1609 | Train score: 0.9444 | Val loss: 0.1237 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:09.515\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1871 | Train score: 0.9321 | Val loss: 0.1232 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:11.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1558 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:12.599\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2213 | Train score: 0.9321 | Val loss: 0.1620 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:14.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1970 | Train score: 0.9321 | Val loss: 0.1503 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:15.810\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2133 | Train score: 0.9383 | Val loss: 0.1436 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:17.460\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.2010 | Train score: 0.9568 | Val loss: 0.1401 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:18.946\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.2089 | Train score: 0.9444 | Val loss: 0.1394 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:20.508\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1791 | Train score: 0.9259 | Val loss: 0.1408 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:22.037\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.2178 | Train score: 0.9383 | Val loss: 0.1437 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:23.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.2409 | Train score: 0.9383 | Val loss: 0.1468 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:25.184\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1746 | Train score: 0.9444 | Val loss: 0.1491 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:26.695\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1703 | Train score: 0.9506 | Val loss: 0.1503 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:28.363\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1788 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:29.908\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1514 | Train score: 0.9444 | Val loss: 0.1762 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:31.533\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2036 | Train score: 0.9383 | Val loss: 0.1749 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:33.084\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2253 | Train score: 0.9259 | Val loss: 0.1727 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:34.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1794 | Train score: 0.9383 | Val loss: 0.1712 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:36.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1747 | Train score: 0.9259 | Val loss: 0.1718 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:37.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1911 | Train score: 0.9259 | Val loss: 0.1722 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:39.478\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1719 | Train score: 0.9444 | Val loss: 0.1710 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:41.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1497 | Train score: 0.9630 | Val loss: 0.1691 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:42.585\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.2134 | Train score: 0.9383 | Val loss: 0.1679 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:44.171\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1554 | Train score: 0.9444 | Val loss: 0.1665 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:45.793\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1934 | Val score: 0.9158\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:47.425\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2283 | Train score: 0.9321 | Val loss: 0.2030 | Val score: 0.9109\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:49.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1611 | Train score: 0.9691 | Val loss: 0.2043 | Val score: 0.9158\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:50.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2109 | Train score: 0.9444 | Val loss: 0.2031 | Val score: 0.9158\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:52.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.2013 | Train score: 0.9321 | Val loss: 0.2047 | Val score: 0.9158\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:53.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1632 | Train score: 0.9444 | Val loss: 0.2061 | Val score: 0.9158\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:55.389\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1371 | Train score: 0.9630 | Val loss: 0.2098 | Val score: 0.9158\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:56.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1096 | Train score: 0.9815 | Val loss: 0.2142 | Val score: 0.9158\u001b[0m\n",
      "\u001b[32m2024-11-04 12:31:58.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1618 | Train score: 0.9444 | Val loss: 0.2214 | Val score: 0.9208\u001b[0m\n",
      "\u001b[32m2024-11-04 12:32:00.437\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1255 | Train score: 0.9630 | Val loss: 0.2343 | Val score: 0.9158\u001b[0m\n",
      "\u001b[32m2024-11-04 12:32:02.074\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1768 | Train score: 0.9568 | Val loss: 0.2391 | Val score: 0.9109\u001b[0m\n",
      "\u001b[32m2024-11-04 12:32:03.720\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1902 | Val score: 0.9257\u001b[0m\n",
      "\u001b[32m2024-11-04 12:32:05.428\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1448 | Train score: 0.9568 | Val loss: 0.2011 | Val score: 0.9257\u001b[0m\n",
      "\u001b[32m2024-11-04 12:32:07.049\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1684 | Train score: 0.9321 | Val loss: 0.1996 | Val score: 0.9257\u001b[0m\n",
      "\u001b[32m2024-11-04 12:32:08.782\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1478 | Train score: 0.9506 | Val loss: 0.1979 | Val score: 0.9257\u001b[0m\n",
      "\u001b[32m2024-11-04 12:32:10.499\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1306 | Train score: 0.9568 | Val loss: 0.1982 | Val score: 0.9257\u001b[0m\n",
      "\u001b[32m2024-11-04 12:32:12.165\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1590 | Train score: 0.9321 | Val loss: 0.1982 | Val score: 0.9307\u001b[0m\n",
      "\u001b[32m2024-11-04 12:32:13.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1620 | Train score: 0.9383 | Val loss: 0.1978 | Val score: 0.9257\u001b[0m\n",
      "\u001b[32m2024-11-04 12:32:15.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1472 | Train score: 0.9506 | Val loss: 0.1977 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 12:32:17.512\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1274 | Train score: 0.9506 | Val loss: 0.2004 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 12:32:19.239\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1484 | Train score: 0.9630 | Val loss: 0.2032 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 12:32:20.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1726 | Train score: 0.9506 | Val loss: 0.2046 | Val score: 0.9356\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " imbalance \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.911         0.000           0.000          0.000         0.00       0.000         0.500        0.000    0.000   0.000         0.000        0.000\n",
      "MedPFNClassifier                      0.907         0.026           0.447          0.277         0.34       0.201         0.869        0.061    0.378   0.219         0.255        0.010\n",
      "MedPFNClassifier                      0.935         0.011           0.851          0.131         0.36       0.174         0.879        0.054    0.469   0.175         1.609        0.026\n",
      "MedPFNClassifier                      0.927         0.018           0.660          0.228         0.40       0.179         0.871        0.055    0.478   0.166        10.763        0.108\n",
      "RandomForestClassifier                0.934         0.011           0.860          0.147         0.31       0.104         0.887        0.043    0.448   0.123         0.250        0.014\n",
      "CatBoostGrid                          0.931         0.009           0.960          0.080         0.25       0.120         0.876        0.059    0.377   0.148        68.022        6.152\n",
      "XGBoostGrid                           0.923         0.011           0.493          0.417         0.20       0.179         0.887        0.040    0.273   0.233        39.759        1.738\n",
      "LogisticRegressionClassifier          0.918         0.019           0.542          0.096         0.63       0.090         0.858        0.064    0.580   0.084         0.008        0.001\n",
      "TabPFNClassifier                      0.929         0.012           0.727          0.189         0.32       0.117         0.900        0.043    0.434   0.141         2.473        0.043\n",
      "TabForestPFNClassifier                0.927         0.019           0.736          0.217         0.37       0.135         0.876        0.058    0.468   0.122        17.733        0.627\n",
      "700 8061\n",
      "(8761, 1391)\n",
      "0.9201004451546627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 12:57:12.036\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1674 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:57:14.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1606 | Train score: 0.9444 | Val loss: 0.1682 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 12:57:16.395\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1432 | Train score: 0.9568 | Val loss: 0.1702 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:57:18.565\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1428 | Train score: 0.9568 | Val loss: 0.1640 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 12:57:20.744\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1925 | Train score: 0.9321 | Val loss: 0.1631 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 12:57:22.979\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1926 | Train score: 0.9259 | Val loss: 0.1607 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 12:57:25.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1583 | Train score: 0.9444 | Val loss: 0.1618 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:57:27.349\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1129 | Train score: 0.9568 | Val loss: 0.1688 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 12:57:29.559\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1991 | Train score: 0.9383 | Val loss: 0.1687 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:57:31.794\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1255 | Train score: 0.9568 | Val loss: 0.1707 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:57:33.979\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.2030 | Train score: 0.9012 | Val loss: 0.1702 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:57:35.996\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1781 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 12:57:38.176\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1898 | Train score: 0.9444 | Val loss: 0.1913 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:57:40.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1957 | Train score: 0.9321 | Val loss: 0.1874 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 12:57:42.659\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1917 | Train score: 0.9321 | Val loss: 0.1796 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:57:44.896\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1667 | Train score: 0.9383 | Val loss: 0.1709 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:57:47.041\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1675 | Train score: 0.9383 | Val loss: 0.1634 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:57:49.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1285 | Train score: 0.9506 | Val loss: 0.1616 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:57:51.392\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1690 | Train score: 0.9321 | Val loss: 0.1626 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:57:53.652\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1350 | Train score: 0.9321 | Val loss: 0.1664 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:57:55.893\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1547 | Train score: 0.9568 | Val loss: 0.1711 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:57:58.177\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0911 | Train score: 0.9630 | Val loss: 0.1785 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:00.221\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1631 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:02.563\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1677 | Train score: 0.9383 | Val loss: 0.1752 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:04.943\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2261 | Train score: 0.9259 | Val loss: 0.1723 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:07.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1770 | Train score: 0.9321 | Val loss: 0.1721 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:09.315\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1337 | Train score: 0.9630 | Val loss: 0.1704 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:11.652\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1804 | Train score: 0.9444 | Val loss: 0.1680 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:14.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1710 | Train score: 0.9321 | Val loss: 0.1651 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:16.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1970 | Train score: 0.9321 | Val loss: 0.1631 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:18.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.2151 | Train score: 0.9321 | Val loss: 0.1604 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:20.956\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.2427 | Train score: 0.9383 | Val loss: 0.1584 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:23.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1958 | Train score: 0.9259 | Val loss: 0.1589 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:25.371\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1617 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:27.697\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1708 | Train score: 0.9321 | Val loss: 0.1608 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:30.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2123 | Train score: 0.9444 | Val loss: 0.1718 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:32.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1583 | Train score: 0.9506 | Val loss: 0.1658 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:35.000\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1686 | Train score: 0.9568 | Val loss: 0.1622 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:37.429\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.2105 | Train score: 0.9259 | Val loss: 0.1622 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:39.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1438 | Train score: 0.9444 | Val loss: 0.1610 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:42.327\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1850 | Train score: 0.9198 | Val loss: 0.1609 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:44.787\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1214 | Train score: 0.9691 | Val loss: 0.1600 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:47.129\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1081 | Train score: 0.9691 | Val loss: 0.1596 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:49.665\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1284 | Train score: 0.9568 | Val loss: 0.1599 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:51.763\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1489 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:54.092\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1315 | Train score: 0.9444 | Val loss: 0.1519 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:56.378\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1381 | Train score: 0.9444 | Val loss: 0.1589 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:58:58.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1989 | Train score: 0.9444 | Val loss: 0.1565 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:01.250\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1156 | Train score: 0.9444 | Val loss: 0.1595 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:03.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1449 | Train score: 0.9568 | Val loss: 0.1643 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:05.900\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1263 | Train score: 0.9444 | Val loss: 0.1681 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:08.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1354 | Train score: 0.9321 | Val loss: 0.1685 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:10.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1486 | Train score: 0.9630 | Val loss: 0.1707 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:12.888\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1431 | Train score: 0.9198 | Val loss: 0.1691 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:15.259\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1653 | Train score: 0.9383 | Val loss: 0.1658 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:17.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1553 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:19.652\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1717 | Train score: 0.9321 | Val loss: 0.1531 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:21.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1615 | Train score: 0.9568 | Val loss: 0.1526 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:24.229\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1515 | Train score: 0.9321 | Val loss: 0.1564 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:26.495\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1595 | Train score: 0.9444 | Val loss: 0.1539 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:28.800\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1153 | Train score: 0.9753 | Val loss: 0.1543 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:31.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1150 | Train score: 0.9691 | Val loss: 0.1559 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:33.402\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1800 | Train score: 0.9259 | Val loss: 0.1537 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:35.603\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1113 | Train score: 0.9630 | Val loss: 0.1530 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:37.783\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1757 | Train score: 0.9383 | Val loss: 0.1523 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:39.997\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1411 | Train score: 0.9568 | Val loss: 0.1523 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:42.035\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1828 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:44.301\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1516 | Train score: 0.9506 | Val loss: 0.1791 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:46.448\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1522 | Train score: 0.9383 | Val loss: 0.1788 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:48.642\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1314 | Train score: 0.9568 | Val loss: 0.1833 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:50.961\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1066 | Train score: 0.9630 | Val loss: 0.1947 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:53.197\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0888 | Train score: 0.9568 | Val loss: 0.2122 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:55.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1323 | Train score: 0.9568 | Val loss: 0.2224 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:57.739\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1044 | Train score: 0.9444 | Val loss: 0.2418 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 12:59:59.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1102 | Train score: 0.9753 | Val loss: 0.2268 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:02.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1380 | Train score: 0.9506 | Val loss: 0.2137 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:04.301\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1623 | Train score: 0.9630 | Val loss: 0.2041 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:06.326\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1351 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:08.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1578 | Train score: 0.9506 | Val loss: 0.1279 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:10.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2004 | Train score: 0.9506 | Val loss: 0.1292 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:13.294\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1660 | Train score: 0.9259 | Val loss: 0.1275 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:15.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1885 | Train score: 0.9383 | Val loss: 0.1263 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:17.817\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1682 | Train score: 0.9506 | Val loss: 0.1277 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:20.056\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1885 | Train score: 0.9383 | Val loss: 0.1289 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:22.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1247 | Train score: 0.9568 | Val loss: 0.1285 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:24.338\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1580 | Train score: 0.9383 | Val loss: 0.1283 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:26.486\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1297 | Train score: 0.9444 | Val loss: 0.1272 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:28.762\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1824 | Train score: 0.9383 | Val loss: 0.1274 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:30.811\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1533 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:33.046\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1378 | Train score: 0.9383 | Val loss: 0.1543 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:35.555\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1563 | Train score: 0.9444 | Val loss: 0.1553 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:37.805\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0973 | Train score: 0.9506 | Val loss: 0.1662 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:40.234\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1482 | Train score: 0.9630 | Val loss: 0.1688 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:42.539\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0957 | Train score: 0.9691 | Val loss: 0.1737 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:44.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1907 | Train score: 0.9444 | Val loss: 0.2683 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:47.150\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1699 | Train score: 0.9630 | Val loss: 0.1663 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:49.409\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1503 | Train score: 0.9568 | Val loss: 0.1674 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:51.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1167 | Train score: 0.9568 | Val loss: 0.1662 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:53.891\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1459 | Train score: 0.9198 | Val loss: 0.1651 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:55.888\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.2049 | Val score: 0.9208\u001b[0m\n",
      "\u001b[32m2024-11-04 13:00:58.093\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1997 | Train score: 0.9506 | Val loss: 0.2008 | Val score: 0.9158\u001b[0m\n",
      "\u001b[32m2024-11-04 13:01:00.225\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1439 | Train score: 0.9383 | Val loss: 0.2012 | Val score: 0.9208\u001b[0m\n",
      "\u001b[32m2024-11-04 13:01:02.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1751 | Train score: 0.9444 | Val loss: 0.2056 | Val score: 0.9208\u001b[0m\n",
      "\u001b[32m2024-11-04 13:01:04.588\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1343 | Train score: 0.9691 | Val loss: 0.2100 | Val score: 0.9257\u001b[0m\n",
      "\u001b[32m2024-11-04 13:01:06.721\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1634 | Train score: 0.9444 | Val loss: 0.2158 | Val score: 0.9307\u001b[0m\n",
      "\u001b[32m2024-11-04 13:01:08.860\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1548 | Train score: 0.9383 | Val loss: 0.2213 | Val score: 0.9307\u001b[0m\n",
      "\u001b[32m2024-11-04 13:01:10.980\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1258 | Train score: 0.9630 | Val loss: 0.2280 | Val score: 0.9257\u001b[0m\n",
      "\u001b[32m2024-11-04 13:01:13.162\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1666 | Train score: 0.9444 | Val loss: 0.2373 | Val score: 0.9158\u001b[0m\n",
      "\u001b[32m2024-11-04 13:01:15.370\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0921 | Train score: 0.9630 | Val loss: 0.2537 | Val score: 0.9158\u001b[0m\n",
      "\u001b[32m2024-11-04 13:01:17.527\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0785 | Train score: 0.9753 | Val loss: 0.2687 | Val score: 0.9158\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " imbalance \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.920         0.000           0.000          0.000        0.000       0.000         0.500        0.000    0.000   0.000         0.000        0.000\n",
      "MedPFNClassifier                      0.905         0.013           0.386          0.124        0.311       0.109         0.827        0.082    0.341   0.111         0.266        0.022\n",
      "MedPFNClassifier                      0.924         0.011           0.587          0.224        0.278       0.090         0.851        0.048    0.365   0.105         1.624        0.026\n",
      "MedPFNClassifier                      0.921         0.014           0.541          0.187        0.333       0.122         0.854        0.048    0.396   0.119        10.702        0.479\n",
      "RandomForestClassifier                0.932         0.009           0.801          0.185        0.256       0.087         0.866        0.059    0.369   0.101         0.237        0.009\n",
      "CatBoostGrid                          0.931         0.011           0.760          0.317        0.233       0.153         0.845        0.038    0.324   0.182        82.143        5.790\n",
      "XGBoostGrid                           0.923         0.007           0.250          0.316        0.089       0.130         0.835        0.040    0.129   0.181        50.140        1.597\n",
      "LogisticRegressionClassifier          0.909         0.031           0.472          0.206        0.489       0.124         0.786        0.096    0.474   0.156         0.009        0.001\n",
      "TabPFNClassifier                      0.930         0.010           0.655          0.165        0.322       0.126         0.869        0.061    0.413   0.130         3.223        0.076\n",
      "TabForestPFNClassifier                0.925         0.011           0.557          0.095        0.422       0.109         0.888        0.042    0.470   0.076        24.470        0.777\n",
      "700 9313\n",
      "(10013, 1391)\n",
      "0.9300908818535903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 13:19:59.276\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1598 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:01.523\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1559 | Train score: 0.9568 | Val loss: 0.1595 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:03.595\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1670 | Train score: 0.9506 | Val loss: 0.1530 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:05.644\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1299 | Train score: 0.9691 | Val loss: 0.1494 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:07.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1686 | Train score: 0.9568 | Val loss: 0.1480 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:09.747\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1165 | Train score: 0.9568 | Val loss: 0.1468 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:11.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1286 | Train score: 0.9506 | Val loss: 0.1458 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:13.934\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.2067 | Train score: 0.9506 | Val loss: 0.1445 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:16.009\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1329 | Train score: 0.9568 | Val loss: 0.1439 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:18.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1198 | Train score: 0.9691 | Val loss: 0.1433 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:20.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1408 | Train score: 0.9444 | Val loss: 0.1445 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:22.050\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1617 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:24.372\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1191 | Train score: 0.9383 | Val loss: 0.1601 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:26.757\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1363 | Train score: 0.9630 | Val loss: 0.1650 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:29.001\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1452 | Train score: 0.9444 | Val loss: 0.1641 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:31.233\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1920 | Train score: 0.9444 | Val loss: 0.1585 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:33.511\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1104 | Train score: 0.9691 | Val loss: 0.1573 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:35.747\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0919 | Train score: 0.9630 | Val loss: 0.1574 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:37.930\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1379 | Train score: 0.9444 | Val loss: 0.1579 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:40.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1016 | Train score: 0.9691 | Val loss: 0.1575 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:42.349\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1097 | Train score: 0.9568 | Val loss: 0.1566 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:44.561\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1368 | Train score: 0.9568 | Val loss: 0.1551 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:46.597\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1420 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:48.674\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1251 | Train score: 0.9506 | Val loss: 0.1483 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:50.690\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1017 | Train score: 0.9630 | Val loss: 0.1616 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:52.701\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0920 | Train score: 0.9753 | Val loss: 0.1719 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:54.739\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1097 | Train score: 0.9691 | Val loss: 0.1660 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:56.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1461 | Train score: 0.9444 | Val loss: 0.1528 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:20:58.770\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0735 | Train score: 0.9877 | Val loss: 0.1484 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:00.847\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1430 | Train score: 0.9444 | Val loss: 0.1415 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:02.882\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1227 | Train score: 0.9630 | Val loss: 0.1372 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:04.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0951 | Train score: 0.9506 | Val loss: 0.1374 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:06.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1159 | Train score: 0.9691 | Val loss: 0.1388 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:08.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1650 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:11.151\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1425 | Train score: 0.9691 | Val loss: 0.1750 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:13.202\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1312 | Train score: 0.9630 | Val loss: 0.1779 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:15.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1793 | Train score: 0.9568 | Val loss: 0.1731 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:17.358\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1063 | Train score: 0.9753 | Val loss: 0.1692 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:19.404\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1684 | Train score: 0.9506 | Val loss: 0.1633 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:21.453\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1487 | Train score: 0.9568 | Val loss: 0.1622 | Val score: 0.9307\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:23.571\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1590 | Train score: 0.9630 | Val loss: 0.1628 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:25.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1189 | Train score: 0.9568 | Val loss: 0.1624 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:27.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0969 | Train score: 0.9753 | Val loss: 0.1622 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:29.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1273 | Train score: 0.9568 | Val loss: 0.1746 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:31.646\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1541 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:33.815\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1197 | Train score: 0.9506 | Val loss: 0.1719 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:35.895\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1198 | Train score: 0.9506 | Val loss: 0.1687 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:38.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1211 | Train score: 0.9753 | Val loss: 0.1607 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:40.033\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1162 | Train score: 0.9753 | Val loss: 0.1528 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:42.130\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1431 | Train score: 0.9568 | Val loss: 0.1473 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:44.176\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1226 | Train score: 0.9753 | Val loss: 0.1455 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:46.218\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0723 | Train score: 0.9877 | Val loss: 0.1459 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:48.277\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1390 | Train score: 0.9568 | Val loss: 0.1479 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:50.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1004 | Train score: 0.9630 | Val loss: 0.1495 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:52.410\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0966 | Train score: 0.9691 | Val loss: 0.1505 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:54.425\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1583 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:56.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1293 | Train score: 0.9630 | Val loss: 0.1556 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:21:58.950\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0748 | Train score: 0.9815 | Val loss: 0.1617 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:01.168\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0517 | Train score: 0.9815 | Val loss: 0.1689 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:03.377\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1528 | Train score: 0.9568 | Val loss: 0.1634 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:05.512\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0907 | Train score: 0.9753 | Val loss: 0.1663 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:07.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0978 | Train score: 0.9815 | Val loss: 0.1636 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:10.009\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1375 | Train score: 0.9691 | Val loss: 0.1555 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:12.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0813 | Train score: 0.9877 | Val loss: 0.1535 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:14.364\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.2799 | Train score: 0.9568 | Val loss: 0.1520 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:16.532\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1311 | Train score: 0.9506 | Val loss: 0.1470 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:18.463\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1668 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:20.601\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1204 | Train score: 0.9444 | Val loss: 0.1712 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:22.681\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1094 | Train score: 0.9691 | Val loss: 0.1853 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:24.696\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1428 | Train score: 0.9691 | Val loss: 0.1770 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:26.810\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1339 | Train score: 0.9630 | Val loss: 0.1720 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:28.891\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1165 | Train score: 0.9753 | Val loss: 0.1678 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:31.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0932 | Train score: 0.9691 | Val loss: 0.1657 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:33.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1260 | Train score: 0.9568 | Val loss: 0.1650 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:35.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1103 | Train score: 0.9691 | Val loss: 0.1661 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:37.217\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1129 | Train score: 0.9691 | Val loss: 0.1680 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:39.239\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0889 | Train score: 0.9691 | Val loss: 0.1697 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:41.175\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1623 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:43.282\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1211 | Train score: 0.9568 | Val loss: 0.1698 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:45.496\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0877 | Train score: 0.9753 | Val loss: 0.1811 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:47.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0866 | Train score: 0.9753 | Val loss: 0.1837 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:49.864\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0699 | Train score: 0.9877 | Val loss: 0.1800 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:52.030\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1108 | Train score: 0.9691 | Val loss: 0.1699 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:54.284\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1580 | Train score: 0.9568 | Val loss: 0.1598 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:56.496\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0991 | Train score: 0.9691 | Val loss: 0.1553 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:22:58.597\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1160 | Train score: 0.9691 | Val loss: 0.1528 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:00.763\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1899 | Train score: 0.9506 | Val loss: 0.1500 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:03.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1232 | Train score: 0.9691 | Val loss: 0.1504 | Val score: 0.9505\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 13:23:05.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1357 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:07.286\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1349 | Train score: 0.9630 | Val loss: 0.1325 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:09.402\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1602 | Train score: 0.9444 | Val loss: 0.1301 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:11.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1050 | Train score: 0.9630 | Val loss: 0.1288 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:13.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1252 | Train score: 0.9630 | Val loss: 0.1287 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:16.016\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1584 | Train score: 0.9568 | Val loss: 0.1277 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:18.139\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1053 | Train score: 0.9630 | Val loss: 0.1294 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:20.297\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0896 | Train score: 0.9691 | Val loss: 0.1305 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:22.495\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1184 | Train score: 0.9630 | Val loss: 0.1322 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:24.695\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0782 | Train score: 0.9815 | Val loss: 0.1342 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:26.793\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0798 | Train score: 0.9753 | Val loss: 0.1388 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:28.825\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1140 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:30.982\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1091 | Train score: 0.9691 | Val loss: 0.1100 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:33.103\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1665 | Train score: 0.9630 | Val loss: 0.1107 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:35.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1304 | Train score: 0.9691 | Val loss: 0.1109 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:37.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1547 | Train score: 0.9568 | Val loss: 0.1120 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:39.339\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1202 | Train score: 0.9630 | Val loss: 0.1125 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:41.468\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1199 | Train score: 0.9630 | Val loss: 0.1102 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:43.779\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1409 | Train score: 0.9568 | Val loss: 0.1078 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:46.090\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1557 | Train score: 0.9506 | Val loss: 0.1058 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:48.189\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1059 | Train score: 0.9691 | Val loss: 0.1043 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:23:50.349\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1656 | Train score: 0.9630 | Val loss: 0.1041 | Val score: 0.9653\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " imbalance \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.938         0.000           0.000          0.000        0.000       0.000         0.500        0.000    0.000   0.000         0.000        0.000\n",
      "MedPFNClassifier                      0.949         0.012           0.617          0.245        0.371       0.171         0.891        0.054    0.458   0.193         0.342        0.010\n",
      "MedPFNClassifier                      0.959         0.013           0.900          0.300        0.357       0.172         0.930        0.045    0.501   0.203         1.968        0.038\n",
      "MedPFNClassifier                      0.955         0.022           0.750          0.316        0.414       0.216         0.928        0.048    0.524   0.241        14.024        0.178\n",
      "RandomForestClassifier                0.960         0.007           1.000          0.000        0.357       0.115         0.883        0.077    0.516   0.128         0.208        0.011\n",
      "CatBoostGrid                          0.957         0.008           1.000          0.000        0.314       0.125         0.914        0.067    0.464   0.152        56.842        6.155\n",
      "XGBoostGrid                           0.947         0.014           0.433          0.473        0.186       0.203         0.916        0.066    0.260   0.284        34.845        2.021\n",
      "LogisticRegressionClassifier          0.936         0.022           0.521          0.266        0.371       0.171         0.801        0.115    0.420   0.184         0.008        0.001\n",
      "TabPFNClassifier                      0.961         0.017           0.833          0.307        0.414       0.225         0.928        0.047    0.539   0.248         3.118        0.062\n",
      "TabForestPFNClassifier                0.948         0.010           0.608          0.247        0.343       0.146         0.899        0.063    0.434   0.174        23.022        0.711\n",
      "686 10761\n",
      "(11447, 1391)\n",
      "0.9400716344893859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 13:41:52.093\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1273 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:41:54.198\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1378 | Train score: 0.9444 | Val loss: 0.1164 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:41:56.380\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1456 | Train score: 0.9506 | Val loss: 0.1171 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:41:58.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1714 | Train score: 0.9444 | Val loss: 0.1157 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:00.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1554 | Train score: 0.9506 | Val loss: 0.1149 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:02.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1326 | Train score: 0.9630 | Val loss: 0.1157 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:05.239\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1146 | Train score: 0.9630 | Val loss: 0.1158 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:07.649\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1146 | Train score: 0.9568 | Val loss: 0.1162 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:09.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1708 | Train score: 0.9383 | Val loss: 0.1148 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:12.089\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1223 | Train score: 0.9568 | Val loss: 0.1142 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:14.217\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1354 | Train score: 0.9568 | Val loss: 0.1138 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:16.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1342 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:18.467\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1615 | Train score: 0.9568 | Val loss: 0.1321 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:20.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1340 | Train score: 0.9506 | Val loss: 0.1338 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:22.884\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1428 | Train score: 0.9383 | Val loss: 0.1321 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:25.036\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1622 | Train score: 0.9444 | Val loss: 0.1299 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:27.186\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1329 | Train score: 0.9568 | Val loss: 0.1273 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:29.336\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1406 | Train score: 0.9568 | Val loss: 0.1263 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:31.500\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1268 | Train score: 0.9506 | Val loss: 0.1257 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:33.641\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1927 | Train score: 0.9444 | Val loss: 0.1268 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:35.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1294 | Train score: 0.9753 | Val loss: 0.1273 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:38.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1297 | Train score: 0.9568 | Val loss: 0.1271 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:40.147\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1579 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:42.317\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1244 | Train score: 0.9506 | Val loss: 0.1660 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:44.466\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1564 | Train score: 0.9383 | Val loss: 0.1550 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:46.642\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0870 | Train score: 0.9753 | Val loss: 0.1604 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:48.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.2071 | Train score: 0.9444 | Val loss: 0.1559 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:50.857\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1435 | Train score: 0.9630 | Val loss: 0.1537 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:52.952\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1340 | Train score: 0.9568 | Val loss: 0.1533 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:55.188\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1259 | Train score: 0.9568 | Val loss: 0.1534 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:57.451\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1080 | Train score: 0.9568 | Val loss: 0.1532 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:42:59.559\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1182 | Train score: 0.9630 | Val loss: 0.1527 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:01.791\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1521 | Train score: 0.9383 | Val loss: 0.1524 | Val score: 0.9554\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 13:43:03.762\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0794 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:05.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1299 | Train score: 0.9506 | Val loss: 0.0769 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:08.086\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1760 | Train score: 0.9321 | Val loss: 0.0779 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:10.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1654 | Train score: 0.9259 | Val loss: 0.0815 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:12.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1683 | Train score: 0.9444 | Val loss: 0.0953 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:14.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1453 | Train score: 0.9444 | Val loss: 0.0929 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:16.746\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1319 | Train score: 0.9630 | Val loss: 0.0946 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:18.890\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1343 | Train score: 0.9568 | Val loss: 0.0944 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:21.068\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1462 | Train score: 0.9506 | Val loss: 0.0959 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:23.183\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1395 | Train score: 0.9444 | Val loss: 0.0961 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:25.292\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1256 | Train score: 0.9630 | Val loss: 0.0938 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:27.301\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1178 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:29.530\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1609 | Train score: 0.9444 | Val loss: 0.1140 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:31.834\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1587 | Train score: 0.9444 | Val loss: 0.1112 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:34.032\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1069 | Train score: 0.9568 | Val loss: 0.1093 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:36.196\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1323 | Train score: 0.9568 | Val loss: 0.1097 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:38.455\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1353 | Train score: 0.9568 | Val loss: 0.1126 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:40.791\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1185 | Train score: 0.9691 | Val loss: 0.1131 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:42.855\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1560 | Train score: 0.9506 | Val loss: 0.1110 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:44.970\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1676 | Train score: 0.9568 | Val loss: 0.1091 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:47.091\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1327 | Train score: 0.9691 | Val loss: 0.1094 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:49.219\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1135 | Train score: 0.9691 | Val loss: 0.1072 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:51.181\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1421 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:53.359\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1497 | Train score: 0.9383 | Val loss: 0.1462 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:55.527\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1242 | Train score: 0.9568 | Val loss: 0.1473 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:57.755\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0881 | Train score: 0.9630 | Val loss: 0.1489 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:43:59.973\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1311 | Train score: 0.9568 | Val loss: 0.1449 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:02.128\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1667 | Train score: 0.9444 | Val loss: 0.1368 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:04.295\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1439 | Train score: 0.9444 | Val loss: 0.1346 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:06.514\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1258 | Train score: 0.9568 | Val loss: 0.1345 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:08.655\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1132 | Train score: 0.9506 | Val loss: 0.1348 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:10.847\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1239 | Train score: 0.9383 | Val loss: 0.1373 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:12.957\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1191 | Train score: 0.9630 | Val loss: 0.1393 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:14.900\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1340 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:17.057\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1696 | Train score: 0.9383 | Val loss: 0.1597 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:19.219\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1566 | Train score: 0.9444 | Val loss: 0.1463 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:21.512\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1571 | Train score: 0.9444 | Val loss: 0.1358 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:23.659\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1674 | Train score: 0.9383 | Val loss: 0.1321 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:25.782\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1322 | Train score: 0.9444 | Val loss: 0.1300 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:27.899\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1691 | Train score: 0.9506 | Val loss: 0.1292 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:30.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1419 | Train score: 0.9444 | Val loss: 0.1275 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:32.130\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1401 | Train score: 0.9506 | Val loss: 0.1264 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:34.279\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1020 | Train score: 0.9753 | Val loss: 0.1264 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:36.555\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1702 | Train score: 0.9321 | Val loss: 0.1262 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:38.525\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1161 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:40.700\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1293 | Train score: 0.9568 | Val loss: 0.1141 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:42.771\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1929 | Train score: 0.9506 | Val loss: 0.1164 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:44.995\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1717 | Train score: 0.9383 | Val loss: 0.1187 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:47.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1477 | Train score: 0.9444 | Val loss: 0.1187 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:49.310\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1472 | Train score: 0.9568 | Val loss: 0.1153 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:51.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1364 | Train score: 0.9691 | Val loss: 0.1123 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:53.541\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1037 | Train score: 0.9568 | Val loss: 0.1081 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:55.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1252 | Train score: 0.9753 | Val loss: 0.1049 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:57.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1051 | Train score: 0.9753 | Val loss: 0.0997 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:44:59.939\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1041 | Train score: 0.9691 | Val loss: 0.1062 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:45:01.890\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1277 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:45:03.990\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1284 | Train score: 0.9568 | Val loss: 0.1293 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:45:06.072\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1531 | Train score: 0.9444 | Val loss: 0.1270 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:45:08.332\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1234 | Train score: 0.9506 | Val loss: 0.1264 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:45:10.511\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1117 | Train score: 0.9753 | Val loss: 0.1263 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:45:12.593\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1300 | Train score: 0.9630 | Val loss: 0.1259 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:45:14.688\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1227 | Train score: 0.9506 | Val loss: 0.1264 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:45:16.767\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1518 | Train score: 0.9691 | Val loss: 0.1263 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:45:18.826\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1080 | Train score: 0.9630 | Val loss: 0.1276 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:45:20.876\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1039 | Train score: 0.9753 | Val loss: 0.1284 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:45:23.196\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1258 | Train score: 0.9630 | Val loss: 0.1290 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:45:25.148\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1250 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:45:27.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1831 | Train score: 0.9444 | Val loss: 0.1166 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 13:45:29.335\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1506 | Train score: 0.9444 | Val loss: 0.1029 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 13:45:31.446\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1448 | Train score: 0.9444 | Val loss: 0.0994 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:45:33.561\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1727 | Train score: 0.9506 | Val loss: 0.0981 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:45:35.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1469 | Train score: 0.9630 | Val loss: 0.0960 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 13:45:37.790\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1822 | Train score: 0.9506 | Val loss: 0.0966 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:45:39.982\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1163 | Train score: 0.9568 | Val loss: 0.0957 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:45:42.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1011 | Train score: 0.9568 | Val loss: 0.0921 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:45:44.217\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1224 | Train score: 0.9568 | Val loss: 0.0897 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 13:45:46.320\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0929 | Train score: 0.9753 | Val loss: 0.0864 | Val score: 0.9653\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " imbalance \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.946         0.000           0.000          0.000        0.000       0.000         0.500        0.000    0.000   0.000         0.000        0.000\n",
      "MedPFNClassifier                      0.959         0.015           0.742          0.303        0.433       0.335         0.897        0.063    0.464   0.273         0.341        0.011\n",
      "MedPFNClassifier                      0.963         0.019           0.760          0.388        0.400       0.309         0.910        0.059    0.484   0.321         1.957        0.019\n",
      "MedPFNClassifier                      0.957         0.019           0.678          0.372        0.433       0.309         0.905        0.065    0.474   0.286        13.943        0.122\n",
      "RandomForestClassifier                0.959         0.012           0.800          0.400        0.250       0.201         0.910        0.066    0.361   0.247         0.191        0.012\n",
      "CatBoostGrid                          0.949         0.012           0.350          0.436        0.133       0.194         0.919        0.068    0.177   0.239        52.881        7.111\n",
      "XGBoostGrid                           0.957         0.007           0.800          0.400        0.200       0.125         0.891        0.055    0.314   0.184        34.862        2.254\n",
      "LogisticRegressionClassifier          0.949         0.020           0.560          0.202        0.467       0.145         0.774        0.058    0.502   0.163         0.009        0.001\n",
      "TabPFNClassifier                      0.962         0.015           0.860          0.297        0.350       0.263         0.921        0.050    0.448   0.271         3.179        0.077\n",
      "TabForestPFNClassifier                0.960         0.015           0.680          0.371        0.383       0.259         0.890        0.084    0.458   0.283        23.344        0.305\n",
      "566 10761\n",
      "(11327, 1391)\n",
      "0.9500308996203761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 14:04:08.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0783 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:10.457\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1395 | Train score: 0.9506 | Val loss: 0.0822 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:12.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1387 | Train score: 0.9630 | Val loss: 0.0854 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:14.806\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1734 | Train score: 0.9568 | Val loss: 0.0951 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:16.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1208 | Train score: 0.9691 | Val loss: 0.0900 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:19.103\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1255 | Train score: 0.9506 | Val loss: 0.0861 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:21.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1259 | Train score: 0.9691 | Val loss: 0.0841 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:23.652\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0883 | Train score: 0.9691 | Val loss: 0.0816 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:25.789\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1225 | Train score: 0.9630 | Val loss: 0.0810 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:27.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.2077 | Train score: 0.9383 | Val loss: 0.0825 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:30.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0850 | Train score: 0.9691 | Val loss: 0.0834 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:32.086\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1300 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:34.332\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0796 | Train score: 0.9753 | Val loss: 0.1364 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:36.664\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1612 | Train score: 0.9630 | Val loss: 0.1284 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:39.056\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1047 | Train score: 0.9753 | Val loss: 0.1249 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:41.472\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0843 | Train score: 0.9815 | Val loss: 0.1235 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:43.773\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0700 | Train score: 0.9630 | Val loss: 0.1240 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:46.036\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1064 | Train score: 0.9691 | Val loss: 0.1240 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:48.244\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1144 | Train score: 0.9630 | Val loss: 0.1234 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:50.500\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0818 | Train score: 0.9691 | Val loss: 0.1233 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:52.713\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1344 | Train score: 0.9568 | Val loss: 0.1233 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:54.942\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0526 | Train score: 0.9753 | Val loss: 0.1242 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:56.969\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1036 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:04:59.159\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1012 | Train score: 0.9568 | Val loss: 0.0980 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:01.399\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0849 | Train score: 0.9753 | Val loss: 0.1000 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:03.600\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1354 | Train score: 0.9568 | Val loss: 0.0996 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:05.814\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0941 | Train score: 0.9630 | Val loss: 0.0978 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:08.051\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0944 | Train score: 0.9506 | Val loss: 0.0960 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:10.226\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0989 | Train score: 0.9630 | Val loss: 0.0923 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:12.448\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1024 | Train score: 0.9691 | Val loss: 0.0896 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:14.625\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0821 | Train score: 0.9753 | Val loss: 0.0880 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:16.807\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1238 | Train score: 0.9568 | Val loss: 0.0869 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:19.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0771 | Train score: 0.9753 | Val loss: 0.0864 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:21.078\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1154 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:23.276\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1002 | Train score: 0.9506 | Val loss: 0.1328 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:25.447\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0673 | Train score: 0.9630 | Val loss: 0.1535 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:27.588\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1071 | Train score: 0.9691 | Val loss: 0.1447 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:29.714\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0748 | Train score: 0.9691 | Val loss: 0.1389 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:32.009\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1077 | Train score: 0.9568 | Val loss: 0.1299 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:34.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0674 | Train score: 0.9815 | Val loss: 0.1260 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:36.280\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1026 | Train score: 0.9753 | Val loss: 0.1196 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:38.459\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1216 | Train score: 0.9630 | Val loss: 0.1147 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:40.600\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0547 | Train score: 0.9815 | Val loss: 0.1142 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:42.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0873 | Train score: 0.9691 | Val loss: 0.1148 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:44.788\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1273 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:47.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0843 | Train score: 0.9691 | Val loss: 0.1401 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:49.451\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1420 | Train score: 0.9630 | Val loss: 0.1291 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:51.590\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1042 | Train score: 0.9568 | Val loss: 0.1256 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:53.957\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0794 | Train score: 0.9691 | Val loss: 0.1290 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:56.138\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0581 | Train score: 0.9753 | Val loss: 0.1353 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:05:58.322\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0611 | Train score: 0.9753 | Val loss: 0.1400 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:00.487\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0595 | Train score: 0.9753 | Val loss: 0.1433 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:02.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1087 | Train score: 0.9815 | Val loss: 0.1315 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:04.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0902 | Train score: 0.9568 | Val loss: 0.1298 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:06.898\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1207 | Train score: 0.9753 | Val loss: 0.1261 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:08.907\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1397 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:11.269\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1587 | Train score: 0.9321 | Val loss: 0.1308 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:13.678\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1370 | Train score: 0.9506 | Val loss: 0.1299 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:15.982\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1277 | Train score: 0.9506 | Val loss: 0.1285 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:18.299\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0944 | Train score: 0.9691 | Val loss: 0.1287 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:20.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1007 | Train score: 0.9568 | Val loss: 0.1319 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:22.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0882 | Train score: 0.9691 | Val loss: 0.1393 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:25.206\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1688 | Train score: 0.9568 | Val loss: 0.1361 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:27.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0964 | Train score: 0.9753 | Val loss: 0.1336 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:29.982\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1068 | Train score: 0.9630 | Val loss: 0.1314 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:32.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0837 | Train score: 0.9691 | Val loss: 0.1307 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:34.438\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1435 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:36.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0972 | Train score: 0.9691 | Val loss: 0.1553 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:38.771\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0868 | Train score: 0.9753 | Val loss: 0.1545 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:40.933\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1187 | Train score: 0.9506 | Val loss: 0.1514 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:43.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1383 | Train score: 0.9691 | Val loss: 0.1477 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:45.297\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1544 | Train score: 0.9630 | Val loss: 0.1449 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:47.398\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0913 | Train score: 0.9753 | Val loss: 0.1440 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:49.521\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1104 | Train score: 0.9753 | Val loss: 0.1415 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:51.681\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1020 | Train score: 0.9753 | Val loss: 0.1419 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:53.766\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0859 | Train score: 0.9691 | Val loss: 0.1416 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:55.859\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0755 | Train score: 0.9691 | Val loss: 0.1430 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:57.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0943 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:06:59.952\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1061 | Train score: 0.9630 | Val loss: 0.0895 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:02.092\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0893 | Train score: 0.9630 | Val loss: 0.0920 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:04.341\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1079 | Train score: 0.9691 | Val loss: 0.0914 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:06.469\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0550 | Train score: 0.9815 | Val loss: 0.0921 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:08.736\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0765 | Train score: 0.9691 | Val loss: 0.0932 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:10.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0569 | Train score: 0.9815 | Val loss: 0.0943 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:12.837\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1406 | Train score: 0.9753 | Val loss: 0.0920 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:15.042\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0509 | Train score: 0.9753 | Val loss: 0.0904 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:17.363\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0614 | Train score: 0.9630 | Val loss: 0.0908 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:19.494\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0931 | Train score: 0.9753 | Val loss: 0.0914 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:21.486\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1249 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:23.692\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0926 | Train score: 0.9506 | Val loss: 0.1332 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:25.817\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1160 | Train score: 0.9568 | Val loss: 0.1258 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:28.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0822 | Train score: 0.9753 | Val loss: 0.1219 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:30.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0738 | Train score: 0.9630 | Val loss: 0.1204 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:32.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0896 | Train score: 0.9630 | Val loss: 0.1193 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:34.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0812 | Train score: 0.9753 | Val loss: 0.1201 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:36.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1177 | Train score: 0.9630 | Val loss: 0.1201 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:38.870\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1103 | Train score: 0.9691 | Val loss: 0.1176 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:41.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1092 | Train score: 0.9506 | Val loss: 0.1149 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:43.249\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0788 | Train score: 0.9753 | Val loss: 0.1131 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:45.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1619 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:47.593\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0977 | Train score: 0.9506 | Val loss: 0.1483 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:49.673\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1243 | Train score: 0.9568 | Val loss: 0.1462 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:51.879\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1117 | Train score: 0.9506 | Val loss: 0.1497 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:54.118\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1547 | Train score: 0.9506 | Val loss: 0.1430 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:56.301\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0963 | Train score: 0.9568 | Val loss: 0.1449 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:07:58.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1368 | Train score: 0.9568 | Val loss: 0.1460 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:08:00.802\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1286 | Train score: 0.9568 | Val loss: 0.1475 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:08:02.929\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0873 | Train score: 0.9691 | Val loss: 0.1506 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:08:04.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1029 | Train score: 0.9568 | Val loss: 0.1541 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:08:07.175\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0756 | Train score: 0.9753 | Val loss: 0.1591 | Val score: 0.9653\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " imbalance \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.955         0.000           0.000          0.000         0.00       0.000         0.500        0.000    0.000   0.000         0.000        0.000\n",
      "MedPFNClassifier                      0.951         0.008           0.447          0.324         0.20       0.126         0.839        0.094    0.254   0.136         0.338        0.010\n",
      "MedPFNClassifier                      0.962         0.011           0.713          0.335         0.32       0.133         0.881        0.095    0.418   0.165         1.986        0.051\n",
      "MedPFNClassifier                      0.956         0.015           0.520          0.288         0.36       0.174         0.876        0.096    0.414   0.210        14.229        0.236\n",
      "RandomForestClassifier                0.960         0.007           0.625          0.375         0.24       0.174         0.854        0.105    0.317   0.189         0.184        0.007\n",
      "CatBoostGrid                          0.962         0.008           0.733          0.318         0.30       0.134         0.883        0.098    0.403   0.160        55.086        2.911\n",
      "XGBoostGrid                           0.962         0.011           0.625          0.407         0.28       0.160         0.870        0.121    0.373   0.217        34.335        0.940\n",
      "LogisticRegressionClassifier          0.937         0.010           0.297          0.096         0.30       0.100         0.733        0.133    0.297   0.097         0.009        0.001\n",
      "TabPFNClassifier                      0.960         0.010           0.700          0.332         0.26       0.128         0.879        0.085    0.360   0.157         3.216        0.071\n",
      "TabForestPFNClassifier                0.961         0.018           0.678          0.334         0.38       0.140         0.851        0.096    0.478   0.193        23.812        0.608\n",
      "448 10761\n",
      "(11209, 1391)\n",
      "0.9600321170488001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 14:31:30.285\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1190 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:31:32.397\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1127 | Train score: 0.9630 | Val loss: 0.1217 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:31:34.492\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0810 | Train score: 0.9630 | Val loss: 0.1250 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:31:36.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1205 | Train score: 0.9630 | Val loss: 0.1239 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:31:38.712\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1091 | Train score: 0.9630 | Val loss: 0.1223 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:31:40.817\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1076 | Train score: 0.9815 | Val loss: 0.1199 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:31:42.874\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1025 | Train score: 0.9753 | Val loss: 0.1171 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:31:45.054\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0973 | Train score: 0.9815 | Val loss: 0.1180 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:31:47.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0949 | Train score: 0.9877 | Val loss: 0.1197 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:31:49.164\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1242 | Train score: 0.9630 | Val loss: 0.1202 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:31:51.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1080 | Train score: 0.9691 | Val loss: 0.1206 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:31:53.289\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0973 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:31:55.394\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1248 | Train score: 0.9630 | Val loss: 0.0785 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:31:57.519\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0971 | Train score: 0.9630 | Val loss: 0.0707 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:31:59.631\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0730 | Train score: 0.9691 | Val loss: 0.0733 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:01.827\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0743 | Train score: 0.9691 | Val loss: 0.0752 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:03.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0411 | Train score: 0.9815 | Val loss: 0.0818 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:06.162\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0928 | Train score: 0.9753 | Val loss: 0.0779 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:08.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1381 | Train score: 0.9630 | Val loss: 0.0754 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:10.390\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0977 | Train score: 0.9753 | Val loss: 0.0732 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:12.553\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1198 | Train score: 0.9630 | Val loss: 0.1022 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:14.635\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1414 | Train score: 0.9753 | Val loss: 0.0673 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:16.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1113 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:18.680\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1212 | Train score: 0.9630 | Val loss: 0.1052 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:20.893\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1258 | Train score: 0.9691 | Val loss: 0.1059 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:23.151\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0934 | Train score: 0.9691 | Val loss: 0.1064 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:25.427\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1259 | Train score: 0.9506 | Val loss: 0.1081 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:27.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1238 | Train score: 0.9753 | Val loss: 0.1140 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:29.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1113 | Train score: 0.9383 | Val loss: 0.1100 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:32.196\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0591 | Train score: 0.9877 | Val loss: 0.1094 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:34.279\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1140 | Train score: 0.9753 | Val loss: 0.1102 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:36.600\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0818 | Train score: 0.9815 | Val loss: 0.1128 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:38.946\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1201 | Train score: 0.9691 | Val loss: 0.1139 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:41.011\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1229 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:43.278\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1132 | Train score: 0.9568 | Val loss: 0.1244 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:45.427\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1099 | Train score: 0.9691 | Val loss: 0.1239 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:47.544\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1287 | Train score: 0.9691 | Val loss: 0.1232 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:49.672\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1273 | Train score: 0.9691 | Val loss: 0.1225 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:51.740\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1431 | Train score: 0.9630 | Val loss: 0.1220 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:53.797\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1245 | Train score: 0.9568 | Val loss: 0.1190 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:55.878\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1057 | Train score: 0.9753 | Val loss: 0.1150 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:32:57.952\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0889 | Train score: 0.9815 | Val loss: 0.1122 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:00.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1128 | Train score: 0.9691 | Val loss: 0.1115 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:02.163\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1110 | Train score: 0.9753 | Val loss: 0.1118 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:04.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1067 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:06.328\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1350 | Train score: 0.9568 | Val loss: 0.1150 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:08.519\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1291 | Train score: 0.9630 | Val loss: 0.1135 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:10.773\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1284 | Train score: 0.9630 | Val loss: 0.1071 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:13.014\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0886 | Train score: 0.9630 | Val loss: 0.1015 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:15.263\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1620 | Train score: 0.9383 | Val loss: 0.1021 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:17.494\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1612 | Train score: 0.9568 | Val loss: 0.1030 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:19.709\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1076 | Train score: 0.9691 | Val loss: 0.1041 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:21.917\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0778 | Train score: 0.9691 | Val loss: 0.1055 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:24.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0997 | Train score: 0.9630 | Val loss: 0.1072 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:26.331\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1518 | Train score: 0.9630 | Val loss: 0.1101 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:28.332\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1118 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:30.548\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1021 | Train score: 0.9691 | Val loss: 0.1102 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:32.700\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0874 | Train score: 0.9691 | Val loss: 0.1156 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:34.778\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0962 | Train score: 0.9630 | Val loss: 0.1184 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:36.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0667 | Train score: 0.9815 | Val loss: 0.1188 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:38.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0632 | Train score: 0.9815 | Val loss: 0.1219 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:40.928\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0855 | Train score: 0.9691 | Val loss: 0.1245 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:43.049\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1128 | Train score: 0.9815 | Val loss: 0.1209 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:45.172\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1112 | Train score: 0.9691 | Val loss: 0.1170 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:47.327\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0764 | Train score: 0.9753 | Val loss: 0.1137 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:49.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1542 | Train score: 0.9630 | Val loss: 0.1094 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:52.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1189 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:54.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1094 | Train score: 0.9630 | Val loss: 0.1167 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:56.555\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1165 | Train score: 0.9691 | Val loss: 0.1136 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:33:58.675\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0927 | Train score: 0.9630 | Val loss: 0.1150 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:00.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1172 | Train score: 0.9630 | Val loss: 0.1137 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:03.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0756 | Train score: 0.9568 | Val loss: 0.1143 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:05.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0976 | Train score: 0.9568 | Val loss: 0.1146 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:07.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0496 | Train score: 0.9753 | Val loss: 0.1148 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:09.587\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1131 | Train score: 0.9568 | Val loss: 0.1156 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:11.825\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1048 | Train score: 0.9691 | Val loss: 0.1166 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:14.042\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0662 | Train score: 0.9753 | Val loss: 0.1203 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:16.036\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1070 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:18.171\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1106 | Train score: 0.9630 | Val loss: 0.1080 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:20.429\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1063 | Train score: 0.9506 | Val loss: 0.1078 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:22.533\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1009 | Train score: 0.9691 | Val loss: 0.1063 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:24.636\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1001 | Train score: 0.9630 | Val loss: 0.1050 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:26.880\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1052 | Train score: 0.9630 | Val loss: 0.1039 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:29.101\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1053 | Train score: 0.9630 | Val loss: 0.1022 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:31.384\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0576 | Train score: 0.9753 | Val loss: 0.1007 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:33.533\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0896 | Train score: 0.9691 | Val loss: 0.1003 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:35.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0997 | Train score: 0.9630 | Val loss: 0.1007 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:37.940\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1012 | Train score: 0.9568 | Val loss: 0.1002 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:39.918\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1053 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:42.169\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1156 | Train score: 0.9630 | Val loss: 0.1088 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:44.520\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1127 | Train score: 0.9630 | Val loss: 0.0993 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:46.878\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1336 | Train score: 0.9630 | Val loss: 0.0960 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:49.092\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1058 | Train score: 0.9691 | Val loss: 0.0961 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:51.429\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1289 | Train score: 0.9691 | Val loss: 0.0955 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:53.795\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0898 | Train score: 0.9630 | Val loss: 0.0888 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:56.187\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1059 | Train score: 0.9630 | Val loss: 0.0888 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:34:58.580\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0758 | Train score: 0.9815 | Val loss: 0.0895 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:35:01.012\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1237 | Train score: 0.9568 | Val loss: 0.0907 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:35:03.193\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0996 | Train score: 0.9691 | Val loss: 0.0914 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:35:05.204\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1039 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:35:07.387\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1358 | Train score: 0.9630 | Val loss: 0.1006 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:35:09.584\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0859 | Train score: 0.9691 | Val loss: 0.0985 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:35:11.769\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0955 | Train score: 0.9753 | Val loss: 0.0998 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:35:13.988\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1281 | Train score: 0.9630 | Val loss: 0.1000 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:35:16.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0786 | Train score: 0.9753 | Val loss: 0.1003 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:35:18.345\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0581 | Train score: 0.9753 | Val loss: 0.1012 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:35:20.532\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1470 | Train score: 0.9568 | Val loss: 0.1011 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:35:22.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0639 | Train score: 0.9815 | Val loss: 0.1015 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:35:24.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.2533 | Train score: 0.9630 | Val loss: 0.1001 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:35:27.021\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0850 | Train score: 0.9753 | Val loss: 0.1003 | Val score: 0.9703\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " imbalance \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.964         0.000            0.00          0.000        0.000       0.000         0.500        0.000    0.000   0.000         0.000        0.000\n",
      "MedPFNClassifier                      0.962         0.004            0.10          0.200        0.050       0.100         0.746        0.199    0.067   0.133         0.344        0.010\n",
      "MedPFNClassifier                      0.969         0.004            0.50          0.500        0.125       0.125         0.761        0.194    0.200   0.200         1.959        0.031\n",
      "MedPFNClassifier                      0.969         0.006            0.50          0.447        0.175       0.160         0.758        0.202    0.253   0.225        14.170        0.189\n",
      "RandomForestClassifier                0.966         0.004            0.30          0.400        0.100       0.122         0.769        0.160    0.147   0.181         0.228        0.020\n",
      "CatBoostGrid                          0.962         0.004            0.00          0.000        0.000       0.000         0.755        0.176    0.000   0.000        80.081        8.472\n",
      "XGBoostGrid                           0.967         0.004            0.45          0.415        0.150       0.122         0.742        0.152    0.220   0.181        39.499        1.958\n",
      "LogisticRegressionClassifier          0.951         0.013            0.30          0.176        0.250       0.158         0.618        0.194    0.269   0.160         0.009        0.001\n",
      "TabPFNClassifier                      0.965         0.006            0.30          0.458        0.075       0.115         0.800        0.135    0.120   0.183         3.206        0.066\n",
      "TabForestPFNClassifier                0.965         0.009            0.45          0.472        0.150       0.166         0.778        0.125    0.220   0.235        23.517        0.672\n",
      "332 10761\n",
      "(11093, 1391)\n",
      "0.970071216082214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 14:58:00.418\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0457 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:02.622\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0795 | Train score: 0.9691 | Val loss: 0.0437 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:04.895\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0696 | Train score: 0.9691 | Val loss: 0.0401 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:07.128\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0962 | Train score: 0.9753 | Val loss: 0.0395 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:09.361\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0595 | Train score: 0.9753 | Val loss: 0.0390 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:11.773\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0434 | Train score: 0.9815 | Val loss: 0.0378 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:13.900\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0599 | Train score: 0.9630 | Val loss: 0.0364 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:16.038\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0800 | Train score: 0.9691 | Val loss: 0.0358 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:18.151\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0574 | Train score: 0.9815 | Val loss: 0.0349 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:20.372\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0690 | Train score: 0.9691 | Val loss: 0.0345 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:22.525\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0889 | Train score: 0.9506 | Val loss: 0.0342 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:24.513\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0514 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:26.589\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0731 | Train score: 0.9691 | Val loss: 0.0466 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:28.779\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0553 | Train score: 0.9753 | Val loss: 0.0456 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:31.013\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0434 | Train score: 0.9815 | Val loss: 0.0445 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:33.282\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1085 | Train score: 0.9691 | Val loss: 0.0439 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:35.524\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0930 | Train score: 0.9691 | Val loss: 0.0429 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:37.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0885 | Train score: 0.9691 | Val loss: 0.0427 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:39.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0458 | Train score: 0.9877 | Val loss: 0.0435 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:41.936\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0774 | Train score: 0.9815 | Val loss: 0.0444 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:44.168\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0673 | Train score: 0.9691 | Val loss: 0.0451 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:46.322\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0651 | Train score: 0.9753 | Val loss: 0.0455 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:48.324\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0625 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:50.599\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0891 | Train score: 0.9691 | Val loss: 0.0504 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:52.747\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0812 | Train score: 0.9753 | Val loss: 0.0499 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:54.987\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0708 | Train score: 0.9815 | Val loss: 0.0491 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:57.166\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0553 | Train score: 0.9691 | Val loss: 0.0474 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:58:59.491\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0666 | Train score: 0.9877 | Val loss: 0.0457 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:01.775\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0431 | Train score: 0.9815 | Val loss: 0.0436 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:03.991\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0327 | Train score: 0.9877 | Val loss: 0.0428 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:06.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0779 | Train score: 0.9815 | Val loss: 0.0401 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:08.570\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1018 | Train score: 0.9691 | Val loss: 0.0407 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:10.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0863 | Train score: 0.9691 | Val loss: 0.0431 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:12.862\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0510 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:15.144\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0900 | Train score: 0.9691 | Val loss: 0.0449 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:17.488\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0611 | Train score: 0.9691 | Val loss: 0.0395 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:19.678\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0761 | Train score: 0.9753 | Val loss: 0.0366 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:21.967\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0506 | Train score: 0.9691 | Val loss: 0.0342 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:24.302\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1357 | Train score: 0.9691 | Val loss: 0.0340 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:26.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1121 | Train score: 0.9691 | Val loss: 0.0350 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:28.825\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0802 | Train score: 0.9691 | Val loss: 0.0362 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:30.951\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0664 | Train score: 0.9691 | Val loss: 0.0364 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:33.218\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0782 | Train score: 0.9815 | Val loss: 0.0364 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:35.521\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0549 | Train score: 0.9691 | Val loss: 0.0354 | Val score: 0.9851\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 14:59:37.539\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0831 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:39.694\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0944 | Train score: 0.9691 | Val loss: 0.0730 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:41.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0900 | Train score: 0.9691 | Val loss: 0.0693 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:44.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1300 | Train score: 0.9630 | Val loss: 0.0728 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:46.250\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1036 | Train score: 0.9691 | Val loss: 0.0770 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:48.583\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0776 | Train score: 0.9691 | Val loss: 0.0744 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:50.785\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0690 | Train score: 0.9691 | Val loss: 0.0694 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:53.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0743 | Train score: 0.9815 | Val loss: 0.0657 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:55.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0751 | Train score: 0.9691 | Val loss: 0.0641 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:57.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0691 | Train score: 0.9630 | Val loss: 0.0642 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 14:59:59.697\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0587 | Train score: 0.9815 | Val loss: 0.0654 | Val score: 0.9653\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 15:00:01.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0511 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:03.939\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1223 | Train score: 0.9630 | Val loss: 0.0559 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:06.370\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0768 | Train score: 0.9691 | Val loss: 0.0470 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:08.714\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0694 | Train score: 0.9691 | Val loss: 0.0409 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:10.860\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0944 | Train score: 0.9691 | Val loss: 0.0390 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:13.040\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1548 | Train score: 0.9691 | Val loss: 0.0406 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:15.203\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0694 | Train score: 0.9691 | Val loss: 0.0416 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:17.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0568 | Train score: 0.9753 | Val loss: 0.0418 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:19.590\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0524 | Train score: 0.9877 | Val loss: 0.0408 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:21.757\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0653 | Train score: 0.9815 | Val loss: 0.0394 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:23.977\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0940 | Train score: 0.9691 | Val loss: 0.0405 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:26.017\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0777 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:28.154\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0712 | Train score: 0.9753 | Val loss: 0.0723 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:30.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0548 | Train score: 0.9691 | Val loss: 0.0716 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:32.370\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0775 | Train score: 0.9630 | Val loss: 0.0673 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:34.487\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0721 | Train score: 0.9877 | Val loss: 0.0639 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:36.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0759 | Train score: 0.9753 | Val loss: 0.0620 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:38.814\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0457 | Train score: 0.9753 | Val loss: 0.0613 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:41.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0582 | Train score: 0.9815 | Val loss: 0.0613 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:43.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0499 | Train score: 0.9753 | Val loss: 0.0613 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:45.376\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0549 | Train score: 0.9753 | Val loss: 0.0610 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:47.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0739 | Train score: 0.9815 | Val loss: 0.0604 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:49.630\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0722 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:51.817\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0986 | Train score: 0.9691 | Val loss: 0.0729 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:54.078\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0881 | Train score: 0.9630 | Val loss: 0.0717 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:56.285\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0931 | Train score: 0.9691 | Val loss: 0.0710 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:00:58.503\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0642 | Train score: 0.9877 | Val loss: 0.0712 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:00.633\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0723 | Train score: 0.9753 | Val loss: 0.0727 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:02.858\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0734 | Train score: 0.9815 | Val loss: 0.0742 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:04.975\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0504 | Train score: 0.9815 | Val loss: 0.0758 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:07.227\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0582 | Train score: 0.9753 | Val loss: 0.0773 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:09.462\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0428 | Train score: 0.9753 | Val loss: 0.0795 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:11.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0854 | Train score: 0.9691 | Val loss: 0.0781 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:13.625\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0519 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:15.751\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0778 | Train score: 0.9815 | Val loss: 0.0551 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:17.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1370 | Train score: 0.9691 | Val loss: 0.0590 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:20.015\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0610 | Train score: 0.9753 | Val loss: 0.0578 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:22.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0676 | Train score: 0.9753 | Val loss: 0.0523 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:24.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0593 | Train score: 0.9753 | Val loss: 0.0486 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:26.426\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0731 | Train score: 0.9691 | Val loss: 0.0477 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:28.562\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0608 | Train score: 0.9691 | Val loss: 0.0470 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:30.718\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0498 | Train score: 0.9877 | Val loss: 0.0467 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:32.889\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0513 | Train score: 0.9753 | Val loss: 0.0471 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:35.007\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0623 | Train score: 0.9691 | Val loss: 0.0479 | Val score: 0.9752\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 15:01:37.040\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0403 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:39.250\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0990 | Train score: 0.9691 | Val loss: 0.0437 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:41.498\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1388 | Train score: 0.9630 | Val loss: 0.0477 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:43.697\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0735 | Train score: 0.9753 | Val loss: 0.0494 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:45.901\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0600 | Train score: 0.9691 | Val loss: 0.0497 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:48.221\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0616 | Train score: 0.9753 | Val loss: 0.0488 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:50.391\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0723 | Train score: 0.9753 | Val loss: 0.0468 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:52.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0555 | Train score: 0.9753 | Val loss: 0.0443 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:54.755\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0869 | Train score: 0.9815 | Val loss: 0.0425 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:56.972\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0520 | Train score: 0.9753 | Val loss: 0.0402 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:01:59.196\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0696 | Train score: 0.9753 | Val loss: 0.0380 | Val score: 0.9901\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " imbalance \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.973         0.000           0.000          0.000        0.000       0.000         0.500        0.000    0.000   0.000         0.000        0.000\n",
      "MedPFNClassifier                      0.972         0.009           0.450          0.400        0.233       0.153         0.890        0.075    0.287   0.202         0.352        0.005\n",
      "MedPFNClassifier                      0.973         0.006           0.300          0.400        0.133       0.163         0.925        0.080    0.180   0.223         1.984        0.060\n",
      "MedPFNClassifier                      0.973         0.006           0.300          0.400        0.133       0.163         0.928        0.079    0.180   0.223        14.227        0.242\n",
      "RandomForestClassifier                0.973         0.000           0.000          0.000        0.000       0.000         0.898        0.104    0.000   0.000         0.206        0.015\n",
      "CatBoostGrid                          0.973         0.000           0.000          0.000        0.000       0.000         0.909        0.117    0.000   0.000        79.324        9.699\n",
      "XGBoostGrid                           0.971         0.004           0.000          0.000        0.000       0.000         0.904        0.114    0.000   0.000        35.243        1.744\n",
      "LogisticRegressionClassifier          0.973         0.009           0.517          0.425        0.233       0.153         0.809        0.124    0.307   0.210         0.008        0.001\n",
      "TabPFNClassifier                      0.973         0.006           0.200          0.400        0.067       0.133         0.938        0.086    0.100   0.200         3.173        0.073\n",
      "TabForestPFNClassifier                0.974         0.009           0.327          0.352        0.300       0.348         0.923        0.086    0.302   0.325        23.804        0.375\n",
      "219 10761\n",
      "(10980, 1391)\n",
      "0.9800546448087432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 15:23:09.327\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0862 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:23:11.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0569 | Train score: 0.9815 | Val loss: 0.0876 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:23:13.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0700 | Train score: 0.9753 | Val loss: 0.0832 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:23:16.306\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0440 | Train score: 0.9815 | Val loss: 0.0833 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:23:18.497\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0368 | Train score: 0.9877 | Val loss: 0.0897 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:23:20.651\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0450 | Train score: 0.9815 | Val loss: 0.1027 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:23:22.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0399 | Train score: 0.9815 | Val loss: 0.1032 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:23:25.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0387 | Train score: 0.9691 | Val loss: 0.1037 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:23:27.364\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0307 | Train score: 0.9815 | Val loss: 0.1034 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:23:29.681\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0312 | Train score: 0.9877 | Val loss: 0.1035 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:23:31.801\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0202 | Train score: 0.9938 | Val loss: 0.1071 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:23:33.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0788 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:23:36.034\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0586 | Train score: 0.9815 | Val loss: 0.0799 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:23:38.360\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0442 | Train score: 0.9815 | Val loss: 0.0866 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:23:40.536\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0489 | Train score: 0.9815 | Val loss: 0.0864 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:23:42.695\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0488 | Train score: 0.9938 | Val loss: 0.0838 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:23:44.848\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0507 | Train score: 0.9753 | Val loss: 0.0800 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:23:47.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0350 | Train score: 0.9877 | Val loss: 0.0792 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:23:49.313\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0360 | Train score: 0.9938 | Val loss: 0.0804 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:23:51.475\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0429 | Train score: 0.9815 | Val loss: 0.0807 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:23:53.594\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0885 | Train score: 0.9877 | Val loss: 0.0772 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:23:55.904\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0279 | Train score: 0.9938 | Val loss: 0.0752 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:23:57.905\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0653 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:00.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0638 | Train score: 0.9815 | Val loss: 0.0663 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:02.385\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0574 | Train score: 0.9815 | Val loss: 0.0672 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:04.526\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0363 | Train score: 0.9815 | Val loss: 0.0714 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:06.738\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0245 | Train score: 0.9938 | Val loss: 0.0790 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:09.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0475 | Train score: 0.9877 | Val loss: 0.0845 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:11.224\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0970 | Train score: 0.9753 | Val loss: 0.0828 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:13.392\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0270 | Train score: 0.9815 | Val loss: 0.0823 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:15.569\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1258 | Train score: 0.9815 | Val loss: 0.0816 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:17.755\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0454 | Train score: 0.9815 | Val loss: 0.0794 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:19.912\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0166 | Train score: 0.9938 | Val loss: 0.0778 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:21.925\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0786 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:24.160\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0610 | Train score: 0.9815 | Val loss: 0.0746 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:26.466\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0599 | Train score: 0.9815 | Val loss: 0.0731 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:28.694\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0497 | Train score: 0.9815 | Val loss: 0.0760 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:30.996\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0400 | Train score: 0.9815 | Val loss: 0.0815 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:33.243\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0335 | Train score: 0.9753 | Val loss: 0.0859 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:35.547\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0428 | Train score: 0.9815 | Val loss: 0.0841 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:37.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0534 | Train score: 0.9753 | Val loss: 0.0775 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:40.092\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0546 | Train score: 0.9815 | Val loss: 0.0685 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:42.400\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0420 | Train score: 0.9877 | Val loss: 0.0706 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:44.657\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0622 | Train score: 0.9815 | Val loss: 0.0642 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:46.659\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0695 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:49.016\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0665 | Train score: 0.9815 | Val loss: 0.0643 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:51.375\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0802 | Train score: 0.9815 | Val loss: 0.0637 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:53.736\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0577 | Train score: 0.9815 | Val loss: 0.0621 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:56.145\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0553 | Train score: 0.9815 | Val loss: 0.0594 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:24:58.443\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0495 | Train score: 0.9815 | Val loss: 0.0568 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:00.750\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0576 | Train score: 0.9815 | Val loss: 0.0569 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:03.032\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0465 | Train score: 0.9815 | Val loss: 0.0569 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:05.359\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0495 | Train score: 0.9815 | Val loss: 0.0574 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:07.686\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0428 | Train score: 0.9815 | Val loss: 0.0581 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:10.029\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0470 | Train score: 0.9815 | Val loss: 0.0559 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:12.025\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0540 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:14.151\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0727 | Train score: 0.9753 | Val loss: 0.0535 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:16.249\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0541 | Train score: 0.9815 | Val loss: 0.0476 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:18.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0528 | Train score: 0.9815 | Val loss: 0.0471 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:20.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0598 | Train score: 0.9815 | Val loss: 0.0505 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:22.848\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0757 | Train score: 0.9815 | Val loss: 0.0491 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:25.098\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0389 | Train score: 0.9815 | Val loss: 0.0487 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:27.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0715 | Train score: 0.9815 | Val loss: 0.0484 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:29.365\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0443 | Train score: 0.9815 | Val loss: 0.0490 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:31.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0556 | Train score: 0.9753 | Val loss: 0.0491 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:33.804\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0524 | Train score: 0.9815 | Val loss: 0.0494 | Val score: 0.9752\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 15:25:35.793\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0567 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:37.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0710 | Train score: 0.9815 | Val loss: 0.0581 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:40.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0525 | Train score: 0.9815 | Val loss: 0.0591 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:42.038\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0868 | Train score: 0.9815 | Val loss: 0.0591 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:44.063\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0809 | Train score: 0.9691 | Val loss: 0.0560 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:46.158\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0596 | Train score: 0.9753 | Val loss: 0.0531 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:48.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0425 | Train score: 0.9815 | Val loss: 0.0508 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:50.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0395 | Train score: 0.9877 | Val loss: 0.0490 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:52.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0784 | Train score: 0.9877 | Val loss: 0.0493 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:54.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0880 | Train score: 0.9877 | Val loss: 0.0497 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:25:56.273\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0456 | Train score: 0.9753 | Val loss: 0.0500 | Val score: 0.9802\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 15:25:58.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0523 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:00.317\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0620 | Train score: 0.9815 | Val loss: 0.0441 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:02.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0428 | Train score: 0.9815 | Val loss: 0.0418 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:04.506\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0823 | Train score: 0.9753 | Val loss: 0.0397 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:06.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1121 | Train score: 0.9815 | Val loss: 0.0390 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:08.695\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0440 | Train score: 0.9815 | Val loss: 0.0396 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:10.814\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0367 | Train score: 0.9753 | Val loss: 0.0392 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:12.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0424 | Train score: 0.9815 | Val loss: 0.0390 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:15.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0461 | Train score: 0.9877 | Val loss: 0.0397 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:17.475\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0209 | Train score: 0.9877 | Val loss: 0.0407 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:19.568\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0723 | Train score: 0.9877 | Val loss: 0.0426 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:21.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0696 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:23.771\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0883 | Train score: 0.9815 | Val loss: 0.0722 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:25.996\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0747 | Train score: 0.9815 | Val loss: 0.0740 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:28.097\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0561 | Train score: 0.9815 | Val loss: 0.0743 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:30.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0530 | Train score: 0.9815 | Val loss: 0.0753 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:32.337\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0534 | Train score: 0.9815 | Val loss: 0.0781 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:34.586\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0273 | Train score: 0.9815 | Val loss: 0.0827 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:36.706\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0364 | Train score: 0.9815 | Val loss: 0.0870 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:38.808\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0454 | Train score: 0.9877 | Val loss: 0.0904 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:40.989\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0342 | Train score: 0.9877 | Val loss: 0.0934 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:43.150\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0714 | Train score: 0.9877 | Val loss: 0.0930 | Val score: 0.9703\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 15:26:45.197\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0646 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:47.431\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0517 | Train score: 0.9815 | Val loss: 0.0629 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:49.671\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0577 | Train score: 0.9815 | Val loss: 0.0678 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:51.975\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0514 | Train score: 0.9815 | Val loss: 0.0711 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:54.181\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0737 | Train score: 0.9753 | Val loss: 0.0689 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:56.445\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0430 | Train score: 0.9815 | Val loss: 0.0648 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:26:58.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0773 | Train score: 0.9877 | Val loss: 0.0607 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:27:00.825\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0504 | Train score: 0.9753 | Val loss: 0.0592 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:27:03.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0547 | Train score: 0.9815 | Val loss: 0.0576 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:27:05.404\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0588 | Train score: 0.9815 | Val loss: 0.0565 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:27:07.658\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0341 | Train score: 0.9815 | Val loss: 0.0552 | Val score: 0.9802\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " imbalance \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.982         0.000             0.0            0.0         0.00        0.00         0.500        0.000    0.000     0.0         0.000        0.000\n",
      "MedPFNClassifier                      0.982         0.000             0.0            0.0         0.00        0.00         0.780        0.131    0.000     0.0         0.345        0.010\n",
      "MedPFNClassifier                      0.982         0.000             0.0            0.0         0.00        0.00         0.837        0.118    0.000     0.0         1.943        0.036\n",
      "MedPFNClassifier                      0.982         0.000             0.0            0.0         0.00        0.00         0.840        0.117    0.000     0.0        14.103        0.143\n",
      "RandomForestClassifier                0.983         0.003             0.1            0.3         0.05        0.15         0.811        0.136    0.067     0.2         0.179        0.007\n",
      "CatBoostGrid                          0.983         0.003             0.1            0.3         0.05        0.15         0.801        0.120    0.067     0.2        75.123        3.790\n",
      "XGBoostGrid                           0.982         0.000             0.0            0.0         0.00        0.00         0.842        0.153    0.000     0.0        31.351        0.949\n",
      "LogisticRegressionClassifier          0.968         0.011             0.0            0.0         0.00        0.00         0.401        0.261    0.000     0.0         0.009        0.001\n",
      "TabPFNClassifier                      0.979         0.004             0.0            0.0         0.00        0.00         0.832        0.158    0.000     0.0         3.134        0.067\n",
      "TabForestPFNClassifier                0.978         0.007             0.1            0.3         0.05        0.15         0.791        0.152    0.067     0.2        23.753        0.771\n",
      "108 10761\n",
      "(10869, 1391)\n",
      "0.9900634833011317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 15:56:39.061\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0469 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:56:41.270\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0454 | Train score: 0.9877 | Val loss: 0.0506 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:56:43.259\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0648 | Train score: 0.9815 | Val loss: 0.0484 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:56:44.982\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0292 | Train score: 0.9938 | Val loss: 0.0492 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:56:46.664\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0724 | Train score: 0.9815 | Val loss: 0.0499 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:56:48.507\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0272 | Train score: 0.9938 | Val loss: 0.0505 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:56:50.269\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0543 | Train score: 0.9877 | Val loss: 0.0507 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:56:51.977\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0347 | Train score: 0.9877 | Val loss: 0.0506 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:56:53.705\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0405 | Train score: 0.9877 | Val loss: 0.0507 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:56:55.370\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0174 | Train score: 0.9938 | Val loss: 0.0511 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:56:57.053\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0245 | Train score: 0.9877 | Val loss: 0.0520 | Val score: 0.9851\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 15:56:58.701\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0691 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:00.286\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0316 | Train score: 0.9877 | Val loss: 0.0755 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:01.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0230 | Train score: 0.9877 | Val loss: 0.0763 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:03.462\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0174 | Train score: 0.9938 | Val loss: 0.0832 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:05.001\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0506 | Train score: 0.9815 | Val loss: 0.0757 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:06.547\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0270 | Train score: 0.9938 | Val loss: 0.0743 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:08.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0221 | Train score: 0.9938 | Val loss: 0.0794 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:09.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0529 | Train score: 0.9877 | Val loss: 0.0778 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:11.162\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0290 | Train score: 0.9877 | Val loss: 0.0795 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:12.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0243 | Train score: 0.9938 | Val loss: 0.0811 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:15.395\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0328 | Train score: 0.9877 | Val loss: 0.0828 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:17.961\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0558 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:22.123\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0473 | Train score: 0.9877 | Val loss: 0.0597 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:24.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0259 | Train score: 0.9877 | Val loss: 0.0655 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:26.455\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0663 | Train score: 0.9877 | Val loss: 0.0648 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:28.181\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0538 | Train score: 0.9938 | Val loss: 0.0645 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:30.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0174 | Train score: 0.9938 | Val loss: 0.0651 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:33.007\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0152 | Train score: 0.9938 | Val loss: 0.0667 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:35.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0339 | Train score: 0.9938 | Val loss: 0.0685 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:37.969\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0113 | Train score: 0.9938 | Val loss: 0.0712 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:39.922\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0195 | Train score: 0.9938 | Val loss: 0.0747 | Val score: 0.9802\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:41.571\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0250 | Train score: 0.9877 | Val loss: 0.0811 | Val score: 0.9802\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 15:57:43.496\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0465 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:45.338\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0484 | Train score: 0.9877 | Val loss: 0.0430 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:47.043\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0334 | Train score: 0.9877 | Val loss: 0.0411 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:48.802\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0260 | Train score: 0.9877 | Val loss: 0.0494 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:50.705\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0209 | Train score: 0.9877 | Val loss: 0.0472 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:52.433\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1384 | Train score: 0.9877 | Val loss: 0.0443 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:54.407\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0645 | Train score: 0.9938 | Val loss: 0.0401 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:56.291\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0616 | Train score: 0.9877 | Val loss: 0.0407 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:57:58.368\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0123 | Train score: 1.0000 | Val loss: 0.0431 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:00.177\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0477 | Train score: 0.9938 | Val loss: 0.0423 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:01.893\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0407 | Train score: 0.9877 | Val loss: 0.0412 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:03.727\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0630 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:05.570\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0400 | Train score: 0.9877 | Val loss: 0.0744 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:07.329\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0237 | Train score: 0.9877 | Val loss: 0.0870 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:09.381\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0217 | Train score: 0.9877 | Val loss: 0.0998 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:11.853\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0166 | Train score: 0.9938 | Val loss: 0.1086 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:14.545\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0238 | Train score: 0.9877 | Val loss: 0.1099 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:17.574\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0786 | Train score: 0.9877 | Val loss: 0.0971 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:20.939\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0671 | Train score: 0.9877 | Val loss: 0.0816 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:23.535\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0175 | Train score: 0.9938 | Val loss: 0.0738 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:25.717\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0457 | Train score: 0.9877 | Val loss: 0.0669 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:28.028\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0382 | Train score: 0.9938 | Val loss: 0.0627 | Val score: 0.9901\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 15:58:30.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0435 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:32.757\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0556 | Train score: 0.9877 | Val loss: 0.0423 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:35.270\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0580 | Train score: 0.9877 | Val loss: 0.0418 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:37.803\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0517 | Train score: 0.9877 | Val loss: 0.0414 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:40.361\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0425 | Train score: 0.9877 | Val loss: 0.0406 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:42.881\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0343 | Train score: 0.9877 | Val loss: 0.0406 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:45.565\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0404 | Train score: 0.9877 | Val loss: 0.0414 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:48.222\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0680 | Train score: 0.9877 | Val loss: 0.0419 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:50.671\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0511 | Train score: 0.9877 | Val loss: 0.0424 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:53.139\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0274 | Train score: 0.9877 | Val loss: 0.0441 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:58:55.630\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0449 | Train score: 0.9877 | Val loss: 0.0467 | Val score: 0.9901\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 15:58:57.877\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0325 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:00.390\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0645 | Train score: 0.9877 | Val loss: 0.0363 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:03.174\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0552 | Train score: 0.9877 | Val loss: 0.0360 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:05.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0473 | Train score: 0.9877 | Val loss: 0.0342 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:08.026\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0760 | Train score: 0.9877 | Val loss: 0.0353 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:10.474\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0372 | Train score: 0.9815 | Val loss: 0.0356 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:13.429\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0389 | Train score: 0.9877 | Val loss: 0.0350 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:16.186\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0339 | Train score: 0.9877 | Val loss: 0.0360 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:18.916\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0254 | Train score: 0.9877 | Val loss: 0.0394 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:21.242\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0161 | Train score: 0.9938 | Val loss: 0.0450 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:23.282\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0277 | Train score: 0.9877 | Val loss: 0.0501 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:25.331\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0470 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:27.430\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0635 | Train score: 0.9877 | Val loss: 0.0469 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:29.458\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0376 | Train score: 0.9877 | Val loss: 0.0456 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:31.501\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0296 | Train score: 0.9877 | Val loss: 0.0458 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:33.709\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0310 | Train score: 0.9877 | Val loss: 0.0466 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:35.646\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0624 | Train score: 0.9877 | Val loss: 0.0464 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:37.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0416 | Train score: 0.9877 | Val loss: 0.0468 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:39.569\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0341 | Train score: 0.9938 | Val loss: 0.0475 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:41.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0433 | Train score: 0.9877 | Val loss: 0.0493 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:43.635\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0542 | Train score: 0.9877 | Val loss: 0.0471 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:46.062\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0317 | Train score: 0.9938 | Val loss: 0.0465 | Val score: 0.9901\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 15:59:48.341\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0567 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:50.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0342 | Train score: 0.9877 | Val loss: 0.0581 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:52.715\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0477 | Train score: 0.9938 | Val loss: 0.0558 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:54.649\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0317 | Train score: 0.9877 | Val loss: 0.0558 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:56.654\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0384 | Train score: 0.9938 | Val loss: 0.0562 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 15:59:58.497\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0162 | Train score: 1.0000 | Val loss: 0.0571 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 16:00:00.357\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0215 | Train score: 0.9877 | Val loss: 0.0590 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 16:00:02.312\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0119 | Train score: 0.9938 | Val loss: 0.0623 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 16:00:04.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0330 | Train score: 0.9938 | Val loss: 0.0671 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 16:00:06.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0369 | Train score: 0.9938 | Val loss: 0.0702 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 16:00:07.885\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0131 | Train score: 0.9938 | Val loss: 0.0726 | Val score: 0.9851\u001b[0m\n",
      "\u001b[32m2024-11-04 16:00:09.737\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.0426 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 16:00:11.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0440 | Train score: 0.9877 | Val loss: 0.0390 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 16:00:13.481\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0642 | Train score: 0.9877 | Val loss: 0.0373 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 16:00:15.577\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0238 | Train score: 0.9877 | Val loss: 0.0349 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 16:00:18.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0189 | Train score: 0.9938 | Val loss: 0.0341 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 16:00:20.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0242 | Train score: 0.9877 | Val loss: 0.0342 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 16:00:22.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0559 | Train score: 0.9877 | Val loss: 0.0314 | Val score: 0.9901\u001b[0m\n",
      "\u001b[32m2024-11-04 16:00:23.846\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0265 | Train score: 0.9938 | Val loss: 0.0311 | Val score: 0.9950\u001b[0m\n",
      "\u001b[32m2024-11-04 16:00:25.789\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0204 | Train score: 0.9938 | Val loss: 0.0310 | Val score: 0.9950\u001b[0m\n",
      "\u001b[32m2024-11-04 16:00:27.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0127 | Train score: 1.0000 | Val loss: 0.0310 | Val score: 0.9950\u001b[0m\n",
      "\u001b[32m2024-11-04 16:00:29.416\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0402 | Train score: 0.9877 | Val loss: 0.0315 | Val score: 0.9950\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " imbalance \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.991         0.000             0.0            0.0          0.0         0.0         0.500        0.000      0.0     0.0         0.000        0.000\n",
      "MedPFNClassifier                      0.991         0.000             0.0            0.0          0.0         0.0         0.805        0.229      0.0     0.0         0.360        0.006\n",
      "MedPFNClassifier                      0.991         0.000             0.0            0.0          0.0         0.0         0.814        0.200      0.0     0.0         1.987        0.076\n",
      "MedPFNClassifier                      0.991         0.000             0.0            0.0          0.0         0.0         0.796        0.233      0.0     0.0        14.202        0.326\n",
      "RandomForestClassifier                0.991         0.000             0.0            0.0          0.0         0.0         0.666        0.293      0.0     0.0         0.212        0.015\n",
      "CatBoostGrid                          0.991         0.000             0.0            0.0          0.0         0.0         0.737        0.219      0.0     0.0       125.652       18.589\n",
      "XGBoostGrid                           0.991         0.000             0.0            0.0          0.0         0.0         0.618        0.220      0.0     0.0        31.094        3.714\n",
      "LogisticRegressionClassifier          0.989         0.004             0.0            0.0          0.0         0.0         0.678        0.310      0.0     0.0         0.005        0.001\n",
      "TabPFNClassifier                      0.991         0.000             0.0            0.0          0.0         0.0         0.802        0.215      0.0     0.0         2.829        0.525\n",
      "TabForestPFNClassifier                0.988         0.004             0.0            0.0          0.0         0.0         0.796        0.356      0.0     0.0        22.925        3.237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "save = True\n",
    "sampling = None\n",
    "cv = 10\n",
    "best_delete = 0\n",
    "strat_split = True\n",
    "recomp = False\n",
    "n_optim = 1000\n",
    "cat_optim = 10\n",
    "ft_epochs = 20\n",
    "ft_epochs_forest = 10\n",
    "ft_lr = 1e-5\n",
    "max_s = 1024\n",
    "max_q = 128\n",
    "max_samples = 1024\n",
    "no_pre_process = False\n",
    "multi_decoder = \"permutation\"\n",
    "N_ens = 5\n",
    "seed = 42\n",
    "overwrite = True\n",
    "metrics = [\"accuracy\", \"precision\", \"recall\", \"roc_auc\", \"f1\"]\n",
    "dir_path = os.path.abspath(os.getcwd())\n",
    "#run_name = \"medium_net_mlp_balance_bsplit_baseline\" ## NO PERM, VERY ROBUST\n",
    "#run_name2 = \"large_mlp_var_balance_05weight_anova\" ## das aller bestigste\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_newprior\" ## das aller bestigste\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_newprior\" ## das aller bestigste\n",
    "run_name = \"medium_mlp_var_balance_05weight_anova_bestwithnoisebnn_100\" ## good start, best with ft\n",
    "#run_name3 = \"medium_mlp_var_balance_05weight_anova_bestwithnoisebnn_100_moreweight\" ## best start, ft no so good\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_200\" ## das aller bestigste\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_longer\" ## das aller bestigste\n",
    "#run_name = \"medium_mlp_balance_lownoisefixparam_anova\"\n",
    "#run_name = \"medium_mlp_0.5static_balance_anova\"\n",
    "#run_name = \"large_mlp_fullbalance\"\n",
    "#run_name = \"small_net_mlp_var_imbalance_05weight\" ## WORKS VERY WELL WITH PERM\n",
    "#run_name = \"small_net_mlp_varbalance_weight_batchunisplit\"\n",
    "#run_name = \"small_net_mlp_variable_balance_weight\"\n",
    "#run_name = \"small_net_mlp_balance_minevalup\"\n",
    "path = dir_path + f\"/logs/trainrun_{run_name}\"\n",
    "#path2 = dir_path + f\"/logs/trainrun_{run_name2}\"\n",
    "#path3 = dir_path + f\"/logs/trainrun_{run_name3}\"\n",
    "filename = \"model\"\n",
    "\n",
    "\n",
    "\n",
    "models = [\n",
    "    MajorityClass(),\n",
    "    #XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic'),\n",
    "    MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=1, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process),\n",
    "    MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process),\n",
    "    MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process,\n",
    "                    ft_epochs=ft_epochs, ft_lr=ft_lr),\n",
    "    RandomForestClassifier(),\n",
    "    #AutoGluon(),\n",
    "    CatBoostGrid(),\n",
    "    XGBoostGrid(),\n",
    "    LogisticRegressionClassifier(), \n",
    "    TabPFNClassifier(device='cpu', N_ensemble_configurations=5, no_preprocess_mode=no_pre_process),\n",
    "    TabForestPFNClassifier(\"saved_models/tabforest/mix600k/tabforestpfn.pt\", \"saved_models/tabforest/mix600k/config_run.yaml\", max_epochs=ft_epochs_forest)\n",
    "]\n",
    "reducer  = AnovaSelect()\n",
    "#for reducer in [AnovaSelect(), RandomSelect(), NonZeroSelect(), MeanSelect(), StdSelect(), MaxSelect(), PCASelect()]:\n",
    "#data = clr(all_data)\n",
    "\n",
    "#all_data = normalize(all_data)\n",
    "\n",
    "frac = [0.91,0.92,0.93,0.94,0.95,0.96,0.97,0.98,0.99]\n",
    "for f in frac:\n",
    "    data_c0 = all_data[labels==0]\n",
    "    data_c1 = all_data[labels==1]\n",
    "    num_c1 = data_c1.shape[0]\n",
    "    num_c0 = min(int(num_c1*f/(1-f)),data_c0.shape[0])\n",
    "    num_c1 = min(num_c1, int(num_c0*(1-f)/f))\n",
    "    print(num_c1,num_c0)\n",
    "    data = np.concatenate((data_c0[:num_c0], data_c1[:num_c1]), axis=0)\n",
    "    print(data.shape)\n",
    "    labels_new = np.concatenate((np.zeros(num_c0), np.ones(num_c1)))\n",
    "    data_new, labels_new = unison_shuffled_copies(data, labels_new)\n",
    "    counts = np.unique(labels_new, return_counts=True)[1]\n",
    "    print(counts[0]/np.sum(counts))\n",
    "    results_mean = pd.DataFrame(np.zeros((len(models), len(metrics)+1)),\n",
    "                                index=[m.__class__.__name__ for m in models],\n",
    "                                columns=metrics+[\"runtime\"])\n",
    "    results_std = pd.DataFrame(np.zeros((len(models), len(metrics)+1)), \n",
    "                               index=[m.__class__.__name__ for m in models],\n",
    "                               columns=metrics+[\"runtime\"])\n",
    "    \n",
    "    for ii, model in enumerate(models):\n",
    "        results_mean.iloc[ii,:], results_std.iloc[ii,:] = cross_validate_sample(\n",
    "            model, data_new, labels_new, metrics, strat_split, cv, sampling, \n",
    "            reducer, max_samples, seed=seed, overwrite=overwrite, n_best_delete=best_delete,\n",
    "            recomp=recomp)\n",
    "    \n",
    "    results_mean = results_mean.add_suffix(\" mean\")\n",
    "    results_std = results_std.add_suffix(\" std\")\n",
    "    results_full = pd.concat((results_mean, results_std), axis=1)\n",
    "    cols = results_full.columns.tolist()\n",
    "    new_cols = []\n",
    "    for i in range(int(len(cols)/2)):\n",
    "        new_cols.append(cols[i])\n",
    "        new_cols.append(cols[i+int(len(cols)/2)])\n",
    "    results_full = results_full[new_cols]\n",
    "    red_name = \"imbalance\"\n",
    "    if save:\n",
    "        directory = f\"results/{red_name}\"\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        save_path = f'results/{red_name}/majclass_{f}.csv'\n",
    "        results_full.to_csv(save_path)\n",
    "    print(\"\\n\", \"\\n\", red_name, \"\\n\", results_full.round(3))\n",
    "    #print(results_full.sort_values(\"roc_auc mean\").round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "eb97879e-b2c6-4571-ab1d-c0ec7cba47ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9388413889373582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\AppData\\Local\\Temp\\ipykernel_19724\\3596895818.py:45: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  fig.show()\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2IAAAHACAYAAADA5NteAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAADw2klEQVR4nOzdd3xT1fvA8c9NuvdeQBllL1mVDS0bVBBBUEHFvUHRr4gbUXH9EBFFZQgKCgKCKCJD9lJkiexVZksXbelukvv7oyRNOtM2aQs8b1992Xty7r2nbVry5DnnOYqqqipCCCGEEEIIIaqMproHIIQQQgghhBA3GwnEhBBCCCGEEKKKSSAmhBBCCCGEEFVMAjEhhBBCCCGEqGISiAkhhBBCCCFEFZNATAghhBBCCCGqmARiQgghhBBCCFHFHKp7ANc7g8FAYmIiAG5ubiiKUs0jEkIIIYQQQlQHVVXJzMwEICAgAI2m5LyXBGKVlJiYSHBwcHUPQwghhBBCCFGDXL58maCgoBIfl6mJQgghhBBCCFHFJCNWSW5ubqbPL1y4gI+PT/UNRtxU8vLyWLNmDf3798fR0bG6hyNuEvK8E9VBnneiutxszz3VYEB3MR4Ah1pBKKVMqxPFy8jIMM2WM48TiiOBWCWZrwlzd3fH3d29GkcjbiZ5eXm4uLjg7u5+U/zjIGoGed6J6iDPO1FdbrbnniEjizPdxwBQP2YtGnfX6h3Qda6s2hES5gohhBBCCCFEFZNATAghhBBCCCGqmARiQgghhBBCCFHFJBATQgghhBBCiComxTqqmKqq6PV6dDpddQ9FXOfy8vJwcHAgOzsbvV5frWNxdHREq9VW6xiEEEIIIa4nEohVEVVVSUlJISEhodpfNIsbg6qqhISEcP78+TKr8lQFHx8fQkJCasRYhBBCCCFqOgnEqkhcXBwpKSl4eXnh5eWFg4ODvGAVlWIwGEhPT8fDwwNNNe7zoaoqmZmZxMfn7zsSGhpabWMRQgghRMUpDlq8Hhpq+lzYlwRiVUCv15OamkpgYCABAQHVPRxxgzAYDOTm5uLi4lKtgRiAq2v+PiPx8fEEBQXJNEUhhBDiOqQ4OxH40fjqHsZNQ4p1VIG8vDxUVZXNnsUNzbh7fF5eXjWPRAghhBCi5pOMWBWSqYjiRibPbyGEEOL6pqoqhqQUADT+PvJvu51JICaEEEIIIYRAzcwmptlgAOrHrEVxd63mEd3YZGqiEEIIIYQQQlQxCcREpSxduhRFUVi8eHGRx2655RYURWHNmjVFHouIiKBdu3YAbNq0CUVR2LRpk83G9eWXXzJv3rwi7cZ7LV261Gb3qozyjCcqKoqWLVva9P6KovD222+X2W/evHkoikJMTIxN7y+EEEIIcbOSQExUSlRUFIqisHHjRov25ORkDh48iLu7e5HHLly4wOnTp4mOjgagXbt27Ny50xSY2UJJgZgQQgghhBA1gawRE5USEBBAy5Yti2SzNm/ejIODA4888kiRQMx4bAzEvLy86NSpU5WMt7IyMzNN1QGFEEIIIYSoKMmIiUqLjo7m2LFjxMbGmto2bdpEZGQkgwYNYs+ePVy9etXiMa1WS/fu3U3HhacmjhkzBg8PD06ePMmgQYPw8PCgTp06vPjii+Tk5JQ6nnr16nHo0CE2b96MoigoikK9evUs+uTl5fHaa68RFhaGl5cXffr04dixYxZ9jFMBt2zZQpcuXXBzc+Phhx8GIC0tjZdeeon69evj5ORErVq1eP7558nIyLC4xpIlS+jYsSPe3t64ubnRoEED0zXKOx6j3bt30717dzw8PGjTpg0ffvghBoPBos+5c+cYPXo0QUFBODs706xZM/7v//6vSL/i7Nq1i65du+Li4kJYWBgTJ06UkvRCCCGEEDYmgVgNkJGRUeJHdna21X2zsrIq3LcyjJkt80Bq48aN9OzZk65du6IoClu3brV4rF27dnh7e5d63by8PAYPHkzv3r355ZdfePjhh/n000/58MMPSz1v+fLlNGjQgLZt27Jz50527tzJ8uXLLfq8+uqrnD17ltmzZ/PNN99w4sQJ7rjjDvR6vUW/2NhYRo8ezX333cfvv//O008/TWZmJj179mT+/PmMHTuW1atXM2HCBObNm8fgwYNRVRWAnTt3MnLkSBo0aMCiRYtYtWoVb775JjqdrsiYrR1PXFwco0aNYvTo0axYsYI+ffrw6quvsmDBAlOfhIQEunTpwtq1a5k8eTIrV66kT58+vPTSSzz77LOlfu8OHz5M7969SUlJYd68eXz11Vfs27ePd999t9TzhBBCCCFEOamiUtLT01VABdQrV64U2ycrK0s9fPiwmpWVVezjxvOL+xg0aJBFXzc3txL79uzZ06JvQEBAiX07dOhgiy9fVVVVTU5OVjUajfr444+rqqqqiYmJqqIo6h9//KGqqqreeuut6ksvvaSqqqqeO3dOBdSXX37ZdP7GjRtVQN24caOp7cEHH1QB9aeffrK416BBg9QmTZqUOaYWLVoU+X6Y36vw9/Wnn35SAXXnzp2mtp49e6qA+ueff1r0nTJliqrRaNTdu3dbtC9dulQF1N9//11VVVX95JNPVEBNSUkpcZwVGc9ff/2lqqqq6vV69cqVK2rz5s3V/v37m/q98sorFv2MnnrqKVVRFPXYsWOmNkB96623TMcjR45UXV1d1bi4OFObTqdTmzZtqgLqmTNnSvxaynqeixtDbm6uumLFCjU3N7e6hyJuIvK8E9XlZnvuGbJz1MvPvKtefuZd1ZCdU93DuS6Zxwbp6eml9pWMmKg0X19fbrnlFlNGbPPmzWi1Wrp27QpAz549TevCCq8PK42iKNxxxx0Wba1bt+bs2bOVHvPgwYOLXBcocm1fX1969epl0fbbb7/RsmVL2rRpg06nM33079/fYoplZGQkACNGjOCnn37i4sWLlR5PSEgIt956q0Vbq1atLPpt2LCB5s2bF+k3ZswYVFVlw4YNJY5j48aN9O7dm+DgYFObVqtl5MiRJZ4jhBBCiBuD4uxE0IzXCJrxGoqzU3UP54YnxTpqgPT09BIf02q1Fsfx8fEl9tVoLOPq0kqNF+5bWdHR0UydOpVLly6xceNG2rdvj4eHB5AfiP3f//0fqampbNy4EQcHB7p161bmNd3c3HBxcbFoc3Z2LjJdsyL8/f2LXBcoMmUzNDS0yLmXL1/m5MmTODo6FnvtxMREAHr06MGKFSuYPn06DzzwADk5ObRo0YLXXnuNe++9t0LjKdzP2Ne8X1JSUpE1cQBhYWGmx0uSlJRESEhIkfbi2oQQQgghRMVJIFYDuLu7V3vfyjIGYps2bWLTpk0MGjTI9Jgx6NqyZYupiIcxSKvpFEUp0hYQEICrqytz584t9pyAgADT50OGDGHIkCHk5OSwa9cupkyZwn333Ue9evXo3LmzXcbs7+9vUTjF6NKlS0XGV9y5cXFxRdqLaxNCCCHEjUVVVdTM/De8FTeXYl8HCduRqYnCJnr06IFWq2Xp0qUcOnSIqKgo02Pe3t60adOG+fPnExMTY9W0xMoqnCWypdtvv51Tp07h7+9Phw4dinwUl41ydnamZ8+epkIj+/bts8vYAHr37s3hw4fZu3evRft3332Hoiilfv+jo6P5888/uXz5sqlNr9cXu2G3EEIIIW4samY2Z+r140y9fqaATNiPZMSETXh5edGuXTtWrFiBRqMxrQ8z6tmzJ9OmTQOsWx9WWa1atWLRokUsXryYBg0a4OLiQqtWrWxy7eeff55ly5bRo0cPXnjhBVq3bo3BYODcuXOsXbuWF198kY4dO/Lmm29y4cIFevfuTe3atUlJSeGzzz7D0dGRnj172mQsxXnhhRf47rvvuO2223jnnXeoW7cuq1at4ssvv+Spp56icePGJZ77+uuvs3LlSnr16sWbb76Jm5sbX3zxRZGy/EIIIYQQonIkEBM2Ex0dze7du2nbti1eXl4Wj/Xs2ZNPP/0UJycnunTpYvexTJo0idjYWB577DGuXr1K3bp1S10zVx7u7u5s3bqVDz74gG+++YYzZ87g6upKeHg4ffr0MWXEOnbsyD///MOECRNISEjAx8eHDh06sGHDBlq0aGGTsRQnMDCQHTt2MHHiRCZOnEhaWhoNGjTgo48+Yvz48aWe27JlS9avX8+LL77Igw8+iK+vL/fffz/Dhg3j8ccft9uYhRBCCCFuNoqqXtv0SFRIRkaGab3TlStX8PHxKdInOzubM2fOUL9+/SLFJ4SoKIPBQFpaGl5eXjYvvlIR8jy/OeTl5fH7778zaNCgEgvWCGFr8rwT1eVme+4ZMrI4U68fAPVj1qJxd63mEV1/zGOD9PT0Ums2VP+rNyGEEEIIIYS4yUggJoQQQgghhBBVTAIxIYQQQgghhKhiUqxDCCGEEEIIAVoN7ndEmT4X9iWBmBBCCCGEEAKNizMhcydX9zBuGhLqCiGEEEIIIUQVk0BMCCGEEEIIIaqYBGJCCCGEEEIIDBlZnArszqnA7hgysqp7ODc8CcSEEEIIIYQQoopJICaEEEIIIYQQVUwCMWEzu3bt4u677yY0NBQnJydCQkIYPnw4O3fuLNd13n77bRRFqdAYNm3ahKIobNq0qULnWysqKoqoqKgKn1+vXj3GjBlT7vMyMzN5++237f71CSGEEEII+5JATNjE559/TteuXblw4QIfffQR69ev55NPPuHixYt069aNGTNmWH2tRx99tNzBm1G7du3YuXMn7dq1q9D5NV1mZiaTJk2SQEwIIYQQ4jon+4iJStu+fTvPP/88gwYNYvny5Tg4FDyt7rnnHoYOHcq4ceNo27YtXbt2LfE6mZmZuLm5Ubt2bWrXrl2hsXh5edGpU6cKnSuEEEIIIURVkYyYqLQpU6agKAozZ860CMIAHBwc+PLLL1EUhQ8++MDUbpx+uHfvXoYPH46vry8REREWj5nLycnhxRdfJCQkBDc3N3r06MGePXuKTPErbmrimDFj8PDw4OTJkwwaNAgPDw/q1KnDiy++SE5OjsV9Jk2aRMeOHfHz88PLy4t27doxZ84cVFWt0PcmLy+Pl19+2TTubt268ffffxfpl5CQwNNPP03z5s3x8PAgKCiIXr16sXXrVlOfmJgYAgMDTePUarX4+vry0EMPAXDy5EkeeughGjVqhJubG7Vq1eKOO+7g4MGDFRq7EEIIIYSwH8mI1QCllgfVatC4OFvXV6NB41qxvhWl1+vZuHEjHTp0KDGLVadOHdq3b8+GDRvQ6/VotVrTY3fddRf33HMPTz75JBkZGSXe56GHHmLx4sW8/PLL9OrVi8OHDzN06FDS0tKsGmdeXh6DBw/mkUce4cUXX2TLli1MnjwZb29v3nzzTVO/mJgYnnjiCcLDw4H8dW/PPfccFy9etOhnrccee4zvvvuOl156ib59+/Lff/9x1113cfXqVYt+ycnJALz11luEhISQnp7O8uXLiYqK4s8//yQqKorQ0FD++OMPBgwYwCOPPMLDDz9MRkYG9erVA+DSpUv4+/vzwQcfEBgYSHJyMvPnz6djx47s27ePJk2alHv8QgghhLiJaDW49elk+lzYlwRiNcCZev1KfMytTydCf/zYdBzTfDBqZnaxfV26tKHWL5+bjs+2vxtDUmqxfZ3bNKX2ulkVHHGBxMREMjMzqV+/fqn96tevz99//01SUhJBQUGm9gcffJBJkyaVeu7hw4f58ccfmTBhAlOmTAGgb9++BAcHc++991o1ztzcXCZNmsTdd98NQO/evfnnn3/44YcfLAKsb7/91vS5wWAgKioKVVX57LPPeOONN8pVROTo0aPMnz+fF154gY8++shi3KNGjbLo26RJE7788kvTsV6vp3///sTExDB9+nSioqJwdnamffv2ANSuXZtOnTqRlpaGl5cXAD169KBHjx4W17jtttto0aIFX3/9NVOnTrV67EIIIYS4+WhcnC1edwr7uu5C3S+//JL69evj4uJC+/btLaZuFRYbG8t9991HkyZN0Gg0PP/888X2W7ZsGc2bN8fZ2ZnmzZuzfPlyO43+5mWc2lc4kBk2bFiZ527evBmAESNGWLQPHz68yFTIkiiKwh133GHR1rp1a86ePWvRtmHDBvr06YO3tzdarRZHR0fefPNNkpKSiI+Pt+peRhs3bgQoEnSNGDGi2HF/9dVXtGvXDhcXFxwcHHB0dOTPP//kyJEjVt1Pp9Px/vvv07x5c5ycnHBwcMDJyYkTJ05YfQ0hhBBCCFE1rquM2OLFi3n++ef58ssv6dq1K19//TUDBw7k8OHDpqlk5nJycggMDOS1117j008/LfaaO3fuZOTIkUyePJmhQ4eyfPlyRowYwbZt2+jYsaO9vyQA6sesLfnBQmnheodXltxXY9m37p4lVvetqICAANzc3Dhz5kyp/WJiYnBzc8PPz8+iPTQ0tMx7JCUlARAcHGzR7uDggL+/v1XjdHNzw8XFxaLN2dmZ7OyC7OLff/9Nv379iIqKYtasWdSuXRsnJydWrFjBe++9R1ZW+XaYN447JCSkzHFPnTqVF198kSeffJLJkycTEBCAVqvljTfesDqIGj9+PF988QUTJkygZ8+e+Pr6otFoePTRR8s9diGEEEIIYV/XVSA2depUHnnkER599FEApk2bxpo1a5g5c6Zpypq5evXq8dlnnwEwd+7cYq85bdo0+vbty8SJEwGYOHEimzdvZtq0afz44492+kosadxdq71vRWm1WqKjo/njjz+4cOFCsevELly4wJ49exg4cKDF+jAomiErjjFouXz5MrVq1TK163Q6U7BjC4sWLcLR0ZHffvvNImhbsWJFha5nHHdcXFyZ416wYAFRUVHMnDnTor3wWrLSLFiwgAceeID333/foj0xMREfH59yjl4IIYQQNxtDRhYxzQcD+W/+V8VryZvZdROI5ebmsmfPHl555RWL9n79+rFjx44KX3fnzp288MILFm39+/dn2rRpJZ6Tk5NjqrZnXmAiLy+PvLy8Iv3z8vJQVRWDwYDBYKjwWGuqCRMmsHr1ap566il+/vlni2BLr9fz5JNPoqoqEyZMMH39xqmKxX1PzB8D6NatG5AfKLVp08bU76effkKn05m+t+bnmF+38PVKug/kZ6sURTG1ZWVl8f3335c41tJ+nsb1WgsWLKBt27am9kWLFhUZt6IoODk5WVzv33//ZefOndSpU8fU7ujoCOSX+jeO33id4q6xatUqLl68SMOGDe3+3DMYDKiqSl5eXpGAW9w4jH/jivtbJ4S9yPNOVJeb6bmXdj6N9PPJJKblv9bQ/nMBjatLkX5ugW541faq6uFdN8rzXLluArHExET0en2R6WnBwcHExcVV+LpxcXHlvuaUKVOKLTCxYcOGItPfIP/FvbESXm5uboXHWlO1atWKKVOmMHHiRLp27cqjjz5K7dq1uXDhArNnz2bPnj1MmTKFli1bmqocGgPZq1ev4uTkZHE942PGvnXq1GHYsGFMnToVnU5Hjx49OHr0KDNmzMDLywu9Xm/qm5mZafq/sc34C1G4wmLh+0RFRfHpp58ycuRIHnzwQZKTk5kxY4Yp+ElPTzf11el0xV7TXK1atRgxYgSfffaZqfDHkSNHmDFjBp6enuTl5ZnO79OnDx9//LHpe3jixAk+/vhj6tati06ns7hPnTp1WLFiBZ06dcLX1xd/f3/Cw8Pp168f8+fPp169erRo0YL9+/fz+eefExYWVuQa9pCbm0tWVhZbtmwxfX/EjWvdunXVPQRxE5LnnaguN/pzz5Bn4PBjh9Gl6IBrS3Oifii2r4OPA81nNUfjeN2VmqgS5steynLdBGJGhaeyqaparkp2trjmxIkTGT9+PJCfEQsLCwOgV69exU4By87O5vz583h4eBQbqN0IXnrpJbp168bUqVNNxS38/Pzo2rUrn376KZ07d7bo7+ycXzrf09PTVPWv8GPm7d9//z2vvfYaCxcuZObMmbRp04affvqJQYMGERgYaOrr5uZm+r+xzRhIlXWf22+/ndmzZ/Pxxx9z7733UqtWLR599FECAwN57LHH8PDwMPU1FtsofM3C5s+fT+3atVmwYAHffPMNbdq0YenSpdx33304Ojqazp80aRJ6vZ6FCxcyffp0mjdvzsyZM1mxYgWbN2+2uM+cOXOYMGEC9913Hzk5OTzwwAN8++23fPHFF7i5uTFt2jTS09Np164dy5YtM1WFLGuslZWdnY2rqys9evS4YZ/nIv+NjXXr1tG3b1/T75YQ9ibPO1FdbpbnnqqqJHyQQOzeWCht61QNBEYEctvg2yr9+vtGVdp2TIUpakV3qq1iubm5uLm5sWTJEoYOHWpqHzduHPv37zdV1itJVFQUbdq0KTLlMDw8nBdeeMFieuKnn37KtGnTilTUK05GRgYeHh4AXLlypcRA7MyZM6Zqj8I2duzYQdeuXVm4cCH33XdfdQ+nyhkMBlP5eo2Niq9UhjzPbw55eXn8/vvvDBo06IZ+USJqFnneiepyMz33Tq45ycIBC8vsN+qPUTTs37AKRnR9Mo8N0tPTcXd3L7Fv9b96s5KTkxPt27cvkhpet24dXbp0qfB1O3fuXOSaa9eurdQ1he2tW7eOd955h1WrVrFhwwY+/fRThg4dSqNGjbjrrruqe3hCCCGEENe1iH4RhLYLQaH4NeWKViEsMoyIfhFVPLIb13U1NXH8+PHcf//9dOjQgc6dO/PNN99w7tw5nnzySSB/yuDFixf57rvvTOfs378fyI9IExIS2L9/P05OTjRv3hzIz6j16NGDDz/8kCFDhvDLL7+wfv16tm3bVuVfnyiZl5cXa9euZdq0aVy9epWAgAAGDhzIlClTJPsihBBCCFFJiqIQ/WZ3friz+O2PVL1K9ORomZJoQ9dVIDZy5EiSkpJ45513iI2NpWXLlvz+++/UrVsXyN/A+dy5cxbnmFer27NnDz/88AN169YlJiYGgC5durBo0SJef/113njjDSIiIli8eHGV7SEmrNOxY0cJjoUQQggh7KhB3wa4u+rJyCq03ZBWIbRd6A2bDTufmkrCtYJvpQlyd6e2DdfcX1eBGMDTTz/N008/Xexj8+bNK9JmzRK44cOHM3z48MoOTQghhBBCiOvWlXPpZOkcodD0xBs5G5aj0xE5axaXrSiyEeLhQcy4cTg72CaEum7WiAkhhBBCCCHsQ5+nZ/n9yzHkFV0jdiOvDXPSagn39i4zKNIAdby8cLLhXqkSiAkhhBBCCHGT2/reVi79c6nYx7q90u2GzIZB/tq4ydHRJZQoKWAAJkfbNisogZgQQgghhBA3sYu7L7Ll3S0lPu4Vbt+9SKtbv4gIIsPC0JYQZGkVhciwMPpF2DYrKIGYEEIIIYQQN6m8zDyW378cVV9QV6GV62mLPsnHk6t6WFXKmBXTl1BbQq+qNs+GgQRiQgghhBBC3LTWv7KepGNJpuN6znG0dDsDZjFH0vGkYs68sRizYoVDLXtlw+A6rJoohBBCCCGEqLxT607x9+d/m449wzyIzD6KVlHxqetNSkwqYP9ALPV8KpkJZZePdw9yx6u2faZJGrNiAxYutGi3VzYMJBATQgghhBDippN1JYtfHvrFom3wV4NQHl4BgH8jvyoJxHQ5OmZFziLjctnl4z1CPBgXMw4HZ/uEMP0iItAqimmKogJ0sFM2DGRq4nXpfGoqe2Njy/y4kJZWJeOZN28eiqKYPhwcHAgNDeWee+7hxIkTxZ6Tl5fHzJkz6dy5M97e3ri6utKsWTNeeeUVkpKK/2U3GAx8//339OnTh4CAABwdHQkKCuL222/n119/xWAoq95Nwb1DQkJQFIWlS5cW22fMmDF4eHiUeA0PDw/GjBlTpP306dM8++yzNG7cGFdXV9zc3GjRogWvv/46Fy9etGp8QgghhBD2tvrZ1Vy9eNV0HPlsJA161TMd+zf0M32edDzJqr15K0LrpMU73LvsqEQDXnW80DrZrnx8YSnZ2RbrxFRsXynRnGTErjPVuelcWb799luaNm1KdnY227dv57333mPjxo0cPXoUX19fU7/MzEwGDRrEtm3bePzxx3njjTdwdXVl586dfPLJJ/zwww+sW7eOJk2amM7Jzs7mzjvvZO3atdxzzz3MnDmTkJAQEhIS+OOPP7j77rtZvHgxQ4YMKXOcv/32G5cvXwZgzpw5NtvM+7fffuOee+4hICCAZ599lrZt26IoCgcPHmTu3LmsWrWKffv22eReQgghhBAVdeinQxz84aDp2L+xP30/7AuqztTm17DgtVvu1VwyLmfgEVLym9QVpSgK0ZOjWThgYekdDdh9U+kzKSkWxw19fe2WDQMJxK47xk3nEjIySt3vwB6bzpWlZcuWdOjQAYCoqCj0ej1vvfUWK1as4KGHHjL1e+GFF9i8eTOLFi1i5MiRpvbo6GiGDx/OrbfeyrBhwzhw4ADaa+MfP348a9asYf78+TzwwAMW973rrrv43//+R1ZWllXjnDNnDk5OTvTs2ZO1a9dy4cIFateuXamv/cyZM9xzzz00btyYjRs34u3tbXqsV69ejB07luXLl1fqHkIIIYQQlXX10lV+e/I307GiVRj6/VAc3RwxZBlwbtMUyA/OzCUeS7RLIAYQ0S+CsMgwYvfGWlRvNB9jaLtQu28qffrKFYvj/3XtatfAT6YmXmeqc9O58jIGZcbsE0BcXBxz586lf//+FkGYUePGjZkwYQKHDh1ixYoVpnNmz55N//79iwRhRo0aNaJ169ZljunSpUv88ccf3HHHHfzvf//DYDAwb9688n9xhUydOpWMjAy+/PJLiyDMSFEU7rrrrkrfRwghhBCiolRV5ZeHfyH7Sraprftr3al1ay0ANK7O1F43i9rrZhHQKsTiXHuuEzNmxYoLwgBUvWr3bBjAmUKB2L0tW9r1fpIRq0ap2dkcjI8v93lujo409ffneHIyhmLm62oUhcZ+frg5OrLt3LlyXbtVUBDeLi7lHlNxzpw5A+QHV0YbN25Ep9Nx5513lnjenXfeyauvvsq6desYNmwYGzduJC8vr9RzrDVv3jz0ej0PP/wwffr0oW7dusydO5fXXnutUr/ca9euJTg4mE6dOlV6jEIIIYQQ9vDPV/9was0p03FYhzB6vN6j2L7edbxxcHFAl50/XdHelRONWbFL/1zKX5xlpOSP097ZMLDMiAW6ueHp7GzX+0kgVo0OxsfT/dtvbX5dg6pyNCmJHhXI9Gx96CG6hYdX6L56vR6dTmdaI/buu+/So0cPBg8ebOpz7lpgWL9+/RKvY3zM2Neac6yhqirffvsttWrVon///iiKwpgxY5g0aRIbN26kV69eFb72uXPnaNOmTaXGJ4QQQghhL0knklj30jrTsYOLA0O/H4rWsfhlLIpGwa+RH/EH85MG9t7UucS1Yqr914YZnTZbI1bfrL6BvcjURGEznTp1wtHREU9PTwYMGICvry+//PILDhUsFmLrX7jNmzdz8uRJHnzwQdPas4ceeghFUZg7d65N7yWEEEIIUVMYdAaW37+cvMw8U1ufD/sQ0DTAsl9mNmfb3c3ZdndjyMy2WCdWFZs6R/SLwNHdsUh7WIcwu98bLKcmNpBATFxPvvvuO3bv3s2GDRt44oknOHLkCPfee69Fn/Br2TbjtMXiGB+rU6eO1edYY86cOQAMHTqUlJQUUlJS8Pb2plu3bixbtowUs3dBHBwc0Ov1JV5Lp9Ph6FjwhyI8PLzS4xNCCCGEsIdtH2zj4l8F2+jU712fW5+9tWhHVUV3Pg7d+ThQVYtALPlUMgaddVsFVYZqKLrs5vT603a/r95gIMY8I+bjY/d7ytTEatQqKIitZtUEy0tVVR7/9VfTWjHj2rBv7rijwtmkVkFBFR5Ps2bNTAU6oqOj0ev1zJ49m6VLl5pKxEdHR+Pg4MCKFSt48skni72OsUhH3759Tec4OjqWek5ZUlNTWbZsGQCRkZHF9vnhhx94+umnAQgODiY7O5vk5GT8/Pws+iUlJZGTk0NwcLCprX///nz++efs2rVL1okJIYQQosqlnk8lMyGzSHvCkQQ2vb3JdOzk6cSQb4egaMp+rWgeiBnyDKTEpODX0K+UMyon7XwauixdkfaTq0/ScqR9C2dcvHqVPLM9aasiIyaBWDXydnGp8Hoso2kDBjBgYf5cWoOqMm3AALrXrWuL4VXaRx99xLJly3jzzTe566670Gg0hISE8PDDD/PNN9+wePHiIpUTjx8/zocffkiLFi1MxTlCQkJ49NFHmTlzJt99912xlRNPnTpFRkZGiZUTf/jhB7Kyspg8eTLdunUr8vjdd9/N3LlzTYFYnz59eP/991m8eDFPPfWURd+ffvrJ1MfohRdeMJ1fuHw95AfNK1asYOjQoWV814QQQgghykeXo2NW5CwyLpe9z6yiUXAPcrfquoVL2CcdT7JrIBZ/qPgidif/OIlqUK0KHiuqcMVECcREmfpFRBAZFsbuS5eIDAuz66Zz5eXr68vEiRN5+eWX+eGHHxg9ejSQX+r92LFjjB49mi1btnDHHXfg7OzMrl27+OSTT/D09GTZsmWmdVzGc06fPs2YMWNYs2YNQ4cOJTg4mMTERNatW8e3337LokWLSgzE5syZg6+vLy+99BIuxVSFfOCBB5g6dSoHDhzglltuITo6msGDBzNu3DhiYmLo2bMnqqqyZcsWPv30UwYPHkxUVJTp/Pr165v2RWvTpo1pQ2eAw4cPM3fuXFRVlUBMCCGEEDanddLiHe5NRkIGZe1x5N/IH62TdfvM+jcpGog1GtSoosMsU8KhhGLbMy5nELc/jtB2oXa7d+E9xKpiaqKsEbvOKYrC+7170ywggPd7967WfcOK89xzzxEeHs4777xjWnPl7u7OunXr+Oyzz9izZw933303AwcOZP78+Tz66KPs37+fJk2aWFzHxcWFVatWMW/ePOLi4njiiSfo1asXTzzxBDExMcydO5c77rij2DH8+++/7NmzhwcffLDYIAzg8ccfBwrWkQEsXbqUSZMmsWrVKu666y6GDRvGqlWrmDRpEkuXLi1yjdtvv52DBw8yaNAgvvrqKwYNGsTtt9/OzJkziY6Olg2dhRBCCGEXxoqDZW40C0S/a30FQjd/N1z9XE3H9i7YEf9fQUbMwdUyX3Ri9Qm73vuM2fowraJQp5h9YW1NMmI3gD4NGnD4mWeq7f5jxoxhzJgxxT7m4uLC2bNni7Q7Ojry9NNPm6YCWkOr1fLAAw+UuKlzSVq3bo1azH5r5po0aVKkj6OjIxMnTmTixIlW36tBgwZ88cUX5RqfEEIIIURlGffhit0bW+zGyIpGIbR9aLn34/Jv7M+FXRcA+wdi5hmxOl3qkHY+zXTPk6tP0uO14vc8swXzjFi4tzcOGvvnqyQjJoQQQgghxHXOmBUrLgiD/GqEZe7HpSg4NqmHY5N6cK1fVZWwVw0qCYcLArGglkE0HNjQdHxh5wWykrPsdv/TVVy6HiQQE0IIIYQQ4oZgzIoVpmgVwiLDysyGadxcCN/2PeHbvkfjlr+cw69xQXGOtPNpFnuR2VLK2RSLawe2CLQIxFSDyql1p+xyb7CcmiiBmBBCCCGEEMJqiqIQNSmqSLuqtyIbVoIilRNP2CcrZr4+DCCoRRD1etazWCt2cvVJu9w7My+PuPR003FVFOoACcSEEEIIIYS4YQQ2D7RsULAqG1aSgCYBFsf2mp5YuGJiYPNAHFwcqB9d39RmLGNva+YbOYNkxIQQQgghhBDllHSsUKCkYnU2zJCZzblu93Ou2/0YMrMBiuwbVhWBmFdtL1x88qdGNhxUMD3RWMbe1gqXrpdATAghhBBCCFEuiUcTLY6D2wRbnw1TVfKOxZB3LAauVZN2dHPEq46XqUvy8WRbDdWC+WbOgS0KsnqNBlruW2aPMvZF9hCTQEwIIYQQQghRHglHCjJLikah70d9K73PrL0rJxr0BhKPFASQ5oGYbwNfi/vbY53YGbNAzNPJCX9X11J6244EYkIIIYQQQtwgko4WBEq1OtYiom/F1oaZs3cgduX0FXTZOtNxUIsgi8eLlLG/Ytsy9qfN1ojV9/WtdOBqLQnEhBBCCCGEuEGYT00MaBpQSk/r+TcpCMSykrPITMy0yXWNihTqaGFZcKRwGfvT607b9P5nqmEPMZBATAghhBBCiBtCdko26XEFZdgDmtkoECtcwt7GWTHz9WFQtPJj4TL2J3633ToxVVUtN3OuotL1IIHY9SntPFzeW/bH1QtVPrTp06ejKAotW7as8nsLIYQQQtzMEo9ZFuqwWUbMzoFYwn8FGTHvut44ezpbPG7PMvYJmZlk5BVsJF1VhToAHMruImoUXQ4sjITMy2X3dQuBx2LAwbnMrrYyd+5cAA4dOsRff/1Fx44dq+zeQgghhBA3s8IVE8sdiCkKDnVCTJ8b+dT1QeOowZBnAOybESu8Psyo4cCGpkyYsYx9aLvQSt/7TDWVrgfJiF1/tE7gGU7ZPzoNeNbJ719F/vnnHw4cOMBtt90GwJw5c6rs3uWRmWnbec1CCCGEEDWBeeVBjaMG3/rlCyo0bi7U3buEunuXoHFzKWh30OAXUbCfmC0DMYPOYLH3WeH1YUbm68TAdmXsi5Sul6mJokSKAt0mA4YyOhry+1VR1RcoCLw++OADunTpwqJFi4oEPRcvXuTxxx+nTp06ODk5ERYWxvDhw7l8uSDDl5KSwosvvkiDBg1wdnYmKCiIQYMGcfToUQA2bdqEoihs2rTJ4toxMTEoisK8efNMbWPGjMHDw4ODBw/Sr18/PD096d27NwDr1q1jyJAh1K5dGxcXFxo2bMgTTzxBYqLlu0kAR48e5d577yU4OBhnZ2fCw8N54IEHyMnJISYmBgcHB6ZMmVLkvC1btqAoCkuWLKnQ91QIIYQQwlrmGTH/Rv5oHGz3Ut9elROTTyajz9WbjoNaFp8R84vww69RQTBoqzL2Z8wqJgLUq8JATKYmVqecVEg4WP7ztG7g2xRSjoNaTECmaMCncX6/C9vKd+3AVuDsXe4hZWVl8eOPPxIZGUnLli15+OGHefTRR1myZAkPPvggkB+ERUZGkpeXx6uvvkrr1q1JSkpizZo1XLlyheDgYK5evUq3bt2IiYlhwoQJdOzYkfT0dLZs2UJsbCxNmzYt99hyc3MZPHgwTzzxBK+88go6XX551FOnTtG5c2ceffRRvL29iYmJYerUqXTr1o2DBw/i6OgIwIEDB+jWrRsBAQG88847NGrUiNjYWFauXElubi716tVj8ODBfPXVV7z88stotVrTvWfMmEFYWBhDhw4t97iFEEIIIcrDomKijQp1GJlXTkw+kYxqUFE0lX/Dv0ihjhIyYgCNBjXir8/+AgrK2Lv6Vm7PL/OMWJinJ67XXv9VBQnEqlPCQVjc3fbXVQ1w5Sj81KP8547cCrW7lfu0pUuXkpqayiOPPJJ/mZEjef7555kzZ44pEHvzzTdJTEzkwIEDNGvWzHTuiBEjTJ9PmzaNQ4cOsW7dOvr06WNqv+uuu8r/tVyTl5fHm2++yUMPPWTR/uSTT5o+V1WVLl26EBUVRd26dVm9ejWDBw8GYPz48Tg4OPD3338TGFjwx2HUqFGmz8eOHUt0dDS//vord955JwCXLl1i+fLlvPHGGzg4yK+aEEIIIexHn6fnyqmCoKIihToMWTlcGvwsAGErZ6BxLagzYJ4R02XrSD2fik9dn4oP+Jr4/8wCMQUCm5UciDUc2NAUiBnL2LcY0aJS9zcPxKpyWiLI1ERhI3PmzMHV1ZV77rkHAA8PD+6++262bt3KiRP5c3hXr15NdHS0RRBW2OrVq2ncuLFFEGYLw4YNK9IWHx/Pk08+SZ06dXBwcMDR0ZG6desCcOTIESB/PdnmzZsZMWKERRBWWFRUFLfccgtffPGFqe2rr75CURQef/xxm34tQgghhBCFXTl1BYOuYKZUhSomGgzk7D9Kzv6jYLCcdWWvyonme4j51vfF0a3kjFThMva2mJ5oPjWxKgt1gARiwgZOnjzJli1buO2221BVlZSUFFJSUhg+fDhQUEkxISGB2rVrl3ota/qUl5ubG15eXhZtBoOBfv368fPPP/Pyyy/z559/8vfff7Nr1y4gf6olwJUrV9Dr9VaNaezYsfz5558cO3aMvLw8Zs2axfDhwwkJCbHp1yOEEEIIUVilKyaWoSoCsZLWhxnZuox9nl7PudRU03FVZ8RkvlR1CmyVPxWwolQV1j1esFbMuDas7zcVL9IR2Krcp8ydOxdVVVm6dClLly4t8vj8+fN59913CQwM5MKF0vc2s6aPi0t+FZ+cnByL9uKKbAAoxXwv/vvvPw4cOMC8efNMUychP6g05+fnh1arLXNMAPfddx8TJkzgiy++oFOnTsTFxfHMM8+UeZ4QQgghRGUlHEmwODZf02UL7sHuOHk6kXs1F7BNIKbP1Vtcp7T1YUbmZezT49IrVcb+fFoaBrUgkKvqjJgEYtXJ2btC67Es9JoGywbkf64a8o/r2GHdWQn0ej3z588nIiKC2bNnF3n8t99+4//+7/9YvXo1AwcO5Pvvv+fYsWM0adKk2OsNHDiQN998kw0bNtCrV69i+9SrVw+Af//9l/79+5vaV65cafW4jcGZs7PlHmtff/21xbGrqys9e/ZkyZIlvPfeewQElPzukouLC48//jgzZsxgx44dtGnThq5du1o9JiGEEEKIiko6WhDQeNbyLLIpcmUpikJAkwAu/XMJgOTjyZW+ZtLxJIvplNYGYuZOrD5R4UCscOl6CcRE+dTtB8GRcHl3/v/r9qvS269evZpLly7x4YcfEhUVVeTxli1bMmPGDObMmcOMGTNYvXo1PXr04NVXX6VVq1akpKTwxx9/MH78eJo2bcrzzz/P4sWLGTJkCK+88gq33norWVlZbN68mdtvv53o6GhCQkLo06cPU6ZMwdfXl7p16/Lnn3/y888/Wz3upk2bEhERwSuvvIKqqvj5+fHrr7+ybt26In2NlRQ7duzIK6+8QsOGDbl8+TIrV67k66+/xtPT09T36aef5qOPPmLPnj3FBqZCCCGEEPZgPjWxtIIXleHf2N8UiCUeK34mUnkUrphY0mbO5oxl7JNP5AeCJ1efpMdrFShQRzF7iMkaMVEuigLd3we/Zvn/r8J9wyC/SIeTk1ORioRGAQEBDB06lN9++81UefD222/ngw8+YMCAATz33HOkpqbi55e/L4Snpyfbtm3jkUce4ZtvvuG2227jscce49ixY4SFhZmu+/3339O7d28mTJjA3XffzcWLF/nxxx+tHrejoyO//vorjRs35oknnuDee+8lPj6e9evXF+l7yy238Pfff9O+fXsmTpzIgAEDmDBhAs7Ozjg5WW6YXatWLbp164afnx/33Xef1eMRQgghhKgoVVUt9xBrattpiUZ+jQv28UqJSUGXo6vU9czXhykaxep1beZZMWMZ+4o4YxaIOWm1hJm9uV4VJCN2I6jbBx46XC23Xr58eZl9fvzxR4sgybjxc0l8fHyYNm0a06ZNK7FPSEhIsZskq6rlgs158+ZZbPBsrlmzZqxdu7bMaxj7/vTTT6WOG/IrMe7atYvnnnsOV9fK7WshhBBCCGGN9Lh0ctIK1s5XplCHxr/k/WQtCnao+ZUaA5tXPPtmHoj5NfTDwcW60KTRwEb8Pf3v/GFUooz9abOKifV8fNBUcUJDMmJC2MCFCxfYsmULjzzyCBqNhnHjxlX3kIQQQghxk7BVxUSNuyv1j/5G/aO/oXEv+oayrSsnmu8hZs36MKO6PetaBG0VLWNvnhGr6vVhIIGYEDYxe/ZsoqKiOHToEAsXLqRWrVrVPSQhhBBC3CQSj9i3dL2RfyPbBWK6bB3JJwsKfpQnEHN0daR+r8qXsTdfI9agikvXgwRiQtjE22+/jcFg4PTp09x5553VPRwhhBBC3ETMM2JOnk54htlnrZOzlzMeoR6m48oEYonHEi2Cp7L2ECvMfJ1Yelw6cQfiynV+Wk4OSVkFa8uqulAHWLlGrDxlwY369u0ra2SEEEIIIYSwM/NALKBpQLF7qFrDkJVD7D0vARC66BM0rkVL4Ps39ic9Nh2ApGMVD8TM14eBdRUTzRUuY39y9UlC21pfxv5MNZeuBysDsfK+w68oCidOnKBBgwYVGZMQQgghhBDCSoUDsQozGMjesd/0eXH8G/tzdvNZoHIZMfP1YRoHTZH1Z2UpXMb+xO8n6P6q9XvpVvceYlCOqYlxcXEYDAarPtzc3Ow5ZiGEEEIIIQSQm55L2vk007G91ocZmQdMGfEZZKdkV+g6FhUTG/mhddKW+xqVKWN/xqxiIkD9mrpG7MEHHyzXNMPRo0fj5eVV4UEJIYQQQgghylY4K1WVgRhA0omKZcXMN3Mu7/owo0YDG5k+N5axt5Z5RszP1RVvF5cKjaEyrArEvv32WzzLscHZzJkzCQiw75NACCGEEEKIm52tStdby79J5Ssn5mXmceV0QSBUnoqJ5ipTxt48EKuObBjYoGpiWloaK1as4MiRI7YYjxBCCCGEEMJKCUcKpvgpWgW/hn52vZ9vfV8UbUExkIoEYolHE8Gs2nx5C3UYObo6Ui+6num4PGXszacmVsf6MKhAIDZixAhmzJgBQFZWFh06dGDEiBG0bt2aZcuW2XyAQgghhBBCiOIlHS0IhPwiKrbWqjy0Tlp86xcELhWpnGheqAMqnhGDipWxN6hqtW/mDBUIxLZs2UL37vkVSZYvX46qqqSkpDB9+nTeffddmw9QFJV6PpXYvbFlfqRdSCv7YjYwb948FEUp9uOll/JLoP7222888MADtGrVCkdHxwqXVRVCCCGEEAVsVjHxGsXNBcWt9PVS5uvEKpIRM18fpnHUVCqLZ75ODKybnhiXnk6OXm86rq6piVaVrzeXmpqKn1/+N+uPP/5g2LBhuLm5cdttt/G///3P5gMUlnQ5OmZFziLjckaZfT1CPBgXMw4H53L/mCvk22+/pWnTphZtYWFhQH7QvmvXLtq2bYuzszN79uypkjEJIYQQQtyoDHqDRSDk37R8JeAL07i70uDsujL7+TX2g9/zP086noSqquV6k928YmJA0wC0jhXP4vk1tCxjf3L1yTLL2NeE0vVQgUCsTp067Ny5Ez8/P/744w8WLVoEwJUrV3CphmojNxutkxbvcG8yEjKg+O0d8mnAq46X3dPT5lq2bEmHDh2KfWzWrFloNPkJ2Gefffa6DMTy8vJQFAUHh6oJbIUQQgghSpMSk4I+tyCzY+9CHUbmGbG8jDzSY9PxDLO+sJ95IFbR9WHmGg5syN8n/gbg/M7zZF3JwtW35IrvhQOx+tfL1MTnn3+eUaNGUbt2bUJDQ4mKigLypyy2atXK1uMThSiKQvTk6NKDMAADRE+OrjFTAI1BWEUZDAbeffddmjRpgqurKz4+PrRu3ZrPPvvMot/Ro0e59957CQ4OxtnZmfDwcB544AFycnJMff777z+GDBmCr68vLi4utGnThvnz51tcZ9OmTSiKwvfff8+LL75IrVq1cHZ25uTJ/HT3+vXr6d27N15eXri5udG1a1f+/PPPSn2NQgghhBDlUdUVE033aWJ5n/JMT8xNzyUlJsV0XJn1YUYWZez1ZZexN18fplEUwr29Kz2Giij3W/tPP/00t956K+fPn6dv376mF9gNGjSQNWLllJ2aTfzB+LI7FuLo5oh/U3+SjycXWxlG0Sj4NfbD0c2Rc9vOlevaQa2CcPGuWGZTr9ej0+ks2myVPfroo494++23ef311+nRowd5eXkcPXqUFLOKNwcOHKBbt24EBATwzjvv0KhRI2JjY1m5ciW5ubk4Oztz7NgxunTpQlBQENOnT8ff358FCxYwZswYLl++zMsvv2xx34kTJ9K5c2e++uorNBoNQUFBLFiwgAceeIAhQ4Ywf/58HB0d+frrr+nfvz9r1qyhd+/eNvmahRBCCCFKk3jEtoGYITuHyw+9DkDwt++icXEutl+RvcSOJ1Evqp5V90g4nGBxbItAzFjGXped/zr05OqTtBjRosT+p81eP9bx8sJJW3UzyMxV6FVyhw4daN26NWfOnCEiIgIHBwduu+02W4/thhd/MJ5vu39r8+uqBpWko0nM6zGv3Oc+tPUhwruFV+i+nTp1KtKWl5dnk2Bs+/bttGrVirffftvU1r9/f4s+48ePx8HBgb///pvAwIJf6lGjRpk+f/vtt8nNzWXjxo3UqVMHgEGDBpGSksKkSZN44okn8DZ7VyQiIoIlS5aYjjMzMxk3bhy33347y5cvN7UPGjSIdu3a8eqrr/LXX39V+usVQgghhCiLeUbMPdi91Ol4VtEbyFy/y/R5STzDPHF0cyQvMy9/HMcSS+xbmHmhDqj4Zs7mjGXsjYU6jGXsFU3xM8Ms9hCrpmmJUIGpiZmZmTzyyCO4ubnRokULzp3Lz7iMHTuWDz74wOYDFNeP7777jt27d1t8lDcI0+l0Fh+qmp/xu/XWWzlw4ABPP/00a9asIS3NsiJkZmYmmzdvZsSIERZBWGEbNmygd+/epiDMaMyYMWRmZrJz506L9mHDhlkc79ixg+TkZB588EGLcRoMBgYMGMDu3bvJyCi7kIoQQgghRGXZumKitRSNgl+jgkqHyceTrT7XfH2Yg4sDvg1sEwiVp4y9Ren6aqqYCBUIxCZOnMiBAwfYtGmTRXGOPn36sHjxYpsOTlxfmjVrRocOHSw+ysvR0dHiw7h2a+LEiXzyySfs2rWLgQMH4u/vT+/evfnnn3+A/GIxer2e2rVrl3r9pKQkQkNDi7QbqzsmJVnOcS7c9/LlywAMHz68yFg//PBDVFUlOdn6P0ZCCCGEEBVVXYEYVLyEvfkeYgFNA9BoK1dHAPK3dvIOt1zntW/2vmK3dsrW6bh49aqpX3VmxMo9Z2zFihUsXryYTp06WRSCaN68OadOnbLp4G50Qa2CeGjrQxU+X1VVfn38V9NaMePasDu+uaPCRTqCWlU+PVwZu3fvtjiuX78+kL/WbPz48YwfP56UlBTWr1/Pq6++Sv/+/Tl//jx+fn5otVouXLhQ6vX9/f2JjY0t0n7p0iUAAgIs/4gV/j4aH//888+LnYoJEBwcXOoYhBBCCCEqKzMxk6ykLNNxdQZiV05fQZ+nt6oMvXlGzBbrw0ra2mn3l7vZ/aXl60qPEA8G/jPaoq26StdDBQKxhIQEgoKKvljPyMioMRX6rhcu3i4VXo9lNGDaABYOWAjkrw0bMG0AdbvXtcXwqoU1WTQfHx+GDx/OxYsXef7554mJiaF58+b07NmTJUuW8N577xUJqIx69+7N8uXLuXTpkikLBvnTKt3c3EoMroy6du2Kj48Phw8f5tlnny3fFyeEEEIIYSPVVTHRyL9JQSBm0BlIiUnBv1Hp+5hlp2aTdqFgeYkt1oeVd2unmIxUi+brKhCLjIxk1apVPPfcc0BBxmDWrFl07tzZtqMTZYroF0FYZBiXdl8iLDKMiH4R1T2kYp09e9aU7TJmTpcuXQpAvXr1ygzA7rjjDtM+ZYGBgZw9e5Zp06ZRt25dGjXKL1k6depUunXrRseOHXnllVdo2LAhly9fZuXKlXz99dd4enry1ltv8dtvvxEdHc2bb76Jn58fCxcuZNWqVXz00UcWhTqK4+Hhweeff86DDz5IcnIyw4cPJygoiISEBA4cOEBCQgIzZ86s7LdLCCGEEKJUCUcsqw9WZ0YM8qcnlhWI2aNionFrJ2NiokTXtnZak2K5hKR+Na4RK3cgNmXKFAYMGMDhw4fR6XR89tlnHDp0iJ07d7J582Z7jFGUQlEUer/fm9VjV9P7/d41Niu5ceNGHnrIchrm3XffDcCDDz7IvHnzSj0/OjqaZcuWMXv2bNLS0ggJCaFv37688cYbODo6AnDLLbfw999/89ZbbzFx4kSuXr1KSEgIvXr1wsnJCYAmTZqwY8cOXn31VZ555hmysrJo1qwZ3377LWPGjLHqaxk9ejTh4eF89NFHPPHEE1y9epWgoCDatGlj9TWEEEIIISrDPCPm4OpQZI2UvRUOupKOJUEZRdTN14eBbTZzhoLEROzeWFR9MVs7aRVC24US0S+CM2Z7jLk5OhLk7m6TMVREuQOxLl26sH37dj755BMiIiJYu3Yt7dq1Y+fOnbKhczVp0KcBzxx+ptruP2bMmDIDEGv6lMa4PqwszZo146effiq1T8uWLVm5cmWpfaKiokwVG4vTo0cPevToUeZ4hBBCCCHsIeloQYGMgCYBJZZqLw+NuysRCVut6uvq54pbgBuZiZn547GiYIf5+jBHN0d86vlUaJyFlZUVU/Uq0ZOjURTFsnS9j0+1JjEqtMFTq1atTNXshBBCCCGEEFWrOismGvk39q9wIBbYPNAmwaORabnOP5fA7L1082wYwBmzzZyrc30YVDAQMxgMnDx5kvj4eAwGy1VxkiUQQgghhBDCfnTZOq6cKcjs+DctfW2Wvfg38ef8jvOAdYGY+WbOtlgfZq6krJh5NkxVVYuM2HUXiO3atYv77ruPs2fPFpm6pSgKer3eZoMTQgghhBBCWEo6kWSR9bFVRsyQnUP80+8CEPTl62hcnEvtb16w4+rFq+Sm5+Lk4VRs36zkLNJj003Htg7EID8r5t/Y3yIoDGgWYMqGJWdlkZaTY3qsOgt1QAU2dH7yySfp0KED//33H8nJyVy5csX0IRvZCiGEEEIIYV+JR+xUul5vIOPXTWT8ugn0pdWCz1e4cmLyyZJjAfNsGNiuUIc5RVHo+HxHi7YWI1qY1oGZT0uE6zAjduLECZYuXUrDhg3tMR4hhBBCCCFEKSz2EFOKBkRVpfB9E48lEtImpNi+5uvDwDZ7iBWn6Z1N+f3p303HnrU8TZ+bT0sEqF/NgVi5M2IdO3bk5MmT9hjLDa+0KnxCXO/k+S2EEEJUDfNAzKeeD46ujtUyDt8IXzCrt1HaOjHzjJiTpxNedbzsMib3QMty9JkJmabPzxQOxKp5amK5M2LPPfccL774InFxcbRq1cq0h5NR69atbTa4G4VWqwUgLy8PV1fXah6NEPah0+kAcHCoUA0gIYQQQlipJlRMBHB0dcQ73JvUs6kAJB8veWpikYqJdiobr3HQ4OrvSlZSFgAZ8Rmmx8wzYsHu7rg7Fb+eraqU+xXTsGHDAHj44YdNbcYqJFKso3iOjo44OzuTmpqKp6dnjd10WYjKSEtLQ6vVmt54EEIIIYTtqQY1f/Pka6ozEIP8PcyMgVipGbH/7FcxsTD3IPfiAzGzNWLVPS0RKhCInTlzxh7juOEFBARw8eJFLly4gLe3N46OjhKQiUoxGAzk5uaSnZ2NRlPuWcY2o6oqGRkZpKWlERoaKs9rIYQQwo7SLqSRl5lnOq7uQMyvsR+n1p4C8gMxY3LGXEZChsUUQXsU6jDnHuRuKmhiHoidqUGl66ECgVjdunXtMY4bnpdX/jzYxMRELl68WM2jETcCVVXJysrC1dW12oMfRVHw8fHB29u7WschhBBC3OgSjlgWvQhoVr2BmHnBjuyUbDITM4us06qqQh1G7kEF9zcGYnqDgbOpqab2BtW8PgysDMRWrlzJwIEDcXR0ZOXKlaX2HTx4sE0GdiPy8vLCy8uLvLw8mcIpKi0vL48tW7bQo0ePIms1q5qjo6NMSRRCCCGqgEXFRGybEVPcXKgfs9b0uTUKV05MOpZUJBArXLq+KqYmGhkDsQtpaegMBSX5r5upiXfeeSdxcXEEBQVx5513lthP1ohZx9HRsdpfOIvrn1arRafT4eLiIs8nIYQQ4iZhHoi5+rniFuBms2srioLiXr7CckUCseNJhHcLt2gzXx/m7O2MZ5gn9mQeiGUmZKIa1CKl66+bqYkGs+jR/HMhhBBCCFFzpJ5PtViLUxL3IHe8atunfLiwr6SjloU6qnt5gne4N1pnLfqc/GRMcQU7zKcmBrUIsvuYzQMx1aCSmZRZdA+x62VqohBCCCGEqNl0OTpmRc4i43JGmX09QjwYFzMOB2d5KXi9Mc+I+Te17UbOak4uCS9+DEDg//0Pxbns8u4arQa/hn6mYKtwIKaqqmXp+pb2nZYIloEY5E9PPGNWMdFBo6G2V/W/EWHVb9/06dOtvuDYsWMrPBghhBBCCFExWict3uHeZCRkQGkTmDTgVccLrZOs7b3eZKdkkx6Xbjq2dcVEVafn6uI/8q/94XgUZ+vO82/sX2IglnE5g6zkLNOxvSsmQvGBmHlGrJ6PD9pqrDhtZFUg9umnn1p1MUVRJBATQgghhKgGiqIQPTmahQMWlt7RANGTo6t9Spsov8RjloU6ApvZP7tkDfN1YsknkzHoDWi0+YGO+fowsH+hDighI5aeYjquCdMSwcpATPYOE0IIIYSo+SL6RRAWGUbs3lhUvVrkcUWrENoulIh+EdUwOlFZxr2xjKp7DzEj80BMn6Mn7XwaPvV8gKIVE6stI5ZTs/YQA6hwTi43N5djx46h0+lsOR4hhBBCCFFBxqxYcUEYgKpXiXonSrJh1ynz9WFaJ60p2KluhSsnmmfuzNeHufq74h5sGSTZg7O3s8XU25TYNOIzCtZO1pSMWLkDsczMTB555BHc3Nxo0aIF586dA/LXhn3wwQc2H6AQQgghhLBeRL8IfCNKfsd/+wfbubj7YhWOSNiKeSDm18gPjUP1r3MC8G9StIS9UVVXTIT8NyTMs2KXL6RYPH7dZsQmTpzIgQMH2LRpEy4uBRu99enTh8WLF9t0cMX58ssvqV+/Pi4uLrRv356tW7eW2n/z5s20b98eFxcXGjRowFdffWXx+Lx58/L3TCj0kZ2dbc8vQwghhBDCLmI2xpB6NrXEx89uPsvsW2ez7N5lXDl9pcR+ouYxD8RqyrREALcAN1x8CuICYyCmqqrFGrGqWB9mZB6IJcda/j5ct4HYihUrmDFjBt26dbOIaJs3b86pU6dsOrjCFi9ezPPPP89rr73Gvn376N69OwMHDjRl5Qo7c+YMgwYNonv37uzbt49XX32VsWPHsmzZMot+Xl5exMbGWnyYB5lCCCGEENeDS3susWjIIgy6QmUTi0lC/LfoP2Y0ncEfL/xBZlLZe4+J6qXP03PlVEHgXJMCMUVRLAt2HE8G4OrFq+Sk5ZjaqysQSy+0pUP9GhKIlXvziISEBIKCii6yy8jIsHuqcerUqTzyyCM8+uijAEybNo01a9Ywc+ZMpkyZUqT/V199RXh4ONOmTQOgWbNm/PPPP3zyyScMGzbM1E9RFEJCQuw6diGEEEIIe0o6nsTCgQvJTc8t+qAKg+cO5uTqkxxectjUbMgz8Ne0v9j/7X66TexGx7EdcXR1rMJR3zjsvZn2lVNXLALsgGa2D8QUNxfqHVlp+rw8/Bv7c/Hv/CmvxoxYkUIdLe1fqMPIPBDLTSoon+/t7IxvDUm4lDsQi4yMZNWqVTz33HMApuBr1qxZdO7c2bajM5Obm8uePXt45ZVXLNr79evHjh07ij1n586d9OvXz6Ktf//+zJkzh7y8PBwd8//QpKenU7duXfR6PW3atGHy5Mm0bdu2xLHk5OSQk5Mf3WeYLfzLy8sjLy+vQl+fEOVlfK7Jc05UJXneieogz7uyXb14le/7fW8RCNTvV5+sxCzi9sYR2j6UFqNa0HJ0SyLHRbLhlQ2c33be1DcnNYc/X/mTv2f8Tc+3e9JyVEtT+fGbmbXPPV2OjlkdZpERX/Zm2u7B7jxz8plyb6YddzDO4tinoY99fie8PQAwlLMgn0+Ej+nzlLMpZF3NIu5fyzH7Nvatst9jl4CCYEu9UnDPej4+di02WJ6vr9yB2JQpUxgwYACHDx9Gp9Px2WefcejQIXbu3MnmzZvLezmrJSYmotfrCQ4OtmgPDg4mLi6u2HPi4uKK7a/T6UhMTCQ0NJSmTZsyb948WrVqRVpaGp999hldu3blwIEDNGrUqNjrTpkyhUmTJhVp37Bhg0xpFFVu3bp11T0EcROS552oDvK8K57uqo6Tr50k+1zB+na3Jm54POyB5pgG53hn3Aa7sXr1atPjfi/64dDDgUvfXSLnQsHUsasXrvLbo7+x/t31hD0YhmcbT6mwSNnPPVVVMXgZIAEovmBlPgUMngbWrF9T7u/r5ZWXLY7/OfMP2riasyn3lQyz9YYq/PLtLySsKSjU4eDtwKa/N1XZeOKTCrJxDlkGHPJA5wiu2dn8/vvvdrtveepMlDsQ69KlC9u3b+eTTz4hIiKCtWvX0q5dO3bu3EmrVq3Ke7lyK/ykVVW11Cdycf3N2zt16kSnTp1Mj3ft2pV27drx+eefM3369GKvOXHiRMaPHw/kZ8TCwsIA6NWrFz41pBymuPHl5eWxbt06+vbta8ruCmFv8rwT1UGedyXLy8zjx4E/WgRhAc0CuH/j/bj6ueY3TCzh5NvA8LqBA/MOsOWdLWTEFWRzsmOyOT3pNPV616PX+70IaXtzLuEoz3OvmWMzFt2+qPQLqjBk2hAa9GtQ7rH8uvRXYokFwLO2J3cMu6Pc1yiLmpPLlbdnAuD79lMozk5Wn3s57DJzPpljOm4R0oJdabtMx7Xa1mLQoEG2G2wZ/k38l0vzL5mO3TIhzRu6NG3KoN697XZf89lyZSl3IAbQqlUr5s+fX5FTKywgIACtVlsk+xUfH18k62UUEhJSbH8HBwf8/f2LPUej0RAZGcmJEydKHIuzszPOzs4AaLUF70Q4OjrKPxCiysnzTlQHed6J6iDPO0v6PD0r7lvBhZ0XTG3e4d7cv/Z+vIKtXIPkCLc+dStt7m/Dzqk72f7RdvIyCqZWxfwZw9yOc2k9ujXR70bjU9fHxl/F9cGa517jQY2t2ky78aDGFcoyGgtgAAQ2DbTL74IhV0f6/F/y7zHpGTTluEdQM8v1XymnUiw2oA5uFVylv79eYZa/A+4Z+YFYhL+/XcdRnmuXe/Lv3r17OXjwoOn4l19+4c477+TVV18lN7eYxaE24uTkRPv27YukhtetW0eXLl2KPadz585F+q9du5YOHTqU+E1SVZX9+/cTGhpqm4ELIYQQQtiYalBZ+fBKTvxe8MaxW4Abo9eOrlAhCCcPJ3q+2ZOxp8bS4akOKFrLQOHfBf8yo/EM1v5vLVlXskq4ys3Nms20oydHVygIU1XVonS9f9PiEwrVycnDCc9anqbjM+vPWBSOqcqKiWBZrAPAIz3//zWldD1UIBB74oknOH78OACnT59m5MiRuLm5sWTJEl5++WWbD9Dc+PHjmT17NnPnzuXIkSO88MILnDt3jieffBLInzL4wAMPmPo/+eSTnD17lvHjx3PkyBHmzp3LnDlzeOmll0x9Jk2axJo1azh9+jT79+/nkUceYf/+/aZrCiGEEELUJKqqsubFNfy74F9Tm5OHE6NWjyKgSeUq6XkEe3Dbl7fx9KGnaTq0qcVj+lw9Oz/ZyfSI6ez4vx3osu1X8OB6FdEvgrDIsKLbBSgQFhlGRL+ICl03PS7dsgx8s6oNaqxlXsI+ZnOMxWNBLaquYiIUDcTcr80YrF+DlhGVOxA7fvw4bdq0AWDJkiX07NmTH374gXnz5hXZn8vWRo4cybRp03jnnXdo06YNW7Zs4ffff6du3boAxMbGWuwpVr9+fX7//Xc2bdpkqoY4ffp0i9L1KSkpPP744zRr1ox+/fpx8eJFtmzZwq233mrXr0UIIYQQoiK2fbCNv6b9ZTrWOmkZuXwkYR3CbHaPgCYBjPx5JA9te4janWtbPJZ9JZt1L61jRtMZ/LvwX1RDadUpbi6KotD+8fZFC3ao0HFcxwoXPjGf4gc1aw8xc+aBWOHMYJVnxAKLBmIKULcGBWLlXiOmqioGQ/4eBuvXr+f2228HoE6dOiQmJpZ2qk08/fTTPP3008U+Nm/evCJtPXv2ZO/evSVe79NPP+XTTz+11fCEEEIIIexm7+y9bHh1Q0GDAkMXDKVBn/IXf7BGeNdwHt7+MEeXH2X9K+tJPlGwTin1bCrLRy9n5//tpO/HfWnQ2z5juN6c33m+2PYzG87QelTrCl3TfFoi1OBArEnxUyY9wzxx9XWt0rE4uDjg7OVsyiS6Z0AtLy9cHCpUIsMuyp0R69ChA++++y7ff/89mzdv5rbbbgPgzJkzJRbNEEIIIYQQlXPk5yP89sRvFm23fXkbLe5uYdf7KopCs7ua8fShpxn0xSDcAt0sHo/bF8f3fb5n4cCFXP73cglXuTlcvXSVgwsOFvvYgXkHiP8vvtjHymIeiDl5OuER6lGh69ibeUbMXFVnw4zcgwuyYu4ZNWtaIlQgEJs2bRp79+7l2Wef5bXXXqNhw4YALF26tMSiGUIIIYQQouLObDzDsnuXWUwDjHonig5PdqiyMWgdtUQ+HcnYk2Pp8UYPHN0sC5+d/OMkX7X5il8e+oW0C2lVNq6aZNdnu9Dn6ot9TDWorJ+wvkLXNQ/EApoG1Ni93WpcIBZkGYjVpEIdUIGpia1bt7aommj08ccfW5RyF0IIIYQQlRe7N5ZFQxZZvMCPfDaSHq/3qJbxOHs5E/1ONB2e7MCmtzexb86+ggBRhf3z9vPfov/o+HxHur3SDRdvl2oZZ1XLTs1mz1d7TMfedb1xdHPE2dOZi39fBODE7yc4s+EM9XvVL9e1Cwdi9qK4OhO+5yfT5+WRej6VrCtZKFqlyPowJw8nYvfm74HmHuReocqeFeFqlr11z4CwGhaIlTsjVhIXFxfZ20MIIYQQwoaSTiSxYMACcq8WlAFveW9LBn42sNqzIp5hntzxzR08dfApGt/R2OIxXbaO7R9sZ3rEdP6a/leJWaIbyT9f/WNR2TD6nWieOfwMg+cORtEU/KzWvrS2XAVOctNzSTtfkGEMaGbHQEyjwTE8FMfwUBSN9WGCLkfHrMhZzOk4p9jy/Vvf3co37b/hm/bfMCtyFrqcqqm4afApiE1uiKmJer2eTz75hFtvvZWQkBD8/PwsPoQQQgghROVdvXSVBf0WkJmQaWqL6B/BnfPutHhhX90Cmwdy78p7eXDTg/ml281kJWXxx7g/+KLZFxz66RCqemNWWNRl6ywqWXrV8aLlvS2B/LLtbR5uY3osbl8cB38sfh1ZcRKP1fxCHVonLd7h3mVHFpr8743WqWpm0WV5FPye3BCB2KRJk5g6dSojRowgNTWV8ePHc9ddd6HRaHj77bftMEQhhBBCiJtL1pUsFvRfQEpMiqmtVsdajFg2ospexJZXvZ71ePSvRxm+eDi+DSyngF05fYWlI5cyu+PsIvtL3QgOfH+A9Lh003GnFzqhdSz4OUVPirZYU7fh1Q1W78NWlRUT1dw8Et/+gsS3v0DNzbP6PONm1hjK6GigwptaV0Saa8GAtAaopXErpXfVK3cgtnDhQmbNmsVLL72Eg4MD9957L7Nnz+bNN99k165d9hijEEIIIcRNIy8zjx/v+NGiwl5AswDuW3UfTu5O1TiysimKQosRLXj68NP0n9YfV3/LkuWXdl9iftR8fhz8IwmHE6pplLZl0BvY+clO07GLrwvtH2tv0cczzJPOL3Y2HaeeS+Wvz//CGuaBmKJV8Iuw3ww0NU9H6heLSP1iEWpe+aYPlriZ9TWKVqnUptYVkehkGUx6ZNacTDJUIBCLi4ujVatWAHh4eJCamgrA7bffzqpVq2w7OiGEEEKIm4g+T8+SEUs4v71gLyqvOl6MXjMaN/+a9W5+aRycHeg0rhNjT46l6ytdcXCxrA93/NfjzGw1k18f/5Wrl65W0yht49gvx0g6nmQ6jnwmEiePogFzl/91sajit/W9rWQmZRbpV1jS0YJr+0X41diMqCkrVsLsU1WvVmk2DOCSQ47FcVZC2d/vqlTuQKx27drExuZXPWnYsCFr164FYPfu3Tg7l6+6ihBCCCGEyKcaVH599FdOrDphanP1d+X+tffjXce7GkdWcS4+LvSZ0odnjz9LmzFtLLIlqkFl76y9fN7ocza+uZGcqzklXqemUlWV7R9uNx07uDjQ8bmOxfZ19nSm59s9Tcc5qTlsfW9rmfeoqoqJthDRL4LgNkX3Fa6ObBhADBkWxxnxGSX0rB7lDsSGDh3Kn3/+CcC4ceN44403aNSoEQ888AAPP/ywzQcohBBCCHGjU1WVtf9by4HvDpjaHN0dGfX7qBr/4tsa3nW8GfLtEJ7c/yQNBzS0eCwvM48tk7cwPWI6u7/cjT7v+qmweHbzWVNpeoA2D7exyHoV1u7Rdvg3Kdhr6+8Zf3PlzJUS+xv0Botsmz0rJtqCoij0+aBPkfbqyIYBHDdYZlvTL6eX0LN6lHsfsQ8++MD0+fDhw6lduzY7duygYcOGDB482KaDE0IIIYS4GWz/aDu7phastdc4ahi5fCS1bq1VjaOyveDWwYxaPYrT60+z7uV1xO2LMz2WmZDJ78/8zq5pu+jzQR+aDm1a7SX6y2KeDVM0Cl1e7FJqf62jlj4f9GHx0MUAGPIMbHh1A8N+HFZs/5SYFIvS/6UF5edTU0nILHvqXZC7O7W97LePl3GtWOzeWFS9iqJVCG0XWuXZsJTsbOKUHAwKaK5Nl6xpGbFyB2KFderUiU6dOtliLEIIIYQQN529c/by5yt/FjQocNeCu4joW7UvXKtSgz4NePyfxzn440E2vLaB1LOppseSTyTz07CfqN25Nn0/7kt41/BqHGnJLv97mZN/nDQdN7+7eZFqkcVpMqQJ4d3CObftHAD/LfqPTuM7USuyaNCdeMS6iok5Oh2Rs2ZxOaPsQCPEw4OYceNwdqh0GFAs41qxhQMWAtWXDTtz5QqqBjLdwOPat6WmBWIV2tD52LFjPPvss/Tu3Zs+ffrw7LPPcuzYMVuPTQghhBDihnZ0xVF+e/w3i7ZBMwbRYkSLahpR1VE0Cq1HtebZo8/S95O+uPi4WDx+YecFvu32LYvvWlxkL62aYPtH2y2Ou07oatV5iqLQ95O+Fm3r/reu2D3WCpeuN5/WaM5JqyXc29uabbyo4+WFk9a+BT9MFRShWtaGAZy+kj/lM92joC0z/jov1rF06VJatmzJnj17uOWWW2jdujV79+6lZcuWLFmyxB5jFEIIIYS44cRsjmHpPUtRDQUvwHu+3ZPIpyOrcVRVz8HFgS4vdmHsqbF0fqlzkaqAR5cf5csWX7Lq6VU1Zo1PSkwK/y36z3TcoG8DQtuGWn1+7Y61aX53c9Px2c1nOf7b8SL9zAMx92B3XH1di/SB/OBucnS0Ndt4MTm65OyU4upMna3fUWfrdyiuFS/CpygKvd/vTUCzAHq/37tappieSUkBIMNsyd51nxF7+eWXmThxIjt37mTq1KlMnTqVHTt28OqrrzJhwgR7jFEIIYQQ4oYSuy+WRYMXoc8pWP8T+UwkPd/sWcpZNzZXP1f6fdyPZ489S+vRrS0eU/Uq/8z8h88bfs7mdzaTm55bTaPMt3PqTlR9QQBtbTbMXO8pvdE4FrwUXz9hPQadZShVnoqJ/SIiiAwLQ1tC0KNVFCLDwugXUXJ2StFocGpaH6em9VE0FZo4Z9KgTwOeOfwMDfo0qNR1KsqYEbuhArG4uDgeeOCBIu2jR48mLi6umDOEEEIIIYRR8slkFg5YSE5aQbn2FiNbMHD6wBpfnKIq+NTzYej3Q3l8z+PU713f4rHc9Fw2vbWJzxt9zp5v9hQJXKpCZmIme2fvNR2Htg+lfq/6pZxRPL8IP4vsZ+KRRPbN3WfRxyIQK6NiojErpi9miiOAXlVLzYbdaG7IQCwqKoqtW4vuebBt2za6d+9uk0EJIYQQQtyIrsZe5ft+31u8IGzQtwFDvxuKork5XiBbK7RdKPevu59Rf4wiuLXl3lTpcen89sRvzGw1k2MrjxW7vspe/p7xN7osnem464SuFQ5uerzeA2evgimAG9/caMr2ZSZmkpWUZXrMmm0MjFmxwqzJhgGouXkkfzSX5I/moubmWftl1EjFTU3MSs6qUdsjWFUuZeXKlabPBw8ezIQJE9izZ4+pWuKuXbtYsmQJkyZNss8ohRBCCCGuc9kp2SwcsJCUMymmtlq31mLkzyOLrIsS+RRFoWH/hjTo04B/F/zLxtc3knYhzfR44tFEFg1ZRHj3cPp+3JfaHWvbdTy5Gbn8PeNv07FvhC/N7mpW4eu5BbjR7dVupqqZGZcz2PF/O4h6K4qEIwkWfa0JxBRF4cXOnbln2TKLdmuzYWqejisffwuAzzP3ojg5lufLqTEMqkpMMYEY5Ae4nqGeVT+oYlgViN15551F2r788ku+/PJLi7ZnnnmGJ5980iYDE0IIIYS4UeRl5fHj4B+5/O9lU1tA0wDuW3UfTh5O1Tiy64NGq6HNg21oMaIFf03/i23vb7OY2nlu6znmdJpD87ub0/v93vg19LPLOPbN3WeRperyUhc02sqtpeo4tiO7v9hN2vn8AHPHxzvo8ESHIhUTrd3YW1NMsKVVFDrVtm+QWpNcunqVXH1+5qtwIJYRn1FjAjGrnjkGg8GqD72+5qT6hBBCCCFqAoPOwNKRSzm39Zypzau2F6PXjMYtwK0aR3b9cXR1pNuEbow9NZaOz3e0KHYBcHjJYb5o/gWrx60mI8G264H0eXp2/t9O07F7kDu3PHhLpa/r6OpIr3d7mY7zMvLY+NZGi0DMwdUB7zreVl1v89mzRdr0qsqXu3dXeqzXC+P6MCg+EKspKhfCCyGEEEKIEqmqyq+P/crxXwtKk7v6uTJ67Wi8w617YS2KcgtwY8CnA3j26LO0vKelxWOGPAN/T/+bzxt+ztYpW8nLtM1ap0M/HbLYeLrjuI44utpm6l7r0a0tinHsnbWXoz8fNR171/Embn8csXtjLaZmFmdTTEyx7VN37SIjt3qrTVaVGyoQmz59OtnZ2VZf9KuvvuLq1asVHpQQQgghxI1g/YT17J+333Ts6ObIfb/fR2CzwOob1A3Et4Evw34cxqN/P0rdnnUtHstJy2HDqxv4vPHn7Pt2HwZ9xSssqqrKjo92mI6dPJzo8FSHCl+vMH2envQ4sz3S1Py9yoySjifxTftv+Kb9N8yKnIUuR1f0IkB8RgaHEgrWljmalaBPzMzk6z17bDbmmuyMWSCW7WH52HUXiL3wwgvlCqxefvllEhISyu4ohBBCCHGD2v7xdnZ8XPDiXeOoYcTPI+xeUOJmVCuyFg9ufJB7f7uXwOaWQe7Vi1dZ+fBKvm7zNSdWn6hQhcXTa09brO9r/0T7EjdXrgitk9a6dW0a8KrjVWJxly2FpiX+cs89hHgURCIf79hBVt71XQ3RGqevFeoACA30wdGtIHOZcbnmBGJWFetQVZXevXvj4GBVd7KyssruJIQQQghxg9r37T7Wv7y+oEGBod8NpWH/htU3qBucoig0vq0xDfs3ZP/8/Wx8YyPpsQVZpvj/4vlh0A/U71WfPh/1Iax90TLvJdn5ScHaMI2jhk7Pd7L52KMnR7NwwMLSOxogenLJ1Q/NpyU6a7VE16/P/7p04cW1awGIS09n7r59PHPrrbYausn51FQSMjPL7Bfk7k5tLy+73vvgZbOiOG5uOPjrTVNUa1JGzKrI6q233irXRYcMGYKfn32q1QghhBBC1GTHVh7j18d+tWgbOH1gkbVMwj40DhraPdKOlve0ZNe0XWz/cDu5VwvWRp3ZcIZZHWbR6r5WRL8bjW9931Kvl3E8g3ObCwqttB7VGq/atg0kACL6RRAWGcalfy5BMUk7RasQ2i6UiH4l7wVmHoh1ql0bFwcHnmjfninbtpF4LVD5cPt2HmvfHidt0aya4uJErbXfmD63Vo5OR+SsWVzOKDvICfHwIGbcOJytTPBU9t67L13iFgMY89BXL6cX26862CUQE0IIIYS4GZ3dcpYlI5ag6gteSfd4swe3Pmv7DIQonZO7Ez1e60H7x9qzefJm9ny1B4OuYJ3YwR8OcnjpYSKfjaTHaz1w9XMl9XwqmQkFmRWdTkfs97EW1210eyPSLqTZPBgrKyum6tVSs2GF14dF1asHgLuTE+M7deLVDRsAOJ+WxncHDvBou3ZFx6DV4tK2/PuiOWm1hHt7k5CRQWkr8TRAHS+vYoPAirLm3habOieUnbWrKhUORXNzc4mPj8dgsPySw8PDKz0oIYQQQojrTdyBOH6840f0OQXb+XR4qgNRb0dV36AE7kHuDPp8EB3HdmTDqxs4vPSw6TF9rp5dU3exf+5+urzchb+m/VXm1LUlw5fgEeLBuJhxODjbJqtjVFJWzJpsWOH1YcZADOCZW2/l4x07uHKt+N6UbdsY06YNDhrbFFBXFIXJ0dEMWFj61EoDWLWxtK3vbR6I1aSpieX+7h8/fpzu3bvj6upK3bp1qV+/PvXr16devXrUr1/fHmMUQgghhKjRkk8ls6D/AotNhluMaMHAzwfa9EWnqDj/Rv7cveRuHt7xMHW61rF4LDslmw2vbiA7JRvK+nGVUTCjMoxZscJTE8vKhkHR9WHmGzh7OTszrmNH0/HpK1f44eDBItdQc/O4MuMHrsz4ATW3fEU9+kVEEBkWhraEMWoVhciwMPpFlBxMVlRZ9840q5yYEZ9RoYIt9lDuQOyhhx5Co9Hw22+/sWfPHvbu3cvevXvZt28fe/futccYhRBCCCFqrPS4dBb0W2BRja1Bnwbc+d2daLSyZWtNU6dzHR7a+hAjV4zEv4m/xWP6XH2x67MslFEwo7KMWTFFm399RasQFhlWajYMil8fZm5sx454OhWs+3p/61b0hWa2qXk6kifNJHnSTNS84kvkl8SYmdKXEOToVdXm2TBr751utm+6LktHXkbNqBxZ7nzq/v372bNnD02bNrXHeIQQQgghrhvZKdksGLCAK6cL9i0KiwxjxM8jbD5tTdiOoig0HdKUxrc1Zu+cvWx6a5NVZc2tmSJoi7GZrxWzJhtW0vowc76urjx7661M2bYNgGNJSSw9fJiRLW1XRCbM0xMNFFmrpVUU2oWG2iUbZtQvIoL2oaHsibVc06dVFIJrewMppraM+AycPKwvRmIv5X6bpnnz5iQmJtpjLEIIIYQQ1428rDwWDVnE5QMFpbL9m/hz36r7cPZ0rsaRCWtpHDR0eKIDY0+OpedbPXF0dyy1vzVBkS0Ys2KAVdmw0taHmXuhUyfcHAu+xne3bsVgo2l6KdnZ3PXTT8UWzLBnNsxIURQ61qpV7L3v625ZmKSmrBMrdyD24Ycf8vLLL7Np0yaSkpJIS0uz+BBCCCGEuNEZdAaW3bOMs1sKXgB71vLk/rX34x7oXsqZoiZy8nAi6u0onjvxHO0eL1pNEKyfImgLiqLQ+/3eBDQLoPf7vcsMYEpbH2Yu0N2dJ9u3Nx3/Fx/PymPHKj1eg6py//LlnExOLvZxJ62W6BKCQ1vJ0en4pdDXYlyX1qNNI4v26zYQ69OnD7t27aJ3794EBQXh6+uLr68vPj4++PqWvg+DEEIIIcT1TlVVfn38V46tLHjR5+Lrwv1r78c73LsaRyYqyzPUkzu+voM7Zt1R5LGqyoYZNejTgGcOP0ODPg3K7FvW+jBzL3XpgrNZ+fjJW7ZUunjFu1u28Nvx46bjYHfLNyNy9Xp+/O+/St2jLPP27+fi1asWbcZMnEewh0V7TQnEyj15eePGjfYYhxBCCCHEdWH9K+vZ/+1+07GjmyOjfh9FYPPA6huUsKm2j7Rlzzd7iN0bi6pXq2RtWEVZsz7MXKinJ4+2a8cXu3cDsDc2lj9OnmRgo0alnleSVceP8/amTaZjVwcH/hg1iodXrmRfXJyp/f1t2xjdujVaG5XMN5en15vWvkF+JkyvqqYqjeb7+sF1HIj17NnTHuMQQgghhKjxdnyygx0f7TAdaxw0jFg2gtqdip8KJq5PFSmYUV2sXR9m7uWuXflmzx7yrlVNnLxlCwMaNiz3vU8mJzN6+XKLQpOz7riDNqGhfNS3L/csXUpSVhYAx5OS+OnQIe5t1arc9ynL9//+y9nUVNPx/a1b89fFi7zfO39ap+Kg4OrvSlZS/liu20DMKDMzk3PnzpGbm2vR3rp160oPSgghhBCiptk/fz/r/rfOou3O+XfScED5X8CKmi+iXwSh7UOJ3RNLaPuamQ0D69eHmQv39ubBW25h9r59AOy8cIGNMTFEh4cTtmI6AIpL6VUFM3JzuWvxYlKubRINMK5jR0ZdiwX6NGjA0Wefpd60aWTk5ZeLf2/rVka2bInGhgGtzmDg/a1bTcfezs5MGzAAbxcXi37uQe41LhArd24wISGB22+/HU9PT1q0aEHbtm0tPoQQQgghbjTHfj3GykdWWrQN+GwAre6z/bv7omZQFIWod6Nwru1M1LtRNTIbBuVbH2ZuYvfuFhsgT96yBUWrxbVrW1y7tkXRlrxhtaqqPPbrrxyMjze1dQ8P5+O+fS36Bbi58VSHDqbjQwkJrDh61KrxWevHgwc5daVg+4ixHTsWCcIgPxAzsmargqpQ7kDs+eef58qVK+zatQtXV1f++OMP5s+fT6NGjVi5cmXZFxBCCCGEuI6c3XqWpSOWWqwz6f56dzqO7ViNoxJVoX7v+jSb0Yz6vetX91CKVd71YeYa+PqasleQH9BtO3fOqnOn7dplUXwjzNOTn+6+G8digrcXu3SxCA7ftUFxECO9wcB7ZtkwDycnnu/Uqdi+FoHY9ZoR27BhA59++imRkZFoNBrq1q3L6NGj+eijj5gyZYo9xiiEEEIIUS0u/3uZH+/4EV22ztTW/on2RL8TXY2jEiJfRdaHmZvYrRvmeb53N28mdc7PpM75GTVPV+w5m2Ji+N+6gim6jhoNS+++mxAPj2L7h3h48Fi7gi0B9sXFserEiXKNsyRLDx/mWFKS6fjZyEj8XF2L7esefAMEYhkZGQQFBQHg5+dHwrUovFWrVuzdu9e2oxNCCCGEqCZXTl9hQf8F5KTmmNqaD2/OoC8G1dhpauLmUpH1YeaaBgQwokUL0/Ga06f5c+ocEl/5FDU3r0j/C2lpjFiyBL1ZRmv6wIF0rlOn1Pu83LUrTjYumW9QVSZv2WI6dnN0ZHznziX2N8+IZSZmYtAXt/V01Sp3INakSROOXdssrU2bNnz99ddcvHiRr776itDQUJsPUAghhBCiqqVfTuf7ft+THpduaqvfqz5DFwxFo7V9+W0hKqKi68PMvda9u8Xxlx2Kn4aZo9Mx7KefSMjMNLU91KYNT5htEF2S2l5ePNSmjen474sXWXf6dLnHam7F0aMW0zKf6tCBQPeSN1M3D8RUg0pWclal7m8LFVojFhsbC8Bbb73FH3/8QXh4ONOnT+f999+3+QCFEEIIIapSdmo2Cwcs5MqpggIAoe1DGbliJA7OFS44LYRNVWZ9mLlWwcHc2bSp6fjPBoEc8S86zXDs6tX8ffGi6bhDWBhf3nab1dnhV7p1w8FsD7F3zbJZ5aUWyoa5ODjwUpcupZ5jHohBzZieWO5AbNSoUYwZMwaAtm3bEhMTw+7duzl//jwjR4609fiEEEIIIaqMLlvHoiGLiNtfsBGtf2N/Rq0ehbOnczWOTAhLm82yYVDxQAzg9TKyYrP37uUbsyVIAW5uLBsxolwZuHo+PtxvVhxk67lzRb4Ga/12/Dj7zTaLfrxduxLXqBndEIGYUW5uLseOHcPJyYl27doREBBgy3EJIYQQQlQpg87AsnuXcXZzQQEEzzBPRq8djXtgyVOehKgOlV0fZq59WBhRdeuajlc3DGLZsWPsjY3luwMHeGrVKtNjCrBo2DDCvb3LfZ+J3bpZ7CE2uQJZMVVVecfsPCetlpe7di3zvBsiEMvMzOSRRx7Bzc2NFi1acO5amcuxY8fywQcf2HyAQgghhBD2pqoqvz35G0dXFOxx5OLrwui1o/Gp61N9AxOiBJvMKiZWdH2YUY5Ox7+XLxc0KAojfv2F9t98w4MrVqAzFBS28HByolt4eIXu08jfn3tatjQd/3nmDDvPny/XNdacOsU/ly6Zjh9p25ZaXl5lnndDBGITJ07kwIEDbNq0CRezzdL69OnD4sWLbTo4IYQQQoiq8Oerf7Jvzj7TsYOrA/f9dh9BLYKqcVRCFC8+I4PDZuvDoisxLRHys0oRfn5W9W0SEGBRAbG8Xuve3aJkfnmyYqqq8s7mzaZjB42GCVZkwwCcvZzROhWM+7oMxFasWMGMGTPo1q2bxeK85s2bc+rUKZsOTgghhBDC3nZO3cn2D7abjjUOGkYsG0GdLqWX5BaiuthyfRiAoihMjrZub7x3o6MrtX1D88BAhjVvbjpeffKkRYarNBvOnGHnhQum4zG33EJdHx+rzlUUpcZt6lzuQCwhIcG0j5i5jIwM2VNDCCGEENeVA98dYO2Lay3ahswbQqOBjappREKUrfD6sI6VWB9m1C8igg5hYSU+rlEUIsPC6BcRUel7FS4O8t7WrVadZ5490yoKEwtdpywWe4nFZ5bSs2qUOxCLjIxklfmCvWvB16xZs+hcyiZqQgghhBA1yfFVx/nl4V8s2vpP60/rUa1LOEOImsF8fVjnOnUqtT7MSFEU3i0lK2ZQVSZXMhtmdEtICIObNDEdrzh61HKNWjG2nD3LZrOve3Tr1jTw9S3XfWtaRqzcP7UpU6YwYMAADh8+jE6n47PPPuPQoUPs3LmTzWZzNoUQQgghaqpz28+x5O4lqHrV1Nbt1W50GtepGkclRNkKrw8zr3ZYWX3D69LW2Y19OZbZIq2i0C401CbZMKPXu3dn5bFjpuP3tm5l8fDhJfY3z4ZpFIVXy5kNA8tALP1yeik9q0a5M2JdunRh+/btZGZmEhERwdq1awkODmbnzp20t2JnbSGEEEKI6nT54GV+vP1HdFk6U1u7x9rR691e1TgqIaxj6/VhFvJ0PLdkW5FmvQ2zYUaRtWrR3yywW3LoEEfMAkxzO8+fZ/3p06bje1q2pLG/f7nv6R58nWfEAFq1asX8+fNtPRYhhBBCCLu6cuYKC/ovIDsl29TW7K5m3DbzNlnrLq4L9lgfZq77uWRaXU7lcIgPelW1SzbM6I0ePVhzrdifCry/bRvfDx1apJ95Nkwhv/JiRZhnxHKv5pKXlYejq2OFrmULFd7QOT4+nv/++49///3X4kMIIYQQoibKiM9gQb8FpMcWTEmqF12PuxbehUZb4ZdEQlQpe6wPM6cAL/x1Cr2aP23XHtkwo67h4Ral9384eJCTyckWfXZfvMjqkydNx8ObN6d5YGCF7ld4L7HMhOot2FHuvzp79uyhZcuWhIaG0rp1a9q0aWP6aNu2rT3GKIQQQghRKTlpOSwYsIDkkwUv8kLbhXLPintwcLHtC1kh7MWe68PMdT+XTIfgEACbVUosyRs9epg+N6gqH2yznBr5bqGKiq+b9S+vmrapc7kDsYceeojGjRuzY8cOTp8+zZkzZ0wfp83mbgohhBBC1AS6bB2L7lxE3L44U5tfIz9GrR6Fs5dzNY5MiPKx6/owMwrwXo8eNAsI4P3eve06bTeqXj261inYs2/+gQOcTUkBYH9cnEVBjyFNmtA6OLjC96ppgVi53wI6c+YMP//8Mw0bNrTHeIQQQgghbMagN/DzqJ+J2RhjavMI9eD+tfcXeVEmRE1n7/Vh5vrUrcfhZ56x2/WNFEXhyfbt2X7+PAA6g4GX1q5lYvfu/G+t5R5/j7drV6l71bRArNwZsd69e3PgwAF7jEUIIYQQwmZUVWXVU6s48vMRU5uLjwv3r70fn3o+1TcwISrI3uvDqkOOTsdL69ZZtC09coT233zDhkIZwEd+/ZUcnY6Kcgt0sziu7kCs3D+92bNn8+CDD/Lff//RsmVLHB0tK40MHjzYZoMTQgghhKioDa9vYO+svaZjB1cH7v3tXoJaBlXjqISomKpYH6Y4OxI8+x3T51XBSasl3Nub+IwM1FL6KUAdLy+ctNoK38vB2QFnb2dyUnOA6zAQ27FjB9u2bWP16tVFHlMUBb1eb5OBCSGEEEJU1K5pu9j2fsGif0WrcPeSuwnvGl6NoxKi4qpifZji4IDHkGibX7fUeyoKk6OjGbBwYan9VLBJ9Ub3IPcaE4iVe2ri2LFjuf/++4mNjcVgMFh8SBAmhBBCiOr274J/WfPCGou2Id8OofFtjatpREJUXlWuD6tq/SIiiAwLQ1NCkKVRFJtVbzRfJ3bdBWJJSUm88MILBFeiYokQQgghhD2c+P0Evzz0i0Vbv6n9uOX+W6ppRELYRlWsD1N1OtJ/2Uj6LxtRK7EWq7yMWTGDWvzkRIMN9zK7rgOxu+66i40bN9pjLEIIIYQQFXZ+x3l+Gv4TBp3B1NZtYjc6v9C5GkclROVV1f5hak4elx99k8uPvomak2eXe5SkpKyYLbNhULMCsXKH0o0bN2bixIls27aNVq1aFSnWMXbsWJsNTgghhBDCGvH/xfPDbT+gyyp4F7/to23p9V6vahyVELZRVfuHVaeS1orZMhsGRQMxVVXtuk9aaSpUNdHDw4PNmzezefNmi8cURZFATAghhBBVKiUmhQX9F5Cdkm1qazq0KbfPvL3aXmAJYUs38vowc8as2N7YWPSqilZRaBcaarNsGIB7cEEgZsgzkJ2Sjauvq82uXx4V2tBZCCGEEKImyIjP4Pt+33P10lVTW72oegz7YRgah3KvwBCiRroR9w8rTuGsmN7G2TAoflPn6grE5C+UEEIIIa5LOWk5LBy4kOQTyaa2kLYh3PPLPTi43JgvVMXNp6rWh9UUxqwYYNO1YUbFBWLVRQIxIYQQQlx3dNk6Fg9dTOzeWFObX0M/Rq0ehbOXczWOTAjb2nQTrA8zpygK7/fuTbOAAN7v3dvm04trUiAmbxcJIYQQ4rpi0Bv4efTPnNlQsFzCI8SD0WtH4xHsUY0jE8L2bpb1Yeb6NGjA4Weescu1JRATQgghhChB6vlUMhMyTcc6nY7MU5nE7YtDq9Wy9f2tHP35qOlxZ29nRq8ZjW993+oYrhB2ZR6I2Xt9mOLkSOD0iabPb0Suvq4oWgVVn79nmQRiQgghhBCALkfHrMhZZFwu+uLoOMeLtGmdtdz3230Etw6uiuEJUaUup6dzJDHRdBxt52mJiqMDXvcOsus9qpuiUXAPdCc9Lh24jteItWrVivPnz9tqLEIIIYS4yWmdtHiHe1v9CuXuJXcT3i3cvoMSoppsNquWCDf++rCqYj49MTM+s5Se9lWpQCwmJoa8vKrddVsIIYQQNy5FUYieHA2Gsvt2fqkzTe5oYv9BCVFNzKclujg4cGutWna9n6rTkbF2Bxlrd6DqdGWfcJ0qvKlzdZGpiUIIIYSoUSL6RRAWGUbs3ljTOo7CvOp40fejvlU8MiGqlsX6sNq17b5/mJqTR9yoCQDUj1mLUlX7laWdh6yEsvu5BYFn5YuV3BCBWPfu3XF1rZ4N0IQQQghxY9Hn6Yn/L55Luy/h6u9aYhAGcMesO2xe1lqImqTw+rAbdlqiLgcWRkLm5bL7uoXAYzHgULktKtyC3EyfX7eB2O+//26rcQghhBDiJqIaVJJOJHFp9yUu7r7Ipd2XiNsXhy67jOlQCoS1DyOin203eb1RnE9NJSGz7DUvQe7u1PbyqoIRCWsV/tmtPXXK4vEwT0/2xsbeeD87rRN4hkNmAqXPSdaAZ538/pVknhHLSs5Cn6dH66it9HXLS6YmCiGEEMKuVFXl6sWrXNx9kYt/5wddl/65RE5qTgUuBtHvRks2rBg5Oh2Rs2ZxOaPsd/hDPDyIGTcO56qaeiZKZc3P7rFffwVuwJ+dokC3ybBsQBkdDfn9bPC7X3gvsczETDxDPSt93fK6QX6CQgghhKgpspKzTFkuY+BlLBVtLWdvZ0Lbh5J4OJGM+AxUg4qiVQhtFyrZsBI4abWEe3uTkJFRVl6BOl5eOGmrPgMgimeTn10Vr7Oyqbr9IDgS4veCqi/6uKKFoHb5/Wyg8MbvGZczJBATQgghxPUlNyOX2L2x+Vmua9MMr5y6Uq5rOLg4ENI2hLDIMGpF1qLWrbXwa+iHolE4ueYkCwcsBEDVq0RPlmxYSRRFYXJ0NAMWLiy1nwGYHC3fx5qk0j+7alhnZVNlZcVUvc2yYVA0I5ZxJgZCL5V9oo2DWAnEhBBCCGEVfZ6e+IPxFlMMEw4loBpKLqpRmKJVCGoZZAq6wiLDCGoZVOL6jIh+EYS2DyV2Tyyh7SUbVpZ+ERF0CAtjX2wserXoz0WrKLQLDaVfhHwfa5p+ERFEhoWxtyI/u2pYZ2VzTt6gcQRDcVtjaeDqRVBVu0xNzPjlf3B6W9kn2jiIlUBMCCGEEEWoBpWk40kWUwzj9sehzylm2lAp/Br65Qddt+YHXaFtQ3F0c7T6fEVRiHo3ip8f+5mod6Mki2NGZzAQk5LCkYQEjiYm5n8kJXE0IaHYF/IAelWlkZ8fW8+do1Pt2jI9sQYpKyumV9WSM5k2WmelODkS8MELps+rzME58OfTJQRhAAZY+wic+R36fg2u/pW6nVugm8VxRl4Y+RM/qzaItToQq1+/fpl//BRF4VShCi9CCCGEqNlUVSXtQlpBIQ1jMY208hXT8AzzJCwyrCDw6hCGq2/lt7mp37s+zWY0o37v+pW+1vUoPTeXY8ZAKzGRI9f+fyI5mVx9+QJjgB/++48f/vsPDycnetatS98GDegbEUGzgAAJdKtZv4gIGvj4cDolxaLdqkymDdZZKY4OeD9yVwVHXwH6XNg4Dg58ZV3/E8sgdicMmA91+1T4tk7uTji6O5KXkR/4ZXj1AX4q4yzbFQsxsjoQe/7550t8LCYmhq+//pqcnApUPxJCCCFElcpMyrQopHFx90UyLpdvLx0XH5eCoOvaFEOvWjdQSe0qpqoqcenpFoGW8eN8WprV16mtpBKolP2zjFfduZjrzaoTJ1h14gQAtTw96dOgAX0bNKBPgwYEe3iUcRVha5l5eaTl5hZpLzUbZmTNOqvAVpB6GnyKCeiquthHeiz8Ohwu7bBsr9UDLm4pOG75MBz+viBbln4JlvaF9i9At/fBwaVCt3cPciflTAoAGdlBVVosxMjqQGzcuHFF2pKTk5k8eTIzZ86kY8eOfPjhhzYdnBBCCCEqJzc9v5iG+RRD44sPazm4OhDaNpSwWwuCLr+GfpI9qYA8vZ7TV64UCbaOJiaSWsk3tMM9XNinTMVPLTtwizV4UC/zeXLNXgpevHqV+QcOMP/AAQBaBwfnZ8saNKB73bq4OVbhVLWb1Mc7dpBYaB+48q3r01LqFLv/5uZ/BN4CjYdDo2Hg36zqi31c3JEfhGXEFrQpGug2BTq8BD90gsu784OjfrOhzTPw+yhIPlrQf8+ncHY93PYDBLQs9xAsArG45PzvyeXdxXe2cbEQowqtEcvKymLq1Kl8/PHH1KtXj59//plBgwbZdGBCCCGEKB99rp7LBy9bTDFMOFz+YhrBrYItphgGtQhC46Cx48hvPKnZ2RxLSioynfBkcjI6Q2nrUEqnVRQi/PxoGhBAs4AAml77aOLvj6+LCyxcBpf3UNpaFxUNjj51uadhO9adPk1sevFbC/x7+TL/Xr7M/+3ciZNWS7fwcFNg1jY0FI0E4jZ1PjWVj7ZvL9JuVTYM4MTPsOpeSl/ndE3CgfyP7W+Af3NoeBe4BqBmJqDYc52UqsK/38CG5yzXg7n4wW2LoF7f/OPu78OGsfn/VxQIbgej98Dm/8GBLwvOSzwICzrAra9Ag9vzg7nSmGXz3M3WiWUc2gn/zS7+HEUDQe1tng2DcgZier2eWbNmMWnSJFxcXPj8888ZPXq0vCMmhBBCVDHVoJJ4LNFiimHc/jj0ueUsptHIz1RIo1ZkLULahJSrmMbNTFVVLl69mh9oGQtmXAu+Ll29Wqlrezo5mYIs40ezgAAi/PxKL7BhRcEGBQMBff+P+fX6o6oqhxMSWHf6NOtOn2ZzTAwZeUULJuTq9Ww4c4YNZ84w8c8/8Xd1pfe1oKxvgwbU9fGp1Nd7Q6jk1L5X/vyTLJ3OdFzfx4czKSlEhoWVnQ07OAfWPQ5qMUGUogHXoPwpfGkxRR9POpz/AZT9ir6UdVJlff36XNj9IZxcYdkeeAsMWQ7eZmtA6/aBhw5b9nN0gz5fQINBsOZhyIy/dt0c2Dkp/6MsbiFw1yo4shD35AtAcwAy0t1LPke1/dowI6sDsZ9++onXX3+d1NRUXn31VZ566imcnKq+9OWXX37Jxx9/TGxsLC1atGDatGl07969xP6bN29m/PjxHDp0iLCwMF5++WWefPJJiz7Lli3jjTfe4NSpU0RERPDee+8xdOhQe38pQgghbmCp51PJTMgss597kDtetUtfW6WqKqnnUk3ruYzFNHKvFl1LUhrPWp75UwuvTTEMbR9qk2IaN7pcvZ6TyclFgq2jiYmkF7OepzxqeXpaBFrGz8M8PSv2RnfdfhDcHuL3lfCi3HKti6IotAgKokVQEM936kSuXs/O8+dNgdk/ly5hKKYCY1JWFj8dOsRPhw4B0MjPz7S+LLp+fXxcKrZu57pVyal9O8+f54eDB03Ht9aqxeToaJ7/4w/e79279OfC7o9hy8uWbbWj4MKm/M9VAwycl/8zj98PJ5bC8WVw5ZiVX9w1pa2TKs/Xb67pvflTDx3dyu5r1OA2ePAgrHkETv9WjpspkJsGC9oD4O7S2/RIRrp7fmV8zzr50xAz4/K/b3ZaG2ZkdSB2zz334Orqyr333svZs2d55ZVXiu03depUmw2usMWLF/P888/z5Zdf0rVrV77++msGDhzI4cOHCQ8PL9L/zJkzDBo0iMcee4wFCxawfft2nn76aQIDAxk2bBgAO3fuZOTIkUyePJmhQ4eyfPlyRowYwbZt2+jYsaPdvhYhhBA3Ll2OjlmRs6wqgOER4sG4mHE4OBf8k5yZmGmxV9el3ZfIiC9nMQ1fF9N6LmO2yzPMs9xfy83kSlaWxZot43TC01eulFgO3hoOGg2N/PxoFhhIU3//gumEAQF4OVu5zsagh6xEyIjLf5GYUejD1BYLOaklX0fVg6N7/vqa4HYQ2AZcfEwPO2m19KxXj5716vFur15cycpiw5kzrDt9mvWnT3PqSvGbdZ9ITuZEcjIz//kHjaJwa61apmxZp9q1cbzRy+RXYh8vg6oy7o8/LHp9NmAAnWrX5vAzz5R8KVWFra/A7o8s29s8C9HT4IfOBeus6va7NsWvbf5H13fzs2DHl+ZXIkw8WOwtLO93Ldu+610I7QghtxY8d6z++o0U6PlJfsGNirzh4BYEd66Ef7+GTeNBl2XFSSroCt4cc/co+Juqy3Mkb9AfODXrC2fXFWSV7bQ2zEhRVev+skRFlb13h6IobNiwwSYDK07Hjh1p164dM2fONLU1a9aMO++8kylTphTpP2HCBFauXMmRI0dMbU8++SQHDhxg586dAIwcOZK0tDRWr15t6jNgwAB8fX358ccfyxxTRkYGHteqCl24cAGfYlLzWq0WF7N3hjIySv7HVKPR4OrqWqG+mZmZlPTjVBQFNze3CvXNysrCUMp8dnd39wr1zc7ORl9K2d3y9HVzczM9P3NyctCZpfYr09fV1RWNJn++cW5uLnnFTNeoSF8XFxe01/5RKk/fvLw8cq+9+5qXl8eaNWvo378/jtcWUDs7O+Pg4FCkb3HM++p0ulKrnjo5OZnuUZ6+er2e7OzsEvs6OjqaMuvl6WswGMjKKvmPbnn6Ojg44HzthZCqqmRmlpzBKE/f8vzeX09/I/Ly8li7di1Dhw41/Zzlb0TR33tVVVnQcwGX918u8zVZUOsgot6P4vK+y8TtiSN2TyxpZ62vkgfXimm0CyW0QyiBtwQS0j4EnwY+Rf7dvl7+RlxISyMxKwsHBwccHR3R6XRs2bKFyMhI05gAAt3cqOWZH1xa+3tvUFXisrI4nZrKkWtTCg/Hx3M8OZn4Un6nreHt7JwfbF1bs9XA05PGfn7U8/YuEohotVpcnJ0hLx0y4shKPI2SeRkl6zJKZnz+59eONZmXUbISiq/mZgs+ERDUjlzflhgC2qAPuAVcAyy6GP9GnLlyhXWnT/PH8eNsOneOK6X83TbycHSke506RNerR6+6dWniZ1nopSb/jSju39qS+mrPr8dl1Z0l3sM0lttWoK9TUHr9h0OHeNzsdeioVq2Ye/vtpb82cHJAu+EZ+G+ORXtuh1fJaz8RFAXNhY04b3sJtddnaOv3N309xf3eKykncDj9Cw6nlqNJOlDm12Di1wxCO6IPjkSXm4vzthfKPEV19CR7wI8YakUV+3i5X0dcPQ2r7oOEfdaPGzhwcjArvmpnOn704KP41PcBVcV1eRSa+D35Qeyov8oViJnHBunp6RbPw8KsDsSqW25uLm5ubixZssRi2uC4cePYv38/mzdvLnJOjx49aNu2LZ999pmpzZjxyszMxNHRkfDwcF544QVeeKHgifPpp58ybdo0zp49W+xYcnJyTP/IZGRkEBYWVurYBw4cyC+//GI69vHxKfEFXI8ePVi/fr3pOCwsjMTExGL7tm/f3hRQAjRq1KjEMTdr1owDBwp+sW655RaLANVc3bp1OXGtlC1A586d2bNnT7F9AwICuHTpkum4T58+bNmypdi+bm5upJjtizFkyBCLALgw8z8U99xzDz///HOJfa9cuWJ6oj/yyCN8//33Jfa9ePEigYGBAIwdO5avvip574rjx49Tr149AF555ZVSM7779u2jRYsWALzzzju8++67JfbdsWMHHTp0AOD//u//mDhxYol9161bR8+ePQGYOXNmsRVMjVasWGEqnPPdd9/x6KOPltj3hx9+YPjw4QAsXbqU++67r8S+s2fP5oEHHgDg999/58477yyx72effcZTTz0F5E8N7tu3b4l9p0yZwosvvgjAP//8Q5cuXUrs+/rrr/Pmm28CcOjQIdq2bVti3/Hjx/PBBx8A+dtrNG7cuMS+Tz75JNOnTwcgISGBWrVqldj3/vvvZ86c/H/0MjIy8PX1LbHvXXfdxaJFi0zHpU3lvt7+RgQGBhITE2P6h1L+RtQDiv6NiHBrxf2Zw0o810hFRbFiZYaRHj3xxHPx2n9vff0WA+4fgMZBc2P8jdBq4YUXwJrS6VevwrRpoNcX/RsRGQn+/hAQUPSjstX/UlIgMbHIx+ihQ5k7Zw7oc8lMiqF3p5aEeEKIJ4R6Yfo8xBMiQt0J9lBRdJUL/uzl3BXYe/HaxwVIc23In7sK1uzccsstHDl6FEJDISICGjSA8PD8n19Z0tLg1Ck4fRq/lBTizPagvd7/Rvw1FtrVhuJq2xhUhX/Oq3Scbtbo5ATPPQfX3lBwc3TkvyeeYO60aSW+jnB2gIvfROGfvMmi/bnlMKNorY9yvY74ZfFPdJz5GsG3nyixT2n0BtAoJcctqoMr68Km0X/EEyVeo0KvI/S5pCwaQmDSn6WOT3UNwtB0FCecujKo+/94kAdNj81mNhe4AMDMV4bxRKND6Ht+ihreu6TLFcv89UFZgZjVUxMNBoPpXb/qkJiYiF6vJzg42KI9ODiYuLi4Ys+Ji4srtr9OpyMxMZHQ0NAS+5R0Tcj/oU+aZMWCwGvi4+P5/fffTcelvSOTlJRk0be0dytTU1Mt+pb27nx6erpF3/QSKiQZr2PeNzW15CkOubm5Fn2TkpJK7KvX6y36xsfHl9gXsOhb2s8DYM2aNaaMwoULF0rtu379ery9vQFKfFFqtHHjRtPz4/Tp06X23bp1q+l65oFscbZv3276+o8ePVpq3127dpmyHoeuzcUvyT///GP63PxFdXH27dtnyoDs21f6u0gHDhww/TzM71GcQ4cOmfoePFj6VIejR4+a+pb1PTtx4oSp77lz50rte/r0aVPfy5dLn69+9uxZU9/SnuuQ/9wy9i3tHTrIf86aP4dLc739jYD8f9jN71OSm/ZvhFbL2Uf7E/8DBCTmF5MuSVlBWK5XLkfSjnCJS1zkInHEoaMgS3cw/iCszf/8hvgboddTO+MigR4e+a/oSmJQic9M56KzMwQE8EdCAv/OmsXFnBxi0tPhtdcqN51Ip4OkJEIcHOjRvDm1nJ0JzU1h3uSXCXHV5QdUXhASAqGNjMHVzxhmrMDZcBVv4J/nS7tBBpScbLVacibEXb32kQa5Tv5E9rydbI03jVOW4pZzCa0m/wVy3FXYdxHa1YIw79KvG+6b/3GnqSr4SbK/CCbFuQGpzg3oGhxPRpzKuUuX4NIl2Lo1P8CtWxfXli0J7NSJcyX9nfTygrZtoW1bkoHGU6fSxtOTWzw9SShh6iNcH38j3vgD1jxe/HkaReVgLPi6whVjwrZbN1MQBjDE359/t20r8d9ED2dYMQaLIEynKjz4g8oPJfyalud1xL69+2jxXxDe7WJxCs1Ao6joDXA+Bbachk51oXFgyedrywgV/gp4nq3/ni+1T4VfRyT257b4P2kaZPmrr6qQkgWzL3alyYAXUK86cO7cOTKwnFHiTkHAtOaontBOH8B/OfCfdf+WG5X1+sCc1RkxrVZLbGwsQUFBAPzvf/9j4sSJ+Pn5lWtwFXXp0iVq1arFjh076Ny5s6n9vffe4/vvvy/2xWzjxo156KGHLLIN27dvp1u3bsTGxhISEoKTkxPz58/n3nvvNfVZuHAhjzzySInfyJIyYmfOnJGpiTVsSkFl+9b0qYkbNmygV69eMjWxEn1lamK+8kxN3LhxI7fffrtMTaTg9z47NZuL/1wkdl8s8QfiSfg3gYRjSWjKWaXcI8yD4PbB1I6sTditYYS2C0Xjpvn/9u47PKoqfeD4986kd9IbqRAISSihdxApgghWBEWxYFt/umtbXdfeXXtXFHUVYVXECgii9E4IJPSS0NJDCOll5v7+uGSSIZNKMim8n+e5TzL3npl7Jhxm7nvPOe9p1meEJR3iM8JQhsM3vXAoP13na1TJUF0ILTJfC6upghx0DHLX0dcFoh0riLArI1BXRBdjPvrSLHQl2kZxJoqx7n+HlqTq7TE6+qE6+mF08gUnf/RugajOAeDkR4nOHaOjL6qjL+jN55jV/H+vHFuBzU+Xm44VTvyeymDt7r5SnIHt6WTs8/egZO9EyUpEKaj/xoMlRvsuGLz6YPDqjcG7DwavPqjuETg5u5BeWMiqlBRWHD7M6uPHyajn86qKvV7P4IAAxoSEMDYkhN6+vmZp8ttiaOL537X1fUbY7ZuP48YH6729ouodKe92HamhN9Lnp82UnatXsJsbyXfeiZOtrcVrA6U0F+ffr8UmZ2eN13KgbMLXlAbW3WvTlM8IO0VHyRc/YWvcjZvxNdN+s7ZTehp99g7sT+9En7UDJXMrStmZet4xqCiovvEYZmyk0mBoteuIysO/4fL7NbXKFU78HiV8ktm1Qc6xHD7tUZ2yftxb44i9ObbW6zZVq/SInf+F/PHHH3P33XdbLRDz9vZGr9fXuqORlZVVq0erir+/v8XyNjY2eHl51VumrtcE7cup6mJMX6ML3sPDw2Igdr7GlGlO2aq7My1d1rYJQzikbOuXrbpYrqiowMHBAQ8PD4uvUbNsY1635gV7S5Z1aGTmrKaUBUz/B1u6bFM+eJtStrX+31v7M6KiogJ7e3tsbW1N7a69/N+wVtmi7CIydmaQnpBOekI6GTszOH24dtDQ0BgSgwIp4TB6UiwjJ8USNDAIF/9GDMdroL72Dg5UGI1UGAxUGI2UGwym3yuKiuo+VuNnuYV9DR2rd3+TjlWy3t6B/jrQ13M1a1DhuNGNcmoPhdNhxFcpwl8pxF8pJEApJNqpkiiHCkJtSvFTCnE3nMGhLBtdRQEUAQ3HCBdI0RIMOPtXb041fncOMP2u2Lmhr6c3r9EpVyIna3NcziVscIm5qrqrwMMDAnsCNS5aS3K1bIuZCZB1bsurf7SCriwPXdpqbNNWV++0cwXffoT49ecW33huGReP6nEVe3JP88e5bIyrU1MptnCDocxgYO3Jk6w9eZJnN26slSbfo8b/SWv8v2/Mdy0AxkotacTOdxt8fcVQgv2BL+lx4Et+to3gbYawzNCN90fE4V6gdSzUOlNRBqz6m3n6eXt3lOm/4hA8gsZ+ezbm2sDp/tlaN9KCNZbbDh7gHwFcqz1UjVo7Sd+sbakrIf+I2WsqqCgjX0BnZ4cttNp1BDFXQeJAre2qBlPWQ/P6awIiArR8/edCHGOhsUnfqfXWo5GafQvJ2lPL7Ozs6N+/PytXrjSbI7Zy5UqmTZtm8TlDhw7ll19+Mdu3YsUKBgwYYDa3YeXKlWZzxFasWFHvXBUhRMfSkmnExcVDVVXOnjxbK+g6e7JpiTTqsnAW5Pdxwi7KhnWGfVRsSG5csNPAsQ4x8bsBT5Rfwu+OX9dbRq9AgiGAl+z+qA64dEUE6YvxVAvRnZ8lxQi0xnQsO9fqIMossDov2HLyAV3ze+6aRVFqL4xbH0cvbf2m0OpEEpTlaynPsxKqA7TT+y2nxq9SXgAn12pbVVVsnIj16UOsXzx/j4unYuxENpW4siL1ZJPT5I+PiGB8ZCRjw8Jwbw9p8kvPwK8z4NiK8w6cu8pX9FobUXRQYD60foLNUSbYHOW44kvXTW/C2kauP+foC9esAN8+LfEOamtK21F04NlD22Ju1oK4rwdAdqJVUsDXqnfNtfTqyXqos9Hh5OVEcY72wdDUzLQtwcqfCBfmgQceYPbs2QwYMIChQ4fyySefcPz4cdO6YI899hinTp3iv//9L6BNwn/vvfd44IEHmDt3Lps2beKzzz4zy4Z4//33M2rUKF555RWmTZvGTz/9xB9//MH69evb5D0KIVrWhaYRFxcH1ahy+sjpWkFX1Rd0Uzj7OWsZDGOcyffJ5/X0LQz4tgvu6bboVAWjopIfUIFrVA6upfD7rnROqY3vrexYVJyowFUpw5Vy859KOa6c+1nreClnVTtcKa/3+u8uOwtJYloiEtXZ1AiqAuoOrpz9tFTw7ZmlhXGbwt4duo7WtioVRZC9uzowy0yA3GStV6gulcWQvknb0Hp8RuntGOUdx/Mh8RT1jWNLuS8/5NiyLPUkRxtIk//B9u3oa6bJj4xkcFCQ9dPk5x2CJVPPW5NLgbjbIWme9lA1wMRPIWQcHPkZdcdbKKfWmb1MiJoFjR35qreDmRugS7cWeQs1qQYDZbsPAmDfeyxKc9pOVRBnpRTwtYROMOsJri8AdPZ1Nn3OF2dZP3FOk642nnzySVN3Znl5OS+88EKt4SutuY7YjBkzyM3N5dlnnyU9PZ3Y2FiWLl1KaGgoAOnp6WaT+MPDw1m6dCn/+Mc/eP/99wkMDOSdd94xrSEGMGzYMBYtWsS///1vnnjiCSIjI/nf//4na4gJ0Uno7fS4h7hTlF3UYBpxt65u6O06+Vo3AmOlkex92aagK2NnBuk705u8ODKAe6i7FnTFB+Dfz5+A+ABcA1y1xU3nhUJxJlcGw+EpkSyYNxsAnapw75T/8ZazNnQn3ehCWPGFzXNqOSr2VNYbLHnoynFXKnDXVeCmlOOmKzeVd0HbnCjDWS3DkVL07amPzsGrdkDlYqE3y6GLdpdfWGbrDIFDta1KZZkWjJmCsx1asGaoey4QhnKtXOYOnIFLgEsUPXjHUBAWwy41iGVnXflvGpwsrd2ODKrKppMn2XTyJM+uXYurnR1jwsIYHxHBpRER9PT2bt6i2I11/E/45RoorRE02rrAlIXaosNZibXX8ep+FZ8XhvPuoY+533YzM22SsVeauCzBxM9bJQgDUEvLOTVByzYSnroCxbmZC743IRhqcU3ozXP2dSZ7bzbQNj1iHWodsfao5loBeXl5LTK2VIjGqKioYOnSpUyePLlJ45EvRod/P8yCSQsaLHfD8hvoNrF1vtw6i47W7ipLK8lKzjLr5crcnUllaRPT1SngFeVlFnAF9AvA0dPyRUpBaSk5n8YRUnoYvaKN1Pn0nbmknQgisOspbr9vHooCBhSSCeY6u4ex1eux1eux0+ux1em0xzV+2p07bqvTme2313EuACrVAiBjKY6U4mQswVEtxUEtwcFQgr2xBDtjMXYGbbM1FGNbWYRNZRH6qq2iEEVtgVR+1mTjaN5rVce8K5x8zRbRFVZgqIDT+8x7zrITtR61JlBRKHWL5IhNGGtLvVhy2pFtlX7kU3+QEOzmxqXn5pZdGhGBbz1JE+pS52fero/gz/8z7wV0C4MrfwHvc6kmj/2hBQOXvGMa7nm2rIyod98l81ziknDbMhKHgdu++VBcf5ZfAHz7wY07Wq13yVhUQkqYFjSFp65A19xADCy+//bm+xnfs+dbbdirb6wvdyfdfcGv2ZR1xBp9+2316tUXXDEhhGgLkRMiCRwYSHpCOqqh9r0nRafgE+NDyIiQNqidaCllBWVk7so0C7qy92ZjrGxa6kKdjQ6fGB+zoMu/jz92Lo27iP8rJYVbf/6ZqIIh/O54GNCumcZdtoplP17GuMtWma6h9Kj0GfsQB7xjtXk1FQXaT0ubpWMVBVDZ+FTJ7ZbORptrZeuq/azaKoohzcLCSKP+A5FXaL1Zti7WG/IkmkZvCz69tY052j6jQRvOV3POWVaCNhetDgoqjmcPE8thYoF7zk0Ly7ELYIchgL+Ku5BgDGCnIYCcGinIT549yxeJiXyRmAhAHz8/0zDGkSEhOFq4mXQiP5/sGhlxKysrOVJczM6MDC2LqLGS4ISn8D34ufkTg0bAFT9ocwGrWBgW+uK6daYgDOD2kZfhNnIkjHgKDn4LG5+F/MN1/i0Y+VLHae8XOizWCpx8qxOXtPs5YgUFBWzevJmKigoGDRqEt7d3w08SQog2VpJbQvCQYNK2pVk8rhpVspKyeMnlJRw8HHANdMU10BWXABfT7zU3lwAXmUfWxopzi2vN58o9lNvk+UE2Djb49fEzC7p8Y32b9e9bXFHBY3/8wTtbtwKQSiTbDAHE6zLQKyoRUUf52yPv137iX3Uvrtp+KeeCJZfawVPV1pT9envLF5eqirpgEMbMHehRMaCg8+uPMuDBjnMxKszp9ODVU9uizy0SrqqQf9S85ywrAUosL1Zfxbs8nYmkM7FGYtxTeLCt0o8EQwAJRm1LV7UkTLsyM9mVmclrmzZhr9czIiTEFJj19fenwmBg2rz/QEl2rXN9fXg1rpTxkt0qfG3OW2cs5ha49EOwqT9D75HTp3lz82bT4zAPDx6oWpLJxh56zYaeN8AXMefmnNX4QLNmwouLiLNvdeBenFOM0WBE19BiaC2o0d80u3fv5rLLLiM9PR0ANzc3vv/+ey69tH12NQohLm5lBWXs/3E/yQuTObryCMbKxl2hl54ppfRMqWnMeF0cPR1rBWe1AjZ/F5lzdoFUVaUgrcB8PldCOvnH61982xJ7N3v8+/lXDy2MD8C7hzc6mwv/0t144gRzfvyRQ6dPE6bkMVF/mAk2R4jR57SfOVI2ThceMFVtNk7WCYQUBWXE8+jPTfrXo8KI5yUI62wUBTwita1HVUp0FQpO1u45K7R8Q61KEGcIsjnDdJvq5BnpRhdTUFYVoB03uLMqJYVVKSk8umoV3k5OTAgN4nflHXycGpe5UAWU0a9B/wca1SYfXrmS8hprmf1n/HgcbM67FNfp4JK3qhNdmE5m5YQXF4magZhqVCk5XYKzj/US8DQ6EHv00UcJCQnhu+++w8HBgWeeeYZ7773X4kLKQgjRFipLKzm09BDJC5M5+OvBps8DaoKS0yWUnC4hKzmr3nJO3k7VgVnguWAtwDxgc/ZzRm8rAZuqqpxJOWPWy5WekN6s4SJOPk7m87niA+gS3gVF17IXMWWVlbywaim7ty/iPt1hJjodobuu4YWIG0VvXyMocrmw4MnWReuJ6IhCJ2D07Y8ua4f2U3oELg6KAm5dta1bjWWKijLOrXW2ozpAO1v/QtQBukKm6A4xheo10XJVR7Nes4SSABbuK+B+R1c8dQX1rmEHoKJDmfYjdJvaqLfzV0oKS2pcM48KDeXq6GjLhasSXZy3Fpb0hrW8moEYaMMT22Ugtn37dpYuXcqAAQMAmD9/Pr6+vhQWFpompAkhhLUZKgykrEoheWEy+5bsqzfznaNTEYqiUlLshKrqUBQjPn7ZTJy2jMICNwqN0RT4z6EgvZCCtALTVlnS/ICuOKeY4pxiMnfXMwlb0b4MqgI0U8B2XtDm7OvcIr03TXH+GmyVlZUUH9GGBdrUuJPb1DXYjAYjuQdyzYOunemU5deTYa0Obl3daiXRcA1ybb1saaoRMhM4lbyYtKTvecJwFFuHps1DA7S76IHD6gimXCSxRBVFwTjseQp/m4vTsOfRSY/Axc3ZH8Iv07YqzViI2kspYbzNUcZz1LTvrGpHqtGjwSAMgHHvNzoIMxiN/OP3302PFeCtiRPr/oxqwlpY4sJYCsSIsd75Gx2I5eTkEBJSPZHdy8sLJycnsrOzJRATQliValQ5vuE4yQuT2fvd3nrXerJ3syd6ghuxXd4gvFsKRw+Hm9KIq6qO8VNXENE9VSt89asQNtH8XKpK2dkys8CsIK2AwvOCtYK0AgxlTUxBbDoJFGUWUZRZREZiRp3FFJ2Cs1/DAZuTj1OLjHGvbw22gxw0e1zfGmyVZZVk78k2C7oydmU0K8D17O5ZK+hy8nZq+IkXquCUtlhr6grUYytRSnMJAoJAu6qyxNEbQsdrd7ET3oKcZPO726NfkwurRlJDxvFX6HtMDhnX1lUR7ZHFhajPahkaa847O72v3oWo3ZRyeuvrH+WgqnDUNpRMz8kMVVWzYOr8RB9Vfti3j12Z1TfjZsTE0C8goP731Ebp3xVbG7o8fIvp987Oxc88hrF2wo5G/4UVRaGgoACHcyuYq+caX0FBAWfPnjWVc3Nr/B1RIYRoLFVVSU9IJ3lhMnv+t4ezJ8/WWdbGwYaoqVHEzoyl+2XdsbHXw4IvICuVyKgjBHY9ZUojHhl15NyFcT+LX3SKouDg7oCDuwM+0T61T1ajfqV5pRSkFzQYtBkrmtF7ghaAFqYXUpheSHpCep3lFL2Ci3/1MEizgK1G4Obk7VTvUL3mrMFWXlRenblwZzoZCRlk7clq8ntW9Ao+vXwI6BeAf3x15kJ7t/onw7eYihI4tQ5Sf9e23D3VdavjKUbFBl3QcC2YD5ugtamqtahcAuTuthDWZO8GwaO0rUpzFqI+j6LAPQUjWfH550R06cKs2Fhu6N2bcA8PBs6bZ5YRsS6rUlIoq6zE/vz5YeefqJFrYbUkxc4Wz0dutcq52oNaPWIWbjy2pkYHYqqqEhUVVWtfv379TL8rioLB0Mw7wkIIYUHO/hySFiaxZ9Eecg/m1llOZ6MjcmIksTNj6XFFD+xd7bU7n1k7yd/7PfZFuTioBstpxFUDlacPUfH9FBy7DgP/QeA3ABw9G11PRVFw9HTE0dMR3xjfOsupqkpJbokWlJ0XtBWmFZr2F6YXNjntuukcBpWCUwUUnKp/wrnORmeWZMRSwpFhDw3j+xnf139CI9g52/FBrw/IOZDT5MyFens9fr39zHq5fON8sXW04jplqqr1WJ3r9eLU2kalhT9o9OSI2yCGj7wNt24TtaGFlrTl4qZCCE2jFqJO0BZiNtYe5l6pKiQYA1hhiATgaF4ez69bx/Pr1tHP3x87vR6F+j8CFbRsiXb6RszZ7ADp3zs6O1c79PZ604iWdtsj9tdff7VmPYQQwiT/eD7Ji5JJXphc71A9FAgbHUbszFiir47GyctJW1vp2G+w8TdIWQpFGbif9zRLacRtKvKxOb4Mji+r3unRTQvKAgZpP336gu0FLG6JFrA5eTvh5O2EX2+/OsupRpXinOLqQC3dQsCWVkBhZqHFtdEaw1hp5OyJs5w9UXfvolZpGgyuUlenNuqcdi525pkL+wXgHe3dNslKirO1BUeP/a4FX0V19zJWOaPas8oQwYrKSLbaxvDo5BuZERvb8Lna6O62EKIBNvbg11/bqhgqUJM+RVl1j3lRReV/7tdDSe3/vzsz6vmuqkEFnhs7tvXmsF4g1Wik4qCW/MQ2KhRFZ915ydamKArOvs6m78F2G4iNHj26NeshhLjIFWYWsve7vSQvTObExhP1lg0aFETM9THEXBeDW5AbnD4IKR/Dn7/BybVgrGiZSp05rG37v9Ee62zAO04LyvwHgf9A8OrVKtnoFJ325eDs64x/X/86yxkNRoqzi82HQ6ZbDtianUW9mc9z9HI0G1oY0C8Az26eLZ65sNEM5ZC2SRtqeGyFdue7gTdnRMc2YxDLKyP4vTKSrcYgDOi5PCqKpZdfToBrHT1glsjdbSE6Br0tSp+7yN/xIc55ydgoKpWqQlGXWF6/9TXuP3uWhUlJLEhKIimr/jllNekUhf4BAUyIjGzFyl8YtaSMEyNvAiA8dQWK84XdfOwI2n0gVnMOWENkjpgQorFKz5Syb8k+khcmk7IqBdVY90WxT4wPsTNjib0+Fs8wFy3gOvgULP9VC5YasNfozW+V3Zlqc5BuymnTF+tBoxcfV/ZnkC6N6R5ncS6qJw2ysVLLzJW1E3Z/rO2zddbupFYFZwGDwDXEaj0eOr0OF38XXPxdCIive/K3sdJIUVZRrflrBenmAVtzv4Rcg1yrg65+Wrp4t65ubXvXV1W1tpF6rsfrxF9QUdjw81y7UhAwltfSXXk33Zk8qpOBuNnb8/akSdzcp0+7vaMthGgBioLbJa+i/KBlZ7RRVNwueRUUhRB3d/45YgT/HDGCpMxMFiQl8U1SEicauF42qmq77g27WNWcJ9YuAzEPD49GNxqZIyaEqE9FcQUHfjnAnkV7OLT0EIbyuj8zPMI9iL0+ltiZsfiFG7WhhslvwW8rG76g1ttD17EQMQU1fDJzvltFQno6fxgi+d3xa0D7Yv1H+SRWGbuzKSCAWbffDqV5kLkdMrZC+lbtZ3E9qecrirSg8OTa6n2OPtXDGat6zhy9mvBXank6G51p3ld9DBUGCjMKayUYObXtFEdXHK1VfuzzY4m/Pb5W5qk2U3oGTvypBV6pv8PZ1IafY+MEXcdA2ETU0PF8mlLEAytXUlhuPkfk0ogIPrviCkLczx/sKoTojJSwiZxxj8MjP0n7eV5WXYA4Pz9e9vPjxXHjWH/8OF/v2sX8xEQMqvmNxY7QG3axaveBWM35YampqTz66KPMmTOHoUO1yY6bNm3iyy+/5KWXXmqdWgohOjRDuYEjK46QvDCZ/T/tp6Ko7qGDLv4uxMyIIXZGL4JC01BSlkLiI7AioeETuQRBxBQInwKh47TeKuBgTg4h7u5sS0tjhSGSrYZABunT2GoIPDfpWuXJUaO0G06OnlrGu7BzyRRUFQpOagGZadtefyBYkg1Hf9O2Ku4R5vPNfPuBrRXSrjeR3laPe1d33LuaBxuqqvLp4E9JT0hHNagoeoWA+ABG/mtk297dNRogY1v1cMP0LVpWwoZUZckMmwCBw8HGnlNnz3L7L7+w/LB5D6uTrS2vjR/PXQMGyJ1sIS4mioLL2Fc5+9tcXMa+Wu9IB52iMCo0lFGhoVzRowdTFy0yOy69Ye1Xuw/Eas4Pe/bZZ3njjTeYOXOmad8VV1xBXFwcn3zyCTfffHPL11II0eEYDUaOrT2mLbS8eB8lp0vqLOvQxYHoq6OJuzqC0JC96I4vgsRlsLGBsfeKDgKGVAdfPr1NX5QlFRUs3r2beQkJrD1Wc7ihwr/Kx/GO3TL+VT6OqmTkd/32G4/l53NbfDwONVMKKwq4ddW2qKur3hzkHajuMcvYqqVErm9uWv5RbTtw7stZ0YN3rHmvmXeMNg+tHVIUhbHPjWXBpAWAlplx7HNtdFFx9nh14HXsDyg70/BznPzOBdgTIeRScK5OlKKqKgt27+b/li3jTKl5psSRISF8Pm0akZ6Nz6AphOg8mrOG3ZSoKAYGBpKQno5BVdErCvHSG9Zu1QzEygvKqSipsFrW3iZ/42/atImPPvqo1v4BAwZw++23t0ilhBAdk6qqnNp6Slvr69s9FKbX3Wtk62RLj2k9iJ3iQbfwBPQn34R962FPA+u52HtA2CQt+AqbBE7eZoeTs7KYt2MHX+3eTV6p5fTjqwyRxJTca7bvVEEB9y5bxovr1/PP4cOZGx+Po20dH8Q6vZakw6sXxM7R9lWWQvYu8+As76Dl54PWa5O9S9uS5mn7bBxrzDcbqP10D283GfYiJ0QS0D+A9B3pBPQPIHKClS4qKorgxGptuOGxFXB6f8PP0dtB0Egt8AqdYBak15RVVMRdv/7Kkv3mr2mv1/PiuHHcP3gw+k6eNUwI0bIUReG5sWOZtEC7cWWQ3rB27fy1xIqzi3EPsc4Q9CYHYl27duWjjz7i9ddfN9v/8ccf07Vr1xarmBCi48hKzjKt9ZV3NK/Ocno7Pd0mRRA7XiUqbDN2GZ9CRgo0lPXXO1br8YqYoq3/cl6vUVF5Od/u2cMnCQlsPnmyzpeJ9/cnt6SEk2fPYlBVFLThJDXH8qcVFHD/8uW8uG4djwwfzl0DBuBUV0BWk40DBAzWtiqlZ2rPN6svRXplCZxar21VHLxqzDc7F5w51b2wdGtSFIUxz4/hh7k/MOb5Ma13UaEaIWvXuTW9foe0DVrGw4Z4Rlcvphw8usGhn9/v3cvdv/1GTnGx2f6BgYF8OX060T5t83cWQnR8EyIjGRgYyLa0NAYGBkpvWDtWa1HnrKL2G4i9+eabXH311fz+++8MGTIEgM2bN3PkyBEWL17c4hUUQrRPeUfzTMFXVnLdQwgVnUL46ABiRxcR3W0tDjkvQVkxHKjnxW0cIGTcueBrMriFWiyWkJ7OvB07+CY5mbNlZRbLuNrZcWPv3syNj6dfQAC/Hz5sukupAt9eey0HcnJ4fdMmckuqh09mFhXx4IoVvLJhAw8NHcrdAwfiYmfX4N/FjIOHlrI89NLqfQWnas83K68n01ZpLqQs07YqbmE15psNBN94sLNOsozwceFEvxdN+Ljwln3hogw4tvLckMOVUNyIlNAOXSBkvBZ4hU7Qho82wumSEu5dupSFyclm+211Op4aPZp/jhiBjfSCCSEugKIovDhuHPctW8aL48Z1mN4wxdYG979db/r9YmApELOWJv+FJ0+ezMGDB/nwww/Zv38/qqoybdo07rrrLukRE6KTK0gvYM//9pC8MJlTW0/VW7brAHdiR+TSK3wFLhVbtZ319Xy5hmg9XhFTtGyHdfRmnC0rY2FSEvMSEtiRXnfv0tDgYObGx3NdTAzONQKo8+9SXtmzJ4qi8H+DB/Phtm38Z+NGsmv0kGQVFfHIH3/wyoYNPDh0KH8bNAg3e/t633u9XIPA9UrofqX2WDVq66DVDM6yd9XfA3Q2VdsOfqs9VnTgFWPea+YdC3rrjHFvlspSOLWheq5X9q6Gn6PotR7R0HNzvfz6N3kNt98OHmTuL7+QXmg+bLa3nx//nT6dPv51r9kmhBBNcWlEBHv/9re2rkaTKHa2eD/dsep8oTpUIAba8MQXX3yxpesihGiHSk6XsHexttBy6urUete/9etpT+yQU8SG/4qHc6q2s678FYoeAodVB19eMXXOhVJVla2nTvHJjh0s2rOH4grLL9rFwYHZvXszt39/Yn19LZ+2jruULnZ2PDx8OPcMHMjHO3bw6oYNZBZVfxjnlpTwrz//5D8bN/LA0KH836BBuDs41P3HaCxFB149tS1GW0STyjLI2V1jvtk2OL2v7tdQjZCTpG3Jn2n7bBy0nrKawZlHZNvNN1NVbW5XVeB1YrU2FLMh7uHn5nlNhJCxYN+84SJny8r4x/LlzE9MNNuvVxQeHTGCJ0ePxk7f8gtzCyGEaN86XCC2bt06Pv74Y44ePcp3331HUFAQX331FeHh4YwYMaKl6yiEsLLywnL2/7Sf5IXJHPn9CMZKY51lPYMVYgcdJbbbcnx861lvC7T5TuGTtCGHYRO1VPH1yCsp4etzmQ+TsuoeqjYqNJQ74uO5Kjq67gQbNdR3l9LZzo4Hhg7l7gEDmJeQwCsbNpBWUFBdp9JSnvjrL17buJG/DxnC/YMH08XRscFzNomN/bngaSBwrp5l+ZC5wzw4K6x7PhyVpZC2UduqOHQxD8z8B5llD7To7AktHb/pdStxLz2iLWpdM7ukky+4Bps/tyQXjq+qXlC5vvpWsXOFrpdUDzfs0q3h5zRg1dGj3PrzzxzPzzfb39Pbmy+nT2dQUNAFn0MIIToD1Wik8qT2XW4T7IdyEQzT1tvpcfBwoPSMluCrMLOBdUpbUJMDscWLFzN79mxuuOEGEhISKDs3L6OgoIAXX3yRpUuXtnglhRCtr7KsksPLDpO8MJkDvxygsqTu7IWu3gZi++0jNmYDAUHp9Xey+PSpTi8fMLjBoWSqqrL++HHmJSTw3d69lFZaroe3kxNz+vTh9vh4enh7WyxzIRxtbblv8GDu6N+f+Tt38tL69Zw8Wz2XK7+sjGfWrOHNzZu5b9Ag/j5kCF5OrbgumL07hFyibVUK07SArCowy9iqBWx1Kc07FxT9Xr3PNUSba+Y38NzP/lowBFrP3IKBZgta2wJjAMyXyAEnf7j1EGQnwrFzgVfGNurtQgVAAf8B1cMNA4a02JDKovJy/vnHH7y/bdv5Z+QfQ4bw/CWXNCpwF0KIi4VaUsbx/tcBEJ66AsW5hW80tlPOvs6mQKw4q7iB0i2nyYHY888/z0cffcRNN93EohqL1Q0bNoxnn322RSsnhGhdxkojKX+laGt9/bCPsnzLCS8AHF0r6BWXTFyfRELCj6Po6rjAtnHSklNETIHwybV7SeqQU1zMf3ftYl5CAvtzcuosd2lEBHfExzOtZ0+rDCVzsLHhnoEDua1fP75ITOTF9evNelbOlpXx/Lp1vLVlC/cOHMgDQ4fi4+xczyu2IJdA6DZN20Aboph3uMZ8s21az5Wh7n9XCo5r28Hvz+1QtLT8/gO14MzRC4qzgbp7RUEBQyl8HAgVBfWUq1Hv0Inn1vQaV2sJgpaw4fhxbv7xR47kmWfxjOjShS+mTWNkqOUEMEIIIS4+zr7O5B7MBdr50MQDBw4watSoWvvd3Nw4c+ZMS9RJCNGKVKPKiU0nSF6YzN7v9tb7gWPnUEF0zB5i+iYTEXUUvb6Oi3H38Or08l3HaPOTGsGoqvyVksK8hASW7N9PucFgsZy/iwu39u3LbfHxRHTp0qjXbmn2NjbcOWAAt/Trx1e7dvHCunWk1PjMKywv5+UNG3hn61buGTCAh4YNw8/FOpkMTRQdeEZpW68btX2Gcm3uWHqNXrPcvdTdU6VC7h5t2/NFI0+s1r+oso2Dlk6+ak0vr16tNlettLKSJ/78k9c3bar1Du8ZMIBXxo9vevZLIYQQnVrNeWLtOhALCAjg8OHDhIWFme1fv349ERERLVUvIUQLUlWVzF2ZpnTz+cfrHr6mt6kkKvogsf2S6B59CFtbC0MDdTYQNKI6+PLs2aQL64zCQr5ITOTThIRaPRZVFOCy7t2ZGx/PlO7dsW0niRTs9Hpui4/npj59WJCUxAvr1nH49GnT8eKKCl7btIn3t23jrgEDeHjYMAJcXduuwno7bbihX3/gbm1feUH1fLPMbdrPguMte17vuOrAK3hko4PzC7E9LY2blixh33k9qsFubsy/4grGyzo+QgghLHDyrZ5a0K4DsTvvvJP777+f+fPnoygKaWlpbNq0iYceeognn3yyNeoohADyT+RTnF09brmyspLiI8Vk7MzApkbSBGdfZ9yC3QDIPZhL8qJkkhcmk7O/7uF+is5IZPcjxPZLpmfsfuwdLAxlc/SB8Msg4nItkUITs9cZjEZWHj3KJzt28MvBg1QaLfeudXVz49Z+/bi1Xz9C3K2zoGJz2Or1zOnblxt792ZRcjLPr13Lgdxc0/GSykre3LyZD7Zt447+/fnn8OEEubm1YY1rsHPVei67jqneV5RRe75Zad2Lc9fi6H1untcECB2vDT+0knKDgefXruXFdevMFucGuKVvX96cOLFlMlwKIYTolM7vEVNV1SprvzU5EHvkkUfIz89n7NixlJaWMmrUKOzt7XnooYe49957W6OOQlz0KssqmTfgI4qySmsdO8hBs8dO3g4MfXA4e7/bS3pC3etsAYRGpBLbN5no3ntxdrEwOdU3vjq9vP9AbehbE508e5b5O3fy2c6dtbLWVdErClN79GBufDwTIyPRd6AsTTY6HTf27s3M2Fi+27uX59auZW92dZbBMoOBd7du5eMdO7i9Xz/+OWJE+wwwnf0hcqq2gZZu/swRLSBL3wrJn0KFhbuELkEw7Sfw69es9nGhkjIzuenHH0nMMF+kzs/ZmXlTpzK1Rw+r10kIIUTHUjMQM1YaKT1TimOX1k9U0qz09S+88AKPP/44e/fuxWg00qtXL1ysPRdCiIuIXleJu+NxihRvUOu72FUpzill1WOr6iwREJxGbN8kYvvuwc3jrPlBWxetNyNiitb71cxejUqjkaWHDjEvIYGlhw5hVC3PRwr38OD2+Hhu6du3bYfvtQC9Tsf1sbFcFxPD4r17eXbtWpJrpNwvNxj4YPt25iUkcEvfvjw2ciRhHh5tV+GGKIqWOr5LN4ieBRGXweJJtctN/Az8+1u9epVGI//ZsIGnVq+m4rze1etjY3nvsstaN4ulEEKITsPSWmLtNhADcHJyYsCAAS1ZFyFEHRQbe8Zel8KC/1hepLhGSYt7vX2zie2nBV9ePrnmBz26VaeXDx6lrWHVTCl5eXy2cyefJyaarb1Vk61Ox/SePbmjf38uCQ9H11YLDLcSnaJwbUwMV/fqxY/79/PsmjXsyqxO/15hNPJJQgLzExO5qXdv/jVyJJGe9a+n1i6ETgC/gahZCSiqAVXRo/jGa/utbH9ODjf/+CNbT50y2+/l6MgHU6ZwXUyM1eskhBCdgWKjx+2WK02/XywsBWLePVo+o+/5Gh2I3XrrrY0qN3/+/GZXRghhzlhpJC8lj9wDueTYXouT8z6Ki5yoK+Cqyb3LGWL7JhPbLwm/gMzqXBo6Wy3gqgq+PKMuqI7lBgM/HzjAvIQEVh45UmcuvigvL+aeS3Lha6307m1IpyhcFR3NlT178svBgzy7Zg070quHilYajcxPTOTLXbu4sXdvHh85ku5eXm1Y4wYoCox4DuVcr5iiGmDEc62W/dASo6ry9ubN/OvPP2utL3dFjx58cvnl1s9UKYQQnYhib4fPqw+0dTWszlIgZg2NDsS++OILQkND6devH2odw4yEEE2nqirF2cXkHMgh90AuuQdztcDrQA55R/IwVtYcdlV/AGPvUELv/ruJ65dMcOiJ6mtkJ7/quV4hl4L9hSeNOJSby6cJCXyxaxdZRZY/sOz1eq7p1Yu58fGMCg21ysTX9kZRFK7o0YOpUVEsO3yYZ9asMevJMagqX+7axVe7dzMrLo7HR46kZyssUN0iQidg9O2PLmuH9tOKvWFH8/K45aefWHvsmNl+d3t73rnsMmb37n1Rti8hhBAXrt0HYnfddReLFi3i6NGj3Hrrrdx44414doThNEK0ExUlFZw+dFoLuM4FW1WBV9Vq7s2n4uWTy90PfoDe5lzg5j+wOr28X3yLJFIoraxkyb59fJKQwOrU1DrLxfj4cEf//tzYuzeejq0/xrojUBSFyd27c1m3bqw4coRn1qxh08mTpuNGVeXr3btZsHs3M2Jj+ffIkcT4NjQU1coUBeOw5yn8bS5Ow563yrBSVVX5eMcOHlqxgqKKCrNjEyIj+eyKKwhuL9kohRCig1NVFWPuGQB0Xh4XzQ0uxy6OKHoF1aB1NrW7QOyDDz7gzTff5IcffmD+/Pk89thjTJkyhdtuu40JEyZcNP9QQtRHNarkn8g3BVimXq4DueSfyK97Dd1GcnIuwtmlkOxMv/OOKEya/jv66Cu19PLhl4Hz+WWab292NvN27OC/u3dzuqTEct1sbZkRE8Pc+HiGBAfLZ0IdFEVhYrduTIiM5M+UFJ5Zs4Z1x6vX8FKBRcnJLEpO5ppevXhi1Ch6+7Xcv+WFUkPG8Vfoe0wOGdfq5zqRn8/tv/zCiiNHzPY729ry+oQJ3NG/v7QzIYRoQWpxKanRVwAQnroCxfniuJmq6BScfZ0pTC8E2mEgBmBvb8/MmTOZOXMmx44d44svvuCee+6hoqKCvXv3SuZEcdEoPVNqcSjh6UOnqSy1sAByE9jYVODpcxpvnxw8fXLx9snFyycHL59cHJ1KUVX49J25pJ8MQFV1KIqRgOB0Ih95HbpNbaF3qC1M/N2ePcxLSGDDiRN1luvn78/c+HhmxcXJWk1NoCgK4yIiGBcRwerUVJ5ds4a/zutl/H7vXr7fu5cre/bkiVGj6BcQ0DaVtTJVVfnvrl3cv3w5+WXma9qNCg3l82nTiOjSpY1qJ4QQojOqGYgVZ1lY0qcVNDtroqIoKIqidWHWsTCrEB2ZodxA3tG8WkMJcw7kmC2s3FzuPuV4eWXi5ZWGV42Ay93jLIrOQteZogPf/iiBIxh79Q4WvBUEgKrqGHv9SZTIyy+4TgCJGRnM27GDBUlJtS6Cq7jY2XFDXBxz4+PpH2i9hXs7qzFhYYwJC2PdsWM8t3YtK48eNTu+ZP9+luzfz9SoKJ4YNYqBQUFtVNPWl1FYyJ2//srPBw6Y7XewseGlceO4b/DgTpdpUwghRNurOU+sMLPQKudsUiBWVlZmGpq4fv16Lr/8ct577z0mTZqErgMtwCpEFVVVKcwoNAVYNQOuvJQ801jh5rJ3t8c73B6vgEK8PI7h5ZCId5eTeHqfxtauov4n6+0hYDAEjYTgkRAw1JRkIzJ8OYGLfyDtRBCBXU8Refd9F5S9rqCsjEXJycxLSGBbWlqd5QYHBTE3Pp4ZsbG42Nk1+3zCspGhoayYPZtNJ07w7Nq1LD982Oz4LwcP8svBg1zWrRtPjh7NkODgNqpp6/h2zx7u+e03cs8b/jo4KIgvp0+nR3tNYiKEEKLDqxmItbuhiffccw+LFi0iJCSEW265hUWLFuHVnlMtC1FDeVF5dZBVYyhh7sFcygvKL+i1dTY6ukR2wbuHN56RLnj75uHlehBvm404FW9AMVruVarFzg2Chp8LvEaB34A61/RSwiYyduZb/P6FHWNnHkcJm9jkequqyva0NOYlJLAwOZnCcst/Bw8HB26Mi2Nu//7taq5SZza0a1eW3XADW0+d4rm1a/n14EGz48sOH2bZ4cNMiIzkyVGjGB4S0kY1bRm5xcX8belS/rdnj9l+W52OZ8eO5aFhw7CRm31CCCFaUbsOxD766CNCQkIIDw9nzZo1rFmzxmK5H374ocUqJzqf/BP5jRrW5+zrjFtw0zKhGQ1G8o/lWxxKWHDK8uLCTeHi74JXDy9ti/LCu4c3XiHgYZOEPnM9nPwcshNBNUJjkiA6+Wk9XUGjtJ/ecaBr5OKJikLYHX9ndtBcnKbMa1JvWH5pKQuSkvhkxw6zhYbPNyIkhDvi47mmVy8cbW0b/fqi5QwKCuKXmTPZkZbGc2vX8tN5w/VWHDnCiiNHuCQ8nKdGj2ZUaGgb1bT5fj5wgDt++YXM85ZA6Ovvz5fTp0vwL4QQwipqBmKleaUYyg3o7Vp3UetGB2I33XSTZKcSF6SyrJJ5A+dRlNnwXQYXfxfuT70fG/vaTbQ4t9jiUMLTh09jKDdcUB1tnWzxiqoOtrx6nAu4orywd7WDs8fg1Do4+TOcXAfnXRjXyz1C6+mqGmro0e2ChhM2JXudqqpsPHGCeQkJfLtnDyWVlhOKeDk6cnOfPtweH0+0j0+z6yZaVv/AQH68/noSMzJ4fu1aFu/bZ3b8z5QU/kxJYXRoKE+OHs3YsLB2/3mdX1rK33//nS8SE8326xWFx0eO5PFRo7DTt+4XoBBCCFHl/LXEinOKcQ10bdVzNmlBZyEuhN5Oj3uIO0XZRVBffhcduAa5knsol9MHT9caSliSazl9eqMp4BHmoQVY5wVcroGuKLpzF7CqEXL3wcmfYN06LfAqPFn/a9c8iXeseeDlcmFJLU7k55NdXN2bWFlZyZHiYnZmZGBjU/1f2dfZ2bSuUm5xMV/t3s28hAT2ZmfX+dqXhIdzR3w803v2xN6m2Tl8RCvr6+/P99ddR3JWFs+vXcu3e/aYrYiw5tgxxv33vwzv2pUnR49mfEREuwzIVh45wq0//8zJs2fN9kd7e/PfK69kgCSAEUKINqHY6HGdMcn0+8XE0qLO7SYQE+JCKYrC2OfGsmDSgvoLGiE9IZ2P4j66oPM5ejqaAizPKE9T4OUZ6YmNg4Wmb6iAzG1wcq3W63VqPZSebtzJdLbanK7gkVrgFTQcHFouvXZZZSUD582rNXwLgPPmD/k7O/PF9Ol8uWsXi/fto9xguZfQz9mZW/r25bb4eLrJ4uwdSqyvL4uuuYYnR4/mhXXrWJScjFGtDsk2nDjBxK+/ZkhwME+OGsWkbt3aRUBWWF7OIytX8uH27Wb7FeChYcN4duxYHORGgBBCtBnF3g7f9x5v62q0CUuBWGuTbzxhVZETIvHv509GYkb9ixs3Mlmh3k6PZzfP2kMJe3jh5OVU/5MriiF9s9bTdWodpG2Cykampbd11rIYVgVeAYPBtoHzXQA7vZ4Qd3eyi4rq7UxUgLzSUiYtsBzsKsDEbt2YGx/P1KgobGXoV4fWy8eHBVddxZOjRvHi+vV8vXu3WUC2+eRJJn/zDQMCA3ly1Cguj4pqs4Bs7bFj3PLTTxzNyzPb383Tky+mTevwCUeEEEJ0bBKIiU6roriCg78eJOmbJDJ3ZzY60KriGuRqcSihe6g7On0js6mVnIa0DdWBV+Z2MDZy8WUHLwgaoQVewaPApy/orZfAQlEUnhs7ts4Aq4oKlFnoAQtydeXWfv24rV8/Qj08WqeSos308Pbmy+nTeWLUKF5ct47/7tqFoUZAtj0tjSsWLaKfvz9Pjh7NFT16WG0trpKKCh7/80/e2ry51n/7ewcO5OVLL8VZlkIQQoh2QVVV1GIt45ji5NAuRlNYi5OP+Q11CcREh2asNHJ01VGSv0lm3w/7KC9sOE28rZMtPab1MOvZ8uruhZ1LMy7UCk6dS6xxLvDKSWr8c127VqeRDx4Jnj21BZXb0ITISAYEBpKQnm7W61EXvaIwJSqKufHxTOrWTdJ/XwS6eXoyf9o0nhg1ipfWr+fzxEQqjdV9qDszMrjyf/+jt58fT4waxVXR0a0akG09dYqblizhQG6u2f4Qd3fmX3EF4yIiWu3cQgghmk4tLiUlbAIA4akrUJwd27hG1mPnbIetsy0VRdo6rxKIiQ5HVVVObTnF7gW72fvt3iY34ut+uI5uE7s158SQd+jc3K512jyv/JTGP9+zp3liDbe2TwNeWlnJnqwsEjMy2JWZSWJGBnuzsxsMwkLd3bk9Pp5b+vYlyK1pSwCIziG8Sxc+mTqVx0eO5OX16/ls504qagRkuzMzufa774jx8eGJUaO4plcv9C0YqJdVVvLsmjW8vGFDrfZ6W79+vDFxIm72ltfIE0IIIdqKi58LeUe1IfQSiIkOI3tvNknfJJH0TRJnUs7UWc7W2Yaek/yInR7I6tcOkpGcj2oARQ8Bce5E9smHzARw8gXX4LpPaDRA9u7qoOvUeiiue00sM4oOfONrJNYYAU5tm6o9q6hIC7gyMkjMzGRXRgb7c3LMhpc1pIuDAwuvvprxkZFWG3Ym2rdQDw8+vPxy/jVyJK9u2MC8hASzoat7srO5fvFieq5Zw79HjmRGbOwF95zuysjgph9/ZPd5a9QFuLgwb+pUpkRFXdDrCyGEEK3F2ddZAjHRMeSfyCd5UTLJ3yRryTfqoLPR0W1SN+Ku70lU9lTsDKcgE3SDIlmwazYAqgHGDnwPZcE/tCc5+cPcVLA5d9e8sgwytlUHXmkbofys5ROez8YB/AdXB16BQ8GuddOR1sVgNHIwN9fUw1X1M6Ow8IJfe+HVVzOxWzN6E0Wn19XdnXcnT+axkSP5z4YNfLRjB6U11pLbn5PDjUuW8MyaNTw+ciQ39O7d5ICs0mjk5fXreXbNGrPeN4BZcXG8e9lleDpePENchBBCdDw1E3ZIICbanZLTJez9fi9J3yRxbO2xepNuhIwMIe6GOHpd00vLYKiqsCAQMtMBI5FRRwjseoq0E0EEdj1FZNSRc8/UgUsAnPireo5XxlYwlDWukvbuEDi8eo6XX//qgM6KCsrK2H1ewJWclVXnYsr1cbK1pbefH339/Ojt58e7W7dyMDcXg6qiVxTiAwKYEBnZCu9CdCaBrq68OWkS/xwxgtc2buTD7dsprqgwHT90+jRzfvqJZ9eu5fGRI5nduzcZhYUNrl+XkpfHc2vXsuu8XjBvJyc+mjKFq3v1ss4bFEIIIS6Ak291wo6iTAnERDtQUVzBgV8OkLQgicPLD2OsqDuBul8fP+JmxRF7fSzuIe7mBxUFRjwHiyeZHo67bBXLfryMcZetono0nRGyEuGHyxpXQWf/6qAraKS2kLLOemnZVVXlxNmztYYWHjkvTXdjBbm60tffnz5+ftpPf38iu3Qxm8MT0aWLKYOiQVV5buzYiyqzkbgw/i4uvDZhAo8MH84bmzbx3tatFNUIyI7m5XHbzz/z7Jo1nC4poaDcQqKd89avO9+VPXvy0eWX4+vsXG85IYQQor04v0dMVdVWvb6SQExYZKgwcPSPcxkPl+wzZZCxxCPMg9hZscTNisM3xrf+Fw6dAH4DISsBVAMRUUf52yPvWyhYT1ebR6R54OURCVYKQsoqK9mbnW02tHBXRgZ5paVNfi0bnY5ePj7VAZefH338/fF2ang9sgmRkfQPCGBHejr9pTdMNJOvszMvX3opDw0bxpubNvHu1q1mQdex/Pwmv6aHgwPvXXYZs+Li5OaAEEKIDqVmIFZZWkl5YTn2rq03qkoCMWGiqionN50k6Zsk9ny7h+Lsuhc3dvJ2ImZGDHE3xBE8JLjxF1yKArG3wKptjayVAj5xEHQujXzQCHAJbORzL0xOcbHWw1VjaOG+nByzdOCN1cXBgT7+/vQ9F2z19fcn2tsbe5vm/RdUFIXnx4xh7g8/8PyYMXLBKy6It5MTL4wbx4PDhvH25s28vWUL+WWNHApcw6Ru3fh06lTJ1imEEB2VXofz1DGm3y82lhZ1lkBMtKqsPVkkLUgieWEyZ1LP1FnO1tmW6CujibshjvBx4ehtmzj8L2MbbH4ejvxcf7mAodXrdwUOBwePpp2niYyqyuHTp2sNLTxVUNCs14vs0qXW0MKubm4tHiyNCw/nvehoxoWHt+jriouXp6Mjz4wdyz+GDuXdLVt4c/PmRvX26hSFj6ZM4fb4eLkpIIQQHZjOwR7/+c+1dTXajKVAzDPSs9XOJ4HYRSr/eD5JC5NI/iaZzN11p33X2erofll3YmfF0mNqD2ydbJt+spPrYcvzkPp7w2Wn/QTdrmj6ORqpsLycpMxMs6GFuzMzzRIWNJaDjQ29/fzMhhb29vPDVdZHEh2ch4MDT4wezf1DhvDe1q28tH49hZbmiZ0zf9o0bu7Tx4o1FEIIIVqepUCsNUkgdhEpzik2ZTw8vu54vWVDR4cSN0vLeOjo2YyU06oKx/+Ezc/ByTWWy9i5QUUhqEZtITHfeIic2vRzWTy9SlpBAYnnDS08fPp0fbPP6hTg4lJraGF3T88WXQRXiPbGzd6ef40cyb0DBxLzwQecPK+XWAH6BwZyU+/ebVNBIYQQogXkn8inOLuY4lzzaTlp29Jw71qdfM7Z1xm34JYbfi+BWCdXXlTOgZ8PkPxNspbxsLLu+U3+ff2JuyGOmBkxZo2uSVQVUpZqQxDTN1ssciZ4Ehkx96Mvy6P76lnnnmfgUPQ/KMjQ1iPzdXYmuJHzTCoMBvbl5JiGFlYFXbklJU2uvl5R6OntXWtooWR+ExczNwcHPr3iClOmzioq8Lxk7BRCiE7DWFRCStgEAMJTV6Bz7vzrP1aWVTJv4DyL6erXvbCOdS+sMz128Xfh/tT7sbFvmRBKArFOyFBh4OjKoyQtSGL/j/upKK572F2XiC5axsOZcfj08mn+SVUjHP5RC8CydloooGCIupZxB4JZs98N9m8BVLY4BjJIn8ZWQyCDfz0AaCmx/V1cSL3//lrJLPJKSmothrwnK6vWArKN4WZvbx5w+fkR4+uLQzMTaAjRmU2IjGRgYCAJ6emyfp0QQohOQ2+nxz3EnaLsIqjvclIHbl3d0Nu13BJJcsXZSahGlRMbT5gyHpbk1t0b5OzrrGU8nBVH0OCgC7ubbayEA9/Clhcgd2/t44oeet0Igx5D1yWK4oxP0RWlnWvnCv8qH8c7dsv4V/k4tIFOoAOC3dw4kZ+vpYevEXgdb0Y6bYAwDw/6nje0MNTdXe7kC9FIiqLw3Nixsn6dEEKITkVRFMY+N5YFkxbUX9AIY59r2e89CcQ6uMykTJK+0TIe5h+rO0ixc7Ej+qpoYmfFEjEuAp3NBc5tMlTA3q9g60tw5nDt4zpbLU39wH+CRwSghVk1L+QAVhkiiSm51+ypRiA5K4vu773X5GrZ6/XE+vqaDSvs7eeHh4NDk19LCGFO1q8TQgjRGUVOiCRwYCDpCemohtrZBBS9QkB8AJETWvZ7TwKxDujMsTMkL0wm6ZskspKy6iyns9XRfXJ34m6II+ryKGwdm5Hx8HyVpZD8OWx9GQosJPywcYC4O2Dgw+AajKqq5BQVceLsWU6ePcuJ/HwCXFzIKCysN2lGaWVlg1XxcXLSerlqDC/s4e2NjSTQEKJVyPp1QgghOqOGesVUg9rivWEggViHUZxTzJ7v9pC0IIkTG07UXVCBsDFhxM2KI/rqaBy7tNAky4pi2P0JbP8PFKbVOlypd2J3wFUsdZvKvjM2nFz8ByfPBV/lBsMFnVqnKER5edWaz+Xv4iIXgkJYmaxfJ4QQojOq6hVL255Gzd6C1uoNAwnE2rXywnL2/7Sf5G+SObLiSL0ZDwPiA4idFUvsjNgWSatpMBrJKiriVO4pHJI/IeLoFzhV5NUqd0a1552KwbxdPoTT+U7Avgs6r05RGBIUVN3T5e9PrK8vTrYt0JsnhBBCCCGEBXX1irVWbxhIINbuGCoMHPn9CEnfJHHgpwP1ZzyM7ELcrDjiZsXh3dO78ecwGskoLNSGCp7rtaraqh4XF2Rxj34T99ttxlMprfUaOaojb5YP5f2KgeTTtF43e70eT0dH0gsLax37deZMLuvevUmvJ4QQQgghWoBeh9OlQ0y/X2zOnyvWmr1hIIFYu6AaVY5vOE7SN0ns/W5v/RkP/ZyJvT6WuFlxBA4MrBWdVxqNpBcUWAyyqvalFxRgUC3P0PJRCvmH7Wb+5rgVN6W81vEMozP/qRjOxxX9KcK+1nFHGxuC3dwIdnOjq7s7wa6upsdV+7wctcBt8Kef1kqFPalbt6b86YQQQgghRAvROdgTsPA/bV2NNnN+r1hr9oaBBGItaldmJq41FhGub1FiVVXJSspi94LdJC9M5uyJs3W+rp2rHb2u7kX0jF7YDvAirbiQ9WfzOLHpWK0gK6OwEGMdQVZ9ApSzPGy7kTttt+Ok1E6UccLoxpuGUaxyHouPnzfXuLnRtUaAVRVkdXFwaHRjlVTYQgghhBCiPTHNFduWRuDAwFbrDQMJxFrUjFf+i87WzvTYydeJPU/9w2xR4ryUPFPGw+w92XW/mK1C2UAP0gc5sq+byrulh8nYkoi6pWXrHKKc4Z9267nNZif2Su2kGsVOwZyO+zuu/ebyupNriwZKVQvEbktLY2BgoKTCFkIIIYQQbUpRFMa9OI5l9y1j3IvjWrWTQAKxFnTb52BX43GpWym6x1Vys/LZ8vVODny7l7M76g6+VCAlHJLiYF+0SqljHpAHORdWL3d7e7Oeq2A3N2JszjA0/WuCTvyEolpIFd+lBwx5HKeeM3HStU4zURSFF8eN475ly3hxXOs2dCGEEEIIUT9jUQmpva4AIGzvz+icWyj7dgcTcWkEf9v7t1Y/jwRircQIVNiq3NnnJboeUtHVM1rwVKAWfO2JgYImJjz0cHCoPUTwvMeu9jXmcuXsgS0vwoFFoFrIwugdB0P+Dd2vBp2+aZVphksjItj7t9Zv6EIIIYQQomFqce0kbaJ1SCDWSnSAa66Ka67l47meWvCVFAe5dSQ89HR0rDfICnJzw8XOzvKTz5e5E7Y8D4d+sHzcbwAMeQIiLwfl4suSI4QQQgghhDVJIGZFBS6QHKsFX+XdHOnq7s6weoKsFlk7K22zFoAd/c3y8cDhMPQJCJ0AMjRQCCGEEEIIq5BArJUZnfTYjPHFb3oEoy+J4O4uHgS5ueFg04p/elWFk2th8/Nw/A/LZULGaT1gwaMkABNCCCGEEMLKJBBrDQr0vLInvW/oTffJ3bFxsNKfWVXh2AotADu13nKZiCkw+HEIHGqdOgkhhBBCCCFqkUCsFVz77bX0uqaX9U6oqnDkF20IYsY2y2W6XwWD/w1+/axXLyGEEEIIIYRFEoi1ICPgHOdJ9NXRVjqhAQ4thi0vQPbu2scVHfS4Hgb/C7xjrFMnIYQQQgjRMel0OAzra/pdtC4JxFqQDpj26qTWXw/LWAn7F2pp6E/vt1ARG4ieDYMfgy7dW7cuQgghhBCiU9A52hP007ttXY2LhgRiLcg5pgvdJnZrvRMYymHPl7D1Zcg/Wvu43g5ib4OBj4B7WOvVQwghhBBCCHFBJBBrQZOfv7R1esMqSiD5M9j6ChSerH3cxhF63wkDHgLXoJY/vxBCCCGEEKJFSSDWgsLGhLXsC5YXwu6PYftrUJRR+7itC/S7F/r/A5x8W/bcQgghhBDiomIsKuFY/2sBCN3xHTpnxzauUecmgVh7VJYPO9+DHW9CaW7t4/YeEH8/9LsPHD2tXj0hhBBCCNE5GXPz27oKFw0JxNqTklxIeBt2vqMFY+dz9Ib+D0Lfe8Dezfr1E0IIIYQQQrQICcTag6IM2P4G7PoAKopqH3cOgIEPQ+87wNbZ+vUTQgghhBBCtCgJxNpSwUnY9iokzYPK0trHXUNg0KMQewvYOFi/fkIIIYQQQohWIYFYWzhzFLa9Asmfg7Gi9nGPSBj0L+h1o5aSXgghhBBCCNGpSCBmTacPwNaXYO/XoBpqH/eMhiGPQ48Z2qLMQgghhBBCiE5JrvZbUvYuKHOtfuzkC67BkJ0EW16AA98Cau3n+fSFIf+G7leCorNWbYUQQgghhKim02Hft6fpd9G6JBBrQbbfjQH7GjscvCBwKBz91fITAgbDkCcgfDK0xkLQQgghhBBCNJLO0Z7glfPauhoXDQnEWlNpruUgLHiUFoCFjJMATAghhBBCiItQh+lzzMvLY/bs2bi7u+Pu7s7s2bM5c+ZMvc9RVZWnn36awMBAHB0dGTNmDHv27DErM2bMGBRFMduuv/761nkToRNgxhptC71UgjAhhBBCCCEuUh0mEJs1axaJiYksX76c5cuXk5iYyOzZs+t9zquvvsobb7zBe++9x7Zt2/D392f8+PEUFBSYlZs7dy7p6emm7eOPP27ZykdeAbO2wDW/a71hQgghhBBCtDPG4lKOxV/LsfhrMRZbWFpJtKgOMTRx3759LF++nM2bNzN48GAA5s2bx9ChQzlw4AA9evSo9RxVVXnrrbd4/PHHueqqqwD48ssv8fPz45tvvuHOO+80lXVycsLf37/lKx51LQz+F/j2bfnXFkIIIYQQoiWpKpUnMky/i9bVIXrENm3ahLu7uykIAxgyZAju7u5s3LjR4nNSUlLIyMhgwoQJpn329vaMHj261nMWLFiAt7c3MTExPPTQQ7V6zJrMwQtu3gNTv5UgTAghhBBCCFFLh+gRy8jIwNfXt9Z+X19fMjIy6nwOgJ+fn9l+Pz8/jh07Znp8ww03EB4ejr+/P8nJyTz22GPs2rWLlStX1lmfsrIyysrKACgqKqp1vHLil6ju3aHCwmLNQrSQinPtq0LambAiaXeiLUi7E23lYmt7xsrq91lRWYGuokOECu1KU9pKm/51n376aZ555pl6y2zbtg0AxUJiC1VVLe6v6fzj5z9n7ty5pt9jY2Pp3r07AwYMICEhgfj4eIuv+dJLL1mstxGFPPtI1iZXwJ6l9dZLiJZS300DIVqLtDvRFqTdibZysbQ9paycmHO///7776j2dm1an46otLTxc+vaNBC79957G8xQGBYWxu7du8nMzKx1LDs7u1aPV5WqOV8ZGRkEBASY9mdlZdX5HID4+HhsbW05dOhQnYHYY489xgMPPABoPWKBgYEA6FBxnfQWk0MnWHyeEC2poqKClStXMn78eGxtbdu6OuIiIe1OtAVpd6KtXGxtz1hcwkneAWDixInonBzbuEYdj6XRcnVp00DM29sbb2/vBssNHTqU/Px8tm7dyqBBgwDYsmUL+fn5DBs2zOJzqoYbrly5kn79+gFQXl7OmjVreOWVV+o81549e6ioqDAL3s5nb2+Pvb22crNerzftN/r2xSZSFmcW1mVra3tRfDmI9kXanWgL0u5EW7lY2p7RptL0u62NLbqL4D23tKa0kw6RrCM6OppJkyYxd+5cNm/ezObNm5k7dy6XX365WcbEnj17smTJEkAbkvj3v/+dF198kSVLlpCcnMycOXNwcnJi1qxZABw5coRnn32W7du3k5qaytKlS7n22mvp168fw4cPb3I9jYOfkiBMCCGEEEJ0TIqCbY8wbHuEyTWtFXSYGXgLFizgvvvuM2VBvOKKK3jvvffMyhw4cID8/HzT40ceeYSSkhLuuece8vLyGDx4MCtWrMDV1RUAOzs7Vq1axdtvv01hYSFdu3ZlypQpPPXUU2Y9XY2ldh3T/DcohBBCCCFEG9I5ORCy/qu2rsZFo8MEYp6ennz99df1llHPW+9AURSefvppnn76aYvlu3btypo1a1qqikIIIYQQQgjRKB1iaKIQQgghhBBCdCYSiAkhhBBCCCEwFpdyfMRsjo+YjbG48WnYRfN0mKGJQgghhBBCiFakqlQcSDX9LlqX9IgJIYQQQgghhJVJICaEEEIIIYQQViaBmBBCCCGEEEJYmQRiQgghhBBCCGFlEogJIYQQQgghhJVJ1kQhhBBCCCEEKAo2Xf1Nv4vWJYGYEEIIIYQQAp2TA6EJ37V1NS4aMjRRCCGEEEIIIaxMAjEhhBBCCCGEsDIJxIQQQgghhBAYS8o4OX4uJ8fPxVhS1tbV6fRkjpgQQgghhBACjEbKEvebfhetS3rEhBBCCCGEEMLKJBATQgghhBBCCCuTQEwIIYQQQgghrEwCMSGEEEIIIYSwMgnEhBBCCCGEEMLKJGuiEEIIIYQQAgCdl3tbV+GiIYGYEEIIIYQQAp2zI+H7f23ralw0ZGiiEEIIIYQQQliZBGJCCCGEEEIIYWUSiAkhhBBCCCEwlpRxatr/cWra/2EsKWvr6nR6MkdMCCGEEEIIAUYjpRsTTb+L1iU9YkIIIYQQQghhZRKICSGEEEIIIYSVSSAmhBBCCCGEEFYmgZgQQgghhBBCWJkEYkIIIYQQQghhZZI1UQghhBBCCAGA4uTQ1lW4aEggJoQQQgghhEDn7EjEsZVtXY2LhgxNFEIIIYQQQggrk0BMCCGEEEIIIaxMAjEhhBBCCCEExtIy0mc+TPrMhzGWlrV1dTo9mSMmhBBCCCGEAIOR4j82m34XrUt6xIQQQgghhBDCyiQQE0IIIYQQQggrk0BMCCGEEEIIIaxMAjEhhBBCCCGEsDJJ1nGBVFU1/V5UVIStrW0b1kZcTCoqKigtLZV2J6xK2p1oC9LuRFu52NqesaiEYtUAaNe1OiRhR1MVFRWZfq8ZJ1gigdgFKi4uNv0eHBzchjURQgghhBCihfj5tHUNOrzi4mJcXFzqPC5DE4UQQgghhBDCyhS1oT4zUS+j0UhKSgrdunXj1KlTuLu7t3WVxEXi7NmzBAYGkpaWhpubW1tXR1wkpN2JtiDtTrQVaXuiqVRVNY2Y8/b2Rqeru99LhiZeIJ1Oh4+P1nXr4uKCs7NzG9dIXCwMBm0Mt7Ozs7Q7YTXS7kRbkHYn2oq0PdEc9Q1HrEmGJgohhBBCCCGElUkgJoQQQgghhBBWJoFYC7C3t+epp57C3t6+rasiLiLS7kRbkHYn2oK0O9FWpO2J1iTJOoQQQgghhBDCyqRHTAghhBBCCCGsTAIxIYQQQgghhLAyCcSEEEIIIYQQwsokEBNCCCGEEEIIK5NArJE++OADwsPDcXBwoH///qxbt67OsqtXr0ZRlFrb/v37rVhj0Rk0pd0BlJWV8fjjjxMaGoq9vT2RkZHMnz/fSrUVnUVT2t2cOXMsft7FxMRYscaiM2jq592CBQvo06cPTk5OBAQEcMstt5Cbm2ul2orOoqnt7v333yc6OhpHR0d69OjBf//7XyvVVHRKqmjQokWLVFtbW3XevHnq3r171fvvv191dnZWjx07ZrH8X3/9pQLqgQMH1PT0dNNWWVlp5ZqLjqyp7U5VVfWKK65QBw8erK5cuVJNSUlRt2zZom7YsMGKtRYdXVPb3ZkzZ8w+506cOKF6enqqTz31lHUrLjq0pra7devWqTqdTn377bfVo0ePquvWrVNjYmLU6dOnW7nmoiNrarv74IMPVFdXV3XRokXqkSNH1IULF6ouLi7qzz//bOWai85CArFGGDRokHrXXXeZ7evZs6f66KOPWixfFYjl5eVZoXais2pqu1u2bJnq7u6u5ubmWqN6opNqars735IlS1RFUdTU1NTWqJ7opJra7v7zn/+oERERZvveeecdNTg4uNXqKDqfpra7oUOHqg899JDZvvvvv18dPnx4q9VRdG4yNLEB5eXl7NixgwkTJpjtnzBhAhs3bqz3uf369SMgIIBx48bx119/tWY1RSfTnHb3888/M2DAAF599VWCgoKIiorioYceoqSkxBpVFp3AhXzeVfnss8+49NJLCQ0NbY0qik6oOe1u2LBhnDx5kqVLl6KqKpmZmXz//fdMmTLFGlUWnUBz2l1ZWRkODg5m+xwdHdm6dSsVFRWtVlfReUkg1oCcnBwMBgN+fn5m+/38/MjIyLD4nICAAD755BMWL17MDz/8QI8ePRg3bhxr1661RpVFJ9Ccdnf06FHWr19PcnIyS5Ys4a233uL777/nb3/7mzWqLDqB5rS7mtLT01m2bBm33357a1VRdELNaXfDhg1jwYIFzJgxAzs7O/z9/fHw8ODdd9+1RpVFJ9Ccdjdx4kQ+/fRTduzYgaqqbN++nfnz51NRUUFOTo41qi06GZu2rkBHoSiK2WNVVWvtq9KjRw969Ohhejx06FBOnDjBa6+9xqhRo1q1nqJzaUq7MxqNKIrCggULcHd3B+CNN97gmmuu4f3338fR0bHV6ys6h6a0u5q++OILPDw8mD59eivVTHRmTWl3e/fu5b777uPJJ59k4sSJpKen8/DDD3PXXXfx2WefWaO6opNoSrt74oknyMjIYMiQIaiqip+fH3PmzOHVV19Fr9dbo7qik5EesQZ4e3uj1+tr3R3JysqqdRelPkOGDOHQoUMtXT3RSTWn3QUEBBAUFGQKwgCio6NRVZWTJ0+2an1F53Ahn3eqqjJ//nxmz56NnZ1da1ZTdDLNaXcvvfQSw4cP5+GHH6Z3795MnDiRDz74gPnz55Oenm6NaosOrjntztHRkfnz51NcXExqairHjx8nLCwMV1dXvL29rVFt0clIINYAOzs7+vfvz8qVK832r1y5kmHDhjX6dXbu3ElAQEBLV090Us1pd8OHDyctLY3CwkLTvoMHD6LT6QgODm7V+orO4UI+79asWcPhw4e57bbbWrOKohNqTrsrLi5GpzO/hKnqkVBVtXUqKjqVC/m8s7W1JTg4GL1ez6JFi7j88strtUchGqWNkoR0KFXpTT/77DN179696t///nfV2dnZlBXs0UcfVWfPnm0q/+abb6pLlixRDx48qCYnJ6uPPvqoCqiLFy9uq7cgOqCmtruCggI1ODhYveaaa9Q9e/aoa9asUbt3767efvvtbfUWRAfU1HZX5cYbb1QHDx5s7eqKTqKp7e7zzz9XbWxs1A8++EA9cuSIun79enXAgAHqoEGD2uotiA6oqe3uwIED6ldffaUePHhQ3bJlizpjxgzV09NTTUlJaaN3IDo6mSPWCDNmzCA3N5dnn32W9PR0YmNjWbp0qSkrWHp6OsePHzeVLy8v56GHHuLUqVM4OjoSExPDb7/9xuTJk9vqLYgOqKntzsXFhZUrV/J///d/DBgwAC8vL6677jqef/75tnoLogNqarsDyM/PZ/Hixbz99tttUWXRCTS13c2ZM4eCggLee+89HnzwQTw8PLjkkkt45ZVX2uotiA6oqe3OYDDw+uuvc+DAAWxtbRk7diwbN24kLCysjd6B6OgUVZU+fCGEEEIIIYSwJhnQKoQQQgghhBBWJoGYEEIIIYQQQliZBGJCCCGEEEIIYWUSiAkhhBBCCCGElUkgJoQQQgghhBBWJoGYEEIIIYQQQliZBGJCCCGEEEIIYWUSiAkhhLC61atXoygKZ86caeuqsGHDBuLi4rC1tWX69OlNfn57ei+NFRYWxltvvdVhXlcIITojCcSEEOIiMmfOHBRFqbUdPny41c45ZswY/v73v5vtGzZsGOnp6bi7u7faeRvrgQceoG/fvqSkpPDFF1+0dXWaLC8vj9mzZ+Pu7o67uzuzZ89uMCjctm0bd9xxh3UqWI8vvvgCDw+Ptq6GEEK0CQnEhBDiIjNp0iTS09PNtvDw8FrlysvLW60OdnZ2+Pv7oyhKq52jsY4cOcIll1xCcHBwhwwKZs2aRWJiIsuXL2f58uUkJiYye/bsep/j4+ODk5OTlWoohBDCEgnEhBDiImNvb4+/v7/ZptfrGTNmDPfeey8PPPAA3t7ejB8/HoA33niDuLg4nJ2d6dq1K/fccw+FhYVmr7lhwwZGjx6Nk5MTXbp0YeLEieTl5TFnzhzWrFnD22+/bep9S01NtTicb/HixcTExGBvb09YWBivv/662TnCwsJ48cUXufXWW3F1dSUkJIRPPvmk3vdaVlbGfffdh6+vLw4ODowYMYJt27YBkJqaiqIo5Obmcuutt6IoSp09YmVlZTzyyCN07doVe3t7unfvzmeffWaxbG5uLjNnziQ4OBgnJyfi4uJYuHChWZnvv/+euLg4HB0d8fLy4tJLL6WoqAjQhjoOGjQIZ2dnPDw8GD58OMeOHbN4rn379rF8+XI+/fRThg4dytChQ5k3bx6//vorBw4cqPPvcv4QQkVR+PTTT7nyyitxcnKie/fu/Pzzz3U+HyArK4upU6fi6OhIeHg4CxYsqFWmvrazevVqbrnlFvLz801t4+mnnwbg66+/ZsCAAbi6uuLv78+sWbPIysqqtz5CCNHRSCAmhBDC5Msvv8TGxoYNGzbw8ccfA6DT6XjnnXdITk7myy+/5M8//+SRRx4xPScxMZFx48YRExPDpk2bWL9+PVOnTsVgMPD2228zdOhQ5s6da+p969q1a63z7tixg+uuu47rr7+epKQknn76aZ544olagdHrr7/OgAED2LlzJ/fccw933303+/fvr/P9PPLIIyxevJgvv/yShIQEunXrxsSJEzl9+jRdu3YlPT0dNzc33nrrLdLT05kxY4bF17nppptYtGgR77zzDvv27eOjjz7CxcXFYtnS0lL69+/Pr7/+SnJyMnfccQezZ89my5YtAKSnpzNz5kxuvfVW9u3bx+rVq7nqqqtQVZXKykqmT5/O6NGj2b17N5s2beKOO+6os+dw06ZNuLu7M3jwYNO+IUOG4O7uzsaNG+v8u1jyzDPPcN1117F7924mT57MDTfcwOnTp+ssP2fOHFJTU/nzzz/5/vvv+eCDD2oFS/W1nWHDhvHWW2/h5uZmahsPPfQQoPXGPvfcc+zatYsff/yRlJQU5syZ06T3I4QQ7Z4qhBDionHzzTerer1edXZ2Nm3XXHONqqqqOnr0aLVv374Nvsa3336renl5mR7PnDlTHT58eJ3lR48erd5///1m+/766y8VUPPy8lRVVdVZs2ap48ePNyvz8MMPq7169TI9Dg0NVW+88UbTY6PRqPr6+qoffvihxfMWFhaqtra26oIFC0z7ysvL1cDAQPXVV1817XN3d1c///zzOut/4MABFVBXrlxp8fj578WSyZMnqw8++KCqqqq6Y8cOFVBTU1NrlcvNzVUBdfXq1XW+Vk0vvPCC2r1791r7u3fvrr744ot1Pi80NFR98803TY8B9d///rfpcWFhoaooirps2TKLz6/6m2zevNm0b9++fSpg9rrnO7/tfP7556q7u3ud5ats3bpVBdSCgoIGywohREchPWJCCHGRGTt2LImJiabtnXfeMR0bMGBArfJ//fUX48ePJygoCFdXV2666SZyc3NNQ+mqesQuxL59+xg+fLjZvuHDh3Po0CEMBoNpX+/evU2/K4qCv79/nUPWjhw5QkVFhdnr2traMmjQIPbt29fouiUmJqLX6xk9enSjyhsMBl544QV69+6Nl5cXLi4urFixguPHjwPQp08fxo0bR1xcHNdeey3z5s0jLy8PAE9PT+bMmcPEiROZOnUqb7/9Nunp6fWez1JvmaqqTZ5/V/Nv6+zsjKura51/23379mFjY2PWXnr27Flrjl1DbacuO3fuZNq0aYSGhuLq6sqYMWMATH9DIYToDCQQE0KIi4yzszPdunUzbQEBAWbHajp27BiTJ08mNjaWxYsXs2PHDt5//30AKioqAHB0dLzgOlkKHFRVrVXO1tbW7LGiKBiNxjpfs6pMQ+eqT1Pf3+uvv86bb77JI488wp9//kliYiITJ040JT/R6/WsXLmSZcuW0atXL95991169OhBSkoKAJ9//jmbNm1i2LBh/O9//yMqKorNmzdbPJe/vz+ZmZm19mdnZ+Pn59ekerfE37amxrQdS4qKipgwYQIuLi58/fXXbNu2jSVLlgCtm0BGCCGsTQIxIYQQddq+fTuVlZW8/vrrDBkyhKioKNLS0szK9O7dm1WrVtX5GnZ2dma9Wpb06tWL9evXm+3buHEjUVFR6PX6ZtW9W7du2NnZmb1uRUUF27dvJzo6utGvExcXh9FoZM2aNY0qv27dOqZNm8aNN95Inz59iIiI4NChQ2ZlFEVh+PDhPPPMM+zcuRM7OztTsAHQr18/HnvsMTZu3EhsbCzffPONxXMNHTqU/Px8tm7datq3ZcsW8vPzGTZsWKPfY1NFR0dTWVnJ9u3bTfsOHDhglnylMW3HUtvYv38/OTk5vPzyy4wcOZKePXtKog4hRKckgZgQQog6RUZGUllZybvvvsvRo0f56quv+Oijj8zKPPbYY2zbto177rmH3bt3s3//fj788ENycnIALUPfli1bSE1NJScnx2Ivy4MPPsiqVat47rnnOHjwIF9++SXvvfeeKXlDczg7O3P33Xfz8MMPs3z5cvbu3cvcuXMpLi7mtttua/TrhIWFcfPNN3PrrbeaEkesXr2ab7/91mL5bt26sXLlSjZu3Mi+ffu48847ycjIMB3fsmULL774Itu3b+f48eP88MMPZGdnEx0dTUpKCo899hibNm3i2LFjrFixgoMHD9YZOEZHRzNp0iTmzp3L5s2b2bx5M3PnzuXyyy+nR48eTfuDNUGPHj1M592yZQs7duzg9ttvN+s9bEzbCQsLo7CwkFWrVpGTk0NxcTEhISHY2dmZnvfzzz/z3HPPtdp7EUKItiKBmBBCiDr17duXN954g1deeYXY2FgWLFjASy+9ZFYmKiqKFStWsGvXLgYNGsTQoUP56aefsLGxAeChhx5Cr9fTq1cvfHx8LM7ziY+P59tvv2XRokXExsby5JNP8uyzz15wpryXX36Zq6++mtmzZxMfH8/hw4f5/fff6dKlS5Ne58MPP+Saa67hnnvuoWfPnsydO7fOeU5PPPEE8fHxTJw4kTFjxuDv78/06dNNx93c3Fi7di2TJ08mKiqKf//737z++utcdtllODk5sX//fq6++mqioqK44447uPfee7nzzjvrrNuCBQuIi4tjwoQJTJgwgd69e/PVV1816f01x+eff07Xrl0ZPXo0V111FXfccQe+vr6m441pO8OGDeOuu+5ixowZ+Pj48Oqrr+Lj48MXX3zBd999R69evXj55Zd57bXXWv39CCGEtSmqpUH4QgghhBBCCCFajfSICSGEEEIIIYSVSSAmhBBCCCGEEFYmgZgQQgghhBBCWJkEYkIIIYQQQghhZRKICSGEEEIIIYSVSSAmhBBCCCGEEFYmgZgQQgghhBBCWJkEYkIIIYQQQghhZRKICSGEEEIIIYSVSSAmhBBCCCGEEFYmgZgQQgghhBBCWJkEYkIIIYQQQghhZf8PsS/pWsJA/fMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_imb = all_data[labels==0].shape[0]/(all_data[labels==0].shape[0]+all_data[labels==1].shape[0])\n",
    "print(data_imb)\n",
    "models = [\"Majclass\", \"MedPFN-1\", \"MedPFN-7\", \"MedPFN-7FT\", \"RandomForest\", \"CatBoost\", \"XGBoost\", \"Logistic Regression\", \"TabPFN\", \"TabForestPFN\"]\n",
    "fig, axs = plt.subplots(1, 1, figsize=(10, 5))\n",
    "all_accuracies = []\n",
    "all_rocs = []\n",
    "all_f1s = []\n",
    "fracs = [0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.91,0.92,0.93,0.94,0.95,0.96,0.97,0.98]\n",
    "for m in range(0,len(models)):\n",
    "    accuracies = []\n",
    "    rocs = []\n",
    "    f1s = []\n",
    "    for f in fracs:\n",
    "    \n",
    "        path = f'results/imbalance/majclass_{f}.csv'\n",
    "        df = pd.read_csv(path)\n",
    "        accuracies.append(df.iloc[m,1])\n",
    "        rocs.append(df.iloc[m,7])\n",
    "        f1s.append(df.iloc[m,9])\n",
    "    all_accuracies.append(accuracies)\n",
    "    all_rocs.append(rocs)\n",
    "    all_f1s.append(f1s)\n",
    "    \n",
    "#axs[0].plot(all_accuracies[3])\n",
    "#axs[1].plot(all_rocs[3])\n",
    "#axs[2].plot(all_f1s[2])\n",
    "mean_accuracies = all_accuracies[3]-np.mean(np.array(all_accuracies)[4:],axis=0)\n",
    "#axs.plot(fracs, mean_accuracies)\n",
    "mean_rocs = all_rocs[3]-np.mean(np.array(all_rocs)[4:],axis=0)\n",
    "#axs.plot(fracs, mean_rocs)\n",
    "mean_f1s = all_f1s[3]-np.mean(np.array(all_f1s)[4:],axis=0)\n",
    "#axs.plot(fracs, mean_f1s)\n",
    "axs.plot(fracs, np.zeros(len(fracs)), linestyle='--', c=\"black\", label=\"Win threshhold\")\n",
    "axs.vlines(data_imb,-0.075,0.125, linestyles=\"dashed\", colors=\"crimson\", label=\"Original data\")\n",
    "axs.plot(fracs, mean_rocs, marker=\"v\", linewidth=2.5, markersize=7.0, label='ROC AUC', c=\"teal\")\n",
    "axs.plot(fracs, mean_accuracies, marker=\"v\", linewidth=2.5, markersize=7.0, label='Accuracy', c=\"darkorange\")\n",
    "axs.plot(fracs, mean_f1s, marker=\"v\", linewidth=2.5, markersize=7.0, label='F1-score', c=\"purple\")\n",
    "axs.set_yticks([-0.05,0,0.05,0.1])\n",
    "axs.set_ylim(-0.075,0.125)\n",
    "axs.set_xlim(0.5,0.99)\n",
    "axs.set_xlabel(\"Fraction of class 0 in data\")\n",
    "axs.set_ylabel(\"MedPFN - mean[baselines]\")\n",
    "axs.grid()\n",
    "axs.legend(fontsize=12)\n",
    "fig.show()\n",
    "fig.savefig(\"results/plots/imbalance.eps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92b57f2-8a3b-41ad-98b6-235cd6a2454f",
   "metadata": {},
   "source": [
    "## Ensemble testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "730e1ff3-52fd-4746-b51e-7cce8cc46c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " ensemble \n",
      "     accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "1           0.947         0.006           0.400          0.436        0.117       0.130         0.870        0.071    0.166   0.170         0.460        0.080\n",
      "2           0.947         0.006           0.300          0.306        0.167       0.167         0.911        0.063    0.213   0.214         1.368        0.113\n",
      "3           0.951         0.009           0.600          0.436        0.183       0.138         0.907        0.060    0.266   0.189         1.978        0.240\n",
      "4           0.950         0.008           0.533          0.393        0.200       0.145         0.922        0.054    0.276   0.191         2.562        0.185\n",
      "5           0.950         0.008           0.533          0.393        0.200       0.145         0.919        0.055    0.276   0.191         2.810        0.218\n",
      "6           0.950         0.008           0.533          0.393        0.200       0.145         0.919        0.056    0.276   0.191         3.069        0.258\n",
      "7           0.950         0.008           0.533          0.393        0.200       0.145         0.915        0.057    0.276   0.191         3.565        0.436\n",
      "8           0.949         0.007           0.533          0.393        0.183       0.138         0.914        0.056    0.255   0.177         3.152        0.393\n",
      "9           0.949         0.007           0.533          0.393        0.183       0.138         0.915        0.056    0.255   0.177         4.416        0.538\n",
      "10          0.949         0.007           0.533          0.393        0.183       0.138         0.916        0.052    0.255   0.177         5.720        0.516\n",
      "11          0.949         0.007           0.533          0.393        0.183       0.138         0.918        0.052    0.255   0.177         4.744        0.378\n",
      "12          0.949         0.007           0.533          0.393        0.183       0.138         0.916        0.052    0.255   0.177         4.949        0.272\n",
      "13          0.950         0.011           0.613          0.380        0.233       0.133         0.914        0.053    0.319   0.175         5.320        0.310\n",
      "14          0.950         0.011           0.613          0.380        0.233       0.133         0.914        0.053    0.319   0.175         5.573        0.306\n",
      "15          0.947         0.008           0.513          0.397        0.183       0.138         0.913        0.054    0.247   0.171         6.179        0.433\n",
      "16          0.947         0.008           0.513          0.397        0.183       0.138         0.913        0.053    0.247   0.171         6.079        0.299\n",
      "17          0.947         0.008           0.513          0.397        0.183       0.138         0.913        0.054    0.247   0.171         6.229        0.375\n",
      "18          0.946         0.007           0.480          0.389        0.150       0.117         0.914        0.054    0.208   0.141         7.002        0.318\n",
      "19          0.948         0.010           0.580          0.382        0.200       0.125         0.914        0.055    0.280   0.164         7.117        0.591\n",
      "20          0.948         0.010           0.580          0.382        0.200       0.125         0.916        0.053    0.280   0.164         7.832        0.600\n"
     ]
    }
   ],
   "source": [
    "save = True\n",
    "sampling = None\n",
    "cv = 10\n",
    "best_delete = 0\n",
    "strat_split = True\n",
    "recomp = False\n",
    "n_optim = 1000\n",
    "cat_optim = 10\n",
    "ft_epochs = 10\n",
    "ft_lr = 1e-5\n",
    "max_s = 1024\n",
    "max_q = 128\n",
    "max_samples = 1024\n",
    "no_pre_process = False\n",
    "multi_decoder = \"permutation\"\n",
    "N_ens = 7\n",
    "seed = 42\n",
    "overwrite = True\n",
    "metrics = [\"accuracy\", \"precision\", \"recall\", \"roc_auc\", \"f1\"]\n",
    "dir_path = os.path.abspath(os.getcwd())\n",
    "run_name = \"medium_mlp_var_balance_05weight_anova_bestwithnoisebnn_100\"\n",
    "path = dir_path + f\"/logs/trainrun_{run_name}\"\n",
    "filename = \"model\"\n",
    "\n",
    "ens_num = 20\n",
    "\n",
    "    \n",
    "reducer  = AnovaSelect()\n",
    "\n",
    "results_mean = pd.DataFrame(np.zeros((ens_num, len(metrics)+1)),\n",
    "                            index=np.arange(1,1+ens_num),\n",
    "                            columns=metrics+[\"runtime\"])\n",
    "results_std = pd.DataFrame(np.zeros((ens_num, len(metrics)+1)), \n",
    "                           index=np.arange(1,1+ens_num),\n",
    "                           columns=metrics+[\"runtime\"])\n",
    "\n",
    "for ens in range(1,ens_num+1):\n",
    "    model = MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process)\n",
    "    results_mean.iloc[ens-1,:], results_std.iloc[ens-1,:] = cross_validate_sample(\n",
    "        model, all_data, labels, metrics, strat_split, cv, sampling, \n",
    "        reducer, max_samples, seed=seed, overwrite=overwrite, n_best_delete=best_delete,\n",
    "        recomp=recomp)\n",
    "    #print(results_mean)\n",
    "results_mean = results_mean.add_suffix(\" mean\")\n",
    "results_std = results_std.add_suffix(\" std\")\n",
    "results_full = pd.concat((results_mean, results_std), axis=1)\n",
    "cols = results_full.columns.tolist()\n",
    "new_cols = []\n",
    "for i in range(int(len(cols)/2)):\n",
    "    new_cols.append(cols[i])\n",
    "    new_cols.append(cols[i+int(len(cols)/2)])\n",
    "results_full = results_full[new_cols]\n",
    "red_name = \"ensemble\"\n",
    "if save:\n",
    "    directory = f\"results/{red_name}\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    save_path = f'results/{red_name}/medpfn_maxens{ens_num}'\n",
    "    results_full.to_csv(save_path)\n",
    "print(\"\\n\", \"\\n\", red_name, \"\\n\", results_full.round(3))\n",
    "    #print(results_full.sort_values(\"roc_auc mean\").round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "90749abf-81cc-4bbe-8f85-6f3326524d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    }
   ],
   "source": [
    "ens_num = 20\n",
    "results_full = pd.read_csv(f'results/ensemble/medpfn_maxens{20}')\n",
    "#for i in range(ens_num):\n",
    "x = np.arange(1,1+ens_num)\n",
    "acc = results_full.iloc[:,1]\n",
    "acc_error = results_full.iloc[:,2]\n",
    "roc = results_full.iloc[:,7]\n",
    "roc_error = results_full.iloc[:,8]\n",
    "f1 = results_full.iloc[:,9]\n",
    "f1_error = results_full.iloc[:,10]\n",
    "\n",
    "heights = [1,1,1]\n",
    "mpl.rcParams['axes.linewidth'] = 1.5\n",
    "fig, ax = plt.subplots(3, 1, figsize=(8, 8), gridspec_kw={'height_ratios': heights},sharex=True)\n",
    "\n",
    "colors = [\"teal\", \"darkorange\", \"purple\"]\n",
    "#ax[0].fill_between(x, roc - roc_error, roc + roc_error, alpha=0.25, color=colors[0])\n",
    "#ax[1].fill_between(x, acc - acc_error, acc + acc_error, alpha=0.25,color=colors[1])\n",
    "#ax[2].fill_between(x, f1 - f1_error, f1 + f1_error, alpha=0.25, color=colors[2])\n",
    "ax[1].plot(x, acc, marker=\"v\", linewidth=2.5, markersize=7.0, label='Accuracy', c=colors[1])\n",
    "ax[0].plot(x, roc, marker=\"v\", linewidth=2.5, markersize=7.0, label='ROC AUC', c=colors[0])\n",
    "ax[2].plot(x, f1, marker=\"v\", linewidth=2.5, markersize=7.0, label='F1-score', color=colors[2])\n",
    "\n",
    "ax[0].set_ylim(0.85,0.95)\n",
    "ax[1].set_ylim(0.945,0.955)\n",
    "ax[2].set_ylim(0.15,0.35)\n",
    "ax[0].set_yticks([0.85,0.9,0.95])\n",
    "ax[1].set_yticks([0.945,0.95])\n",
    "ax[2].set_yticks([0.15,0.25])\n",
    "# Adding labels and title\n",
    "ax[0].set_ylabel('ROC AUC')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "ax[2].set_ylabel('$F_1$-score')\n",
    "ax[2].set_xlabel('Ensemble size')\n",
    "ax[2].set_xticks([1,5,10,15,20])\n",
    "#plt.yticks([0.3,0.6,0.9])\n",
    "ax[2].set_xlim(1,20)\n",
    "#plt.ylim(0,1)\n",
    "ax[0].grid()\n",
    "ax[1].grid()\n",
    "ax[2].grid()\n",
    "#plt.ylabel('Metric score')\n",
    "#plt.title('Plot with Uncertainty Band')\n",
    "fig.legend(loc=(0.7,0.65), fontsize=15)\n",
    "plt.subplots_adjust(hspace=0)\n",
    "#plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(\"results/plots/ensemble.eps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c0856f-0ec2-4a8d-8cc9-b8c0cccf7f2c",
   "metadata": {},
   "source": [
    "## Finetuning analysis ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a73c8e1-1139-4049-a448-03f5060243ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 48\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m section \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(runs):\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m#print(section)\u001b[39;00m\n\u001b[0;32m     46\u001b[0m     model \u001b[38;5;241m=\u001b[39m MedPFNClassifier(base_path\u001b[38;5;241m=\u001b[39mpath, filename\u001b[38;5;241m=\u001b[39mfilename, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m, N_ensemble_configurations\u001b[38;5;241m=\u001b[39mN_ens, multiclass_decoder\u001b[38;5;241m=\u001b[39mmulti_decoder,  no_preprocess_mode\u001b[38;5;241m=\u001b[39mno_pre_process,\n\u001b[0;32m     47\u001b[0m             ft_epochs\u001b[38;5;241m=\u001b[39mlrs[ens], ft_lr\u001b[38;5;241m=\u001b[39mft_lr)\n\u001b[1;32m---> 48\u001b[0m     out_mean, out_std \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_sections\u001b[49m\u001b[43m[\u001b[49m\u001b[43msection\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_sections\u001b[49m\u001b[43m[\u001b[49m\u001b[43msection\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrat_split\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreducer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_best_delete\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbest_delete\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrecomp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecomp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m     results_mean\u001b[38;5;241m.\u001b[39miloc[ens,:] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m out_mean\n\u001b[0;32m     53\u001b[0m     results_std\u001b[38;5;241m.\u001b[39miloc[ens,:] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m out_std\n",
      "File \u001b[1;32m~\\Desktop\\MT\\TabPFN-medical\\evaluate.py:79\u001b[0m, in \u001b[0;36mcross_validate_sample\u001b[1;34m(model, X, y, metrics, strat_split, cv, sampling, reducer, max_samples, seed, overwrite, n_best_delete, recomp)\u001b[0m\n\u001b[0;32m     76\u001b[0m     model_clean\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;66;03m#preds = model_clean.predict(X_test)\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m     probs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_clean\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;66;03m#if model_clean.__class__.__name__==\"MedPFNClassifier\":\u001b[39;00m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(probs\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m probs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\Desktop\\MT\\TabPFN-medical\\tabpfn_new\\scripts\\transformer_prediction_interface.py:668\u001b[0m, in \u001b[0;36mMedPFNClassifier.predict_proba\u001b[1;34m(self, X, normalize_with_test, return_logits)\u001b[0m\n\u001b[0;32m    667\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, normalize_with_test\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, return_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 668\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpred_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize_with_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_logits\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\MT\\TabPFN-medical\\tabpfn_new\\scripts\\transformer_prediction_interface.py:284\u001b[0m, in \u001b[0;36mTabPFNClassifier.predict_proba\u001b[1;34m(self, X, normalize_with_test, return_logits)\u001b[0m\n\u001b[0;32m    280\u001b[0m y_full \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(y_full, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    282\u001b[0m eval_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 284\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_full\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_full\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mstyle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstyle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43minference_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mpreprocess_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnone\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_preprocess_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmix\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mclr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mnormalize_with_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalize_with_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mN_ensemble_configurations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mN_ensemble_configurations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43msoftmax_temperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mmulticlass_decoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulticlass_decoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mfeature_shift_decoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_shift_decoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mdifferentiable_hps_as_style\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdifferentiable_hps_as_style\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mreturn_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mno_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mbatch_size_inference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size_inference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m                                 \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mget_params_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m prediction_, y_ \u001b[38;5;241m=\u001b[39m prediction\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m), y_full\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mlong()[eval_pos:]\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prediction_\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad \u001b[38;5;28;01melse\u001b[39;00m prediction_\n",
      "File \u001b[1;32m~\\Desktop\\MT\\TabPFN-medical\\tabpfn_new\\scripts\\transformer_prediction_interface.py:549\u001b[0m, in \u001b[0;36mtransformer_predict\u001b[1;34m(model, eval_xs, eval_ys, eval_position, device, max_features, style, inference_mode, num_classes, extend_features, normalize, clr, normalize_with_test, normalize_to_ranking, softmax_temperature, multiclass_decoder, preprocess_transform, categorical_feats, feature_shift_decoder, N_ensemble_configurations, batch_size_inference, differentiable_hps_as_style, average_logits, fp16_inference, normalize_with_sqrt, seed, no_grad, return_logits, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    546\u001b[0m                             message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of the inputs have requires_grad=True. Gradients will be None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    547\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    548\u001b[0m                             message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 549\u001b[0m     output_batch \u001b[38;5;241m=\u001b[39m \u001b[43mcheckpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msoftmax_temperature_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_reentrant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''if device == 'cpu':\u001b[39;00m\n\u001b[0;32m    551\u001b[0m \u001b[38;5;124;03m        output_batch = checkpoint(predict, batch_input, batch_label, style_, softmax_temperature_, True, use_reentrant=False)\u001b[39;00m\n\u001b[0;32m    552\u001b[0m \u001b[38;5;124;03m    else:\u001b[39;00m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;124;03m        with torch.cuda.amp.autocast(enabled=fp16_inference):\u001b[39;00m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;124;03m            output_batch = checkpoint(predict, batch_input, batch_label, style_, softmax_temperature_, True, use_reentrant=False)'''\u001b[39;00m\n\u001b[0;32m    555\u001b[0m outputs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [output_batch]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master7\\Lib\\site-packages\\torch\\_compile.py:24\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dynamo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master7\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:451\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    449\u001b[0m prior \u001b[38;5;241m=\u001b[39m set_eval_frame(callback)\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    453\u001b[0m     set_eval_frame(prior)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master7\\Lib\\site-packages\\torch\\_dynamo\\external_utils.py:36\u001b[0m, in \u001b[0;36mwrap_inline.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master7\\Lib\\site-packages\\torch\\utils\\checkpoint.py:494\u001b[0m, in \u001b[0;36mcheckpoint\u001b[1;34m(function, use_reentrant, context_fn, determinism_check, debug, *args, **kwargs)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;66;03m# Runs pre-forward logic\u001b[39;00m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28mnext\u001b[39m(gen)\n\u001b[1;32m--> 494\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;66;03m# Runs post-forward logic\u001b[39;00m\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Desktop\\MT\\TabPFN-medical\\tabpfn_new\\scripts\\transformer_prediction_interface.py:379\u001b[0m, in \u001b[0;36mtransformer_predict.<locals>.predict\u001b[1;34m(eval_xs, eval_ys, used_style, softmax_temperature, return_logits)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m inference_mode_call:\n\u001b[0;32m    378\u001b[0m     start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 379\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[43mused_style\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_xs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mused_style\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_xs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_ys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m            \u001b[49m\u001b[43msingle_eval_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_position\u001b[49m\u001b[43m)\u001b[49m[:, :, \u001b[38;5;241m0\u001b[39m:num_classes]\n\u001b[0;32m    382\u001b[0m     output \u001b[38;5;241m=\u001b[39m output[:, :, \u001b[38;5;241m0\u001b[39m:num_classes] \u001b[38;5;241m/\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(softmax_temperature)\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_logits:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master7\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master7\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\MT\\TabPFN-medical\\tabpfn_new\\transformer.py:140\u001b[0m, in \u001b[0;36mTransformerModel.forward\u001b[1;34m(self, src, src_mask, single_eval_pos)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_encoder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    138\u001b[0m     src \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_encoder(src)\n\u001b[1;32m--> 140\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(output)\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output[single_eval_pos\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mlen\u001b[39m(style_src)\u001b[38;5;241m+\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_att_embeddings\u001b[38;5;241m.\u001b[39mnum_embeddings \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_att_embeddings \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m):]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master7\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master7\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\MT\\TabPFN-medical\\tabpfn_new\\transformer.py:226\u001b[0m, in \u001b[0;36mTransformerEncoderDiffInit.forward\u001b[1;34m(self, src, mask, src_key_padding_mask)\u001b[0m\n\u001b[0;32m    223\u001b[0m output \u001b[38;5;241m=\u001b[39m src\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m--> 226\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    229\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(output)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master7\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master7\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master7\\Lib\\site-packages\\tabpfn\\layer.py:108\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[1;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m src_key_padding_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    107\u001b[0m single_eval_position \u001b[38;5;241m=\u001b[39m src_mask\n\u001b[1;32m--> 108\u001b[0m src_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43msingle_eval_position\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43msingle_eval_position\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43msingle_eval_position\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    109\u001b[0m src_right \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn(src_[single_eval_position:], src_[:single_eval_position], src_[:single_eval_position])[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    110\u001b[0m src2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([src_left, src_right], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master7\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master7\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master7\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:1266\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[1;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m   1252\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[0;32m   1253\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[0;32m   1254\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1263\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[0;32m   1264\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[0;32m   1265\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1266\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1268\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1269\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1270\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1275\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[0;32m   1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master7\\Lib\\site-packages\\torch\\nn\\functional.py:5470\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[1;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m   5468\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5469\u001b[0m     attn_output_weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbmm(q_scaled, k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m-> 5470\u001b[0m attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_output_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dropout_p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m   5472\u001b[0m     attn_output_weights \u001b[38;5;241m=\u001b[39m dropout(attn_output_weights, p\u001b[38;5;241m=\u001b[39mdropout_p)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master7\\Lib\\site-packages\\torch\\nn\\functional.py:1885\u001b[0m, in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1883\u001b[0m     dim \u001b[38;5;241m=\u001b[39m _get_softmax_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim(), _stacklevel)\n\u001b[0;32m   1884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1885\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1887\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "save = True\n",
    "sampling = None\n",
    "cv = 10\n",
    "best_delete = 0\n",
    "strat_split = True\n",
    "recomp = False\n",
    "n_optim = 1000\n",
    "cat_optim = 10\n",
    "ft_epochs = 10\n",
    "ft_lr = 1e-5\n",
    "max_s = 1024\n",
    "max_q = 128\n",
    "max_samples = 1024\n",
    "no_pre_process = False\n",
    "multi_decoder = \"permutation\"\n",
    "N_ens = 5\n",
    "seed = 42\n",
    "overwrite = True\n",
    "metrics = [\"accuracy\", \"precision\", \"recall\", \"roc_auc\", \"f1\"]\n",
    "dir_path = os.path.abspath(os.getcwd())\n",
    "run_name = \"small_mlp_var_balance_05weight_anova_bestwithnoisebnn_100\" ## good start, best with ftpath = dir_path + f\"/logs/trainrun_{run_name}\"\n",
    "filename = \"model\"\n",
    "path = dir_path + f\"/logs/trainrun_{run_name}\"\n",
    "ens_num = 10\n",
    "\n",
    "    \n",
    "reducer  = AnovaSelect()\n",
    "\n",
    "results_mean = pd.DataFrame(np.zeros((ens_num, len(metrics)+1)),\n",
    "                            index=np.arange(1,1+ens_num),\n",
    "                            columns=metrics+[\"runtime\"])\n",
    "results_std = pd.DataFrame(np.zeros((ens_num, len(metrics)+1)), \n",
    "                           index=np.arange(1,1+ens_num),\n",
    "                           columns=metrics+[\"runtime\"])\n",
    "\n",
    "lrs = np.arange(0,50,5)\n",
    "size = min(labels.shape[0],np.floor(max_samples*(cv/(cv-1))))\n",
    "runs = int(all_data.shape[0]//size)\n",
    "data_sections, label_sections = stratified_split(all_data, labels,cv=runs)\n",
    "\n",
    "\n",
    "for ens in range(len(lrs)):\n",
    "    print(ens)\n",
    "    for section in range(runs):\n",
    "    #print(section)\n",
    "        model = MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process,\n",
    "                ft_epochs=lrs[ens], ft_lr=ft_lr)\n",
    "        out_mean, out_std = cross_validate_sample(\n",
    "            model, data_sections[section], label_sections[section], metrics, strat_split, cv, sampling, \n",
    "            reducer, max_samples, seed=seed, overwrite=overwrite, n_best_delete=best_delete,\n",
    "            recomp=recomp)\n",
    "        results_mean.iloc[ens,:] += out_mean\n",
    "        results_std.iloc[ens,:] += out_std\n",
    "results_mean=results_mean/runs\n",
    "results_std=results_std/runs\n",
    "    \n",
    "results_mean = results_mean.add_suffix(\" mean\")\n",
    "results_std = results_std.add_suffix(\" std\")\n",
    "results_full = pd.concat((results_mean, results_std), axis=1)\n",
    "cols = results_full.columns.tolist()\n",
    "new_cols = []\n",
    "for i in range(int(len(cols)/2)):\n",
    "    new_cols.append(cols[i])\n",
    "    new_cols.append(cols[i+int(len(cols)/2)])\n",
    "results_full = results_full[new_cols]\n",
    "red_name = \"finetuning\"\n",
    "if save:\n",
    "    directory = f\"results/{red_name}\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    save_path = f'results/{red_name}/new_medpfn_maxsteps{ens_num}_lr{ft_lr}'\n",
    "    results_full.to_csv(save_path)\n",
    "print(\"\\n\", \"\\n\", red_name, \"\\n\", results_full.round(3))\n",
    "    #print(results_full.sort_values(\"roc_auc mean\").round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7ea4aae-125f-4d43-af6b-bfaffa9674c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    }
   ],
   "source": [
    "ens_num = 50\n",
    "results_full = pd.read_csv(f'results/finetuning/new_medpfn_maxsteps{10}_lr{1e-05}')\n",
    "#for i in range(ens_num):\n",
    "x = np.arange(0,ens_num, 5)\n",
    "acc = results_full.iloc[:,1]\n",
    "acc_error = results_full.iloc[:,2]\n",
    "roc = results_full.iloc[:,7]\n",
    "roc_error = results_full.iloc[:,8]\n",
    "f1 = results_full.iloc[:,9]\n",
    "f1_error = results_full.iloc[:,10]\n",
    "\n",
    "heights = [1,1,1]\n",
    "mpl.rcParams['axes.linewidth'] = 1.5\n",
    "fig, ax = plt.subplots(3, 1, figsize=(8, 8), gridspec_kw={'height_ratios': heights},sharex=True)\n",
    "\n",
    "colors = [\"teal\", \"darkorange\", \"purple\"]\n",
    "#ax[0].fill_between(x, roc - roc_error, roc + roc_error, alpha=0.25, color=colors[0])\n",
    "#ax[1].fill_between(x, acc - acc_error, acc + acc_error, alpha=0.25,color=colors[1])\n",
    "#ax[2].fill_between(x, f1 - f1_error, f1 + f1_error, alpha=0.25, color=colors[2])\n",
    "ax[1].plot(x, acc, marker=\"v\", linewidth=2.5, markersize=7.0, label='Accuracy', c=colors[1])\n",
    "ax[0].plot(x, roc, marker=\"v\", linewidth=2.5, markersize=7.0, label='ROC AUC', c=colors[0])\n",
    "ax[2].plot(x, f1, marker=\"v\", linewidth=2.5, markersize=7.0, label='F1-score', color=colors[2])\n",
    "\n",
    "#ax[0].set_ylim(0.9,0.94)\n",
    "#ax[1].set_ylim(0.90,0.98)\n",
    "#ax[2].set_ylim(0.2,0.6)\n",
    "#ax[0].set_yticks([0.9,0.92,0.94])\n",
    "#ax[1].set_yticks([0.90,0.94])\n",
    "#ax[2].set_yticks([0.2,0.4])\n",
    "# Adding labels and title\n",
    "ax[2].set_xlabel('Finetuning iterations')\n",
    "ax[0].set_ylabel('ROC AUC')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "ax[2].set_ylabel('$F_1$-score')\n",
    "#ax[2].set_xticks(np.arange(0,50,10))\n",
    "#plt.yticks([0.3,0.6,0.9])\n",
    "ax[2].set_xlim(0,48)\n",
    "#plt.ylim(0,1)\n",
    "ax[0].grid()\n",
    "ax[1].grid()\n",
    "ax[2].grid()\n",
    "#plt.ylabel('Metric score')\n",
    "#plt.title('Plot with Uncertainty Band')\n",
    "fig.legend(loc=(0.7,0.65), fontsize=15)\n",
    "plt.subplots_adjust(hspace=0)\n",
    "#plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(\"results/plots/finetuning.eps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29f154f-c835-46c7-bc4f-729e8a6bb353",
   "metadata": {},
   "source": [
    "### Feature removal ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f3f2fce-a23e-4370-9c28-15a0e7f6170d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 23:32:57.659\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1203 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:32:59.638\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1255 | Train score: 0.9444 | Val loss: 0.1103 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:01.358\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0809 | Train score: 0.9877 | Val loss: 0.1197 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:03.352\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1320 | Train score: 0.9506 | Val loss: 0.1173 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:05.224\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1549 | Train score: 0.9691 | Val loss: 0.1054 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:07.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1521 | Train score: 0.9691 | Val loss: 0.0990 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:08.764\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1214 | Train score: 0.9691 | Val loss: 0.0981 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:10.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1500 | Train score: 0.9630 | Val loss: 0.0977 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:12.481\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0912 | Train score: 0.9815 | Val loss: 0.0957 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:14.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1409 | Train score: 0.9691 | Val loss: 0.0957 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:16.320\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0896 | Train score: 0.9630 | Val loss: 0.0991 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:18.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1265 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:21.121\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1210 | Train score: 0.9506 | Val loss: 0.1134 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:23.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0902 | Train score: 0.9691 | Val loss: 0.1184 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:24.970\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1738 | Train score: 0.9568 | Val loss: 0.1136 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:26.716\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1768 | Train score: 0.9444 | Val loss: 0.1163 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:28.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1170 | Train score: 0.9630 | Val loss: 0.1187 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:30.407\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0819 | Train score: 0.9691 | Val loss: 0.1205 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:32.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0918 | Train score: 0.9691 | Val loss: 0.1217 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:34.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1166 | Train score: 0.9506 | Val loss: 0.1198 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:35.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1108 | Train score: 0.9568 | Val loss: 0.1195 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:37.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0740 | Train score: 0.9753 | Val loss: 0.1323 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:39.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1796 | Val score: 0.9307\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:41.291\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1250 | Train score: 0.9568 | Val loss: 0.1806 | Val score: 0.9257\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:43.289\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0930 | Train score: 0.9753 | Val loss: 0.2040 | Val score: 0.9257\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:45.727\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0623 | Train score: 0.9815 | Val loss: 0.2331 | Val score: 0.9208\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:48.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1584 | Train score: 0.9630 | Val loss: 0.2261 | Val score: 0.9158\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:50.171\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0800 | Train score: 0.9753 | Val loss: 0.2238 | Val score: 0.9208\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:51.956\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1190 | Train score: 0.9815 | Val loss: 0.2239 | Val score: 0.9208\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:53.682\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1220 | Train score: 0.9568 | Val loss: 0.2165 | Val score: 0.9257\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:55.506\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1142 | Train score: 0.9691 | Val loss: 0.2067 | Val score: 0.9158\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:57.511\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1014 | Train score: 0.9753 | Val loss: 0.2054 | Val score: 0.9208\u001b[0m\n",
      "\u001b[32m2024-11-04 23:33:59.341\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1598 | Train score: 0.9568 | Val loss: 0.1972 | Val score: 0.9208\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:01.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1343 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:02.996\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1259 | Train score: 0.9444 | Val loss: 0.1331 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:05.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1099 | Train score: 0.9506 | Val loss: 0.1403 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:06.874\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1209 | Train score: 0.9506 | Val loss: 0.1430 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:08.752\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1832 | Train score: 0.9198 | Val loss: 0.1390 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:10.511\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0905 | Train score: 0.9568 | Val loss: 0.1395 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:12.302\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0994 | Train score: 0.9444 | Val loss: 0.1423 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:14.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1098 | Train score: 0.9506 | Val loss: 0.1454 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:16.678\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1053 | Train score: 0.9506 | Val loss: 0.1490 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:19.094\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1006 | Train score: 0.9568 | Val loss: 0.1541 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:20.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0934 | Train score: 0.9630 | Val loss: 0.1591 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:22.762\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1050 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:24.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1398 | Train score: 0.9444 | Val loss: 0.0993 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:26.401\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1511 | Train score: 0.9444 | Val loss: 0.0987 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:28.243\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1245 | Train score: 0.9259 | Val loss: 0.0963 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:30.001\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1093 | Train score: 0.9630 | Val loss: 0.0947 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:31.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1037 | Train score: 0.9753 | Val loss: 0.0944 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:33.524\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1418 | Train score: 0.9630 | Val loss: 0.0939 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:35.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1196 | Train score: 0.9630 | Val loss: 0.0932 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:37.409\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1164 | Train score: 0.9630 | Val loss: 0.0946 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:39.359\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1024 | Train score: 0.9815 | Val loss: 0.0961 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:41.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1145 | Train score: 0.9630 | Val loss: 0.0974 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:43.061\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1735 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:45.297\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1186 | Train score: 0.9630 | Val loss: 0.1603 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:47.803\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0948 | Train score: 0.9630 | Val loss: 0.1601 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:50.184\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0867 | Train score: 0.9691 | Val loss: 0.1588 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:51.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0976 | Train score: 0.9691 | Val loss: 0.1618 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:53.688\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1210 | Train score: 0.9691 | Val loss: 0.1639 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:55.515\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0816 | Train score: 0.9815 | Val loss: 0.1620 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:57.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0592 | Train score: 0.9815 | Val loss: 0.1620 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:34:59.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1008 | Train score: 0.9630 | Val loss: 0.1608 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:02.118\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0874 | Train score: 0.9691 | Val loss: 0.1596 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:04.319\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0618 | Train score: 0.9815 | Val loss: 0.1591 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:06.123\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1321 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:08.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1506 | Train score: 0.9691 | Val loss: 0.1402 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:10.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1440 | Train score: 0.9444 | Val loss: 0.1381 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:12.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1129 | Train score: 0.9568 | Val loss: 0.1391 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:14.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0721 | Train score: 0.9753 | Val loss: 0.1408 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:16.515\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0671 | Train score: 0.9691 | Val loss: 0.1476 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:19.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1118 | Train score: 0.9691 | Val loss: 0.1485 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:21.477\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1006 | Train score: 0.9630 | Val loss: 0.1459 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:23.470\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1614 | Train score: 0.9444 | Val loss: 0.1422 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:25.516\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1016 | Train score: 0.9568 | Val loss: 0.1391 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:27.580\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0904 | Train score: 0.9691 | Val loss: 0.1378 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:29.295\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1156 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:31.104\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1428 | Train score: 0.9321 | Val loss: 0.1055 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:32.970\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1358 | Train score: 0.9321 | Val loss: 0.1139 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:34.770\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1042 | Train score: 0.9506 | Val loss: 0.1090 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:36.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1280 | Train score: 0.9568 | Val loss: 0.1083 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:38.491\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1495 | Train score: 0.9444 | Val loss: 0.1084 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:40.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0874 | Train score: 0.9691 | Val loss: 0.1077 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:42.278\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1119 | Train score: 0.9506 | Val loss: 0.1069 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:44.131\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1275 | Train score: 0.9630 | Val loss: 0.1076 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:46.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1404 | Train score: 0.9506 | Val loss: 0.1100 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:49.104\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1089 | Train score: 0.9568 | Val loss: 0.1121 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:50.993\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1410 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:52.795\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1551 | Train score: 0.9444 | Val loss: 0.1391 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:54.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1105 | Train score: 0.9506 | Val loss: 0.1389 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:56.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0955 | Train score: 0.9506 | Val loss: 0.1404 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:35:58.315\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0786 | Train score: 0.9506 | Val loss: 0.1460 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:36:00.363\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1205 | Train score: 0.9753 | Val loss: 0.1484 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:36:02.227\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1037 | Train score: 0.9691 | Val loss: 0.1489 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:36:04.072\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1056 | Train score: 0.9753 | Val loss: 0.1477 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:36:06.042\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1057 | Train score: 0.9630 | Val loss: 0.1464 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:36:08.030\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0943 | Train score: 0.9691 | Val loss: 0.1454 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:36:09.908\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0809 | Train score: 0.9691 | Val loss: 0.1454 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:36:11.809\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1100 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:36:13.682\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1447 | Train score: 0.9630 | Val loss: 0.1086 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:36:15.787\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0897 | Train score: 0.9506 | Val loss: 0.1054 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:36:18.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0884 | Train score: 0.9630 | Val loss: 0.1056 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:36:20.656\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0930 | Train score: 0.9691 | Val loss: 0.1065 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:36:22.470\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1169 | Train score: 0.9691 | Val loss: 0.1065 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:36:24.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0886 | Train score: 0.9691 | Val loss: 0.1066 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:36:26.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1003 | Train score: 0.9691 | Val loss: 0.1061 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:36:28.247\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0873 | Train score: 0.9815 | Val loss: 0.1058 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:36:30.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1203 | Train score: 0.9568 | Val loss: 0.1063 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:36:31.965\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1332 | Train score: 0.9506 | Val loss: 0.1073 | Val score: 0.9604\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " 0 \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.946         0.000           0.000          0.000        0.000       0.000         0.500        0.000    0.000   0.000         0.000        0.000\n",
      "MedPFNClassifier                      0.947         0.006           0.400          0.436        0.117       0.130         0.870        0.071    0.166   0.170         0.722        0.299\n",
      "MedPFNClassifier                      0.950         0.008           0.533          0.393        0.200       0.145         0.919        0.055    0.276   0.191         2.673        0.387\n",
      "MedPFNClassifier                      0.949         0.010           0.552          0.117        0.417       0.171         0.917        0.061    0.456   0.105        21.327        2.060\n",
      "RandomForestClassifier                0.950         0.013           0.350          0.391        0.183       0.217         0.893        0.066    0.235   0.268         0.209        0.021\n",
      "LogisticRegressionClassifier          0.939         0.014           0.393          0.245        0.217       0.150         0.825        0.096    0.269   0.169         0.010        0.005\n",
      "TabPFNClassifier                      0.946         0.018           0.373          0.397        0.200       0.194         0.906        0.057    0.259   0.261         2.951        0.279\n",
      "TabForestPFNClassifier                0.938         0.016           0.402          0.193        0.367       0.163         0.884        0.046    0.376   0.169        21.326        0.926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 23:39:43.577\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1255 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:39:45.764\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1584 | Train score: 0.9506 | Val loss: 0.1346 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:39:48.115\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1418 | Train score: 0.9383 | Val loss: 0.1195 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:39:50.261\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1207 | Train score: 0.9444 | Val loss: 0.1150 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:39:51.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1021 | Train score: 0.9691 | Val loss: 0.1165 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:39:53.757\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1086 | Train score: 0.9630 | Val loss: 0.1178 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:39:55.757\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0887 | Train score: 0.9691 | Val loss: 0.1164 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:39:57.701\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1769 | Train score: 0.9506 | Val loss: 0.1146 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:39:59.554\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1621 | Train score: 0.9506 | Val loss: 0.1127 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:01.363\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1309 | Train score: 0.9568 | Val loss: 0.1117 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:03.741\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1279 | Train score: 0.9568 | Val loss: 0.1117 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:06.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1501 | Val score: 0.9307\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:08.165\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1249 | Train score: 0.9383 | Val loss: 0.1432 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:09.943\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1057 | Train score: 0.9630 | Val loss: 0.1439 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:11.850\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1510 | Train score: 0.9506 | Val loss: 0.1391 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:13.738\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1100 | Train score: 0.9630 | Val loss: 0.1360 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:16.084\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1307 | Train score: 0.9506 | Val loss: 0.1344 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:18.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1209 | Train score: 0.9691 | Val loss: 0.1350 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:20.685\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1004 | Train score: 0.9630 | Val loss: 0.1381 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:22.494\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0932 | Train score: 0.9630 | Val loss: 0.1376 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:24.309\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0648 | Train score: 0.9877 | Val loss: 0.1366 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:26.222\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1291 | Train score: 0.9630 | Val loss: 0.1367 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:28.041\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1128 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:30.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1210 | Train score: 0.9444 | Val loss: 0.1009 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:32.234\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1189 | Train score: 0.9506 | Val loss: 0.0999 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:34.278\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1180 | Train score: 0.9568 | Val loss: 0.0991 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:36.325\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1684 | Train score: 0.9568 | Val loss: 0.1022 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:38.357\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1474 | Train score: 0.9630 | Val loss: 0.1055 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:40.385\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1371 | Train score: 0.9568 | Val loss: 0.1081 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:42.385\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1383 | Train score: 0.9568 | Val loss: 0.1096 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:44.338\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1414 | Train score: 0.9444 | Val loss: 0.1099 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:46.576\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1403 | Train score: 0.9630 | Val loss: 0.1100 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:49.093\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1061 | Train score: 0.9691 | Val loss: 0.1085 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:51.216\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1103 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:53.232\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1414 | Train score: 0.9444 | Val loss: 0.0955 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:55.261\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1020 | Train score: 0.9444 | Val loss: 0.0940 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:57.273\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1806 | Train score: 0.9506 | Val loss: 0.0958 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:40:59.371\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1106 | Train score: 0.9568 | Val loss: 0.0950 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:01.475\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1010 | Train score: 0.9506 | Val loss: 0.0939 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:03.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1003 | Train score: 0.9630 | Val loss: 0.0923 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:05.355\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1371 | Train score: 0.9506 | Val loss: 0.0934 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:07.566\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1100 | Train score: 0.9630 | Val loss: 0.0948 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:10.332\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0717 | Train score: 0.9630 | Val loss: 0.0964 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:12.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0786 | Train score: 0.9815 | Val loss: 0.0980 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:15.126\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1243 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:17.805\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1232 | Train score: 0.9630 | Val loss: 0.1195 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:20.839\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0945 | Train score: 0.9568 | Val loss: 0.1207 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:23.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0713 | Train score: 0.9753 | Val loss: 0.1258 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:26.317\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1383 | Train score: 0.9568 | Val loss: 0.1231 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:28.791\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1726 | Train score: 0.9383 | Val loss: 0.1190 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:31.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1763 | Train score: 0.9506 | Val loss: 0.1175 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:34.188\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0660 | Train score: 0.9691 | Val loss: 0.1190 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:36.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1207 | Train score: 0.9506 | Val loss: 0.1195 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:38.216\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0721 | Train score: 0.9630 | Val loss: 0.1194 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:40.098\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0797 | Train score: 0.9753 | Val loss: 0.1194 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:42.027\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1383 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:43.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1590 | Train score: 0.9506 | Val loss: 0.1425 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:46.092\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1411 | Train score: 0.9630 | Val loss: 0.1433 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:48.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1283 | Train score: 0.9568 | Val loss: 0.1392 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:51.185\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0977 | Train score: 0.9630 | Val loss: 0.1409 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:54.331\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1038 | Train score: 0.9630 | Val loss: 0.1430 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:57.471\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.2067 | Train score: 0.9444 | Val loss: 0.1439 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:41:59.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1171 | Train score: 0.9568 | Val loss: 0.1433 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:01.881\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1397 | Train score: 0.9568 | Val loss: 0.1418 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:03.854\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1035 | Train score: 0.9753 | Val loss: 0.1405 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:05.595\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1040 | Train score: 0.9691 | Val loss: 0.1399 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:07.481\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1459 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:09.752\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1490 | Train score: 0.9444 | Val loss: 0.1386 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:11.293\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1391 | Train score: 0.9506 | Val loss: 0.1357 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:13.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0938 | Train score: 0.9753 | Val loss: 0.1342 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:15.001\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0854 | Train score: 0.9691 | Val loss: 0.1344 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:16.929\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1005 | Train score: 0.9506 | Val loss: 0.1366 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:18.898\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1122 | Train score: 0.9630 | Val loss: 0.1377 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:21.024\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0529 | Train score: 0.9877 | Val loss: 0.1406 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:22.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0882 | Train score: 0.9753 | Val loss: 0.1438 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:24.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0661 | Train score: 0.9815 | Val loss: 0.1464 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:25.950\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1451 | Train score: 0.9630 | Val loss: 0.1448 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:27.583\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1158 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:29.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1569 | Train score: 0.9383 | Val loss: 0.1169 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:30.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1410 | Train score: 0.9444 | Val loss: 0.1116 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:32.536\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1275 | Train score: 0.9383 | Val loss: 0.1044 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:34.497\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1299 | Train score: 0.9506 | Val loss: 0.1003 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:36.433\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1269 | Train score: 0.9753 | Val loss: 0.0993 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:38.194\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1234 | Train score: 0.9568 | Val loss: 0.1009 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:39.840\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1297 | Train score: 0.9506 | Val loss: 0.1040 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:41.669\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0741 | Train score: 0.9691 | Val loss: 0.1037 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:43.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1882 | Train score: 0.9568 | Val loss: 0.1040 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:45.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1653 | Train score: 0.9630 | Val loss: 0.1061 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:47.928\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1413 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:49.980\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1154 | Train score: 0.9383 | Val loss: 0.1347 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:52.370\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0918 | Train score: 0.9691 | Val loss: 0.1384 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:55.161\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1310 | Train score: 0.9444 | Val loss: 0.1388 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:42:58.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1112 | Train score: 0.9506 | Val loss: 0.1378 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:43:00.350\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1303 | Train score: 0.9506 | Val loss: 0.1363 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:43:02.678\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1014 | Train score: 0.9815 | Val loss: 0.1341 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:43:05.527\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1094 | Train score: 0.9753 | Val loss: 0.1320 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:43:08.502\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1031 | Train score: 0.9630 | Val loss: 0.1304 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:43:11.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1661 | Train score: 0.9506 | Val loss: 0.1290 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:43:13.714\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1760 | Train score: 0.9444 | Val loss: 0.1283 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:43:16.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1169 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:43:18.918\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1410 | Train score: 0.9444 | Val loss: 0.1081 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:43:21.426\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1361 | Train score: 0.9506 | Val loss: 0.1076 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 23:43:23.962\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1217 | Train score: 0.9568 | Val loss: 0.1080 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:43:26.487\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1091 | Train score: 0.9568 | Val loss: 0.1090 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 23:43:29.099\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1170 | Train score: 0.9630 | Val loss: 0.1117 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:43:31.688\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1218 | Train score: 0.9568 | Val loss: 0.1164 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:43:34.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1531 | Train score: 0.9630 | Val loss: 0.1175 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:43:36.719\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1085 | Train score: 0.9568 | Val loss: 0.1171 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:43:39.315\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0828 | Train score: 0.9753 | Val loss: 0.1158 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:43:41.786\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0985 | Train score: 0.9630 | Val loss: 0.1148 | Val score: 0.9653\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " 1 \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.946         0.000           0.000          0.000        0.000       0.000         0.500        0.000    0.000   0.000         0.000        0.000\n",
      "MedPFNClassifier                      0.941         0.004           0.167          0.211        0.067       0.082         0.822        0.069    0.094   0.116         0.297        0.011\n",
      "MedPFNClassifier                      0.949         0.011           0.513          0.397        0.217       0.150         0.890        0.046    0.290   0.200         1.926        0.170\n",
      "MedPFNClassifier                      0.949         0.011           0.600          0.169        0.433       0.153         0.892        0.051    0.466   0.097        13.004        0.472\n",
      "RandomForestClassifier                0.943         0.006           0.240          0.329        0.100       0.133         0.877        0.075    0.130   0.164         0.199        0.014\n",
      "LogisticRegressionClassifier          0.934         0.016           0.335          0.244        0.200       0.125         0.756        0.097    0.245   0.159         0.008        0.001\n",
      "TabPFNClassifier                      0.945         0.015           0.423          0.378        0.183       0.138         0.893        0.048    0.250   0.199         2.915        0.231\n",
      "TabForestPFNClassifier                0.931         0.025           0.379          0.301        0.300       0.180         0.875        0.036    0.317   0.197        23.708        2.885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 23:47:51.978\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1266 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:47:54.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1073 | Train score: 0.9630 | Val loss: 0.1258 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:47:57.209\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1581 | Train score: 0.9383 | Val loss: 0.1229 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:47:59.518\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0755 | Train score: 0.9630 | Val loss: 0.1236 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:01.852\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1184 | Train score: 0.9568 | Val loss: 0.1239 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:04.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1333 | Train score: 0.9506 | Val loss: 0.1209 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:06.417\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1058 | Train score: 0.9630 | Val loss: 0.1185 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:08.678\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1311 | Train score: 0.9506 | Val loss: 0.1173 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:10.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1022 | Train score: 0.9568 | Val loss: 0.1173 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:13.222\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1083 | Train score: 0.9691 | Val loss: 0.1175 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:15.633\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0979 | Train score: 0.9691 | Val loss: 0.1176 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:17.794\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1381 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:20.150\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1223 | Train score: 0.9383 | Val loss: 0.1450 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:22.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1094 | Train score: 0.9444 | Val loss: 0.1448 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:24.790\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1143 | Train score: 0.9568 | Val loss: 0.1322 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:27.140\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1613 | Train score: 0.9506 | Val loss: 0.1157 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:29.508\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0997 | Train score: 0.9691 | Val loss: 0.1104 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:31.956\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1304 | Train score: 0.9568 | Val loss: 0.1078 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:34.447\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1306 | Train score: 0.9568 | Val loss: 0.1070 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:37.013\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1088 | Train score: 0.9506 | Val loss: 0.1075 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:39.371\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1063 | Train score: 0.9630 | Val loss: 0.1083 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:41.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1048 | Train score: 0.9568 | Val loss: 0.1089 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:43.868\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1083 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:46.184\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1239 | Train score: 0.9568 | Val loss: 0.1040 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:48.635\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1143 | Train score: 0.9568 | Val loss: 0.1053 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:51.024\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1497 | Train score: 0.9568 | Val loss: 0.1031 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:53.242\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0891 | Train score: 0.9815 | Val loss: 0.1008 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:55.481\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0992 | Train score: 0.9630 | Val loss: 0.0987 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:48:57.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1750 | Train score: 0.9383 | Val loss: 0.0975 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:00.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1404 | Train score: 0.9691 | Val loss: 0.0977 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:02.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1583 | Train score: 0.9568 | Val loss: 0.0990 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:04.718\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0687 | Train score: 0.9815 | Val loss: 0.0991 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:07.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0855 | Train score: 0.9691 | Val loss: 0.0991 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:09.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1193 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:11.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1512 | Train score: 0.9506 | Val loss: 0.1241 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:14.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1177 | Train score: 0.9444 | Val loss: 0.1172 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:16.961\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1071 | Train score: 0.9444 | Val loss: 0.1129 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:19.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1422 | Train score: 0.9259 | Val loss: 0.1107 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:23.310\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0876 | Train score: 0.9568 | Val loss: 0.1085 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:25.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1264 | Train score: 0.9630 | Val loss: 0.1062 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:28.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0853 | Train score: 0.9630 | Val loss: 0.1064 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:30.975\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0836 | Train score: 0.9630 | Val loss: 0.1146 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:33.373\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1003 | Train score: 0.9691 | Val loss: 0.1129 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:35.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1259 | Train score: 0.9568 | Val loss: 0.1072 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:38.076\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1161 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:40.674\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1058 | Train score: 0.9568 | Val loss: 0.1044 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:43.091\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1297 | Train score: 0.9568 | Val loss: 0.1040 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:45.574\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0922 | Train score: 0.9506 | Val loss: 0.1025 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:48.148\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1460 | Train score: 0.9630 | Val loss: 0.1008 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:50.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0879 | Train score: 0.9753 | Val loss: 0.0999 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:53.013\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1360 | Train score: 0.9691 | Val loss: 0.0999 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:54.756\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0971 | Train score: 0.9815 | Val loss: 0.1003 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:56.730\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0964 | Train score: 0.9568 | Val loss: 0.1021 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:49:58.767\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1222 | Train score: 0.9630 | Val loss: 0.1033 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:00.845\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0924 | Train score: 0.9630 | Val loss: 0.1041 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:02.549\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1456 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:04.237\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1104 | Train score: 0.9444 | Val loss: 0.1548 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:05.968\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1249 | Train score: 0.9691 | Val loss: 0.1660 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:07.799\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1004 | Train score: 0.9568 | Val loss: 0.1758 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:09.537\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0685 | Train score: 0.9815 | Val loss: 0.1921 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:11.114\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1866 | Train score: 0.9506 | Val loss: 0.1834 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:12.744\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0779 | Train score: 0.9691 | Val loss: 0.1797 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:14.370\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0963 | Train score: 0.9630 | Val loss: 0.1787 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:15.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0872 | Train score: 0.9691 | Val loss: 0.1808 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:17.739\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0856 | Train score: 0.9815 | Val loss: 0.1845 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:19.702\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1534 | Train score: 0.9691 | Val loss: 0.1868 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:21.673\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1563 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:23.778\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1429 | Train score: 0.9444 | Val loss: 0.1495 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:25.679\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1204 | Train score: 0.9630 | Val loss: 0.1461 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:27.740\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1319 | Train score: 0.9630 | Val loss: 0.1450 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:29.737\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0987 | Train score: 0.9630 | Val loss: 0.1495 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:31.785\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1049 | Train score: 0.9691 | Val loss: 0.1558 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:33.748\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1061 | Train score: 0.9630 | Val loss: 0.1598 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:35.543\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1245 | Train score: 0.9506 | Val loss: 0.1536 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:37.373\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0759 | Train score: 0.9815 | Val loss: 0.1535 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:39.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1049 | Train score: 0.9753 | Val loss: 0.1538 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:41.148\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0890 | Train score: 0.9691 | Val loss: 0.1529 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:42.878\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1144 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:44.584\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1489 | Train score: 0.9630 | Val loss: 0.1167 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:46.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1477 | Train score: 0.9691 | Val loss: 0.1194 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:47.840\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1408 | Train score: 0.9444 | Val loss: 0.1170 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:49.425\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1414 | Train score: 0.9568 | Val loss: 0.1172 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:51.170\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1319 | Train score: 0.9753 | Val loss: 0.1158 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:52.839\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0728 | Train score: 0.9815 | Val loss: 0.1163 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:54.482\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0955 | Train score: 0.9630 | Val loss: 0.1197 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:56.169\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1128 | Train score: 0.9630 | Val loss: 0.1245 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:57.879\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1459 | Train score: 0.9506 | Val loss: 0.1299 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:50:59.506\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0754 | Train score: 0.9753 | Val loss: 0.1345 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:51:01.266\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1631 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:51:02.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1307 | Train score: 0.9506 | Val loss: 0.1657 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:51:04.358\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1570 | Train score: 0.9444 | Val loss: 0.1608 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:51:05.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1081 | Train score: 0.9630 | Val loss: 0.1619 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:51:07.549\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1369 | Train score: 0.9506 | Val loss: 0.1627 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:51:09.209\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1211 | Train score: 0.9506 | Val loss: 0.1644 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:51:10.943\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1188 | Train score: 0.9383 | Val loss: 0.1666 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:51:12.543\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1364 | Train score: 0.9568 | Val loss: 0.1665 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:51:14.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1645 | Train score: 0.9444 | Val loss: 0.1624 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:51:16.294\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1154 | Train score: 0.9630 | Val loss: 0.1591 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:51:17.955\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1059 | Train score: 0.9691 | Val loss: 0.1566 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:51:19.814\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1367 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:51:21.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1871 | Train score: 0.9444 | Val loss: 0.1487 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:51:23.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1525 | Train score: 0.9444 | Val loss: 0.1420 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:51:25.571\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1316 | Train score: 0.9444 | Val loss: 0.1316 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:51:27.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1205 | Train score: 0.9815 | Val loss: 0.1221 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:51:29.377\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1884 | Train score: 0.9506 | Val loss: 0.1188 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:51:31.193\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1168 | Train score: 0.9630 | Val loss: 0.1170 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:51:32.902\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1479 | Train score: 0.9506 | Val loss: 0.1167 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:51:34.581\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1279 | Train score: 0.9630 | Val loss: 0.1173 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:51:36.121\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1128 | Train score: 0.9630 | Val loss: 0.1180 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:51:37.704\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1228 | Train score: 0.9630 | Val loss: 0.1190 | Val score: 0.9653\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " 5 \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.946         0.000           0.000          0.000        0.000       0.000         0.500        0.000    0.000   0.000         0.000        0.000\n",
      "MedPFNClassifier                      0.945         0.004           0.000          0.000        0.000       0.000         0.787        0.056    0.000   0.000         0.417        0.043\n",
      "MedPFNClassifier                      0.946         0.011           0.483          0.410        0.150       0.117         0.848        0.051    0.215   0.161         2.217        0.073\n",
      "MedPFNClassifier                      0.953         0.011           0.611          0.191        0.417       0.154         0.839        0.054    0.477   0.127        17.612        1.621\n",
      "RandomForestClassifier                0.938         0.010           0.100          0.200        0.033       0.067         0.858        0.085    0.050   0.100         0.214        0.014\n",
      "LogisticRegressionClassifier          0.942         0.013           0.390          0.253        0.250       0.171         0.744        0.119    0.301   0.202         0.010        0.001\n",
      "TabPFNClassifier                      0.941         0.012           0.323          0.260        0.150       0.117         0.844        0.060    0.200   0.157         3.642        0.063\n",
      "TabForestPFNClassifier                0.931         0.027           0.384          0.268        0.283       0.183         0.836        0.080    0.314   0.210        22.460        3.603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-04 23:54:38.148\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1831 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:54:40.109\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1067 | Train score: 0.9630 | Val loss: 0.1907 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 23:54:42.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0974 | Train score: 0.9630 | Val loss: 0.1916 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 23:54:44.863\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0719 | Train score: 0.9753 | Val loss: 0.2005 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 23:54:46.814\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0878 | Train score: 0.9630 | Val loss: 0.2146 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:54:49.128\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1039 | Train score: 0.9753 | Val loss: 0.2154 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:54:51.331\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1057 | Train score: 0.9630 | Val loss: 0.2086 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:54:53.227\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0526 | Train score: 0.9815 | Val loss: 0.2107 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:54:55.012\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0506 | Train score: 0.9815 | Val loss: 0.2192 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:54:56.804\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0717 | Train score: 0.9691 | Val loss: 0.2276 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 23:54:58.684\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0520 | Train score: 0.9815 | Val loss: 0.2437 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:00.515\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1437 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:02.458\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1443 | Train score: 0.9444 | Val loss: 0.1461 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:04.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1349 | Train score: 0.9568 | Val loss: 0.1478 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:05.895\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1121 | Train score: 0.9630 | Val loss: 0.1511 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:07.571\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0964 | Train score: 0.9691 | Val loss: 0.1534 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:09.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0896 | Train score: 0.9815 | Val loss: 0.1531 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:10.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1189 | Train score: 0.9630 | Val loss: 0.1466 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:12.738\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1856 | Train score: 0.9444 | Val loss: 0.1395 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:14.326\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0830 | Train score: 0.9753 | Val loss: 0.1370 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:16.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1056 | Train score: 0.9630 | Val loss: 0.1363 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:17.879\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0916 | Train score: 0.9753 | Val loss: 0.1358 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:19.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1016 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:21.745\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1810 | Train score: 0.9506 | Val loss: 0.1125 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:23.658\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1443 | Train score: 0.9444 | Val loss: 0.1051 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:25.762\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1484 | Train score: 0.9444 | Val loss: 0.0980 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:27.629\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1640 | Train score: 0.9444 | Val loss: 0.0949 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:29.579\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1089 | Train score: 0.9444 | Val loss: 0.0889 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:31.545\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1366 | Train score: 0.9444 | Val loss: 0.0857 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:33.409\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1042 | Train score: 0.9630 | Val loss: 0.0835 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:35.047\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1272 | Train score: 0.9630 | Val loss: 0.0832 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:36.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1105 | Train score: 0.9630 | Val loss: 0.0847 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:38.936\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1250 | Train score: 0.9753 | Val loss: 0.0858 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:40.542\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1761 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:42.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.0979 | Train score: 0.9506 | Val loss: 0.2008 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:43.673\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1216 | Train score: 0.9506 | Val loss: 0.1995 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:45.322\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0883 | Train score: 0.9568 | Val loss: 0.2014 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:47.062\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.0934 | Train score: 0.9753 | Val loss: 0.2026 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:48.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1059 | Train score: 0.9753 | Val loss: 0.1942 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:50.414\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0588 | Train score: 0.9753 | Val loss: 0.1904 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:51.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1068 | Train score: 0.9691 | Val loss: 0.1746 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:53.640\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0951 | Train score: 0.9753 | Val loss: 0.1628 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:55.497\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0683 | Train score: 0.9753 | Val loss: 0.1577 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:57.364\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0993 | Train score: 0.9691 | Val loss: 0.1559 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:55:59.041\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1110 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:00.864\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1616 | Train score: 0.9383 | Val loss: 0.1136 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:03.755\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1394 | Train score: 0.9383 | Val loss: 0.1088 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:05.412\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1522 | Train score: 0.9630 | Val loss: 0.1056 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:07.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1333 | Train score: 0.9691 | Val loss: 0.1029 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:08.515\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1228 | Train score: 0.9568 | Val loss: 0.0992 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:10.039\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1084 | Train score: 0.9506 | Val loss: 0.0966 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:11.771\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1079 | Train score: 0.9630 | Val loss: 0.0929 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:13.349\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1107 | Train score: 0.9568 | Val loss: 0.0883 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:15.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0828 | Train score: 0.9568 | Val loss: 0.0871 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:17.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1015 | Train score: 0.9691 | Val loss: 0.0903 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:19.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1131 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:21.413\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1324 | Train score: 0.9506 | Val loss: 0.1108 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:23.317\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1087 | Train score: 0.9630 | Val loss: 0.1123 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:25.214\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1438 | Train score: 0.9506 | Val loss: 0.1102 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:26.980\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1052 | Train score: 0.9753 | Val loss: 0.1073 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:28.822\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1417 | Train score: 0.9568 | Val loss: 0.1066 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:30.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0890 | Train score: 0.9815 | Val loss: 0.1077 | Val score: 0.9752\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:32.827\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0849 | Train score: 0.9691 | Val loss: 0.1098 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:35.210\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0695 | Train score: 0.9877 | Val loss: 0.1123 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:37.827\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0944 | Train score: 0.9630 | Val loss: 0.1145 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:40.961\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1084 | Train score: 0.9630 | Val loss: 0.1168 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:46.942\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1306 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:51.305\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1425 | Train score: 0.9568 | Val loss: 0.1242 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:53.436\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1146 | Train score: 0.9568 | Val loss: 0.1230 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:55.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1372 | Train score: 0.9506 | Val loss: 0.1242 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:57.411\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1552 | Train score: 0.9630 | Val loss: 0.1230 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:56:59.294\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1141 | Train score: 0.9630 | Val loss: 0.1230 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-04 23:57:01.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1265 | Train score: 0.9691 | Val loss: 0.1233 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:57:05.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1112 | Train score: 0.9630 | Val loss: 0.1246 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:57:10.049\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0916 | Train score: 0.9753 | Val loss: 0.1267 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:57:13.408\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1284 | Train score: 0.9691 | Val loss: 0.1295 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:57:17.235\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1138 | Train score: 0.9630 | Val loss: 0.1318 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:57:20.183\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1298 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:57:23.029\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1763 | Train score: 0.9444 | Val loss: 0.1432 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:57:25.806\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1473 | Train score: 0.9444 | Val loss: 0.1318 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:57:28.730\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1351 | Train score: 0.9383 | Val loss: 0.1286 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:57:31.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1345 | Train score: 0.9568 | Val loss: 0.1291 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:57:34.001\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1271 | Train score: 0.9383 | Val loss: 0.1328 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:57:36.693\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1199 | Train score: 0.9691 | Val loss: 0.1377 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:57:39.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1156 | Train score: 0.9691 | Val loss: 0.1445 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:57:42.644\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1029 | Train score: 0.9506 | Val loss: 0.1482 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:57:45.050\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1515 | Train score: 0.9568 | Val loss: 0.1461 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 23:57:47.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1459 | Train score: 0.9444 | Val loss: 0.1419 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-04 23:57:48.951\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1571 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:57:51.085\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1275 | Train score: 0.9321 | Val loss: 0.1602 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-04 23:57:53.158\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1083 | Train score: 0.9568 | Val loss: 0.1804 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:57:55.122\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1255 | Train score: 0.9568 | Val loss: 0.1804 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:57:57.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1774 | Train score: 0.9568 | Val loss: 0.1679 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:57:59.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1240 | Train score: 0.9630 | Val loss: 0.1603 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:58:00.514\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1082 | Train score: 0.9506 | Val loss: 0.1588 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:58:02.157\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0964 | Train score: 0.9568 | Val loss: 0.1617 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:58:03.698\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0666 | Train score: 0.9753 | Val loss: 0.1693 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:58:05.241\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1344 | Train score: 0.9691 | Val loss: 0.1744 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:58:07.083\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1093 | Train score: 0.9506 | Val loss: 0.1740 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:58:08.688\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1986 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:58:10.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1163 | Train score: 0.9630 | Val loss: 0.2157 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:58:12.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.0906 | Train score: 0.9630 | Val loss: 0.2353 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:58:13.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.0808 | Train score: 0.9815 | Val loss: 0.2629 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:58:15.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1805 | Train score: 0.9630 | Val loss: 0.2311 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-04 23:58:16.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0938 | Train score: 0.9568 | Val loss: 0.2095 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:58:18.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0885 | Train score: 0.9815 | Val loss: 0.2021 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-04 23:58:19.965\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1233 | Train score: 0.9630 | Val loss: 0.1982 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:58:21.654\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0899 | Train score: 0.9691 | Val loss: 0.2087 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:58:23.327\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0857 | Train score: 0.9691 | Val loss: 0.2012 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-04 23:58:24.858\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0839 | Train score: 0.9753 | Val loss: 0.1929 | Val score: 0.9406\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " 10 \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.946         0.000           0.000          0.000        0.000       0.000         0.500        0.000    0.000   0.000         0.000        0.000\n",
      "MedPFNClassifier                      0.946         0.003           0.000          0.000        0.000       0.000         0.781        0.066    0.000   0.000         0.285        0.035\n",
      "MedPFNClassifier                      0.941         0.017           0.383          0.409        0.117       0.130         0.839        0.061    0.171   0.181         1.698        0.127\n",
      "MedPFNClassifier                      0.951         0.011           0.503          0.194        0.433       0.238         0.837        0.066    0.450   0.195        12.035        0.735\n",
      "RandomForestClassifier                0.941         0.006           0.158          0.206        0.067       0.082         0.860        0.084    0.092   0.114         0.210        0.013\n",
      "LogisticRegressionClassifier          0.939         0.011           0.345          0.216        0.267       0.186         0.728        0.059    0.299   0.198         0.008        0.001\n",
      "TabPFNClassifier                      0.942         0.013           0.273          0.350        0.117       0.130         0.847        0.065    0.154   0.175         2.907        0.220\n",
      "TabForestPFNClassifier                0.933         0.025           0.417          0.271        0.333       0.167         0.857        0.056    0.355   0.191        22.537        5.077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:01:00.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1494 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:01.687\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1376 | Train score: 0.9383 | Val loss: 0.1542 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:03.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1391 | Train score: 0.9444 | Val loss: 0.1489 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:04.719\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1195 | Train score: 0.9444 | Val loss: 0.1482 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:06.172\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1755 | Train score: 0.9506 | Val loss: 0.1460 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:07.634\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1439 | Train score: 0.9568 | Val loss: 0.1447 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:09.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1060 | Train score: 0.9630 | Val loss: 0.1442 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:10.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1022 | Train score: 0.9630 | Val loss: 0.1441 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:12.374\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1206 | Train score: 0.9506 | Val loss: 0.1439 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:13.905\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0734 | Train score: 0.9753 | Val loss: 0.1438 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:15.372\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1123 | Train score: 0.9630 | Val loss: 0.1437 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:16.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1559 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:18.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1565 | Train score: 0.9444 | Val loss: 0.1500 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:19.921\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1686 | Train score: 0.9568 | Val loss: 0.1522 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:21.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1809 | Train score: 0.9383 | Val loss: 0.1494 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:22.960\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1890 | Train score: 0.9444 | Val loss: 0.1482 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:24.391\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1367 | Train score: 0.9506 | Val loss: 0.1470 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:25.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1320 | Train score: 0.9691 | Val loss: 0.1467 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:27.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1434 | Train score: 0.9506 | Val loss: 0.1434 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:28.861\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0979 | Train score: 0.9630 | Val loss: 0.1428 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:30.399\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1564 | Train score: 0.9568 | Val loss: 0.1438 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:31.864\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1343 | Train score: 0.9630 | Val loss: 0.1471 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:33.405\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1630 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:34.858\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1469 | Train score: 0.9444 | Val loss: 0.1622 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:36.279\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1516 | Train score: 0.9568 | Val loss: 0.1649 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:37.782\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1002 | Train score: 0.9691 | Val loss: 0.1726 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:39.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1993 | Train score: 0.9568 | Val loss: 0.1695 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:40.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1188 | Train score: 0.9444 | Val loss: 0.1677 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:42.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0814 | Train score: 0.9815 | Val loss: 0.1685 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:43.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1176 | Train score: 0.9691 | Val loss: 0.1672 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:45.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1041 | Train score: 0.9753 | Val loss: 0.1662 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:46.485\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1334 | Train score: 0.9691 | Val loss: 0.1635 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:47.945\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1357 | Train score: 0.9568 | Val loss: 0.1600 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:49.485\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1761 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:50.984\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1375 | Train score: 0.9444 | Val loss: 0.1842 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:52.577\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1469 | Train score: 0.9568 | Val loss: 0.1828 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:54.205\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1450 | Train score: 0.9506 | Val loss: 0.1788 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:55.755\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1345 | Train score: 0.9444 | Val loss: 0.1766 | Val score: 0.9307\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:57.332\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1418 | Train score: 0.9630 | Val loss: 0.1760 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:01:58.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.0947 | Train score: 0.9691 | Val loss: 0.1775 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:00.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1666 | Train score: 0.9568 | Val loss: 0.1783 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:01.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1339 | Train score: 0.9568 | Val loss: 0.1799 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:03.628\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.0893 | Train score: 0.9753 | Val loss: 0.1828 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:05.188\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1152 | Train score: 0.9568 | Val loss: 0.1868 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:06.751\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1467 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:08.294\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1292 | Train score: 0.9444 | Val loss: 0.1366 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:09.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1224 | Train score: 0.9630 | Val loss: 0.1387 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:11.368\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1684 | Train score: 0.9568 | Val loss: 0.1366 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:12.883\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1449 | Train score: 0.9506 | Val loss: 0.1331 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:14.410\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1549 | Train score: 0.9444 | Val loss: 0.1317 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:15.921\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1146 | Train score: 0.9691 | Val loss: 0.1315 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:17.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1566 | Train score: 0.9506 | Val loss: 0.1324 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:18.941\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1605 | Train score: 0.9506 | Val loss: 0.1341 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:20.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1193 | Train score: 0.9568 | Val loss: 0.1339 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:22.164\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1399 | Train score: 0.9568 | Val loss: 0.1315 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:23.749\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1591 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:25.548\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1447 | Train score: 0.9321 | Val loss: 0.1537 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:27.096\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1220 | Train score: 0.9444 | Val loss: 0.1597 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:28.578\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1316 | Train score: 0.9383 | Val loss: 0.1594 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:30.087\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1211 | Train score: 0.9568 | Val loss: 0.1581 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:31.567\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1002 | Train score: 0.9444 | Val loss: 0.1586 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:33.037\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1297 | Train score: 0.9506 | Val loss: 0.1581 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:34.526\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.0984 | Train score: 0.9815 | Val loss: 0.1578 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:36.010\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1062 | Train score: 0.9691 | Val loss: 0.1588 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:37.476\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1082 | Train score: 0.9630 | Val loss: 0.1599 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:38.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1155 | Train score: 0.9630 | Val loss: 0.1615 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:40.498\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1707 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:41.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1477 | Train score: 0.9444 | Val loss: 0.1775 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:43.487\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1617 | Train score: 0.9568 | Val loss: 0.1770 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:44.942\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1329 | Train score: 0.9444 | Val loss: 0.1754 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:46.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1148 | Train score: 0.9568 | Val loss: 0.1765 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:48.054\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1059 | Train score: 0.9691 | Val loss: 0.1788 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:49.489\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1207 | Train score: 0.9568 | Val loss: 0.1795 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:50.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1364 | Train score: 0.9568 | Val loss: 0.1804 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:52.409\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1371 | Train score: 0.9568 | Val loss: 0.1751 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:54.035\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1492 | Train score: 0.9630 | Val loss: 0.1691 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:55.455\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1415 | Train score: 0.9630 | Val loss: 0.1655 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:57.021\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1553 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:02:58.689\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1535 | Train score: 0.9444 | Val loss: 0.1384 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:00.429\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1421 | Train score: 0.9506 | Val loss: 0.1397 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:02.065\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1748 | Train score: 0.9506 | Val loss: 0.1360 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:03.794\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1988 | Train score: 0.9630 | Val loss: 0.1358 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:05.437\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1646 | Train score: 0.9506 | Val loss: 0.1402 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:07.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1281 | Train score: 0.9630 | Val loss: 0.1427 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:08.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1080 | Train score: 0.9753 | Val loss: 0.1409 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:10.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1466 | Train score: 0.9506 | Val loss: 0.1391 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:12.124\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1039 | Train score: 0.9691 | Val loss: 0.1361 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:13.817\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1365 | Train score: 0.9568 | Val loss: 0.1343 | Val score: 0.9455\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:03:15.397\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1587 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:16.845\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1428 | Train score: 0.9444 | Val loss: 0.1606 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:18.329\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1305 | Train score: 0.9568 | Val loss: 0.1615 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:19.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1217 | Train score: 0.9568 | Val loss: 0.1633 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:21.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1064 | Train score: 0.9630 | Val loss: 0.1661 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:22.749\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.0970 | Train score: 0.9691 | Val loss: 0.1703 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:24.247\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1575 | Train score: 0.9506 | Val loss: 0.1708 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:25.845\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1815 | Train score: 0.9568 | Val loss: 0.1679 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:27.523\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1488 | Train score: 0.9383 | Val loss: 0.1648 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:29.008\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1008 | Train score: 0.9630 | Val loss: 0.1626 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:30.658\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1525 | Train score: 0.9568 | Val loss: 0.1602 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:32.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1753 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:33.710\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1354 | Train score: 0.9568 | Val loss: 0.1793 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:35.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1567 | Train score: 0.9383 | Val loss: 0.1760 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:36.761\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1007 | Train score: 0.9568 | Val loss: 0.1776 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:38.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1672 | Train score: 0.9444 | Val loss: 0.1748 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:39.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1568 | Train score: 0.9506 | Val loss: 0.1725 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:41.250\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1095 | Train score: 0.9630 | Val loss: 0.1723 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:42.727\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1102 | Train score: 0.9691 | Val loss: 0.1734 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:44.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.0944 | Train score: 0.9691 | Val loss: 0.1772 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:45.714\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1221 | Train score: 0.9506 | Val loss: 0.1814 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:03:47.286\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1074 | Train score: 0.9630 | Val loss: 0.1850 | Val score: 0.9356\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " 25 \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.946         0.000           0.000          0.000        0.000       0.000         0.500        0.000    0.000   0.000         0.000        0.000\n",
      "MedPFNClassifier                      0.944         0.008           0.100          0.300        0.017       0.050         0.801        0.101    0.029   0.086         0.257        0.010\n",
      "MedPFNClassifier                      0.941         0.009           0.300          0.384        0.083       0.083         0.854        0.073    0.122   0.125         1.584        0.019\n",
      "MedPFNClassifier                      0.941         0.020           0.536          0.268        0.350       0.117         0.835        0.095    0.396   0.116        10.326        0.102\n",
      "RandomForestClassifier                0.947         0.006           0.300          0.458        0.050       0.076         0.832        0.081    0.086   0.131         0.226        0.015\n",
      "LogisticRegressionClassifier          0.940         0.011           0.333          0.253        0.217       0.150         0.712        0.074    0.260   0.184         0.007        0.000\n",
      "TabPFNClassifier                      0.944         0.007           0.267          0.389        0.067       0.082         0.864        0.063    0.102   0.126         2.423        0.018\n",
      "TabForestPFNClassifier                0.938         0.020           0.395          0.279        0.283       0.150         0.872        0.049    0.323   0.191        16.585        0.590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:06:22.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1916 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:23.671\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1435 | Train score: 0.9444 | Val loss: 0.1974 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:25.163\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1660 | Train score: 0.9506 | Val loss: 0.1907 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:26.727\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1576 | Train score: 0.9568 | Val loss: 0.1866 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:28.260\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1767 | Train score: 0.9444 | Val loss: 0.1817 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:29.788\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1356 | Train score: 0.9444 | Val loss: 0.1812 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:31.335\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1133 | Train score: 0.9630 | Val loss: 0.1820 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:32.809\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1630 | Train score: 0.9506 | Val loss: 0.1822 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:34.316\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1301 | Train score: 0.9444 | Val loss: 0.1833 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:35.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1551 | Train score: 0.9444 | Val loss: 0.1845 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:37.290\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1482 | Train score: 0.9444 | Val loss: 0.1858 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:38.852\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1769 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:40.324\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1579 | Train score: 0.9383 | Val loss: 0.1732 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:41.799\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1381 | Train score: 0.9506 | Val loss: 0.1766 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:43.234\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1434 | Train score: 0.9506 | Val loss: 0.1754 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:44.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1627 | Train score: 0.9444 | Val loss: 0.1728 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:46.157\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1728 | Train score: 0.9506 | Val loss: 0.1658 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:47.596\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1215 | Train score: 0.9568 | Val loss: 0.1598 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:49.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1718 | Train score: 0.9568 | Val loss: 0.1538 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:50.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1431 | Train score: 0.9568 | Val loss: 0.1503 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:51.973\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1358 | Train score: 0.9506 | Val loss: 0.1502 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:53.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1459 | Train score: 0.9444 | Val loss: 0.1510 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:54.961\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1968 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:56.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1343 | Train score: 0.9444 | Val loss: 0.2157 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:57.957\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1671 | Train score: 0.9321 | Val loss: 0.2114 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:06:59.440\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1250 | Train score: 0.9506 | Val loss: 0.2149 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:00.982\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1238 | Train score: 0.9506 | Val loss: 0.2173 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:02.448\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1865 | Train score: 0.9321 | Val loss: 0.2079 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:03.958\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1551 | Train score: 0.9321 | Val loss: 0.1980 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:05.471\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1512 | Train score: 0.9506 | Val loss: 0.1900 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:07.079\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1272 | Train score: 0.9568 | Val loss: 0.1864 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:08.594\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1180 | Train score: 0.9383 | Val loss: 0.1852 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:10.149\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1112 | Train score: 0.9506 | Val loss: 0.1857 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:11.703\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1550 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:13.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1884 | Train score: 0.9506 | Val loss: 0.1444 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:14.600\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1631 | Train score: 0.9383 | Val loss: 0.1375 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:16.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1333 | Train score: 0.9444 | Val loss: 0.1370 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:17.500\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1520 | Train score: 0.9383 | Val loss: 0.1384 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:18.995\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1444 | Train score: 0.9383 | Val loss: 0.1405 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:20.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1277 | Train score: 0.9444 | Val loss: 0.1471 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:22.015\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1281 | Train score: 0.9691 | Val loss: 0.1492 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:23.601\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1529 | Train score: 0.9506 | Val loss: 0.1503 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:25.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1651 | Train score: 0.9506 | Val loss: 0.1493 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:26.589\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1333 | Train score: 0.9506 | Val loss: 0.1461 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:28.121\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1311 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:29.594\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1590 | Train score: 0.9444 | Val loss: 0.1186 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:31.203\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1355 | Train score: 0.9444 | Val loss: 0.1135 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:32.633\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1830 | Train score: 0.9383 | Val loss: 0.1125 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:34.092\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1646 | Train score: 0.9506 | Val loss: 0.1133 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:35.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1360 | Train score: 0.9506 | Val loss: 0.1138 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:37.140\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1005 | Train score: 0.9506 | Val loss: 0.1135 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:38.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1745 | Train score: 0.9383 | Val loss: 0.1139 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:40.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.2024 | Train score: 0.9383 | Val loss: 0.1159 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:41.532\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1371 | Train score: 0.9444 | Val loss: 0.1181 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:43.027\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1233 | Train score: 0.9568 | Val loss: 0.1207 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:44.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1523 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:46.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1520 | Train score: 0.9444 | Val loss: 0.1496 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:47.533\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1457 | Train score: 0.9506 | Val loss: 0.1513 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:49.000\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1489 | Train score: 0.9568 | Val loss: 0.1527 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:50.427\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1760 | Train score: 0.9444 | Val loss: 0.1515 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:51.883\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1456 | Train score: 0.9506 | Val loss: 0.1499 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:53.344\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1305 | Train score: 0.9568 | Val loss: 0.1479 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:54.804\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1426 | Train score: 0.9506 | Val loss: 0.1468 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:56.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1513 | Train score: 0.9568 | Val loss: 0.1465 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:57.725\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1247 | Train score: 0.9506 | Val loss: 0.1464 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:07:59.176\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1595 | Train score: 0.9568 | Val loss: 0.1465 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:00.745\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1884 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:02.169\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1539 | Train score: 0.9444 | Val loss: 0.1927 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:03.597\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1309 | Train score: 0.9444 | Val loss: 0.2005 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:05.037\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1417 | Train score: 0.9568 | Val loss: 0.1928 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:06.587\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1678 | Train score: 0.9506 | Val loss: 0.1835 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:08.063\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1221 | Train score: 0.9383 | Val loss: 0.1823 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:09.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1334 | Train score: 0.9444 | Val loss: 0.1825 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:11.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1233 | Train score: 0.9506 | Val loss: 0.1845 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:12.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1309 | Train score: 0.9506 | Val loss: 0.1886 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:14.014\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1082 | Train score: 0.9691 | Val loss: 0.1947 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:15.477\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1420 | Train score: 0.9506 | Val loss: 0.2025 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:17.067\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1455 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:18.731\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1580 | Train score: 0.9444 | Val loss: 0.1407 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:20.301\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1793 | Train score: 0.9444 | Val loss: 0.1391 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:21.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1342 | Train score: 0.9506 | Val loss: 0.1375 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:23.431\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1418 | Train score: 0.9568 | Val loss: 0.1361 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:25.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1244 | Train score: 0.9568 | Val loss: 0.1353 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:26.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1907 | Train score: 0.9321 | Val loss: 0.1338 | Val score: 0.9703\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:28.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1361 | Train score: 0.9506 | Val loss: 0.1326 | Val score: 0.9653\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:29.715\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1803 | Train score: 0.9630 | Val loss: 0.1321 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:31.268\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1408 | Train score: 0.9506 | Val loss: 0.1324 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:32.726\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1768 | Train score: 0.9444 | Val loss: 0.1332 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:34.284\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1685 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:35.855\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1170 | Train score: 0.9444 | Val loss: 0.1695 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:37.490\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2347 | Train score: 0.9444 | Val loss: 0.1612 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:38.972\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1373 | Train score: 0.9506 | Val loss: 0.1571 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:40.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1318 | Train score: 0.9630 | Val loss: 0.1540 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:42.050\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.2079 | Train score: 0.9383 | Val loss: 0.1521 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:43.654\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1378 | Train score: 0.9383 | Val loss: 0.1515 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:45.234\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1390 | Train score: 0.9444 | Val loss: 0.1510 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:46.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1435 | Train score: 0.9444 | Val loss: 0.1506 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:48.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1273 | Train score: 0.9444 | Val loss: 0.1506 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:50.048\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1585 | Train score: 0.9444 | Val loss: 0.1506 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:51.596\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1860 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:53.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1604 | Train score: 0.9444 | Val loss: 0.1920 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:54.521\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1327 | Train score: 0.9506 | Val loss: 0.1942 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:56.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1793 | Train score: 0.9444 | Val loss: 0.1908 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:57.534\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1247 | Train score: 0.9568 | Val loss: 0.1906 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:08:59.022\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1349 | Train score: 0.9444 | Val loss: 0.1909 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:09:00.500\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1705 | Train score: 0.9444 | Val loss: 0.1879 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:09:01.979\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1779 | Train score: 0.9506 | Val loss: 0.1843 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:09:03.428\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1309 | Train score: 0.9506 | Val loss: 0.1833 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:09:04.918\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1205 | Train score: 0.9568 | Val loss: 0.1842 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:09:06.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1681 | Train score: 0.9444 | Val loss: 0.1845 | Val score: 0.9406\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " 50 \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.946         0.000           0.000          0.000        0.000       0.000         0.500        0.000    0.000   0.000         0.000        0.000\n",
      "MedPFNClassifier                      0.942         0.004           0.183          0.229        0.067       0.082         0.790        0.165    0.097   0.119         0.247        0.009\n",
      "MedPFNClassifier                      0.942         0.004           0.217          0.224        0.083       0.083         0.828        0.111    0.119   0.120         1.579        0.030\n",
      "MedPFNClassifier                      0.942         0.007           0.218          0.236        0.117       0.150         0.817        0.125    0.147   0.172        10.249        0.055\n",
      "RandomForestClassifier                0.947         0.005           0.200          0.400        0.033       0.067         0.820        0.092    0.057   0.114         0.273        0.022\n",
      "LogisticRegressionClassifier          0.931         0.008           0.199          0.201        0.183       0.203         0.576        0.208    0.187   0.197         0.007        0.001\n",
      "TabPFNClassifier                      0.943         0.004           0.067          0.133        0.033       0.067         0.853        0.064    0.044   0.089         2.423        0.030\n",
      "TabForestPFNClassifier                0.936         0.009           0.190          0.196        0.100       0.111         0.862        0.034    0.128   0.134        16.312        0.392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:11:41.794\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1775 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:11:43.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1906 | Train score: 0.9383 | Val loss: 0.1698 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:11:44.746\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1519 | Train score: 0.9506 | Val loss: 0.1680 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:11:46.201\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1939 | Train score: 0.9506 | Val loss: 0.1666 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:11:47.689\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1635 | Train score: 0.9506 | Val loss: 0.1668 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:11:49.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1762 | Train score: 0.9444 | Val loss: 0.1694 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:11:50.633\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1504 | Train score: 0.9630 | Val loss: 0.1718 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:11:52.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1545 | Train score: 0.9506 | Val loss: 0.1751 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:11:53.768\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1315 | Train score: 0.9506 | Val loss: 0.1788 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:11:55.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1809 | Train score: 0.9444 | Val loss: 0.1815 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:11:56.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1357 | Train score: 0.9444 | Val loss: 0.1817 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:11:58.399\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1610 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:00.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1641 | Train score: 0.9383 | Val loss: 0.1673 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:01.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1566 | Train score: 0.9444 | Val loss: 0.1659 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:03.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1581 | Train score: 0.9321 | Val loss: 0.1680 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:04.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1561 | Train score: 0.9198 | Val loss: 0.1719 | Val score: 0.9307\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:06.371\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1824 | Train score: 0.9444 | Val loss: 0.1711 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:07.991\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1264 | Train score: 0.9568 | Val loss: 0.1702 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:09.527\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1772 | Train score: 0.9259 | Val loss: 0.1690 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:11.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1487 | Train score: 0.9383 | Val loss: 0.1678 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:12.731\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1641 | Train score: 0.9259 | Val loss: 0.1672 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:14.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1513 | Train score: 0.9506 | Val loss: 0.1663 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:15.841\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1685 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:17.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1555 | Train score: 0.9444 | Val loss: 0.1687 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:18.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1509 | Train score: 0.9383 | Val loss: 0.1684 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:20.384\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1662 | Train score: 0.9444 | Val loss: 0.1700 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:21.857\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1186 | Train score: 0.9506 | Val loss: 0.1806 | Val score: 0.9307\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:23.335\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1311 | Train score: 0.9383 | Val loss: 0.1881 | Val score: 0.9307\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:24.838\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1279 | Train score: 0.9444 | Val loss: 0.1965 | Val score: 0.9307\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:26.365\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1140 | Train score: 0.9506 | Val loss: 0.2065 | Val score: 0.9307\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:28.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1031 | Train score: 0.9506 | Val loss: 0.2193 | Val score: 0.9307\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:29.582\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1825 | Train score: 0.9444 | Val loss: 0.2169 | Val score: 0.9257\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:31.112\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1447 | Train score: 0.9444 | Val loss: 0.2151 | Val score: 0.9257\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:32.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1766 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:34.205\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1548 | Train score: 0.9506 | Val loss: 0.1761 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:35.672\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2721 | Train score: 0.9259 | Val loss: 0.1744 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:37.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1257 | Train score: 0.9568 | Val loss: 0.1742 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:38.673\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1515 | Train score: 0.9506 | Val loss: 0.1735 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:40.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1258 | Train score: 0.9630 | Val loss: 0.1737 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:41.583\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1696 | Train score: 0.9259 | Val loss: 0.1747 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:43.221\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1300 | Train score: 0.9383 | Val loss: 0.1763 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:44.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1591 | Train score: 0.9444 | Val loss: 0.1768 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:46.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1448 | Train score: 0.9506 | Val loss: 0.1775 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:47.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1352 | Train score: 0.9506 | Val loss: 0.1790 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:49.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1456 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:50.815\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1831 | Train score: 0.9444 | Val loss: 0.1446 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:52.385\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1720 | Train score: 0.9444 | Val loss: 0.1434 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:53.969\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2089 | Train score: 0.9444 | Val loss: 0.1458 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:55.535\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1718 | Train score: 0.9444 | Val loss: 0.1467 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:57.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1650 | Train score: 0.9444 | Val loss: 0.1456 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:12:58.714\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1601 | Train score: 0.9506 | Val loss: 0.1432 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:00.302\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1811 | Train score: 0.9506 | Val loss: 0.1427 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:01.804\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1693 | Train score: 0.9506 | Val loss: 0.1415 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:03.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1289 | Train score: 0.9630 | Val loss: 0.1380 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:04.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1817 | Train score: 0.9506 | Val loss: 0.1363 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:06.563\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1484 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:08.020\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1466 | Train score: 0.9444 | Val loss: 0.1461 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:09.595\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1935 | Train score: 0.9321 | Val loss: 0.1520 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:11.085\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1288 | Train score: 0.9444 | Val loss: 0.1466 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:12.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1608 | Train score: 0.9444 | Val loss: 0.1455 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:14.078\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1319 | Train score: 0.9506 | Val loss: 0.1466 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:15.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1375 | Train score: 0.9444 | Val loss: 0.1490 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:17.061\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.2127 | Train score: 0.9383 | Val loss: 0.1496 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:18.545\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1711 | Train score: 0.9383 | Val loss: 0.1504 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:20.093\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1443 | Train score: 0.9444 | Val loss: 0.1507 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:21.578\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1353 | Train score: 0.9444 | Val loss: 0.1535 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:23.176\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1432 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:24.808\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1479 | Train score: 0.9383 | Val loss: 0.1456 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:26.583\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1797 | Train score: 0.9444 | Val loss: 0.1475 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:28.296\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1540 | Train score: 0.9383 | Val loss: 0.1474 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:29.983\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1868 | Train score: 0.9444 | Val loss: 0.1473 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:31.622\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1533 | Train score: 0.9383 | Val loss: 0.1476 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:33.215\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1525 | Train score: 0.9444 | Val loss: 0.1483 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:34.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1361 | Train score: 0.9444 | Val loss: 0.1495 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:36.544\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1172 | Train score: 0.9444 | Val loss: 0.1531 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:38.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1411 | Train score: 0.9506 | Val loss: 0.1572 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:39.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1503 | Train score: 0.9444 | Val loss: 0.1587 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:41.576\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1450 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:43.325\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1706 | Train score: 0.9444 | Val loss: 0.1432 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:44.838\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1525 | Train score: 0.9506 | Val loss: 0.1413 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:46.562\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1720 | Train score: 0.9444 | Val loss: 0.1430 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:48.115\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1607 | Train score: 0.9444 | Val loss: 0.1446 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:49.785\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1525 | Train score: 0.9444 | Val loss: 0.1423 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:51.317\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1673 | Train score: 0.9383 | Val loss: 0.1420 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:52.918\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1655 | Train score: 0.9383 | Val loss: 0.1422 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:54.465\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1550 | Train score: 0.9444 | Val loss: 0.1427 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:56.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1373 | Train score: 0.9444 | Val loss: 0.1442 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:13:57.853\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1313 | Train score: 0.9383 | Val loss: 0.1466 | Val score: 0.9505\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:13:59.442\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1512 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:14:00.916\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1803 | Train score: 0.9383 | Val loss: 0.1467 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:14:02.471\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1312 | Train score: 0.9568 | Val loss: 0.1475 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:14:03.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1571 | Train score: 0.9444 | Val loss: 0.1506 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-05 00:14:05.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1657 | Train score: 0.9506 | Val loss: 0.1524 | Val score: 0.9604\u001b[0m\n",
      "\u001b[32m2024-11-05 00:14:06.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1762 | Train score: 0.9321 | Val loss: 0.1541 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:14:08.445\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1455 | Train score: 0.9506 | Val loss: 0.1558 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:14:10.057\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1578 | Train score: 0.9444 | Val loss: 0.1564 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:14:11.736\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1084 | Train score: 0.9630 | Val loss: 0.1608 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:14:13.193\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1245 | Train score: 0.9506 | Val loss: 0.1664 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:14:14.630\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1148 | Train score: 0.9444 | Val loss: 0.1764 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:14:16.220\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1356 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:14:17.698\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1560 | Train score: 0.9444 | Val loss: 0.1312 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:14:19.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1670 | Train score: 0.9444 | Val loss: 0.1312 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:14:20.670\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1562 | Train score: 0.9506 | Val loss: 0.1301 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:14:22.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.2043 | Train score: 0.9444 | Val loss: 0.1319 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:14:23.590\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1414 | Train score: 0.9506 | Val loss: 0.1313 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:14:25.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1658 | Train score: 0.9383 | Val loss: 0.1318 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:14:26.552\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1472 | Train score: 0.9568 | Val loss: 0.1313 | Val score: 0.9554\u001b[0m\n",
      "\u001b[32m2024-11-05 00:14:28.074\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.2111 | Train score: 0.9321 | Val loss: 0.1332 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:14:29.555\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1425 | Train score: 0.9383 | Val loss: 0.1340 | Val score: 0.9505\u001b[0m\n",
      "\u001b[32m2024-11-05 00:14:31.036\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1497 | Train score: 0.9568 | Val loss: 0.1334 | Val score: 0.9505\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " 100 \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.946         0.000           0.000          0.000        0.000       0.000         0.500        0.000    0.000   0.000         0.000        0.000\n",
      "MedPFNClassifier                      0.935         0.006           0.117          0.183        0.050       0.076         0.755        0.138    0.069   0.106         0.247        0.012\n",
      "MedPFNClassifier                      0.945         0.007           0.350          0.391        0.083       0.083         0.815        0.116    0.132   0.133         1.551        0.016\n",
      "MedPFNClassifier                      0.941         0.009           0.250          0.403        0.050       0.076         0.819        0.113    0.082   0.126        10.229        0.049\n",
      "RandomForestClassifier                0.946         0.003           0.000          0.000        0.000       0.000         0.787        0.094    0.000   0.000         0.372        0.011\n",
      "LogisticRegressionClassifier          0.927         0.011           0.130          0.166        0.100       0.133         0.606        0.167    0.113   0.147         0.008        0.001\n",
      "TabPFNClassifier                      0.946         0.000           0.000          0.000        0.000       0.000         0.823        0.109    0.000   0.000         2.416        0.032\n",
      "TabForestPFNClassifier                0.949         0.011           0.558          0.398        0.183       0.157         0.839        0.079    0.260   0.197        16.807        0.629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:17:04.848\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.2094 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:06.327\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2128 | Train score: 0.9444 | Val loss: 0.1959 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:07.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1937 | Train score: 0.9444 | Val loss: 0.1977 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:09.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1781 | Train score: 0.9444 | Val loss: 0.2104 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:11.103\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.2322 | Train score: 0.9506 | Val loss: 0.2094 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:12.582\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.2034 | Train score: 0.9444 | Val loss: 0.2047 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:14.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.2362 | Train score: 0.9444 | Val loss: 0.2016 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:15.565\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1891 | Train score: 0.9444 | Val loss: 0.2007 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:17.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.2136 | Train score: 0.9444 | Val loss: 0.2000 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:18.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1859 | Train score: 0.9444 | Val loss: 0.1999 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:20.050\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1871 | Train score: 0.9444 | Val loss: 0.2001 | Val score: 0.9455\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:17:21.629\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1899 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:23.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1970 | Train score: 0.9444 | Val loss: 0.1763 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:24.994\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2374 | Train score: 0.9321 | Val loss: 0.1761 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:26.665\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2441 | Train score: 0.9383 | Val loss: 0.1781 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:28.357\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.2059 | Train score: 0.9383 | Val loss: 0.1805 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:30.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1878 | Train score: 0.9444 | Val loss: 0.1818 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:31.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1947 | Train score: 0.9444 | Val loss: 0.1822 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:33.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1918 | Train score: 0.9444 | Val loss: 0.1826 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:35.125\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1949 | Train score: 0.9444 | Val loss: 0.1829 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:36.785\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1755 | Train score: 0.9444 | Val loss: 0.1832 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:38.465\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1823 | Train score: 0.9444 | Val loss: 0.1852 | Val score: 0.9455\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:17:40.035\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.2047 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:41.573\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2027 | Train score: 0.9444 | Val loss: 0.1882 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:43.345\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1924 | Train score: 0.9383 | Val loss: 0.1894 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:44.899\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2219 | Train score: 0.9444 | Val loss: 0.1930 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:46.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1963 | Train score: 0.9444 | Val loss: 0.1965 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:48.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1870 | Train score: 0.9444 | Val loss: 0.1951 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:49.681\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1920 | Train score: 0.9383 | Val loss: 0.1939 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:51.368\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1847 | Train score: 0.9444 | Val loss: 0.1938 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:52.950\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1801 | Train score: 0.9444 | Val loss: 0.1942 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:54.499\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1754 | Train score: 0.9506 | Val loss: 0.1953 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:56.100\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1823 | Train score: 0.9444 | Val loss: 0.1955 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:57.672\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1944 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:17:59.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1965 | Train score: 0.9444 | Val loss: 0.1927 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:00.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2196 | Train score: 0.9321 | Val loss: 0.1930 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:02.046\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1750 | Train score: 0.9444 | Val loss: 0.1934 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:03.651\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1935 | Train score: 0.9444 | Val loss: 0.1938 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:05.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.2237 | Train score: 0.9383 | Val loss: 0.1919 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:06.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.2063 | Train score: 0.9444 | Val loss: 0.1916 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:08.085\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1812 | Train score: 0.9444 | Val loss: 0.1913 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:09.554\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1784 | Train score: 0.9444 | Val loss: 0.1922 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:11.086\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1850 | Train score: 0.9444 | Val loss: 0.1927 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:12.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1818 | Train score: 0.9444 | Val loss: 0.1925 | Val score: 0.9455\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:18:14.130\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.2100 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:15.730\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2082 | Train score: 0.9444 | Val loss: 0.2194 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:17.359\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1842 | Train score: 0.9444 | Val loss: 0.2292 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:18.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1858 | Train score: 0.9444 | Val loss: 0.2302 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:20.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1743 | Train score: 0.9444 | Val loss: 0.2243 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:22.358\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1878 | Train score: 0.9444 | Val loss: 0.2202 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:24.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1528 | Train score: 0.9506 | Val loss: 0.2195 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:25.763\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1855 | Train score: 0.9444 | Val loss: 0.2195 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:27.409\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1703 | Train score: 0.9506 | Val loss: 0.2212 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:29.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1788 | Train score: 0.9506 | Val loss: 0.2173 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:30.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1471 | Train score: 0.9568 | Val loss: 0.2230 | Val score: 0.9406\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:18:32.209\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.2082 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:33.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2091 | Train score: 0.9444 | Val loss: 0.1758 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:35.274\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1955 | Train score: 0.9444 | Val loss: 0.1745 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:36.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2037 | Train score: 0.9444 | Val loss: 0.1841 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:38.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.2507 | Train score: 0.9444 | Val loss: 0.1823 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:39.927\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1832 | Train score: 0.9444 | Val loss: 0.1805 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:41.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1989 | Train score: 0.9444 | Val loss: 0.1800 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:43.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.2430 | Train score: 0.9444 | Val loss: 0.1795 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:44.604\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1760 | Train score: 0.9444 | Val loss: 0.1793 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:46.148\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1846 | Train score: 0.9444 | Val loss: 0.1796 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:47.788\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.2019 | Train score: 0.9444 | Val loss: 0.1797 | Val score: 0.9455\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:18:49.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1946 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:51.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1921 | Train score: 0.9444 | Val loss: 0.1940 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:52.672\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1730 | Train score: 0.9444 | Val loss: 0.2001 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:54.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1962 | Train score: 0.9444 | Val loss: 0.2011 | Val score: 0.9307\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:55.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1430 | Train score: 0.9444 | Val loss: 0.2053 | Val score: 0.9257\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:57.498\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1638 | Train score: 0.9444 | Val loss: 0.2101 | Val score: 0.9158\u001b[0m\n",
      "\u001b[32m2024-11-05 00:18:59.053\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1965 | Train score: 0.9444 | Val loss: 0.2089 | Val score: 0.9257\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:00.672\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.2279 | Train score: 0.9383 | Val loss: 0.2075 | Val score: 0.9307\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:02.260\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1648 | Train score: 0.9444 | Val loss: 0.2088 | Val score: 0.9307\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:03.808\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1599 | Train score: 0.9506 | Val loss: 0.2146 | Val score: 0.9208\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:05.566\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.2152 | Train score: 0.9444 | Val loss: 0.2165 | Val score: 0.9208\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:07.143\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1966 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:08.601\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1990 | Train score: 0.9444 | Val loss: 0.1998 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:10.229\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2184 | Train score: 0.9383 | Val loss: 0.2052 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:11.886\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1820 | Train score: 0.9506 | Val loss: 0.2041 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:13.317\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.2046 | Train score: 0.9444 | Val loss: 0.2005 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:14.752\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1606 | Train score: 0.9444 | Val loss: 0.2026 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:16.229\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1779 | Train score: 0.9506 | Val loss: 0.2068 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:17.685\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1825 | Train score: 0.9444 | Val loss: 0.2106 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:19.180\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.2103 | Train score: 0.9383 | Val loss: 0.2113 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:20.642\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1855 | Train score: 0.9444 | Val loss: 0.2115 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:22.123\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1815 | Train score: 0.9444 | Val loss: 0.2120 | Val score: 0.9406\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:19:23.702\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.2189 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:25.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2170 | Train score: 0.9444 | Val loss: 0.2090 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:27.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2001 | Train score: 0.9444 | Val loss: 0.2110 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:28.627\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1986 | Train score: 0.9444 | Val loss: 0.2187 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:30.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1972 | Train score: 0.9444 | Val loss: 0.2257 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:31.928\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1731 | Train score: 0.9444 | Val loss: 0.2350 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:33.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1790 | Train score: 0.9383 | Val loss: 0.2431 | Val score: 0.9356\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:35.103\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1919 | Train score: 0.9383 | Val loss: 0.2495 | Val score: 0.9307\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:36.767\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.2131 | Train score: 0.9444 | Val loss: 0.2535 | Val score: 0.9307\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:38.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1590 | Train score: 0.9444 | Val loss: 0.2592 | Val score: 0.9307\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:39.952\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.2248 | Train score: 0.9321 | Val loss: 0.2604 | Val score: 0.9406\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:19:41.553\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.2041 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:43.103\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2125 | Train score: 0.9444 | Val loss: 0.1716 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:44.670\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2443 | Train score: 0.9444 | Val loss: 0.1774 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:46.226\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2065 | Train score: 0.9444 | Val loss: 0.1852 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:47.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1978 | Train score: 0.9444 | Val loss: 0.1864 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:49.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.2069 | Train score: 0.9444 | Val loss: 0.1852 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:50.904\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.2039 | Train score: 0.9444 | Val loss: 0.1826 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:52.599\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.2005 | Train score: 0.9444 | Val loss: 0.1796 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:54.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1907 | Train score: 0.9444 | Val loss: 0.1764 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:55.777\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.2069 | Train score: 0.9444 | Val loss: 0.1754 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:19:57.333\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1841 | Train score: 0.9444 | Val loss: 0.1773 | Val score: 0.9406\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " 250 \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.946         0.000           0.000          0.000        0.000       0.000         0.500        0.000    0.000   0.000         0.000        0.000\n",
      "MedPFNClassifier                      0.946         0.000           0.000          0.000        0.000       0.000         0.470        0.080    0.000   0.000         0.254        0.003\n",
      "MedPFNClassifier                      0.946         0.000           0.000          0.000        0.000       0.000         0.751        0.070    0.000   0.000         1.550        0.020\n",
      "MedPFNClassifier                      0.946         0.000           0.000          0.000        0.000       0.000         0.768        0.071    0.000   0.000        10.245        0.089\n",
      "RandomForestClassifier                0.946         0.000           0.000          0.000        0.000       0.000         0.784        0.101    0.000   0.000         0.238        0.007\n",
      "LogisticRegressionClassifier          0.923         0.010           0.067          0.133        0.033       0.067         0.544        0.083    0.044   0.089         0.007        0.001\n",
      "TabPFNClassifier                      0.946         0.000           0.000          0.000        0.000       0.000         0.768        0.086    0.000   0.000         2.393        0.018\n",
      "TabForestPFNClassifier                0.945         0.004           0.000          0.000        0.000       0.000         0.792        0.047    0.000   0.000        17.133        0.626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:22:31.827\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.2119 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:22:33.324\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2148 | Train score: 0.9444 | Val loss: 0.2109 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:22:34.800\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2153 | Train score: 0.9444 | Val loss: 0.2110 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:22:36.234\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2145 | Train score: 0.9444 | Val loss: 0.2105 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:22:37.675\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.2136 | Train score: 0.9444 | Val loss: 0.2101 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:22:39.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.2128 | Train score: 0.9444 | Val loss: 0.2090 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:22:40.575\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.2122 | Train score: 0.9444 | Val loss: 0.2062 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:22:42.181\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.2147 | Train score: 0.9444 | Val loss: 0.2065 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:22:43.663\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.2103 | Train score: 0.9444 | Val loss: 0.2066 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:22:45.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.2117 | Train score: 0.9444 | Val loss: 0.2056 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:22:46.569\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.2087 | Train score: 0.9444 | Val loss: 0.2038 | Val score: 0.9455\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:22:48.109\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.2116 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:22:49.727\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2148 | Train score: 0.9444 | Val loss: 0.2118 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:22:51.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2149 | Train score: 0.9444 | Val loss: 0.2113 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:22:52.946\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2138 | Train score: 0.9444 | Val loss: 0.2112 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:22:54.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.2143 | Train score: 0.9444 | Val loss: 0.2107 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:22:56.222\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.2147 | Train score: 0.9444 | Val loss: 0.2102 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:22:57.680\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.2137 | Train score: 0.9444 | Val loss: 0.2100 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:22:59.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.2133 | Train score: 0.9444 | Val loss: 0.2097 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:00.977\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.2088 | Train score: 0.9444 | Val loss: 0.2092 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:02.415\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.2043 | Train score: 0.9444 | Val loss: 0.2090 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:04.106\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.2026 | Train score: 0.9444 | Val loss: 0.2114 | Val score: 0.9455\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:23:05.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.2108 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:07.160\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2144 | Train score: 0.9444 | Val loss: 0.2103 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:08.625\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2141 | Train score: 0.9444 | Val loss: 0.2087 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:10.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2132 | Train score: 0.9444 | Val loss: 0.2070 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:11.528\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.2135 | Train score: 0.9444 | Val loss: 0.2040 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:12.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.2117 | Train score: 0.9444 | Val loss: 0.1978 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:14.548\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.2082 | Train score: 0.9444 | Val loss: 0.1857 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:16.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.2091 | Train score: 0.9444 | Val loss: 0.1793 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:17.539\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1980 | Train score: 0.9444 | Val loss: 0.1695 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:18.987\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1791 | Train score: 0.9444 | Val loss: 0.1708 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:20.446\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1882 | Train score: 0.9444 | Val loss: 0.1786 | Val score: 0.9455\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:23:22.010\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.2118 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:23.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2153 | Train score: 0.9444 | Val loss: 0.2115 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:24.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2147 | Train score: 0.9444 | Val loss: 0.2113 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:26.332\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2142 | Train score: 0.9444 | Val loss: 0.2109 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:27.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.2145 | Train score: 0.9444 | Val loss: 0.2109 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:29.316\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.2142 | Train score: 0.9444 | Val loss: 0.2112 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:30.771\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.2133 | Train score: 0.9444 | Val loss: 0.2110 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:32.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.2139 | Train score: 0.9444 | Val loss: 0.2106 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:33.728\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.2109 | Train score: 0.9444 | Val loss: 0.2100 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:35.195\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.2120 | Train score: 0.9444 | Val loss: 0.2093 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:36.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.2083 | Train score: 0.9444 | Val loss: 0.2080 | Val score: 0.9455\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:23:38.205\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.2113 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:39.655\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2146 | Train score: 0.9444 | Val loss: 0.2111 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:41.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2115 | Train score: 0.9444 | Val loss: 0.2112 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:42.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2117 | Train score: 0.9444 | Val loss: 0.2122 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:44.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.2067 | Train score: 0.9444 | Val loss: 0.2168 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:45.506\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1910 | Train score: 0.9444 | Val loss: 0.2285 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:46.961\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.2006 | Train score: 0.9506 | Val loss: 0.2359 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:48.389\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1865 | Train score: 0.9444 | Val loss: 0.2436 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:49.842\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.2326 | Train score: 0.9444 | Val loss: 0.2407 | Val score: 0.9406\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:51.284\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.2042 | Train score: 0.9444 | Val loss: 0.2348 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:52.972\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1999 | Train score: 0.9444 | Val loss: 0.2271 | Val score: 0.9455\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:23:54.520\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.2111 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:56.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2136 | Train score: 0.9444 | Val loss: 0.2094 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:57.638\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2066 | Train score: 0.9444 | Val loss: 0.2058 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:23:59.290\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2049 | Train score: 0.9444 | Val loss: 0.2037 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:00.756\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1927 | Train score: 0.9444 | Val loss: 0.2033 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:02.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.2238 | Train score: 0.9444 | Val loss: 0.2016 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:04.035\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.2186 | Train score: 0.9444 | Val loss: 0.2038 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:05.635\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.2077 | Train score: 0.9444 | Val loss: 0.2038 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:07.269\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1975 | Train score: 0.9444 | Val loss: 0.2030 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:08.945\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1957 | Train score: 0.9444 | Val loss: 0.2024 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:10.638\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1988 | Train score: 0.9444 | Val loss: 0.2022 | Val score: 0.9455\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:24:12.261\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.2118 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:13.783\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2152 | Train score: 0.9444 | Val loss: 0.2118 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:15.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2150 | Train score: 0.9444 | Val loss: 0.2111 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:16.786\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2139 | Train score: 0.9444 | Val loss: 0.2107 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:18.274\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.2150 | Train score: 0.9444 | Val loss: 0.2107 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:19.763\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.2139 | Train score: 0.9444 | Val loss: 0.2105 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:21.261\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.2152 | Train score: 0.9444 | Val loss: 0.2100 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:22.737\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.2120 | Train score: 0.9444 | Val loss: 0.2092 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:24.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.2145 | Train score: 0.9444 | Val loss: 0.2089 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:25.763\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.2121 | Train score: 0.9444 | Val loss: 0.2083 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:27.219\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.2095 | Train score: 0.9444 | Val loss: 0.2071 | Val score: 0.9455\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:24:28.790\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.2116 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:30.230\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2145 | Train score: 0.9444 | Val loss: 0.2106 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:31.685\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2138 | Train score: 0.9444 | Val loss: 0.2079 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:33.161\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2115 | Train score: 0.9444 | Val loss: 0.2052 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:34.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.2109 | Train score: 0.9444 | Val loss: 0.2048 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:36.101\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.2086 | Train score: 0.9444 | Val loss: 0.2062 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:37.539\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.2008 | Train score: 0.9444 | Val loss: 0.2109 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:39.066\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.2013 | Train score: 0.9444 | Val loss: 0.2187 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:40.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1805 | Train score: 0.9444 | Val loss: 0.2322 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:42.106\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1678 | Train score: 0.9444 | Val loss: 0.2537 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:43.566\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.2122 | Train score: 0.9383 | Val loss: 0.2489 | Val score: 0.9455\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:24:45.143\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.2120 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:46.565\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2138 | Train score: 0.9444 | Val loss: 0.2120 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:48.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2105 | Train score: 0.9444 | Val loss: 0.2141 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:49.457\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2140 | Train score: 0.9444 | Val loss: 0.2162 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:50.930\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.2092 | Train score: 0.9444 | Val loss: 0.2185 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:52.351\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1946 | Train score: 0.9444 | Val loss: 0.2249 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:53.809\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1979 | Train score: 0.9444 | Val loss: 0.2285 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:55.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.2111 | Train score: 0.9444 | Val loss: 0.2271 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:56.730\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1974 | Train score: 0.9444 | Val loss: 0.2252 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:58.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1973 | Train score: 0.9444 | Val loss: 0.2240 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:24:59.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.2009 | Train score: 0.9444 | Val loss: 0.2179 | Val score: 0.9455\u001b[0m\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-11-05 00:25:01.183\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.2110 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:25:02.660\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2141 | Train score: 0.9444 | Val loss: 0.2095 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:25:04.153\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2131 | Train score: 0.9444 | Val loss: 0.2085 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:25:05.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2097 | Train score: 0.9444 | Val loss: 0.2080 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:25:07.149\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.2079 | Train score: 0.9444 | Val loss: 0.2073 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:25:08.602\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1989 | Train score: 0.9444 | Val loss: 0.2091 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:25:10.109\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.2224 | Train score: 0.9444 | Val loss: 0.2066 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:25:11.630\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1964 | Train score: 0.9444 | Val loss: 0.2050 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:25:13.108\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1984 | Train score: 0.9444 | Val loss: 0.2052 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:25:14.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1822 | Train score: 0.9444 | Val loss: 0.2075 | Val score: 0.9455\u001b[0m\n",
      "\u001b[32m2024-11-05 00:25:16.124\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1875 | Train score: 0.9444 | Val loss: 0.2140 | Val score: 0.9455\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " 500 \n",
      "                               accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                         0.946         0.000             0.0            0.0          0.0         0.0         0.500        0.000      0.0     0.0         0.000        0.000\n",
      "MedPFNClassifier                      0.946         0.000             0.0            0.0          0.0         0.0         0.604        0.126      0.0     0.0         0.252        0.012\n",
      "MedPFNClassifier                      0.946         0.000             0.0            0.0          0.0         0.0         0.552        0.128      0.0     0.0         1.589        0.039\n",
      "MedPFNClassifier                      0.946         0.000             0.0            0.0          0.0         0.0         0.641        0.122      0.0     0.0        10.281        0.075\n",
      "RandomForestClassifier                0.946         0.000             0.0            0.0          0.0         0.0         0.645        0.081      0.0     0.0         0.178        0.005\n",
      "LogisticRegressionClassifier          0.945         0.004             0.0            0.0          0.0         0.0         0.435        0.122      0.0     0.0         0.006        0.000\n",
      "TabPFNClassifier                      0.946         0.000             0.0            0.0          0.0         0.0         0.588        0.130      0.0     0.0         2.456        0.074\n",
      "TabForestPFNClassifier                0.946         0.000             0.0            0.0          0.0         0.0         0.625        0.095      0.0     0.0        16.313        0.527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master7\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "save = True\n",
    "sampling = None\n",
    "cv = 10\n",
    "best_delete = 0\n",
    "strat_split = True\n",
    "recomp = False\n",
    "n_optim = 1000\n",
    "cat_optim = 10\n",
    "ft_epochs = 20\n",
    "ft_epochs_forest = 10\n",
    "ft_lr = 1e-5\n",
    "max_s = 1024\n",
    "max_q = 128\n",
    "max_samples = 1024\n",
    "no_pre_process = False\n",
    "multi_decoder = \"permutation\"\n",
    "N_ens = 5\n",
    "seed = 42\n",
    "overwrite = True\n",
    "metrics = [\"accuracy\", \"precision\", \"recall\", \"roc_auc\", \"f1\"]\n",
    "dir_path = os.path.abspath(os.getcwd())\n",
    "run_name = \"medium_mlp_var_balance_05weight_anova_bestwithnoisebnn_100\"\n",
    "path = dir_path + f\"/logs/trainrun_{run_name}\"\n",
    "filename = \"model\"\n",
    "\n",
    "\n",
    "models = [\n",
    "    MajorityClass(),\n",
    "    #XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic'),\n",
    "    MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=1, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process),\n",
    "    MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process),\n",
    "    MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process,\n",
    "                    ft_epochs=ft_epochs, ft_lr=ft_lr),\n",
    "    RandomForestClassifier(),\n",
    "    #AutoGluon(),\n",
    "    #CatBoostGrid(),\n",
    "    #XGBoostGrid(),\n",
    "    LogisticRegressionClassifier(), \n",
    "    TabPFNClassifier(device='cpu', N_ensemble_configurations=5, no_preprocess_mode=no_pre_process),\n",
    "    TabForestPFNClassifier(\"saved_models/tabforest/mix600k/tabforestpfn.pt\", \"saved_models/tabforest/mix600k/config_run.yaml\", max_epochs=ft_epochs_forest)\n",
    "]\n",
    "reducer  = AnovaSelect()\n",
    "#for reducer in [AnovaSelect(), RandomSelect(), NonZeroSelect(), MeanSelect(), StdSelect(), MaxSelect(), PCASelect()]:\n",
    "#data = clr(all_data)\n",
    "\n",
    "#all_data = normalize(all_data)\n",
    "to_delete = [0,1,5,10,25,50,100,250,500]\n",
    "for best_delete in to_delete:\n",
    "    results_mean = pd.DataFrame(np.zeros((len(models), len(metrics)+1)),\n",
    "                                index=[m.__class__.__name__ for m in models],\n",
    "                                columns=metrics+[\"runtime\"])\n",
    "    results_std = pd.DataFrame(np.zeros((len(models), len(metrics)+1)), \n",
    "                               index=[m.__class__.__name__ for m in models],\n",
    "                               columns=metrics+[\"runtime\"])\n",
    "    \n",
    "    for ii, model in enumerate(models):\n",
    "        results_mean.iloc[ii,:], results_std.iloc[ii,:] = cross_validate_sample(\n",
    "            model, all_data, labels, metrics, strat_split, cv, sampling, \n",
    "            reducer, max_samples, seed=seed, overwrite=overwrite, n_best_delete=best_delete,\n",
    "            recomp=recomp)\n",
    "    \n",
    "    results_mean = results_mean.add_suffix(\" mean\")\n",
    "    results_std = results_std.add_suffix(\" std\")\n",
    "    results_full = pd.concat((results_mean, results_std), axis=1)\n",
    "    cols = results_full.columns.tolist()\n",
    "    new_cols = []\n",
    "    for i in range(int(len(cols)/2)):\n",
    "        new_cols.append(cols[i])\n",
    "        new_cols.append(cols[i+int(len(cols)/2)])\n",
    "    results_full = results_full[new_cols]\n",
    "    red_name = \"feature_removal\"\n",
    "    if save:\n",
    "        directory = f\"results/{red_name}\"\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        save_path = f'results/{red_name}/best_delete{best_delete}.csv'\n",
    "        results_full.to_csv(save_path)\n",
    "    print(\"\\n\", \"\\n\", best_delete, \"\\n\", results_full.round(3))\n",
    "    #print(results_full.sort_values(\"roc_auc mean\").round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef7a442-b698-44d5-869a-756ec1e70b55",
   "metadata": {},
   "source": [
    "## New data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2ab1872-e271-44ac-b463-9ee4fa7127d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"datasets/external_pdac.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df_data = df.iloc[:,2:-5]\n",
    "data = df_data.to_numpy()\n",
    "labels = df[\"Disease\"].to_numpy()\n",
    "labels[labels==\"Healthy\"] = 0\n",
    "labels[labels==\"PDAC\"] = 1\n",
    "all_data = data\n",
    "data_c0 = data[labels==0]\n",
    "data_c1 = data[labels==1]\n",
    "num_c1 = data_c1.shape[0]\n",
    "num_c0 = int(num_c1*0.05)\n",
    "data = np.concatenate((data_c0[:num_c0], data_c1), axis=0)\n",
    "#labels = np.concatenate((np.zeros(num_c0), np.ones(num_c1)))\n",
    "all_data, labels = unison_shuffled_copies(data, labels)\n",
    "all_data = data_to_comp(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5860c111-1280-470e-a332-3945d589858d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-05 15:24:41.403\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.2916 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:42.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.5151 | Train score: 0.7308 | Val loss: 0.3171 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:42.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.4749 | Train score: 0.7692 | Val loss: 0.3599 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:43.628\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.4746 | Train score: 0.7308 | Val loss: 0.3794 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:44.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.4510 | Train score: 0.7308 | Val loss: 0.3534 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:44.953\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.3663 | Train score: 0.8462 | Val loss: 0.3204 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:45.594\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.3435 | Train score: 0.8077 | Val loss: 0.3064 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:46.206\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.3675 | Train score: 0.8846 | Val loss: 0.2934 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:46.838\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.6610 | Train score: 0.6154 | Val loss: 0.2878 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:47.493\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.3857 | Train score: 0.8077 | Val loss: 0.2834 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:48.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.5030 | Train score: 0.8462 | Val loss: 0.2836 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:48.779\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.3848 | Train score: 0.8846 | Val loss: 0.2847 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:49.743\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.4436 | Train score: 0.8077 | Val loss: 0.2889 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:50.365\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.5059 | Train score: 0.8077 | Val loss: 0.2965 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:50.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.3777 | Train score: 0.8462 | Val loss: 0.2995 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:51.518\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.3292 | Train score: 0.8077 | Val loss: 0.2984 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:52.074\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.3318 | Train score: 0.8462 | Val loss: 0.3038 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:52.701\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.2923 | Train score: 0.9231 | Val loss: 0.2978 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:53.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.2202 | Train score: 0.9615 | Val loss: 0.2981 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:54.726\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.2545 | Train score: 0.8846 | Val loss: 0.2757 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:55.328\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.1457 | Train score: 1.0000 | Val loss: 0.2648 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:56.180\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.3618 | Val score: 0.9091\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:56.943\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2762 | Train score: 0.8846 | Val loss: 0.3630 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:57.530\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.3941 | Train score: 0.8462 | Val loss: 0.3790 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:58.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2477 | Train score: 0.9615 | Val loss: 0.3893 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:58.844\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.2133 | Train score: 0.9615 | Val loss: 0.4065 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:24:59.418\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.5501 | Train score: 0.8846 | Val loss: 0.4061 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:00.030\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.3449 | Train score: 0.8462 | Val loss: 0.4007 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:00.660\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.3194 | Train score: 0.8077 | Val loss: 0.4048 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:01.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.3465 | Train score: 0.8077 | Val loss: 0.4122 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:01.841\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.2845 | Train score: 0.8846 | Val loss: 0.4116 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:02.457\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.3623 | Train score: 0.8462 | Val loss: 0.4104 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:03.019\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.3654 | Train score: 0.8846 | Val loss: 0.4079 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:03.634\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.2222 | Train score: 0.9231 | Val loss: 0.4117 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:04.226\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.3845 | Train score: 0.8462 | Val loss: 0.4115 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:04.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.3047 | Train score: 0.8077 | Val loss: 0.4074 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:05.629\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.3698 | Train score: 0.7692 | Val loss: 0.4103 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:06.212\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.2180 | Train score: 0.8846 | Val loss: 0.4169 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:06.796\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.2552 | Train score: 0.8846 | Val loss: 0.4307 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:07.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.1518 | Train score: 0.9615 | Val loss: 0.4555 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:08.043\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.3783 | Train score: 0.8077 | Val loss: 0.4630 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:08.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.2206 | Train score: 0.9615 | Val loss: 0.4641 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:09.486\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.4509 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:10.148\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.4866 | Train score: 0.8462 | Val loss: 0.4411 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:10.856\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.3499 | Train score: 0.8462 | Val loss: 0.4398 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:11.567\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.3791 | Train score: 0.7308 | Val loss: 0.4410 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:12.292\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.2894 | Train score: 0.9231 | Val loss: 0.4436 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:12.965\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.3695 | Train score: 0.8846 | Val loss: 0.4433 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:13.721\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.3273 | Train score: 0.8846 | Val loss: 0.4442 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:14.857\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.4324 | Train score: 0.7308 | Val loss: 0.4459 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:15.491\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.2727 | Train score: 0.8077 | Val loss: 0.4486 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:16.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.3162 | Train score: 0.8846 | Val loss: 0.4540 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:16.803\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.3338 | Train score: 0.8077 | Val loss: 0.4587 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:17.581\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.2602 | Train score: 0.8846 | Val loss: 0.4676 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:18.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.2604 | Train score: 0.8462 | Val loss: 0.4831 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:18.853\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.3089 | Train score: 0.8846 | Val loss: 0.4878 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:19.540\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.3011 | Train score: 0.8077 | Val loss: 0.4854 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:20.244\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.1748 | Train score: 0.9231 | Val loss: 0.4850 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:20.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.2639 | Train score: 0.8462 | Val loss: 0.4882 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:21.563\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.1709 | Train score: 0.8846 | Val loss: 0.4997 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:22.248\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.2629 | Train score: 0.8846 | Val loss: 0.5147 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:22.887\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.2203 | Train score: 0.9231 | Val loss: 0.5338 | Val score: 0.6970\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:23.507\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.1109 | Train score: 1.0000 | Val loss: 0.5700 | Val score: 0.6970\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:24.339\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.4728 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:25.010\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.3254 | Train score: 0.8462 | Val loss: 0.4845 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:25.633\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.3499 | Train score: 0.8462 | Val loss: 0.4991 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:26.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.5414 | Train score: 0.8462 | Val loss: 0.4905 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:26.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.5126 | Train score: 0.7692 | Val loss: 0.4918 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:27.447\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.3769 | Train score: 0.8462 | Val loss: 0.4961 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:28.047\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.3712 | Train score: 0.8077 | Val loss: 0.4912 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:28.762\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.2231 | Train score: 0.9615 | Val loss: 0.4961 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:29.457\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.3811 | Train score: 0.8462 | Val loss: 0.4963 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:30.117\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.4140 | Train score: 0.8462 | Val loss: 0.5024 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:30.826\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.2575 | Train score: 0.9231 | Val loss: 0.5106 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:31.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.3902 | Train score: 0.8846 | Val loss: 0.5308 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:32.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.4854 | Train score: 0.8462 | Val loss: 0.5447 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:32.727\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.3552 | Train score: 0.8846 | Val loss: 0.5600 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:33.329\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.4977 | Train score: 0.7308 | Val loss: 0.5725 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:33.927\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.4028 | Train score: 0.8462 | Val loss: 0.5778 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:34.519\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.2044 | Train score: 0.9231 | Val loss: 0.5930 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:35.118\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.3312 | Train score: 0.8846 | Val loss: 0.6044 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:35.758\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.3048 | Train score: 0.8846 | Val loss: 0.6051 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:36.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.2287 | Train score: 0.9231 | Val loss: 0.6170 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:36.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.2951 | Train score: 0.8846 | Val loss: 0.6243 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:37.827\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.3766 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:38.544\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.6770 | Train score: 0.8077 | Val loss: 0.3614 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:39.218\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2983 | Train score: 0.9231 | Val loss: 0.3618 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:39.915\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.3495 | Train score: 0.8462 | Val loss: 0.3616 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:40.549\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.5068 | Train score: 0.8077 | Val loss: 0.3693 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:41.151\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.4319 | Train score: 0.8077 | Val loss: 0.3723 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:41.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.4340 | Train score: 0.8077 | Val loss: 0.3794 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:42.453\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.4123 | Train score: 0.8462 | Val loss: 0.3790 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:43.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.3321 | Train score: 0.8462 | Val loss: 0.3724 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:43.655\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.3558 | Train score: 0.8846 | Val loss: 0.3670 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:44.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.4858 | Train score: 0.7692 | Val loss: 0.3672 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:44.915\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.3800 | Train score: 0.8462 | Val loss: 0.3725 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:45.573\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.4554 | Train score: 0.8077 | Val loss: 0.3771 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:46.177\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.4380 | Train score: 0.7692 | Val loss: 0.3782 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:46.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.2563 | Train score: 0.9231 | Val loss: 0.3801 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:47.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.2003 | Train score: 0.9615 | Val loss: 0.3804 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:48.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.3800 | Train score: 0.8077 | Val loss: 0.3812 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:48.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.3920 | Train score: 0.8462 | Val loss: 0.3836 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:49.357\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.3258 | Train score: 0.8846 | Val loss: 0.3912 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:50.039\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.2638 | Train score: 0.8462 | Val loss: 0.4010 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:50.712\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.1902 | Train score: 0.9231 | Val loss: 0.4078 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:51.587\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.3234 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:52.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.4183 | Train score: 0.8462 | Val loss: 0.3099 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:52.898\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.4690 | Train score: 0.8077 | Val loss: 0.3205 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:53.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.5090 | Train score: 0.8077 | Val loss: 0.3321 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:54.123\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.3021 | Train score: 0.9615 | Val loss: 0.3337 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:54.712\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.4051 | Train score: 0.8462 | Val loss: 0.3377 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:55.337\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.2882 | Train score: 0.8846 | Val loss: 0.3344 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:55.936\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.3410 | Train score: 0.8077 | Val loss: 0.3205 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:56.533\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.3769 | Train score: 0.8077 | Val loss: 0.3113 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:57.110\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.3441 | Train score: 0.8462 | Val loss: 0.3094 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:57.709\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.3317 | Train score: 0.8462 | Val loss: 0.3009 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:58.324\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.3426 | Train score: 0.8462 | Val loss: 0.2898 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:58.968\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.2182 | Train score: 0.8462 | Val loss: 0.2870 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:25:59.694\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.2917 | Train score: 0.8846 | Val loss: 0.2847 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:00.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.3689 | Train score: 0.8462 | Val loss: 0.2813 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:01.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.1761 | Train score: 0.9231 | Val loss: 0.2789 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:02.284\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.1546 | Train score: 0.9615 | Val loss: 0.2759 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:02.882\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.1661 | Train score: 0.9231 | Val loss: 0.2691 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:03.500\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.2228 | Train score: 0.9231 | Val loss: 0.2691 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:04.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.1785 | Train score: 0.9615 | Val loss: 0.2685 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:04.648\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.1588 | Train score: 0.8846 | Val loss: 0.2689 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:05.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.2940 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:06.011\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.5956 | Train score: 0.8077 | Val loss: 0.3020 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:06.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.3387 | Train score: 0.8077 | Val loss: 0.2924 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:07.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.5447 | Train score: 0.6923 | Val loss: 0.2919 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:08.417\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.4277 | Train score: 0.7692 | Val loss: 0.2968 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:09.191\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.3554 | Train score: 0.8462 | Val loss: 0.2870 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:09.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.3410 | Train score: 0.8462 | Val loss: 0.2753 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:10.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.7439 | Train score: 0.8462 | Val loss: 0.2723 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:11.205\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.3636 | Train score: 0.8462 | Val loss: 0.2725 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:11.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.3278 | Train score: 0.8846 | Val loss: 0.2707 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:12.641\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.3474 | Train score: 0.8462 | Val loss: 0.2656 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:13.215\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.3120 | Train score: 0.8462 | Val loss: 0.2600 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:13.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.2571 | Train score: 0.8846 | Val loss: 0.2553 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:14.417\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.2865 | Train score: 0.8846 | Val loss: 0.2510 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:15.021\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.3719 | Train score: 0.8077 | Val loss: 0.2556 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:15.627\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.2316 | Train score: 0.8846 | Val loss: 0.2607 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:16.242\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.4055 | Train score: 0.8077 | Val loss: 0.2674 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:16.842\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.1855 | Train score: 0.9615 | Val loss: 0.2739 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:17.503\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.1841 | Train score: 0.8846 | Val loss: 0.2779 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:18.125\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.2168 | Train score: 0.9231 | Val loss: 0.2826 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:18.726\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.3553 | Train score: 0.8846 | Val loss: 0.2895 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:19.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.4826 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:20.218\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2636 | Train score: 0.8846 | Val loss: 0.4716 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:20.808\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2857 | Train score: 0.8846 | Val loss: 0.4834 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:21.394\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.3052 | Train score: 0.8462 | Val loss: 0.4923 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:21.984\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.5524 | Train score: 0.7308 | Val loss: 0.4788 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:22.578\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.2625 | Train score: 0.8462 | Val loss: 0.4743 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:23.185\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.3099 | Train score: 0.8846 | Val loss: 0.4714 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:23.775\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.3112 | Train score: 0.9231 | Val loss: 0.4652 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:24.429\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1409 | Train score: 0.9231 | Val loss: 0.4603 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:25.027\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.3570 | Train score: 0.8846 | Val loss: 0.4579 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:25.625\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.0949 | Train score: 1.0000 | Val loss: 0.4631 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:26.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.4568 | Train score: 0.8462 | Val loss: 0.4604 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:26.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.4145 | Train score: 0.8462 | Val loss: 0.4598 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:27.539\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.1011 | Train score: 1.0000 | Val loss: 0.4715 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:28.221\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.1570 | Train score: 0.9615 | Val loss: 0.4859 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:28.920\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.2823 | Train score: 0.8846 | Val loss: 0.4813 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:29.531\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.1626 | Train score: 0.9615 | Val loss: 0.4726 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:30.187\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.2607 | Train score: 0.9231 | Val loss: 0.4502 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:30.855\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.2306 | Train score: 0.8846 | Val loss: 0.4309 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:31.526\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.1336 | Train score: 0.9615 | Val loss: 0.4291 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:32.263\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.1435 | Train score: 0.9231 | Val loss: 0.4465 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:33.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.3136 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:33.799\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.4854 | Train score: 0.7692 | Val loss: 0.3248 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:34.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.4365 | Train score: 0.8462 | Val loss: 0.3363 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:35.198\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.7329 | Train score: 0.7692 | Val loss: 0.3513 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:35.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.3351 | Train score: 0.8462 | Val loss: 0.3569 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:36.425\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.5012 | Train score: 0.7308 | Val loss: 0.3547 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:37.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.4093 | Train score: 0.8077 | Val loss: 0.3482 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:37.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.3557 | Train score: 0.9231 | Val loss: 0.3361 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:38.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.4031 | Train score: 0.7692 | Val loss: 0.3226 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:38.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.3834 | Train score: 0.8462 | Val loss: 0.3074 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:39.512\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.3282 | Train score: 0.8846 | Val loss: 0.2882 | Val score: 0.9091\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:40.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.2403 | Train score: 0.9231 | Val loss: 0.2652 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:40.732\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.4139 | Train score: 0.8462 | Val loss: 0.2560 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:41.318\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.4137 | Train score: 0.8077 | Val loss: 0.2620 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:41.916\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.3100 | Train score: 0.8462 | Val loss: 0.2656 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:42.516\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.4191 | Train score: 0.8077 | Val loss: 0.2690 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:43.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.4029 | Train score: 0.8462 | Val loss: 0.2739 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:43.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.2608 | Train score: 0.8846 | Val loss: 0.2756 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:44.447\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.3712 | Train score: 0.8462 | Val loss: 0.2720 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:45.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.2732 | Train score: 0.8462 | Val loss: 0.2703 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:45.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.3718 | Train score: 0.8462 | Val loss: 0.2709 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:46.681\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.3725 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:47.416\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.3899 | Train score: 0.8077 | Val loss: 0.3757 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:48.057\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.3760 | Train score: 0.8462 | Val loss: 0.3773 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:48.660\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.3077 | Train score: 0.8462 | Val loss: 0.3811 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:49.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.3083 | Train score: 0.8462 | Val loss: 0.3847 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:49.839\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.3198 | Train score: 0.8462 | Val loss: 0.3945 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:50.427\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1899 | Train score: 0.9615 | Val loss: 0.4110 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:51.014\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.3111 | Train score: 0.8462 | Val loss: 0.4174 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:51.599\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.3233 | Train score: 0.9615 | Val loss: 0.4179 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:52.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1631 | Train score: 0.9615 | Val loss: 0.4339 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:52.806\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.3688 | Train score: 0.8846 | Val loss: 0.4469 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:53.387\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.5671 | Train score: 0.8462 | Val loss: 0.4279 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:53.970\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.2184 | Train score: 0.9231 | Val loss: 0.4250 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:54.566\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.4199 | Train score: 0.8846 | Val loss: 0.4226 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:55.184\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.2262 | Train score: 0.9231 | Val loss: 0.4227 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:55.795\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.0941 | Train score: 1.0000 | Val loss: 0.4295 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:56.446\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.3090 | Train score: 0.9231 | Val loss: 0.4385 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:57.051\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.2831 | Train score: 0.8846 | Val loss: 0.4501 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:57.820\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.1393 | Train score: 0.9231 | Val loss: 0.4658 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:58.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.1294 | Train score: 1.0000 | Val loss: 0.4837 | Val score: 0.8788\u001b[0m\n",
      "\u001b[32m2024-11-05 15:26:59.293\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.1189 | Train score: 0.9615 | Val loss: 0.5107 | Val score: 0.8788\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " AnovaSelect \n",
      "                         accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                   0.778         0.000           0.778          0.000        1.000       0.000         0.500        0.000    0.875   0.000         0.000        0.000\n",
      "XGBClassifier                   0.733         0.085           0.819          0.048        0.843       0.083         0.657        0.083    0.830   0.060         0.006        0.000\n",
      "MedPFNClassifier                0.744         0.062           0.783          0.027        0.929       0.071         0.602        0.159    0.849   0.041         0.505        0.053\n",
      "MedPFNClassifier                0.750         0.062           0.789          0.037        0.929       0.055         0.609        0.145    0.852   0.038         3.888        0.581\n",
      "MedPFNClassifier                0.711         0.078           0.786          0.046        0.864       0.067         0.629        0.127    0.823   0.050         0.402        0.004\n",
      "MedPFNClassifier                0.700         0.051           0.792          0.036        0.836       0.064         0.607        0.124    0.812   0.035         1.964        0.083\n",
      "RandomForestClassifier          0.744         0.027           0.773          0.014        0.950       0.033         0.567        0.144    0.852   0.017         0.114        0.003\n",
      "LogisticRegression              0.778         0.000           0.778          0.000        1.000       0.000         0.427        0.112    0.875   0.000         0.002        0.000\n",
      "TabPFNClassifier                0.706         0.061           0.802          0.045        0.829       0.080         0.521        0.153    0.813   0.045         0.677        0.040\n",
      "TabForestPFNClassifier          0.706         0.153           0.807          0.104        0.814       0.140         0.621        0.283    0.807   0.116        13.600        0.509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-05 15:28:06.093\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.5224 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:06.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.5411 | Train score: 0.7692 | Val loss: 0.5159 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:07.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.5849 | Train score: 0.7692 | Val loss: 0.5170 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:07.526\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.5409 | Train score: 0.7692 | Val loss: 0.5170 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:07.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.5388 | Train score: 0.7692 | Val loss: 0.5171 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:08.524\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.5403 | Train score: 0.7692 | Val loss: 0.5173 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:08.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.5398 | Train score: 0.7692 | Val loss: 0.5175 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:09.405\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.5381 | Train score: 0.7692 | Val loss: 0.5176 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:09.885\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.5382 | Train score: 0.7692 | Val loss: 0.5176 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:10.356\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.5392 | Train score: 0.7692 | Val loss: 0.5174 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:10.860\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.5407 | Train score: 0.7692 | Val loss: 0.5171 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:11.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.5461 | Train score: 0.7692 | Val loss: 0.5170 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:11.811\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.5395 | Train score: 0.7692 | Val loss: 0.5168 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:12.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.5369 | Train score: 0.7692 | Val loss: 0.5166 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:12.807\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.5418 | Train score: 0.7692 | Val loss: 0.5164 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:13.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.5340 | Train score: 0.7692 | Val loss: 0.5162 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:13.743\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.5280 | Train score: 0.7692 | Val loss: 0.5159 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:14.236\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.5333 | Train score: 0.7692 | Val loss: 0.5155 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:14.731\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.5319 | Train score: 0.7692 | Val loss: 0.5151 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:15.271\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.5419 | Train score: 0.7692 | Val loss: 0.5148 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:15.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.5348 | Train score: 0.7692 | Val loss: 0.5145 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:16.522\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.5107 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:17.007\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.5557 | Train score: 0.7692 | Val loss: 0.5193 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:17.463\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.5380 | Train score: 0.7692 | Val loss: 0.5184 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:17.947\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.5405 | Train score: 0.7692 | Val loss: 0.5177 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:18.431\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.5385 | Train score: 0.7692 | Val loss: 0.5169 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:18.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.5403 | Train score: 0.7692 | Val loss: 0.5165 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:19.447\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.5370 | Train score: 0.7692 | Val loss: 0.5160 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:20.297\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.5394 | Train score: 0.7692 | Val loss: 0.5155 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:21.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.5345 | Train score: 0.7692 | Val loss: 0.5150 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:21.659\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.5347 | Train score: 0.7692 | Val loss: 0.5142 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:22.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.5303 | Train score: 0.7692 | Val loss: 0.5131 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:22.883\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.5355 | Train score: 0.7692 | Val loss: 0.5118 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:23.445\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.5353 | Train score: 0.7692 | Val loss: 0.5104 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:24.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.5376 | Train score: 0.7692 | Val loss: 0.5088 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:24.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.5274 | Train score: 0.7692 | Val loss: 0.5065 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:25.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.5746 | Train score: 0.7692 | Val loss: 0.5068 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:25.849\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.5387 | Train score: 0.7692 | Val loss: 0.5071 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:26.485\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.5203 | Train score: 0.7692 | Val loss: 0.5067 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:27.076\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.5448 | Train score: 0.7692 | Val loss: 0.5067 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:27.719\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.5366 | Train score: 0.7692 | Val loss: 0.5066 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:28.426\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.5243 | Train score: 0.7692 | Val loss: 0.5056 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:29.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.6253 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:30.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.9970 | Train score: 0.6154 | Val loss: 0.5350 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:30.854\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.6666 | Train score: 0.6923 | Val loss: 0.5233 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:31.402\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.5362 | Train score: 0.7692 | Val loss: 0.5223 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:31.967\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.5390 | Train score: 0.7692 | Val loss: 0.5218 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:32.443\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.5401 | Train score: 0.7692 | Val loss: 0.5216 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:33.034\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.5379 | Train score: 0.7692 | Val loss: 0.5214 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:33.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.5295 | Train score: 0.7692 | Val loss: 0.5213 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:33.989\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.5352 | Train score: 0.7692 | Val loss: 0.5213 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:34.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.5337 | Train score: 0.7692 | Val loss: 0.5213 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:34.900\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.5256 | Train score: 0.7692 | Val loss: 0.5214 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:35.359\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.5352 | Train score: 0.7692 | Val loss: 0.5217 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:35.811\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.5412 | Train score: 0.7692 | Val loss: 0.5219 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:36.336\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.5257 | Train score: 0.7692 | Val loss: 0.5223 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:36.812\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.5295 | Train score: 0.7692 | Val loss: 0.5229 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:37.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.5275 | Train score: 0.7692 | Val loss: 0.5236 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:37.700\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.5669 | Train score: 0.7692 | Val loss: 0.5238 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:38.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.5268 | Train score: 0.7692 | Val loss: 0.5243 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:38.850\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.5284 | Train score: 0.7692 | Val loss: 0.5248 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:39.402\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.5096 | Train score: 0.7692 | Val loss: 0.5256 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:39.937\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.5406 | Train score: 0.7692 | Val loss: 0.5263 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:40.665\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.4557 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:41.170\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.6009 | Train score: 0.7308 | Val loss: 0.4955 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:41.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.5398 | Train score: 0.7692 | Val loss: 0.5139 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:42.123\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.5395 | Train score: 0.7692 | Val loss: 0.5171 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:42.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.5372 | Train score: 0.7692 | Val loss: 0.5173 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:43.850\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.5364 | Train score: 0.7692 | Val loss: 0.5169 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:44.467\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.5350 | Train score: 0.7692 | Val loss: 0.5162 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:45.033\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.5384 | Train score: 0.7692 | Val loss: 0.5155 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:45.955\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.5354 | Train score: 0.7692 | Val loss: 0.5145 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:46.429\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.5297 | Train score: 0.7692 | Val loss: 0.5131 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:46.846\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.5378 | Train score: 0.7692 | Val loss: 0.5116 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:47.314\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.5298 | Train score: 0.7692 | Val loss: 0.5095 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:47.883\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.5692 | Train score: 0.7692 | Val loss: 0.5094 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:48.601\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.5111 | Train score: 0.7692 | Val loss: 0.5083 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:49.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.5240 | Train score: 0.7692 | Val loss: 0.5069 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:49.718\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.5209 | Train score: 0.7692 | Val loss: 0.5048 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:50.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.5394 | Train score: 0.7692 | Val loss: 0.5030 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:50.825\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.5002 | Train score: 0.7692 | Val loss: 0.5004 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:51.348\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.5080 | Train score: 0.7692 | Val loss: 0.4977 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:51.956\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.5041 | Train score: 0.7692 | Val loss: 0.4950 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:52.417\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.4900 | Train score: 0.7692 | Val loss: 0.4925 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:53.170\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.5163 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:53.671\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.4352 | Train score: 0.8077 | Val loss: 0.5559 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:54.083\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.6519 | Train score: 0.7692 | Val loss: 0.5264 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:54.524\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.3751 | Train score: 0.7692 | Val loss: 0.5231 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:55.110\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.4630 | Train score: 0.8077 | Val loss: 0.5266 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:55.593\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.4446 | Train score: 0.7692 | Val loss: 0.5266 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:56.015\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.5787 | Train score: 0.7308 | Val loss: 0.5238 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:56.455\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.4119 | Train score: 0.8077 | Val loss: 0.5205 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:57.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.4297 | Train score: 0.8462 | Val loss: 0.5184 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:57.498\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.4475 | Train score: 0.7692 | Val loss: 0.5173 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:57.935\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.3752 | Train score: 0.7692 | Val loss: 0.5194 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:58.402\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.4288 | Train score: 0.8077 | Val loss: 0.5216 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:59.048\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.4588 | Train score: 0.8077 | Val loss: 0.5235 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:28:59.642\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.4848 | Train score: 0.7692 | Val loss: 0.5159 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:00.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.5077 | Train score: 0.7692 | Val loss: 0.5075 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:00.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.3949 | Train score: 0.8077 | Val loss: 0.5013 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:01.154\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.5028 | Train score: 0.7308 | Val loss: 0.4964 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:01.659\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.4435 | Train score: 0.8077 | Val loss: 0.4898 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:02.131\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.3843 | Train score: 0.8077 | Val loss: 0.4922 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:02.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.2867 | Train score: 0.9231 | Val loss: 0.5098 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:03.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.3240 | Train score: 0.8462 | Val loss: 0.5481 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:03.845\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.5672 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:04.331\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.4804 | Train score: 0.8077 | Val loss: 0.6362 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:04.750\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.4415 | Train score: 0.8077 | Val loss: 0.6531 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:05.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.4076 | Train score: 0.7692 | Val loss: 0.6857 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:05.875\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.4102 | Train score: 0.8462 | Val loss: 0.7199 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:06.370\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.6174 | Train score: 0.7308 | Val loss: 0.7026 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:06.790\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.5248 | Train score: 0.8077 | Val loss: 0.6860 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:07.294\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.5292 | Train score: 0.8077 | Val loss: 0.6497 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:07.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.4319 | Train score: 0.8462 | Val loss: 0.6304 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:08.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.4405 | Train score: 0.8077 | Val loss: 0.6134 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:08.946\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.5832 | Train score: 0.8077 | Val loss: 0.5992 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:09.431\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.4525 | Train score: 0.8077 | Val loss: 0.5885 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:09.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.4528 | Train score: 0.8077 | Val loss: 0.5929 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:10.417\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.4004 | Train score: 0.8462 | Val loss: 0.6061 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:10.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.3933 | Train score: 0.8462 | Val loss: 0.6267 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:11.426\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.4726 | Train score: 0.8077 | Val loss: 0.6443 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:11.913\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.4763 | Train score: 0.8077 | Val loss: 0.6601 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:12.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.4383 | Train score: 0.8077 | Val loss: 0.6775 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:12.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.4579 | Train score: 0.8462 | Val loss: 0.6949 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:13.474\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.4659 | Train score: 0.8462 | Val loss: 0.7083 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:14.052\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.3891 | Train score: 0.8462 | Val loss: 0.7257 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:14.898\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.4922 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:15.503\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.4765 | Train score: 0.7692 | Val loss: 0.6134 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:16.012\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.8006 | Train score: 0.6154 | Val loss: 0.5791 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:16.511\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.4605 | Train score: 0.8077 | Val loss: 0.5425 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:16.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.4631 | Train score: 0.6538 | Val loss: 0.5261 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:17.555\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.4678 | Train score: 0.7308 | Val loss: 0.5231 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:18.047\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.5648 | Train score: 0.7692 | Val loss: 0.5095 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:18.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.5014 | Train score: 0.7692 | Val loss: 0.5043 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:19.169\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.5125 | Train score: 0.7692 | Val loss: 0.5035 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:19.717\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.5966 | Train score: 0.8077 | Val loss: 0.5048 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:20.229\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.5195 | Train score: 0.7308 | Val loss: 0.5089 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:20.719\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.5237 | Train score: 0.7692 | Val loss: 0.5100 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:21.210\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.5261 | Train score: 0.7692 | Val loss: 0.5097 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:21.682\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.5253 | Train score: 0.7692 | Val loss: 0.5085 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:22.169\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.5264 | Train score: 0.7692 | Val loss: 0.5064 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:22.649\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.5361 | Train score: 0.7692 | Val loss: 0.5039 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:23.123\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.4969 | Train score: 0.7692 | Val loss: 0.5000 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:23.597\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.4918 | Train score: 0.7692 | Val loss: 0.4973 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:24.104\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.4799 | Train score: 0.7692 | Val loss: 0.5000 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:24.576\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.4522 | Train score: 0.7692 | Val loss: 0.5080 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:25.021\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.4049 | Train score: 0.7692 | Val loss: 0.5194 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:25.752\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.4801 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:26.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.5324 | Train score: 0.7692 | Val loss: 0.4470 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:26.746\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.6478 | Train score: 0.7308 | Val loss: 0.4760 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:27.195\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.5875 | Train score: 0.7308 | Val loss: 0.5067 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:27.732\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.5335 | Train score: 0.7692 | Val loss: 0.5096 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:28.236\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.5340 | Train score: 0.7692 | Val loss: 0.5092 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:28.778\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.5359 | Train score: 0.7692 | Val loss: 0.5078 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:29.293\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.5326 | Train score: 0.7692 | Val loss: 0.5056 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:29.756\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.5393 | Train score: 0.7692 | Val loss: 0.5038 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:30.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.5298 | Train score: 0.7692 | Val loss: 0.5013 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:30.804\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.5696 | Train score: 0.7692 | Val loss: 0.5010 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:31.289\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.5230 | Train score: 0.7692 | Val loss: 0.4998 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:31.797\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.5534 | Train score: 0.7692 | Val loss: 0.4995 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:32.456\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.5261 | Train score: 0.7692 | Val loss: 0.4983 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:33.225\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.5225 | Train score: 0.7692 | Val loss: 0.4962 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:33.982\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.5504 | Train score: 0.7692 | Val loss: 0.4950 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:34.634\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.5270 | Train score: 0.7692 | Val loss: 0.4932 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:35.192\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.5104 | Train score: 0.7692 | Val loss: 0.4904 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:35.769\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.5376 | Train score: 0.7692 | Val loss: 0.4877 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:36.391\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.5123 | Train score: 0.7692 | Val loss: 0.4838 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:37.128\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.4955 | Train score: 0.7692 | Val loss: 0.4780 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:38.045\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.4495 | Val score: 0.8485\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:38.671\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.6410 | Train score: 0.8077 | Val loss: 0.4924 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:39.219\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.5762 | Train score: 0.7308 | Val loss: 0.5140 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:39.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.5411 | Train score: 0.7692 | Val loss: 0.5155 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:40.384\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.5379 | Train score: 0.7692 | Val loss: 0.5154 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:40.911\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.5378 | Train score: 0.7692 | Val loss: 0.5148 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:41.438\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.5403 | Train score: 0.7692 | Val loss: 0.5143 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:42.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.5384 | Train score: 0.7692 | Val loss: 0.5137 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:42.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.5366 | Train score: 0.7692 | Val loss: 0.5129 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:43.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.5410 | Train score: 0.7692 | Val loss: 0.5122 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:43.571\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.5387 | Train score: 0.7692 | Val loss: 0.5116 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:44.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.5389 | Train score: 0.7692 | Val loss: 0.5111 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:44.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.5403 | Train score: 0.7692 | Val loss: 0.5107 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:45.208\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.5385 | Train score: 0.7692 | Val loss: 0.5102 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:45.701\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.5334 | Train score: 0.7692 | Val loss: 0.5094 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:46.327\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.5345 | Train score: 0.7692 | Val loss: 0.5085 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:46.873\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.5380 | Train score: 0.7692 | Val loss: 0.5076 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:47.403\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.5379 | Train score: 0.7692 | Val loss: 0.5068 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:47.972\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.5345 | Train score: 0.7692 | Val loss: 0.5058 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:48.586\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.5332 | Train score: 0.7692 | Val loss: 0.5046 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:49.089\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.5264 | Train score: 0.7692 | Val loss: 0.5030 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:49.854\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.5210 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:50.506\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.5540 | Train score: 0.7692 | Val loss: 0.5218 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:51.028\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.5406 | Train score: 0.7692 | Val loss: 0.5191 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:51.526\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.5403 | Train score: 0.7692 | Val loss: 0.5166 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:52.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.5399 | Train score: 0.7692 | Val loss: 0.5146 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:52.704\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.5374 | Train score: 0.7692 | Val loss: 0.5132 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:53.187\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.5402 | Train score: 0.7692 | Val loss: 0.5123 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:53.665\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.5341 | Train score: 0.7692 | Val loss: 0.5111 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:54.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.5278 | Train score: 0.7692 | Val loss: 0.5088 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:54.762\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.5317 | Train score: 0.7692 | Val loss: 0.5052 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:55.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.5344 | Train score: 0.7692 | Val loss: 0.5002 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:55.800\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.5339 | Train score: 0.7692 | Val loss: 0.4954 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:56.539\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.5900 | Train score: 0.7692 | Val loss: 0.4974 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:57.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.5599 | Train score: 0.7692 | Val loss: 0.5001 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:58.403\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.5316 | Train score: 0.7692 | Val loss: 0.5018 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:29:59.294\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.5270 | Train score: 0.7692 | Val loss: 0.5020 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:30:00.131\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.5191 | Train score: 0.7692 | Val loss: 0.5009 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:30:00.786\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.5065 | Train score: 0.7692 | Val loss: 0.4978 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:30:01.513\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.5375 | Train score: 0.7692 | Val loss: 0.4952 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:30:02.163\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.5233 | Train score: 0.7692 | Val loss: 0.4911 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:30:02.877\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.5179 | Train score: 0.7692 | Val loss: 0.4854 | Val score: 0.7879\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " RandomSelect \n",
      "                         accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                   0.778         0.000           0.778          0.000        1.000       0.000         0.500        0.000    0.875   0.000         0.000        0.000\n",
      "XGBClassifier                   0.656         0.085           0.762          0.038        0.807       0.091         0.569        0.108    0.783   0.061         0.008        0.003\n",
      "MedPFNClassifier                0.628         0.079           0.767          0.057        0.757       0.116         0.462        0.112    0.756   0.062         0.460        0.018\n",
      "MedPFNClassifier                0.722         0.086           0.781          0.042        0.893       0.080         0.521        0.159    0.832   0.055         3.041        0.227\n",
      "MedPFNClassifier                0.694         0.090           0.792          0.046        0.821       0.092         0.579        0.169    0.805   0.064         0.407        0.010\n",
      "MedPFNClassifier                0.689         0.062           0.795          0.051        0.814       0.073         0.543        0.147    0.802   0.042         1.647        0.062\n",
      "RandomForestClassifier          0.733         0.054           0.770          0.020        0.936       0.067         0.584        0.154    0.844   0.037         0.114        0.002\n",
      "LogisticRegression              0.778         0.000           0.778          0.000        1.000       0.000         0.495        0.110    0.875   0.000         0.002        0.000\n",
      "TabPFNClassifier                0.778         0.000           0.778          0.000        1.000       0.000         0.488        0.105    0.875   0.000         0.592        0.021\n",
      "TabForestPFNClassifier          0.767         0.022           0.779          0.008        0.979       0.046         0.616        0.168    0.867   0.017        11.493        1.015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-05 15:31:30.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.5780 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:31.170\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.4803 | Train score: 0.7308 | Val loss: 0.5725 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:31.687\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.4833 | Train score: 0.8077 | Val loss: 0.5627 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:32.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.4398 | Train score: 0.8077 | Val loss: 0.5768 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:32.959\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.4663 | Train score: 0.7692 | Val loss: 0.6151 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:33.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.4590 | Train score: 0.8077 | Val loss: 0.6611 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:34.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.5309 | Train score: 0.8077 | Val loss: 0.6840 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:34.658\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.3834 | Train score: 0.8462 | Val loss: 0.7449 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:35.155\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.2952 | Train score: 0.8846 | Val loss: 0.8276 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:35.637\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.6821 | Train score: 0.8077 | Val loss: 0.8346 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:36.225\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.3496 | Train score: 0.7692 | Val loss: 0.8322 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:36.764\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.3635 | Train score: 0.8846 | Val loss: 0.8139 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:37.248\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.4395 | Train score: 0.8077 | Val loss: 0.8017 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:37.788\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.5695 | Train score: 0.7692 | Val loss: 0.7842 | Val score: 0.6970\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:38.383\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.5696 | Train score: 0.7692 | Val loss: 0.7426 | Val score: 0.6667\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:38.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.4524 | Train score: 0.8462 | Val loss: 0.7336 | Val score: 0.6667\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:39.534\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.5076 | Train score: 0.8462 | Val loss: 0.7201 | Val score: 0.6667\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:40.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.5109 | Train score: 0.8077 | Val loss: 0.7108 | Val score: 0.6667\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:40.774\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.3682 | Train score: 0.8077 | Val loss: 0.7199 | Val score: 0.6364\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:41.270\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.4182 | Train score: 0.8077 | Val loss: 0.7496 | Val score: 0.6364\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:41.794\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.3405 | Train score: 0.8462 | Val loss: 0.7994 | Val score: 0.5758\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:42.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.5293 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:43.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.5475 | Train score: 0.8077 | Val loss: 0.5482 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:43.705\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.4848 | Train score: 0.8077 | Val loss: 0.5514 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:44.333\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.4900 | Train score: 0.8077 | Val loss: 0.5516 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:44.856\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.4881 | Train score: 0.8077 | Val loss: 0.5512 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:45.338\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.5483 | Train score: 0.7692 | Val loss: 0.5520 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:45.868\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.4875 | Train score: 0.8077 | Val loss: 0.5511 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:46.477\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.4804 | Train score: 0.8077 | Val loss: 0.5478 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:46.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.5080 | Train score: 0.8077 | Val loss: 0.5509 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:47.571\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.4831 | Train score: 0.8077 | Val loss: 0.5525 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:48.244\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.4763 | Train score: 0.8077 | Val loss: 0.5546 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:48.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.5355 | Train score: 0.7692 | Val loss: 0.5544 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:49.404\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.4759 | Train score: 0.8077 | Val loss: 0.5536 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:50.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.4732 | Train score: 0.8077 | Val loss: 0.5529 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:50.804\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.4560 | Train score: 0.8077 | Val loss: 0.5534 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:51.332\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.5135 | Train score: 0.7692 | Val loss: 0.5533 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:51.885\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.4809 | Train score: 0.8077 | Val loss: 0.5474 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:52.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.4974 | Train score: 0.8077 | Val loss: 0.5382 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:53.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.5867 | Train score: 0.7692 | Val loss: 0.5300 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:53.640\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.4277 | Train score: 0.8077 | Val loss: 0.5238 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:54.243\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.4165 | Train score: 0.8077 | Val loss: 0.5127 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:55.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.5409 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:55.669\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.5128 | Train score: 0.8077 | Val loss: 0.5546 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:56.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.4922 | Train score: 0.8077 | Val loss: 0.5568 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:56.783\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.4926 | Train score: 0.8077 | Val loss: 0.5581 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:57.310\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.5431 | Train score: 0.7692 | Val loss: 0.5580 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:57.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.4907 | Train score: 0.8077 | Val loss: 0.5584 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:58.495\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.4898 | Train score: 0.8077 | Val loss: 0.5590 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:59.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.5405 | Train score: 0.7692 | Val loss: 0.5588 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:31:59.497\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.4929 | Train score: 0.8077 | Val loss: 0.5590 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:00.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.4879 | Train score: 0.8077 | Val loss: 0.5592 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:00.668\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.5379 | Train score: 0.7692 | Val loss: 0.5584 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:01.193\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.4884 | Train score: 0.8077 | Val loss: 0.5578 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:01.761\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.4839 | Train score: 0.8077 | Val loss: 0.5571 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:02.379\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.4863 | Train score: 0.8077 | Val loss: 0.5565 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:02.912\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.4853 | Train score: 0.8077 | Val loss: 0.5562 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:03.430\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.4926 | Train score: 0.8077 | Val loss: 0.5577 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:04.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.4815 | Train score: 0.8077 | Val loss: 0.5601 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:04.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.5327 | Train score: 0.7692 | Val loss: 0.5561 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:05.131\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.5015 | Train score: 0.8077 | Val loss: 0.5561 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:05.936\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.4846 | Train score: 0.8077 | Val loss: 0.5569 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:06.568\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.4703 | Train score: 0.8077 | Val loss: 0.5571 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:07.386\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.5546 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:08.114\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.4964 | Train score: 0.7692 | Val loss: 0.5260 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:08.983\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.5427 | Train score: 0.7692 | Val loss: 0.5173 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:09.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.5210 | Train score: 0.7692 | Val loss: 0.5175 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:10.162\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.5188 | Train score: 0.7692 | Val loss: 0.5264 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:10.790\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.5001 | Train score: 0.7692 | Val loss: 0.5630 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:11.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.5016 | Train score: 0.7692 | Val loss: 0.5967 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:11.826\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.3866 | Train score: 0.7692 | Val loss: 0.6277 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:12.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.4325 | Train score: 0.6923 | Val loss: 0.6275 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:12.900\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.5590 | Train score: 0.8462 | Val loss: 0.6316 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:13.375\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.6307 | Train score: 0.6923 | Val loss: 0.6167 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:13.921\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.3354 | Train score: 0.8462 | Val loss: 0.6190 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:14.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.4097 | Train score: 0.6923 | Val loss: 0.6389 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:14.957\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.6172 | Train score: 0.7692 | Val loss: 0.6444 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:15.407\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.4058 | Train score: 0.8462 | Val loss: 0.6454 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:15.915\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.3591 | Train score: 0.8846 | Val loss: 0.6455 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:16.487\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.4169 | Train score: 0.8846 | Val loss: 0.6498 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:16.995\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.3451 | Train score: 0.8077 | Val loss: 0.6503 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:17.474\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.4167 | Train score: 0.8462 | Val loss: 0.6579 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:18.019\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.4104 | Train score: 0.8077 | Val loss: 0.6600 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:18.595\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.3941 | Train score: 0.8462 | Val loss: 0.6759 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:19.348\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.5129 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:19.874\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.5658 | Train score: 0.7692 | Val loss: 0.5086 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:20.443\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.5450 | Train score: 0.7692 | Val loss: 0.5179 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:20.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.5422 | Train score: 0.7692 | Val loss: 0.5191 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:21.398\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.5385 | Train score: 0.7692 | Val loss: 0.5194 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:21.954\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.5427 | Train score: 0.7692 | Val loss: 0.5194 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:22.552\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.5411 | Train score: 0.7692 | Val loss: 0.5192 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:23.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.5398 | Train score: 0.7692 | Val loss: 0.5186 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:23.542\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.5415 | Train score: 0.7692 | Val loss: 0.5180 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:24.097\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.5379 | Train score: 0.7692 | Val loss: 0.5174 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:24.660\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.5398 | Train score: 0.7692 | Val loss: 0.5170 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:25.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.5413 | Train score: 0.7692 | Val loss: 0.5166 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:25.597\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.5385 | Train score: 0.7692 | Val loss: 0.5162 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:26.157\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.5372 | Train score: 0.7692 | Val loss: 0.5158 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:26.686\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.5406 | Train score: 0.7692 | Val loss: 0.5154 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:27.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.5378 | Train score: 0.7692 | Val loss: 0.5151 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:27.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.5356 | Train score: 0.7692 | Val loss: 0.5146 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:28.241\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.5405 | Train score: 0.7692 | Val loss: 0.5142 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:28.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.5375 | Train score: 0.7692 | Val loss: 0.5136 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:29.234\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.5450 | Train score: 0.7692 | Val loss: 0.5132 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:29.771\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.5384 | Train score: 0.7692 | Val loss: 0.5127 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:30.579\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.5345 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:31.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.5019 | Train score: 0.7692 | Val loss: 0.5582 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:31.599\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.4902 | Train score: 0.8077 | Val loss: 0.5429 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:32.157\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.5423 | Train score: 0.7308 | Val loss: 0.5305 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:32.738\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.5557 | Train score: 0.7692 | Val loss: 0.5197 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:33.263\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.6202 | Train score: 0.7308 | Val loss: 0.5163 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:33.762\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.5381 | Train score: 0.7692 | Val loss: 0.5196 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:34.373\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.5422 | Train score: 0.7692 | Val loss: 0.5210 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:34.911\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.5399 | Train score: 0.7692 | Val loss: 0.5211 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:35.388\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.5418 | Train score: 0.7692 | Val loss: 0.5208 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:35.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.5377 | Train score: 0.7692 | Val loss: 0.5202 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:36.515\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.5376 | Train score: 0.7692 | Val loss: 0.5196 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:37.019\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.5456 | Train score: 0.7692 | Val loss: 0.5193 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:37.486\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.5424 | Train score: 0.7692 | Val loss: 0.5191 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:38.029\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.5379 | Train score: 0.7692 | Val loss: 0.5190 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:38.604\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.5389 | Train score: 0.7692 | Val loss: 0.5189 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:39.162\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.5391 | Train score: 0.7692 | Val loss: 0.5188 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:39.685\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.5383 | Train score: 0.7692 | Val loss: 0.5187 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:40.266\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.5381 | Train score: 0.7692 | Val loss: 0.5189 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:40.862\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.5403 | Train score: 0.7692 | Val loss: 0.5191 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:41.370\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.5376 | Train score: 0.7692 | Val loss: 0.5194 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:42.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.5465 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:42.812\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.4783 | Train score: 0.7692 | Val loss: 0.5599 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:43.315\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.5714 | Train score: 0.6923 | Val loss: 0.5450 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:43.822\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.5174 | Train score: 0.7692 | Val loss: 0.5485 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:44.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.5866 | Train score: 0.7692 | Val loss: 0.5382 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:44.933\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.5109 | Train score: 0.7692 | Val loss: 0.5373 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:45.410\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.5066 | Train score: 0.7692 | Val loss: 0.5479 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:45.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.5115 | Train score: 0.7692 | Val loss: 0.5540 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:46.511\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.6099 | Train score: 0.6538 | Val loss: 0.5509 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:46.995\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.4682 | Train score: 0.7692 | Val loss: 0.5500 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:47.503\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.4172 | Train score: 0.8462 | Val loss: 0.5528 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:48.043\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.5124 | Train score: 0.8462 | Val loss: 0.5552 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:48.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.4324 | Train score: 0.7308 | Val loss: 0.5620 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:49.138\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.3780 | Train score: 0.8077 | Val loss: 0.5793 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:49.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.4172 | Train score: 0.8077 | Val loss: 0.6066 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:50.216\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.3815 | Train score: 0.8077 | Val loss: 0.6311 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:50.719\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.4961 | Train score: 0.7692 | Val loss: 0.6495 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:51.202\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.4558 | Train score: 0.7692 | Val loss: 0.6452 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:51.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.3990 | Train score: 0.8462 | Val loss: 0.6535 | Val score: 0.7273\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:52.234\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.2725 | Train score: 0.8846 | Val loss: 0.6845 | Val score: 0.6970\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:52.741\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.2989 | Train score: 0.8462 | Val loss: 0.7336 | Val score: 0.6667\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:53.480\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.5142 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:54.037\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.5310 | Train score: 0.7692 | Val loss: 0.5074 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:54.580\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.5871 | Train score: 0.7692 | Val loss: 0.5197 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:55.091\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.5344 | Train score: 0.7692 | Val loss: 0.5209 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:55.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.5358 | Train score: 0.7692 | Val loss: 0.5210 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:56.096\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.5357 | Train score: 0.7692 | Val loss: 0.5205 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:56.657\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.5280 | Train score: 0.7692 | Val loss: 0.5177 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:57.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.5167 | Train score: 0.7692 | Val loss: 0.5154 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:57.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.5568 | Train score: 0.7308 | Val loss: 0.5159 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:58.170\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.5277 | Train score: 0.7692 | Val loss: 0.5196 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:58.704\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.5167 | Train score: 0.7692 | Val loss: 0.5210 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:59.175\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.5286 | Train score: 0.7692 | Val loss: 0.5225 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:32:59.641\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.5089 | Train score: 0.7692 | Val loss: 0.5258 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:00.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.4891 | Train score: 0.7692 | Val loss: 0.5397 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:00.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.4596 | Train score: 0.7692 | Val loss: 0.6103 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:01.356\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.4546 | Train score: 0.7308 | Val loss: 0.6929 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:01.905\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.4048 | Train score: 0.8462 | Val loss: 0.7549 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:02.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.5621 | Train score: 0.8077 | Val loss: 0.7607 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:02.960\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.5592 | Train score: 0.7308 | Val loss: 0.7421 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:03.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.4112 | Train score: 0.7692 | Val loss: 0.7304 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:03.980\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.4429 | Train score: 0.8077 | Val loss: 0.6811 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:04.781\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.5556 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:05.309\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.5005 | Train score: 0.8077 | Val loss: 0.5832 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:05.886\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.6313 | Train score: 0.8077 | Val loss: 0.5311 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:06.485\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.5225 | Train score: 0.7308 | Val loss: 0.5079 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:06.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.5672 | Train score: 0.7692 | Val loss: 0.5059 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:07.413\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.5362 | Train score: 0.7692 | Val loss: 0.5114 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:07.941\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.5419 | Train score: 0.7692 | Val loss: 0.5157 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:08.513\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.5400 | Train score: 0.7692 | Val loss: 0.5181 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:09.068\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.5382 | Train score: 0.7692 | Val loss: 0.5192 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:09.670\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.5410 | Train score: 0.7692 | Val loss: 0.5198 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:10.330\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.5355 | Train score: 0.7692 | Val loss: 0.5201 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:10.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.5365 | Train score: 0.7692 | Val loss: 0.5202 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:11.415\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.5374 | Train score: 0.7692 | Val loss: 0.5202 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:11.940\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.5344 | Train score: 0.7692 | Val loss: 0.5200 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:12.496\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.5366 | Train score: 0.7692 | Val loss: 0.5197 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:12.967\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.5290 | Train score: 0.7692 | Val loss: 0.5190 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:13.433\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.5295 | Train score: 0.7692 | Val loss: 0.5183 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:13.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.5270 | Train score: 0.7692 | Val loss: 0.5177 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:14.540\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.5167 | Train score: 0.7692 | Val loss: 0.5173 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:15.012\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.5512 | Train score: 0.7692 | Val loss: 0.5182 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:15.499\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.4887 | Train score: 0.7692 | Val loss: 0.5210 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:16.306\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.6015 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:16.906\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.4886 | Train score: 0.7692 | Val loss: 0.7183 | Val score: 0.7576\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:17.412\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.6486 | Train score: 0.6923 | Val loss: 0.6339 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:17.936\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.6495 | Train score: 0.6923 | Val loss: 0.5939 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:18.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.5668 | Train score: 0.7692 | Val loss: 0.5767 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:19.083\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.6965 | Train score: 0.7692 | Val loss: 0.5619 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:19.593\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.5027 | Train score: 0.7692 | Val loss: 0.5533 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:20.176\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.4874 | Train score: 0.7692 | Val loss: 0.5544 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:20.749\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.5358 | Train score: 0.7692 | Val loss: 0.5526 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:21.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.5302 | Train score: 0.7692 | Val loss: 0.5545 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:21.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.5289 | Train score: 0.7692 | Val loss: 0.5559 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:22.351\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 011 | Train loss: 0.5680 | Train score: 0.7692 | Val loss: 0.5531 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:22.859\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 012 | Train loss: 0.5230 | Train score: 0.7692 | Val loss: 0.5521 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:23.361\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 013 | Train loss: 0.5533 | Train score: 0.7692 | Val loss: 0.5487 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:23.907\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 014 | Train loss: 0.5096 | Train score: 0.7692 | Val loss: 0.5533 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:24.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 015 | Train loss: 0.5234 | Train score: 0.7692 | Val loss: 0.5581 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:25.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 016 | Train loss: 0.5010 | Train score: 0.7692 | Val loss: 0.5686 | Val score: 0.7879\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:25.512\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 017 | Train loss: 0.4746 | Train score: 0.7692 | Val loss: 0.5791 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:26.054\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 018 | Train loss: 0.4619 | Train score: 0.7692 | Val loss: 0.5910 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:26.642\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 019 | Train loss: 0.4634 | Train score: 0.7692 | Val loss: 0.5999 | Val score: 0.8182\u001b[0m\n",
      "\u001b[32m2024-11-05 15:33:27.121\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 020 | Train loss: 0.4464 | Train score: 0.7692 | Val loss: 0.6072 | Val score: 0.7879\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " NonZeroSelect \n",
      "                         accuracy mean  accuracy std  precision mean  precision std  recall mean  recall std  roc_auc mean  roc_auc std  f1 mean  f1 std  runtime mean  runtime std\n",
      "MajorityClass                   0.778         0.000           0.778          0.000        1.000       0.000         0.500        0.000    0.875   0.000         0.000        0.000\n",
      "XGBClassifier                   0.756         0.051           0.820          0.060        0.893       0.092         0.579        0.183    0.849   0.036         0.013        0.001\n",
      "MedPFNClassifier                0.783         0.084           0.828          0.057        0.914       0.089         0.620        0.181    0.867   0.056         0.463        0.018\n",
      "MedPFNClassifier                0.789         0.078           0.822          0.059        0.936       0.067         0.620        0.201    0.873   0.048         4.709        2.812\n",
      "MedPFNClassifier                0.728         0.080           0.804          0.041        0.857       0.071         0.595        0.191    0.829   0.054         0.418        0.013\n",
      "MedPFNClassifier                0.733         0.048           0.796          0.031        0.886       0.047         0.593        0.199    0.838   0.031         1.960        0.060\n",
      "RandomForestClassifier          0.778         0.000           0.778          0.000        1.000       0.000         0.555        0.181    0.875   0.000         0.147        0.006\n",
      "LogisticRegression              0.778         0.000           0.778          0.000        1.000       0.000         0.464        0.155    0.875   0.000         0.002        0.000\n",
      "TabPFNClassifier                0.778         0.000           0.778          0.000        1.000       0.000         0.550        0.163    0.875   0.000         0.626        0.035\n",
      "TabForestPFNClassifier          0.733         0.060           0.777          0.012        0.921       0.103         0.462        0.128    0.840   0.047        11.463        0.404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "save = False\n",
    "sampling = None\n",
    "cv = 10\n",
    "best_delete = 0\n",
    "strat_split = True\n",
    "recomp = False\n",
    "n_optim = 1000\n",
    "cat_optim = 10\n",
    "ft_epochs = 20\n",
    "ft_lr = 1e-5\n",
    "max_s = 1024\n",
    "max_q = 128\n",
    "max_samples = 1024\n",
    "no_pre_process = False\n",
    "multi_decoder = \"permutation\"\n",
    "N_ens = 5\n",
    "seed = 42\n",
    "overwrite = True\n",
    "metrics = [\"accuracy\", \"precision\", \"recall\", \"roc_auc\", \"f1\"]\n",
    "dir_path = os.path.abspath(os.getcwd())\n",
    "run_name = \"medium_net_mlp_balance_bsplit_baseline\" ## NO PERM, VERY ROBUST\n",
    "#run_name2 = \"large_mlp_var_balance_05weight_anova\" ## das aller bestigste\n",
    "run_name = \"medium_mlp_var_balance_05weight_anova_bestwithnoisebnn_100\" ## das aller bestigste\n",
    "run_name2 = \"small_mlp_var_balance_05weight_anova_bestwithnoisebnn_100\" ## das aller bestigste ## das aller bestigste\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_200\" ## das aller bestigste\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_longer\" ## das aller bestigste\n",
    "#run_name = \"medium_mlp_balance_lownoisefixparam_anova\"\n",
    "#run_name = \"medium_mlp_0.5static_balance_anova\"\n",
    "#run_name = \"large_mlp_fullbalance\"\n",
    "#run_name = \"small_net_mlp_var_imbalance_05weight\" ## WORKS VERY WELL WITH PERM\n",
    "#run_name = \"small_net_mlp_varbalance_weight_batchunisplit\"\n",
    "#run_name = \"small_net_mlp_variable_balance_weight\"\n",
    "#run_name = \"small_net_mlp_balance_minevalup\"\n",
    "path = dir_path + f\"/logs/trainrun_{run_name}\"\n",
    "path2 = dir_path + f\"/logs/trainrun_{run_name2}\"\n",
    "filename = \"model\"\n",
    "\n",
    "\n",
    "models = [\n",
    "    #CatBoostOptim(n_optim=cat_optim),\n",
    "    MajorityClass(),\n",
    "    XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic'),\n",
    "    MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process),\n",
    "    MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process, ft_epochs=ft_epochs, ft_lr=ft_lr),\n",
    "    MedPFNClassifier(base_path=path2, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process),\n",
    "    MedPFNClassifier(base_path=path2, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process, ft_epochs=ft_epochs, ft_lr=ft_lr),\n",
    "    RandomForestClassifier(),\n",
    "    #AutoGluon(),\n",
    "    #CatBoostGrid(),\n",
    "    #XGBoostGrid(),\n",
    "    #XGBoostOptim(n_optim=n_optim),\n",
    "    LogisticRegression(max_iter=1000), \n",
    "    TabPFNClassifier(device='cpu', N_ensemble_configurations=5, no_preprocess_mode=no_pre_process),\n",
    "    TabForestPFNClassifier(\"saved_models/tabforest/mix600k/tabforestpfn.pt\", \"saved_models/tabforest/mix600k/config_run.yaml\", max_epochs=ft_epochs)\n",
    "]\n",
    "\n",
    "for reducer in [AnovaSelect(), RandomSelect(), NonZeroSelect(), MeanSelect(), StdSelect(), MaxSelect(), PCASelect()]:\n",
    "    results_mean = pd.DataFrame(np.zeros((len(models), len(metrics)+1)),\n",
    "                                index=[m.__class__.__name__ for m in models],\n",
    "                                columns=metrics+[\"runtime\"])\n",
    "    results_std = pd.DataFrame(np.zeros((len(models), len(metrics)+1)), \n",
    "                               index=[m.__class__.__name__ for m in models],\n",
    "                               columns=metrics+[\"runtime\"])\n",
    "    \n",
    "    for ii, model in enumerate(models):\n",
    "        results_mean.iloc[ii,:], results_std.iloc[ii,:] = cross_validate_sample(\n",
    "            model, all_data, labels, metrics, strat_split, cv, sampling, \n",
    "            reducer, max_samples, seed=seed, overwrite=overwrite, n_best_delete=best_delete,\n",
    "            recomp=recomp)\n",
    "\n",
    "    results_mean = results_mean.add_suffix(\" mean\")\n",
    "    results_std = results_std.add_suffix(\" std\")\n",
    "    results_full = pd.concat((results_mean, results_std), axis=1)\n",
    "    cols = results_full.columns.tolist()\n",
    "    new_cols = []\n",
    "    for i in range(int(len(cols)/2)):\n",
    "        new_cols.append(cols[i])\n",
    "        new_cols.append(cols[i+int(len(cols)/2)])\n",
    "    results_full = results_full[new_cols]\n",
    "    red_name = reducer.__class__.__name__\n",
    "    if save:\n",
    "        directory = f\"results/{red_name}\"\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        save_path = f'results/{red_name}/baseline_cv{cv}_mxsamp{max_samples}_sd{seed}_ovrw{int(overwrite)}'\n",
    "        results_full.to_csv(save_path)\n",
    "    print(\"\\n\", \"\\n\", red_name, \"\\n\", results_full.round(3))\n",
    "    #print(results_full.sort_values(\"roc_auc mean\").round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef9e5ef-c542-4525-8e60-6ae0ad51b6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = False\n",
    "sampling = None\n",
    "cv = 10\n",
    "best_delete = 0\n",
    "strat_split = True\n",
    "recomp = False\n",
    "n_optim = 1000\n",
    "cat_optim = 10\n",
    "ft_epochs = 20\n",
    "ft_epochs_forest = 10\n",
    "ft_lr = 1e-5\n",
    "max_s = 1024\n",
    "max_q = 128\n",
    "max_samples = 1024\n",
    "no_pre_process = False\n",
    "multi_decoder = \"permutation\"\n",
    "N_ens = 5\n",
    "seed = 42\n",
    "overwrite = True\n",
    "metrics = [\"accuracy\", \"precision\", \"recall\", \"roc_auc\", \"f1\"]\n",
    "dir_path = os.path.abspath(os.getcwd())\n",
    "#run_name = \"medium_net_mlp_balance_bsplit_baseline\" ## NO PERM, VERY ROBUST\n",
    "#run_name2 = \"large_mlp_var_balance_05weight_anova\" ## das aller bestigste\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_newprior\" ## das aller bestigste\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_newprior\" ## das aller bestigste\n",
    "run_name = \"medium_mlp_var_balance_05weight_anova_bestwithnoisebnn_100\" ## good start, best with ft\n",
    "#run_name3 = \"medium_mlp_var_balance_05weight_anova_bestwithnoisebnn_100_moreweight\" ## best start, ft no so good\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_200\" ## das aller bestigste\n",
    "#run_name = \"medium_mlp_var_balance_05weight_anova_longer\" ## das aller bestigste\n",
    "#run_name = \"medium_mlp_balance_lownoisefixparam_anova\"\n",
    "#run_name = \"medium_mlp_0.5static_balance_anova\"\n",
    "#run_name = \"large_mlp_fullbalance\"\n",
    "#run_name = \"small_net_mlp_var_imbalance_05weight\" ## WORKS VERY WELL WITH PERM\n",
    "#run_name = \"small_net_mlp_varbalance_weight_batchunisplit\"\n",
    "#run_name = \"small_net_mlp_variable_balance_weight\"\n",
    "#run_name = \"small_net_mlp_balance_minevalup\"\n",
    "path = dir_path + f\"/logs/trainrun_{run_name}\"\n",
    "#path2 = dir_path + f\"/logs/trainrun_{run_name2}\"\n",
    "#path3 = dir_path + f\"/logs/trainrun_{run_name3}\"\n",
    "filename = \"model\"\n",
    "\n",
    "\n",
    "models = [\n",
    "    MajorityClass(),\n",
    "    XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic'),\n",
    "    MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=1, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process),\n",
    "    MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process),\n",
    "    MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process,\n",
    "                    ft_epochs=ft_epochs, ft_lr=ft_lr),\n",
    "    RandomForestClassifier(),\n",
    "    #AutoGluon(),\n",
    "    #CatBoostGrid(),\n",
    "    #XGBoostGrid(),\n",
    "    LogisticRegressionClassifier(), \n",
    "    #TabPFNClassifier(device='cpu', N_ensemble_configurations=5, no_preprocess_mode=no_pre_process),\n",
    "    #TabForestPFNClassifier(\"saved_models/tabforest/mix600k/tabforestpfn.pt\", \"saved_models/tabforest/mix600k/config_run.yaml\", max_epochs=ft_epochs_forest)\n",
    "]\n",
    "reducer  = AnovaSelect()\n",
    "#for reducer in [AnovaSelect(), RandomSelect(), NonZeroSelect(), MeanSelect(), StdSelect(), MaxSelect(), PCASelect()]:\n",
    "#data = clr(all_data)\n",
    "\n",
    "#all_data = normalize(all_data)\n",
    "\n",
    "results_mean = pd.DataFrame(np.zeros((len(models), len(metrics)+1)),\n",
    "                            index=[m.__class__.__name__ for m in models],\n",
    "                            columns=metrics+[\"runtime\"])\n",
    "results_std = pd.DataFrame(np.zeros((len(models), len(metrics)+1)), \n",
    "                           index=[m.__class__.__name__ for m in models],\n",
    "                           columns=metrics+[\"runtime\"])\n",
    "\n",
    "for ii, model in enumerate(models):\n",
    "    results_mean.iloc[ii,:], results_std.iloc[ii,:] = cross_validate_sample(\n",
    "        model, all_data, labels, metrics, strat_split, cv, sampling, \n",
    "        reducer, max_samples, seed=seed, overwrite=overwrite, n_best_delete=best_delete,\n",
    "        recomp=recomp)\n",
    "\n",
    "results_mean = results_mean.add_suffix(\" mean\")\n",
    "results_std = results_std.add_suffix(\" std\")\n",
    "results_full = pd.concat((results_mean, results_std), axis=1)\n",
    "cols = results_full.columns.tolist()\n",
    "new_cols = []\n",
    "for i in range(int(len(cols)/2)):\n",
    "    new_cols.append(cols[i])\n",
    "    new_cols.append(cols[i+int(len(cols)/2)])\n",
    "results_full = results_full[new_cols]\n",
    "red_name = reducer.__class__.__name__\n",
    "if save:\n",
    "    directory = f\"results/{red_name}\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    save_path = f'results/{red_name}/baseline_cv{cv}_mxsamp{max_samples}_sd{seed}_ovrw{int(overwrite)}.csv'\n",
    "    results_full.to_csv(save_path)\n",
    "print(\"\\n\", \"\\n\", red_name, \"\\n\", results_full.round(3))\n",
    "#print(results_full.sort_values(\"roc_auc mean\").round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10eb424e-0b18-471f-9cf6-4b1ce31e88c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save = True\n",
    "sampling = None\n",
    "cv = 7\n",
    "best_delete = 0\n",
    "strat_split = True\n",
    "n_optim = 1000\n",
    "cat_optim = 10\n",
    "ft_epochs = 10\n",
    "ft_lr = 1e-7\n",
    "max_s = 1024\n",
    "max_q = 128\n",
    "max_samples = 1024\n",
    "no_pre_process = False\n",
    "multi_decoder = \"permutation\"\n",
    "N_ens = 7\n",
    "seed = 42\n",
    "overwrite = True\n",
    "metrics = [\"accuracy\", \"precision\", \"recall\", \"roc_auc\", \"f1\"]\n",
    "dir_path = os.path.abspath(os.getcwd())\n",
    "run_name = \"medium_net_mlp_balance_bsplit_baseline\" ## NO PERM, VERY ROBUST\n",
    "run_name = \"medium_mlp_var_balance_05weight_anova\" ### BEST!!!!!! ####\n",
    "#run_name = \"medium_mlp_balance_lownoisefixparam_anova\"\n",
    "#run_name = \"medium_mlp_0.5static_balance_anova\"\n",
    "#run_name = \"large_mlp_fullbalance\"\n",
    "#run_name = \"small_net_mlp_var_imbalance_05weight\" ## WORKS VERY WELL WITH PERM\n",
    "#run_name = \"small_net_mlp_varbalance_weight_batchunisplit\"\n",
    "#run_name = \"small_net_mlp_variable_balance_weight\"\n",
    "#run_name = \"small_net_mlp_balance_minevalup\"\n",
    "path = dir_path + f\"/logs/trainrun_{run_name}\"\n",
    "filename = \"model\"\n",
    "models = [\n",
    "    #CatBoostOptim(n_optim=cat_optim),\n",
    "    XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic'),\n",
    "    MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process),\n",
    "    RandomForestClassifier(),\n",
    "    #XGBoostOptim(n_optim=n_optim),\n",
    "    LogisticRegression(max_iter=1000), \n",
    "    TabPFNClassifier(device='cpu', N_ensemble_configurations=5, no_preprocess_mode=no_pre_process),\n",
    "    TabForestPFNClassifier(\"saved_models/tabforest/mix600k/tabforestpfn.pt\", \"saved_models/tabforest/mix600k/config_run.yaml\", max_epochs=ft_epochs)\n",
    "]\n",
    "\n",
    "#for reducer in [AnovaSelect(), NonZeroSelect(), MeanSelect(), StdSelect(), MaxSelect(), PCASelect()]:\n",
    "reducer = AnovaSelect()\n",
    "#for reduce_data in [top_anova, top_non_zero, top_mean, top_std, top_max, pca_reduce]:\n",
    "    #data = reduce_data(all_data, labels, 100)\n",
    "    #print(all_data.shape)\n",
    "for best_delete in range(0,510,10):\n",
    "    #reducer.k = 100\n",
    "    #reducer = None\n",
    "    results_mean = pd.DataFrame(np.zeros((len(models), len(metrics)+1)),\n",
    "                                index=[m.__class__.__name__ for m in models],\n",
    "                                columns=metrics+[\"runtime\"])\n",
    "    results_std = pd.DataFrame(np.zeros((len(models), len(metrics)+1)), \n",
    "                               index=[m.__class__.__name__ for m in models],\n",
    "                               columns=metrics+[\"runtime\"])\n",
    "    \n",
    "    for ii, model in enumerate(models):\n",
    "        results_mean.iloc[ii,:], results_std.iloc[ii,:] = cross_validate_sample(\n",
    "            model, all_data, labels, metrics, strat_split, cv, sampling, \n",
    "            reducer, max_samples, seed=seed, overwrite=overwrite, n_best_delete=best_delete)\n",
    "\n",
    "    results_mean = results_mean.add_suffix(\" mean\")\n",
    "    results_std = results_std.add_suffix(\" std\")\n",
    "    results_full = pd.concat((results_mean, results_std), axis=1)\n",
    "    cols = results_full.columns.tolist()\n",
    "    new_cols = []\n",
    "    for i in range(int(len(cols)/2)):\n",
    "        new_cols.append(cols[i])\n",
    "        new_cols.append(cols[i+int(len(cols)/2)])\n",
    "    results_full = results_full[new_cols]\n",
    "    red_name = \"feature_select_shift_10step\"\n",
    "    if save:\n",
    "        directory = f\"results/{red_name}\"\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        save_path = f'results/{red_name}/{best_delete}_cv{cv}_mxsamp{max_samples}_sd{seed}_ovrw{int(overwrite)}'\n",
    "        results_full.to_csv(save_path)\n",
    "    print(\"\\n\", \"\\n\", red_name, \"\\n\", results_full.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16f86dc-a1ee-4706-bc17-cbedd58ff3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "all_labels = []\n",
    "for p in [\"datasets/CRC_AUS_LOSO.csv\", \n",
    "          \"datasets/CRC_FRA_LOSO.csv\",\n",
    "         \"datasets/CRC_CHI_LOSO.csv\",\n",
    "         \"datasets/CRC_GER_LOSO.csv\",\n",
    "         #\"datasets/CRC_IND_additional.csv\",\n",
    "         \"datasets/CRC_USA_LOSO.csv\"]:\n",
    "    df = pd.read_csv(p)\n",
    "    df_binary = df.loc[(df[\"disease\"] == \"healthy\") | (df[\"disease\"]==\"CRC\")]\n",
    "    df_data = df_binary.iloc[:,4:]\n",
    "    data = df_data.to_numpy()\n",
    "    labels = df_binary[\"disease\"].to_numpy()\n",
    "    labels[labels==\"healthy\"] = 0\n",
    "    labels[labels==\"CRC\"] = 1\n",
    "    data = (1/np.sum(data, axis=1, keepdims=True))*data\n",
    "    all_data.append(data)\n",
    "    all_labels.append(labels)\n",
    "\n",
    "all_data = np.concatenate(all_data,axis=0)\n",
    "labels = np.concatenate(all_labels)\n",
    "all_data, labels = unison_shuffled_copies(all_data, labels, seed=412)\n",
    "c1_ind = (labels==1).nonzero()[0]\n",
    "c1_del = c1_ind[:int(len(c1_ind)*0.97)]\n",
    "all_data, labels = np.delete(all_data, c1_del, axis=0), np.delete(labels, c1_del, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbafc58-eff4-4b74-b585-52c0a8cf6234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da53d28-57c8-48ba-a1e1-3080b58d3553",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = 20\n",
    "rocs = []\n",
    "f1s = []\n",
    "for i in range(0,510,10):\n",
    "    results = pd.read_csv(f'results/feature_select_shift_10step/{i}_cv{7}_mxsamp{1024}_sd{42}_ovrw{1}')\n",
    "    rocs.append(results[\"roc_auc mean\"].values)\n",
    "    f1s.append(results[\"f1 mean\"].values)\n",
    "rocs = np.array(rocs)\n",
    "f1s = np.array(f1s)\n",
    "labels = results.iloc[:,0].values\n",
    "plt.figure(figsize=(12,3), dpi=200)\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\n",
    "colors = []\n",
    "for cl in range(rocs.shape[1]):\n",
    "    ax1.plot(np.arange(rocs.shape[0]-ws+1)*10, moving_average(rocs[:,cl], ws), label=labels[cl])\n",
    "    ax2.plot(np.arange(rocs.shape[0]-ws+1)*10, moving_average(f1s[:,cl], ws), label=labels[cl])\n",
    "plt.suptitle(\"ROC AUC and F1-Score shifting feature selection\")\n",
    "#ax1.set_title(\"ROC AUC\")\n",
    "ax1.set_ylabel(\"ROC AUC\")\n",
    "#ax2.set_title(\"F1-Score\")\n",
    "ax2.set_xlabel(\"feature shift\")\n",
    "ax2.set_ylabel(\"F1\")\n",
    "ax1.legend(fontsize=7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d448cf5d-91f9-4f84-9477-6fe30540037e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229c531a-d6f8-464b-bb73-476293131bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.count_nonzero(all_data, axis=0)\n",
    "counts = 1-counts/all_data.shape[0]\n",
    "means = np.mean(all_data, axis=0)\n",
    "plt.scatter(counts, means, s=1)\n",
    "plt.show()\n",
    "plt.scatter(counts, np.max(all_data, axis=0), s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e216c8ae-5da2-4b93-bbde-e5bd0009e3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3d2554-f847-48c5-9566-e04693fa8eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = os.path.abspath(os.getcwd())\n",
    "run_name = \"medium_net_mlp_balance_bsplit_baseline\"\n",
    "run_name = \"medium_net_mlp_balance_bsplit_baseline_longer\"\n",
    "path = dir_path + f\"/logs/trainrun_{run_name}\"\n",
    "filename = \"model\"\n",
    "for sampling in [None]:#, undersample]:\n",
    "    cv = 5\n",
    "    strat_split = True\n",
    "    n_optim = 1000\n",
    "    cat_optim = 10\n",
    "    ft_epochs = 10\n",
    "    ft_lr = 1e-8\n",
    "    max_s = 1024\n",
    "    max_q = 128\n",
    "    max_samples = None\n",
    "    no_pre_process = False\n",
    "    multi_decoder = None\n",
    "    N_ens = 5\n",
    "    metrics = [\"accuracy\", \"precision\", \"recall\", \"roc_auc\"]\n",
    "    models = [\n",
    "        #CatBoostOptim(n_optim=cat_optim),\n",
    "        #MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder, ft_epochs=ft_epochs, ft_lr=ft_lr,\n",
    "        #                 max_s=max_s, max_q=max_q, no_preprocess_mode=no_pre_process),\n",
    "        MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process),\n",
    "        #MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=5, no_preprocess_mode=True),\n",
    "        XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic'),\n",
    "        XGBoostOptim(n_optim=n_optim),\n",
    "        LogisticRegression(max_iter=500), \n",
    "        TabPFNClassifier(device='cpu', N_ensemble_configurations=5, no_preprocess_mode=no_pre_process),\n",
    "        TabForestPFNClassifier(\"saved_models/tabforest/mix600k/tabforestpfn.pt\", \"saved_models/tabforest/mix600k/config_run.yaml\", max_epochs=ft_epochs)\n",
    "    ]\n",
    "    results_mean = pd.DataFrame(np.zeros((len(models), len(metrics)+1)),\n",
    "                                index=[m.__class__.__name__ for m in models],\n",
    "                                columns=metrics+[\"runtime\"])\n",
    "    results_std = pd.DataFrame(np.zeros((len(models), len(metrics)+1)), \n",
    "                               index=[m.__class__.__name__ for m in models],\n",
    "                               columns=metrics+[\"runtime\"])\n",
    "    \n",
    "    for ii, model in enumerate(models):\n",
    "        results_mean.iloc[ii,:], results_std.iloc[ii,:] = cross_validate_sample(model, data, labels, metrics, strat_split, cv, sampling, max_samples)\n",
    "    #results_sorted = results.sort_values(\"roc_auc\")\n",
    "    #print(results_sorted)\n",
    "    print(results_mean)\n",
    "    print(results_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04052993-69b3-4c87-9bf8-163357aa9fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = []\n",
    "for m in metrics + \"runtime\":\n",
    "    cols.append(m)\n",
    "    cols.append(m+\" std\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc23d5f-155a-4e3d-b696-1fd6439a0cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dir_path = os.path.abspath(os.getcwd())\n",
    "run_name = \"medium_net_mlp_balance_bsplit_baseline\"\n",
    "path = dir_path + f\"/logs/trainrun_{run_name}\"\n",
    "filename = \"model\"\n",
    "#model, config = load_model(path, filename, device=\"cpu\", eval_positions=None, verbose=0)\n",
    "#pred_model = TabPFNClassifier(model[2], config, device=\"cpu\", N_ensemble_configurations=5, no_preprocess_mode=False)\n",
    "for sampling in [None]:\n",
    "    cv = 3\n",
    "    strat_split = True\n",
    "    n_optim = 10\n",
    "    ft_epochs = 10\n",
    "    max_samples = None\n",
    "    metrics = metrics = [\"accuracy\", \"precision\", \"recall\", \"roc_auc\"]\n",
    "    models = [\n",
    "        RandomForestClassifier()\n",
    "        #CatBoostOptim(n_optim=n_optim),\n",
    "        #pred_model,\n",
    "        #MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=3, no_preprocess_mode=True),\n",
    "        #XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic'),\n",
    "        #XGBoostOptim(n_optim=n_optim),\n",
    "        #LogisticRegression(max_iter=500), \n",
    "        #TabPFNClassifier(device='cpu', N_ensemble_configurations=3, no_preprocess_mode=True),\n",
    "        #TabForestPFNClassifier(\"saved_models/tabforest/mix600k/tabforestpfn.pt\", \"saved_models/tabforest/mix600k/config_run.yaml\", max_epochs=ft_epochs)\n",
    "    ]\n",
    "    results = pd.DataFrame(np.zeros((len(models), len(metrics)+1)), \n",
    "                           index=[m.__class__.__name__ for m in models],\n",
    "                          columns=metrics+[\"runtime\"])\n",
    "    \n",
    "    for ii, model in enumerate(models):\n",
    "        results.iloc[ii,:] = cross_validate_sample(model, data, labels, metrics, strat_split, cv, sampling, max_samples)\n",
    "    results_sorted = results.sort_values(\"roc_auc\")\n",
    "    \n",
    "    print(results_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5983e6a1-a7ce-4694-b775-e83498cd3be9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819f6306-686d-42f1-829c-303890202785",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac970c40-6003-4c24-b454-014ba31f6b26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
