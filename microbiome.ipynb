{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "716a0985-a3e5-47be-acc6-d58fb95fa8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from tabpfn_new.scripts.transformer_prediction_interface import TabPFNClassifier, MedPFNClassifier\n",
    "from tabpfn_new.scripts.model_builder import load_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from data_prep_utils import *\n",
    "from evaluate import *\n",
    "from load_models import *\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import openml\n",
    "import time\n",
    "pd.set_option('display.expand_frame_repr', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "879ba0a8-b675-49eb-a1dc-64e836de555b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "Using cpu:0 device\n",
      "Using a Transformer with 6.48 M parameters\n"
     ]
    }
   ],
   "source": [
    "path = \"datasets/data_all.csv\"\n",
    "all_data, labels = get_microbiome(path)\n",
    "all_data = remove_zero_features(all_data)\n",
    "sampling = None\n",
    "cv = 5\n",
    "strat_split = True\n",
    "n_optim = 1000\n",
    "cat_optim = 10\n",
    "ft_epochs = 10\n",
    "ft_lr = 1e-7\n",
    "max_s = 1024\n",
    "max_q = 128\n",
    "max_samples = 1024\n",
    "no_pre_process = False\n",
    "multi_decoder = None\n",
    "N_ens = 3\n",
    "seed = 111\n",
    "overwrite = True\n",
    "metrics = [\"accuracy\", \"precision\", \"recall\", \"roc_auc\", \"f1\"]\n",
    "dir_path = os.path.abspath(os.getcwd())\n",
    "run_name = \"medium_net_mlp_balance_bsplit_baseline\"\n",
    "#run_name = \"large_mlp_fullbalance\"\n",
    "#run_name = \"small_net_mlp_var_imbalance_05weight\"\n",
    "#run_name = \"small_net_mlp_varbalance_weight_batchunisplit\"\n",
    "#run_name = \"small_net_mlp_variable_balance_weight\"\n",
    "#run_name = \"small_net_mlp_balance_minevalup\"\n",
    "path = dir_path + f\"/logs/trainrun_{run_name}\"\n",
    "filename = \"model\"\n",
    "models = [\n",
    "    #CatBoostOptim(n_optim=cat_optim),\n",
    "    XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic'),\n",
    "    MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process),\n",
    "    RandomForestClassifier(),\n",
    "    #XGBoostOptim(n_optim=n_optim),\n",
    "    LogisticRegression(max_iter=500), \n",
    "    #TabPFNClassifier(device='cpu', N_ensemble_configurations=5, no_preprocess_mode=no_pre_process),\n",
    "    #TabForestPFNClassifier(\"saved_models/tabforest/mix600k/tabforestpfn.pt\", \"saved_models/tabforest/mix600k/config_run.yaml\", max_epochs=ft_epochs)\n",
    "]\n",
    "\n",
    "all_data, labels = unison_shuffled_copies(all_data, labels, seed)\n",
    "for reducer in [AnovaSelect()]:#, NonZeroSelect(), MeanSelect(), StdSelect(), MaxSelect(), PCASelect()]:\n",
    "#reducer = None\n",
    "#for reduce_data in [pca_reduce, top_anova, top_non_zero, top_mean, top_std, top_max]:\n",
    "    #data = reduce_data(all_data, labels, 50)\n",
    "    #print(all_data.shape)\n",
    "    for dele in range(100,1):\n",
    "        reducer.k = dele\n",
    "        results_mean = pd.DataFrame(np.zeros((len(models), len(metrics)+1)),\n",
    "                                    index=[m.__class__.__name__ for m in models],\n",
    "                                    columns=metrics+[\"runtime\"])\n",
    "        results_std = pd.DataFrame(np.zeros((len(models), len(metrics)+1)), \n",
    "                                   index=[m.__class__.__name__ for m in models],\n",
    "                                   columns=metrics+[\"runtime\"])\n",
    "        \n",
    "        for ii, model in enumerate(models):\n",
    "            results_mean.iloc[ii,:], results_std.iloc[ii,:] = cross_validate_sample(\n",
    "                model, all_data, labels, metrics, strat_split, cv, sampling, \n",
    "                reducer, max_samples, seed=seed, overwrite=overwrite, n_best_delete=dele)\n",
    "    \n",
    "        results_mean = results_mean.add_suffix(\" mean\")\n",
    "        results_std = results_std.add_suffix(\" std\")\n",
    "        results_full = pd.concat((results_mean, results_std), axis=1)\n",
    "        cols = results_full.columns.tolist()\n",
    "        new_cols = []\n",
    "        for i in range(int(len(cols)/2)):\n",
    "            new_cols.append(cols[i])\n",
    "            new_cols.append(cols[i+int(len(cols)/2)])\n",
    "        results_full = results_full[new_cols]\n",
    "        '''directory = f\"results/{reduce_data.__name__}\"\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        save_path = f'results/{reduce_data.__name__}/baseline_cv{cv}_mxsamp{max_samples}_sd{seed}_ovrw{int(overwrite)}\n",
    "        print(\"\\n\", \"\\n\", reduce_data.__name__, \"\\n\", results_full.round(3))'''\n",
    "        print(\"\\n\", \"\\n\", reducer.__class__.__name__, \"\\n\", results_full.round(3))\n",
    "        #results_full.to_csv(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613e9242-f2f9-4b31-a16c-bd900bff9573",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(10,10)\n",
    "a = np.delete(a,1,1)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e216c8ae-5da2-4b93-bbde-e5bd0009e3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3d2554-f847-48c5-9566-e04693fa8eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = os.path.abspath(os.getcwd())\n",
    "run_name = \"medium_net_mlp_balance_bsplit_baseline\"\n",
    "run_name = \"medium_net_mlp_balance_bsplit_baseline_longer\"\n",
    "path = dir_path + f\"/logs/trainrun_{run_name}\"\n",
    "filename = \"model\"\n",
    "for sampling in [None]:#, undersample]:\n",
    "    cv = 5\n",
    "    strat_split = True\n",
    "    n_optim = 1000\n",
    "    cat_optim = 10\n",
    "    ft_epochs = 10\n",
    "    ft_lr = 1e-8\n",
    "    max_s = 1024\n",
    "    max_q = 128\n",
    "    max_samples = None\n",
    "    no_pre_process = False\n",
    "    multi_decoder = None\n",
    "    N_ens = 5\n",
    "    metrics = [\"accuracy\", \"precision\", \"recall\", \"roc_auc\"]\n",
    "    models = [\n",
    "        #CatBoostOptim(n_optim=cat_optim),\n",
    "        #MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder, ft_epochs=ft_epochs, ft_lr=ft_lr,\n",
    "        #                 max_s=max_s, max_q=max_q, no_preprocess_mode=no_pre_process),\n",
    "        MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=N_ens, multiclass_decoder=multi_decoder,  no_preprocess_mode=no_pre_process),\n",
    "        #MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=5, no_preprocess_mode=True),\n",
    "        XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic'),\n",
    "        XGBoostOptim(n_optim=n_optim),\n",
    "        LogisticRegression(max_iter=500), \n",
    "        TabPFNClassifier(device='cpu', N_ensemble_configurations=5, no_preprocess_mode=no_pre_process),\n",
    "        TabForestPFNClassifier(\"saved_models/tabforest/mix600k/tabforestpfn.pt\", \"saved_models/tabforest/mix600k/config_run.yaml\", max_epochs=ft_epochs)\n",
    "    ]\n",
    "    results_mean = pd.DataFrame(np.zeros((len(models), len(metrics)+1)),\n",
    "                                index=[m.__class__.__name__ for m in models],\n",
    "                                columns=metrics+[\"runtime\"])\n",
    "    results_std = pd.DataFrame(np.zeros((len(models), len(metrics)+1)), \n",
    "                               index=[m.__class__.__name__ for m in models],\n",
    "                               columns=metrics+[\"runtime\"])\n",
    "    \n",
    "    for ii, model in enumerate(models):\n",
    "        results_mean.iloc[ii,:], results_std.iloc[ii,:] = cross_validate_sample(model, data, labels, metrics, strat_split, cv, sampling, max_samples)\n",
    "    #results_sorted = results.sort_values(\"roc_auc\")\n",
    "    #print(results_sorted)\n",
    "    print(results_mean)\n",
    "    print(results_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04052993-69b3-4c87-9bf8-163357aa9fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = []\n",
    "for m in metrics + \"runtime\":\n",
    "    cols.append(m)\n",
    "    cols.append(m+\" std\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc23d5f-155a-4e3d-b696-1fd6439a0cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dir_path = os.path.abspath(os.getcwd())\n",
    "run_name = \"medium_net_mlp_balance_bsplit_baseline\"\n",
    "path = dir_path + f\"/logs/trainrun_{run_name}\"\n",
    "filename = \"model\"\n",
    "#model, config = load_model(path, filename, device=\"cpu\", eval_positions=None, verbose=0)\n",
    "#pred_model = TabPFNClassifier(model[2], config, device=\"cpu\", N_ensemble_configurations=5, no_preprocess_mode=False)\n",
    "for sampling in [None]:\n",
    "    cv = 3\n",
    "    strat_split = True\n",
    "    n_optim = 10\n",
    "    ft_epochs = 10\n",
    "    max_samples = None\n",
    "    metrics = metrics = [\"accuracy\", \"precision\", \"recall\", \"roc_auc\"]\n",
    "    models = [\n",
    "        RandomForestClassifier()\n",
    "        #CatBoostOptim(n_optim=n_optim),\n",
    "        #pred_model,\n",
    "        #MedPFNClassifier(base_path=path, filename=filename, device='cpu', N_ensemble_configurations=3, no_preprocess_mode=True),\n",
    "        #XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic'),\n",
    "        #XGBoostOptim(n_optim=n_optim),\n",
    "        #LogisticRegression(max_iter=500), \n",
    "        #TabPFNClassifier(device='cpu', N_ensemble_configurations=3, no_preprocess_mode=True),\n",
    "        #TabForestPFNClassifier(\"saved_models/tabforest/mix600k/tabforestpfn.pt\", \"saved_models/tabforest/mix600k/config_run.yaml\", max_epochs=ft_epochs)\n",
    "    ]\n",
    "    results = pd.DataFrame(np.zeros((len(models), len(metrics)+1)), \n",
    "                           index=[m.__class__.__name__ for m in models],\n",
    "                          columns=metrics+[\"runtime\"])\n",
    "    \n",
    "    for ii, model in enumerate(models):\n",
    "        results.iloc[ii,:] = cross_validate_sample(model, data, labels, metrics, strat_split, cv, sampling, max_samples)\n",
    "    results_sorted = results.sort_values(\"roc_auc\")\n",
    "    \n",
    "    print(results_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5983e6a1-a7ce-4694-b775-e83498cd3be9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819f6306-686d-42f1-829c-303890202785",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac970c40-6003-4c24-b454-014ba31f6b26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
