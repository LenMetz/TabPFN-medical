{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "716a0985-a3e5-47be-acc6-d58fb95fa8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "from tabpfn import TabPFNClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from data_prep_utils import *\n",
    "from evaluate import *\n",
    "from load_models import *\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import openml\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fd72aea-dcf4-4d2c-bc6b-63eb9ccfdd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"datasets/data_all.csv\"\n",
    "data, labels = get_microbiome(path)\n",
    "data = top_non_zero(data)\n",
    "data, labels = unison_shuffled_copies(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "879ba0a8-b675-49eb-a1dc-64e836de555b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = 3\n",
    "strat_split = True\n",
    "n_optim = 1000\n",
    "ft_epochs = 10\n",
    "sampling = None\n",
    "metrics = metrics = [\"accuracy\", \"precision\", \"recall\", \"roc_auc\"]\n",
    "models = [\n",
    "    XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic'),\n",
    "    XGBoostOptim(n_optim=n_optim),\n",
    "    LogisticRegression(max_iter=500), \n",
    "    TabPFNClassifier(device='cpu', N_ensemble_configurations=3),\n",
    "    TabForestPFNClassifier(\"saved_models/tabforest/mix600k/tabforestpfn.pt\", \"saved_models/tabforest/mix600k/config_run.yaml\", max_epochs=ft_epochs)\n",
    "]\n",
    "results = pd.DataFrame(np.zeros((len(models), len(metrics)+1)), \n",
    "                       index=[m.__class__.__name__ for m in models],\n",
    "                      columns=metrics+[\"runtime\"])\n",
    "\n",
    "for ii, model in enumerate(models):\n",
    "    results.iloc[ii,:] = cross_validate_sample(model, data, labels, metrics, strat_split, cv, sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5983e6a1-a7ce-4694-b775-e83498cd3be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               accuracy  precision    recall   roc_auc     runtime\n",
      "XGBClassifier  0.930785   0.379902  0.213162  0.595287    0.167719\n",
      "XGBoostOptim   0.947630   0.742648  0.216023  0.605595  601.872008\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ab792db-2c39-4e9e-80da-6b8b386de0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9389892642052894\n",
      "0.9389892642052894\n",
      "0.9389892642052894\n",
      "152.9787\n",
      "156.81378\n",
      "10000000000.0\n"
     ]
    }
   ],
   "source": [
    "def stratified_split(data, labels, cv=3):\n",
    "    size = labels.shape[0]\n",
    "    fold_size = size//cv\n",
    "    counts = np.unique(labels, return_counts=True)\n",
    "    c0_size = np.floor(fold_size*counts[1][0]/size).astype(int)\n",
    "    c1_size = np.floor(fold_size*counts[1][1]/size).astype(int)#fold_size-c0_size\n",
    "    \n",
    "    c0_data = data[labels==0]\n",
    "    c1_data = data[labels==1]\n",
    "    np.random.shuffle(c0_data)\n",
    "    np.random.shuffle(c1_data)\n",
    "    \n",
    "    data_folds, labels_folds = [], []\n",
    "    for f in range(cv):\n",
    "        data_single_fold = np.concatenate((c0_data[c0_size*f:c0_size*(f+1),:],c1_data[c1_size*f:c1_size*(f+1),:]))\n",
    "        labels_single_fold = np.concatenate((np.zeros((c0_size)), np.ones((c1_size))))\n",
    "        data_single_fold, labels_single_fold = unison_shuffled_copies(data_single_fold, labels_single_fold)\n",
    "        data_folds.append(data_single_fold)\n",
    "        labels_folds.append(labels_single_fold)\n",
    "        \n",
    "    return data_folds, labels_folds\n",
    "data[100] = 1e10\n",
    "data_folds, labels_folds = stratified_split(data, labels)\n",
    "\n",
    "for fold in labels_folds:\n",
    "    counts = np.unique(fold, return_counts=True)\n",
    "    print(counts[1][0]/np.sum(counts[1]))\n",
    "for fold in data_folds:\n",
    "    print(np.max(fold))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
