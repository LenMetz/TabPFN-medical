{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "716a0985-a3e5-47be-acc6-d58fb95fa8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "from tabpfn_new.scripts.transformer_prediction_interface import TabPFNClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from data_prep_utils import *\n",
    "from evaluate import *\n",
    "from load_models import *\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import openml\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fd72aea-dcf4-4d2c-bc6b-63eb9ccfdd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"datasets/data_all.csv\"\n",
    "data, labels = get_microbiome(path)\n",
    "data = top_non_zero(data)\n",
    "data, labels = unison_shuffled_copies(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "879ba0a8-b675-49eb-a1dc-64e836de555b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[32m2024-10-02 21:21:43.961\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1896 | Val score: 0.9450\u001b[0m\n",
      "\u001b[32m2024-10-02 21:21:46.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1990 | Train score: 0.9437 | Val loss: 0.1940 | Val score: 0.9450\u001b[0m\n",
      "\u001b[32m2024-10-02 21:21:49.487\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2016 | Train score: 0.9375 | Val loss: 0.1959 | Val score: 0.9450\u001b[0m\n",
      "\u001b[32m2024-10-02 21:21:52.263\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1619 | Train score: 0.9375 | Val loss: 0.1964 | Val score: 0.9450\u001b[0m\n",
      "\u001b[32m2024-10-02 21:21:55.259\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1926 | Train score: 0.9375 | Val loss: 0.1939 | Val score: 0.9400\u001b[0m\n",
      "\u001b[32m2024-10-02 21:21:58.264\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1518 | Train score: 0.9313 | Val loss: 0.1937 | Val score: 0.9300\u001b[0m\n",
      "\u001b[32m2024-10-02 21:22:01.331\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.2057 | Train score: 0.9187 | Val loss: 0.1922 | Val score: 0.9300\u001b[0m\n",
      "\u001b[32m2024-10-02 21:22:04.358\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1433 | Train score: 0.9563 | Val loss: 0.1930 | Val score: 0.9300\u001b[0m\n",
      "\u001b[32m2024-10-02 21:22:07.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.2478 | Train score: 0.9187 | Val loss: 0.1913 | Val score: 0.9300\u001b[0m\n",
      "\u001b[32m2024-10-02 21:22:10.068\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1865 | Train score: 0.9563 | Val loss: 0.1892 | Val score: 0.9300\u001b[0m\n",
      "\u001b[32m2024-10-02 21:22:13.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1449 | Train score: 0.9437 | Val loss: 0.1880 | Val score: 0.9250\u001b[0m\n",
      "\u001b[32m2024-10-02 21:22:15.805\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1517 | Val score: 0.9500\u001b[0m\n",
      "\u001b[32m2024-10-02 21:22:18.738\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2501 | Train score: 0.9437 | Val loss: 0.1582 | Val score: 0.9450\u001b[0m\n",
      "\u001b[32m2024-10-02 21:22:21.335\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1829 | Train score: 0.9437 | Val loss: 0.1599 | Val score: 0.9400\u001b[0m\n",
      "\u001b[32m2024-10-02 21:22:23.912\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.2100 | Train score: 0.9437 | Val loss: 0.1613 | Val score: 0.9400\u001b[0m\n",
      "\u001b[32m2024-10-02 21:22:26.769\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1715 | Train score: 0.9437 | Val loss: 0.1606 | Val score: 0.9400\u001b[0m\n",
      "\u001b[32m2024-10-02 21:22:29.807\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.2367 | Train score: 0.9437 | Val loss: 0.1637 | Val score: 0.9400\u001b[0m\n",
      "\u001b[32m2024-10-02 21:22:32.433\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1616 | Train score: 0.9437 | Val loss: 0.1647 | Val score: 0.9400\u001b[0m\n",
      "\u001b[32m2024-10-02 21:22:35.222\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1615 | Train score: 0.9437 | Val loss: 0.1659 | Val score: 0.9450\u001b[0m\n",
      "\u001b[32m2024-10-02 21:22:37.984\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1870 | Train score: 0.9375 | Val loss: 0.1690 | Val score: 0.9350\u001b[0m\n",
      "\u001b[32m2024-10-02 21:22:40.555\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1738 | Train score: 0.9500 | Val loss: 0.1730 | Val score: 0.9350\u001b[0m\n",
      "\u001b[32m2024-10-02 21:22:43.139\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1555 | Train score: 0.9563 | Val loss: 0.1790 | Val score: 0.9300\u001b[0m\n",
      "\u001b[32m2024-10-02 21:22:45.844\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1852 | Val score: 0.9350\u001b[0m\n",
      "\u001b[32m2024-10-02 21:22:48.806\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.2398 | Train score: 0.9375 | Val loss: 0.1876 | Val score: 0.9350\u001b[0m\n",
      "\u001b[32m2024-10-02 21:22:51.511\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.2121 | Train score: 0.9375 | Val loss: 0.1932 | Val score: 0.9350\u001b[0m\n",
      "\u001b[32m2024-10-02 21:22:54.292\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1752 | Train score: 0.9500 | Val loss: 0.2010 | Val score: 0.9300\u001b[0m\n",
      "\u001b[32m2024-10-02 21:22:56.584\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1873 | Train score: 0.9563 | Val loss: 0.2069 | Val score: 0.9250\u001b[0m\n",
      "\u001b[32m2024-10-02 21:22:58.555\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1588 | Train score: 0.9563 | Val loss: 0.2099 | Val score: 0.9250\u001b[0m\n",
      "\u001b[32m2024-10-02 21:23:00.294\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1734 | Train score: 0.9437 | Val loss: 0.2121 | Val score: 0.9250\u001b[0m\n",
      "\u001b[32m2024-10-02 21:23:02.102\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1795 | Train score: 0.9437 | Val loss: 0.2169 | Val score: 0.9150\u001b[0m\n",
      "\u001b[32m2024-10-02 21:23:04.027\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1313 | Train score: 0.9688 | Val loss: 0.2254 | Val score: 0.9150\u001b[0m\n",
      "\u001b[32m2024-10-02 21:23:06.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1642 | Train score: 0.9437 | Val loss: 0.2410 | Val score: 0.9200\u001b[0m\n",
      "\u001b[32m2024-10-02 21:23:08.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1309 | Train score: 0.9625 | Val loss: 0.2650 | Val score: 0.9150\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        accuracy  precision    recall   roc_auc     runtime\n",
      "XGBClassifier           0.925852   0.303644  0.166667  0.570540    0.028001\n",
      "XGBoostOptim            0.946560   0.708333  0.211111  0.602357  149.215310\n",
      "LogisticRegression      0.927188   0.243590  0.100000  0.540050    0.054667\n",
      "TabPFNClassifier        0.939212   0.000000  0.000000  0.499645    4.207857\n",
      "TabForestPFNClassifier  0.943888   0.512500  0.200000  0.595736   28.593347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-02 21:27:50.387\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.6394 | Val score: 0.6667\u001b[0m\n",
      "\u001b[32m2024-10-02 21:27:51.087\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.5949 | Train score: 0.6000 | Val loss: 0.6519 | Val score: 0.6250\u001b[0m\n",
      "\u001b[32m2024-10-02 21:27:51.799\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.4604 | Train score: 0.8000 | Val loss: 0.6919 | Val score: 0.6667\u001b[0m\n",
      "\u001b[32m2024-10-02 21:27:52.502\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.4103 | Train score: 0.8500 | Val loss: 0.7167 | Val score: 0.6667\u001b[0m\n",
      "\u001b[32m2024-10-02 21:27:53.153\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.5404 | Train score: 0.7500 | Val loss: 0.7439 | Val score: 0.6667\u001b[0m\n",
      "\u001b[32m2024-10-02 21:27:53.825\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.7966 | Train score: 0.5500 | Val loss: 0.7265 | Val score: 0.6667\u001b[0m\n",
      "\u001b[32m2024-10-02 21:27:54.433\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.4171 | Train score: 0.8500 | Val loss: 0.7162 | Val score: 0.6667\u001b[0m\n",
      "\u001b[32m2024-10-02 21:27:55.083\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.4885 | Train score: 0.7500 | Val loss: 0.7075 | Val score: 0.6667\u001b[0m\n",
      "\u001b[32m2024-10-02 21:27:55.745\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.4530 | Train score: 0.8000 | Val loss: 0.7089 | Val score: 0.6667\u001b[0m\n",
      "\u001b[32m2024-10-02 21:27:56.482\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.4531 | Train score: 0.8000 | Val loss: 0.7075 | Val score: 0.6667\u001b[0m\n",
      "\u001b[32m2024-10-02 21:27:57.126\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.4555 | Train score: 0.7500 | Val loss: 0.7060 | Val score: 0.6250\u001b[0m\n",
      "\u001b[32m2024-10-02 21:27:58.396\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.4258 | Val score: 0.8333\u001b[0m\n",
      "\u001b[32m2024-10-02 21:27:59.107\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.5101 | Train score: 0.7000 | Val loss: 0.4168 | Val score: 0.8333\u001b[0m\n",
      "\u001b[32m2024-10-02 21:27:59.825\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.4342 | Train score: 0.8500 | Val loss: 0.3937 | Val score: 0.8333\u001b[0m\n",
      "\u001b[32m2024-10-02 21:28:00.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.4150 | Train score: 0.8000 | Val loss: 0.3796 | Val score: 0.8333\u001b[0m\n",
      "\u001b[32m2024-10-02 21:28:01.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.5802 | Train score: 0.5500 | Val loss: 0.3699 | Val score: 0.8333\u001b[0m\n",
      "\u001b[32m2024-10-02 21:28:01.854\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.6718 | Train score: 0.6500 | Val loss: 0.3697 | Val score: 0.8333\u001b[0m\n",
      "\u001b[32m2024-10-02 21:28:02.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.4271 | Train score: 0.9000 | Val loss: 0.3654 | Val score: 0.8333\u001b[0m\n",
      "\u001b[32m2024-10-02 21:28:03.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.6139 | Train score: 0.7000 | Val loss: 0.3583 | Val score: 0.8333\u001b[0m\n",
      "\u001b[32m2024-10-02 21:28:03.741\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.5417 | Train score: 0.8000 | Val loss: 0.3559 | Val score: 0.7917\u001b[0m\n",
      "\u001b[32m2024-10-02 21:28:04.192\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.4152 | Train score: 0.7500 | Val loss: 0.3556 | Val score: 0.8333\u001b[0m\n",
      "\u001b[32m2024-10-02 21:28:04.629\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.4806 | Train score: 0.8000 | Val loss: 0.3536 | Val score: 0.8333\u001b[0m\n",
      "\u001b[32m2024-10-02 21:28:05.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.6855 | Val score: 0.5833\u001b[0m\n",
      "\u001b[32m2024-10-02 21:28:06.284\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.5578 | Train score: 0.6500 | Val loss: 0.6729 | Val score: 0.7083\u001b[0m\n",
      "\u001b[32m2024-10-02 21:28:07.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.5205 | Train score: 0.8000 | Val loss: 0.6681 | Val score: 0.7083\u001b[0m\n",
      "\u001b[32m2024-10-02 21:28:07.628\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.5878 | Train score: 0.6000 | Val loss: 0.6898 | Val score: 0.7083\u001b[0m\n",
      "\u001b[32m2024-10-02 21:28:08.130\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.4822 | Train score: 0.7000 | Val loss: 0.7143 | Val score: 0.7083\u001b[0m\n",
      "\u001b[32m2024-10-02 21:28:08.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.4575 | Train score: 0.8000 | Val loss: 0.7567 | Val score: 0.7083\u001b[0m\n",
      "\u001b[32m2024-10-02 21:28:09.099\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.5481 | Train score: 0.6500 | Val loss: 0.7978 | Val score: 0.6667\u001b[0m\n",
      "\u001b[32m2024-10-02 21:28:09.635\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.5984 | Train score: 0.8000 | Val loss: 0.8211 | Val score: 0.6250\u001b[0m\n",
      "\u001b[32m2024-10-02 21:28:10.121\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.5864 | Train score: 0.7500 | Val loss: 0.8375 | Val score: 0.6250\u001b[0m\n",
      "\u001b[32m2024-10-02 21:28:10.594\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.6684 | Train score: 0.7000 | Val loss: 0.8511 | Val score: 0.5833\u001b[0m\n",
      "\u001b[32m2024-10-02 21:28:11.099\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.5804 | Train score: 0.6500 | Val loss: 0.8639 | Val score: 0.5833\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        accuracy  precision    recall   roc_auc    runtime\n",
      "XGBClassifier           0.661991   0.110978  0.655556  0.658979   0.011333\n",
      "XGBoostOptim            0.732799   0.134467  0.633333  0.686247  92.377979\n",
      "LogisticRegression      0.639947   0.088202  0.533333  0.590050   0.064170\n",
      "TabPFNClassifier        0.649967   0.119187  0.733333  0.688984   0.916393\n",
      "TabForestPFNClassifier  0.700735   0.140319  0.755556  0.726392   6.917409\n"
     ]
    }
   ],
   "source": [
    "for sampling in [None, undersample]:\n",
    "    cv = 3\n",
    "    strat_split = True\n",
    "    n_optim = 1000\n",
    "    ft_epochs = 10\n",
    "    max_samples = 1000\n",
    "    metrics = metrics = [\"accuracy\", \"precision\", \"recall\", \"roc_auc\"]\n",
    "    models = [\n",
    "        XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic'),\n",
    "        XGBoostOptim(n_optim=n_optim),\n",
    "        LogisticRegression(max_iter=500), \n",
    "        TabPFNClassifier(device='cpu', N_ensemble_configurations=5, no_preprocess_mode=True),\n",
    "        TabForestPFNClassifier(\"saved_models/tabforest/mix600k/tabforestpfn.pt\", \"saved_models/tabforest/mix600k/config_run.yaml\", max_epochs=ft_epochs)\n",
    "    ]\n",
    "    results = pd.DataFrame(np.zeros((len(models), len(metrics)+1)), \n",
    "                           index=[m.__class__.__name__ for m in models],\n",
    "                          columns=metrics+[\"runtime\"])\n",
    "    \n",
    "    for ii, model in enumerate(models):\n",
    "        results.iloc[ii,:] = cross_validate_sample(model, data, labels, metrics, strat_split, cv, sampling, max_samples)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5983e6a1-a7ce-4694-b775-e83498cd3be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_sorted = results.sort_values(\"roc_auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "819f6306-686d-42f1-829c-303890202785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        accuracy  precision    recall   roc_auc    runtime\n",
      "LogisticRegression      0.639947   0.088202  0.533333  0.590050   0.064170\n",
      "XGBClassifier           0.661991   0.110978  0.655556  0.658979   0.011333\n",
      "XGBoostOptim            0.732799   0.134467  0.633333  0.686247  92.377979\n",
      "TabPFNClassifier        0.649967   0.119187  0.733333  0.688984   0.916393\n",
      "TabForestPFNClassifier  0.700735   0.140319  0.755556  0.726392   6.917409\n"
     ]
    }
   ],
   "source": [
    "print(results_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac970c40-6003-4c24-b454-014ba31f6b26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
