{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "716a0985-a3e5-47be-acc6-d58fb95fa8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "from tabpfn import TabPFNClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from data_prep_utils import *\n",
    "from evaluate import *\n",
    "from load_models import *\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fd72aea-dcf4-4d2c-bc6b-63eb9ccfdd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"datasets/data_all.csv\"\n",
    "data, labels = get_microbiome(path)\n",
    "data = top_non_zero(data)\n",
    "data, labels = unison_shuffled_copies(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "879ba0a8-b675-49eb-a1dc-64e836de555b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master3\\Lib\\site-packages\\torch\\utils\\checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master3\\Lib\\site-packages\\torch\\utils\\checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master3\\Lib\\site-packages\\torch\\utils\\checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "\u001b[32m2024-09-10 17:19:26.986\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1753 | Val score: 0.9405\u001b[0m\n",
      "\u001b[32m2024-09-10 17:20:19.164\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1268 | Train score: 0.9609 | Val loss: 0.1781 | Val score: 0.9411\u001b[0m\n",
      "\u001b[32m2024-09-10 17:21:04.797\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1474 | Train score: 0.9492 | Val loss: 0.1721 | Val score: 0.9444\u001b[0m\n",
      "\u001b[32m2024-09-10 17:21:49.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1570 | Train score: 0.9570 | Val loss: 0.1717 | Val score: 0.9405\u001b[0m\n",
      "\u001b[32m2024-09-10 17:22:45.020\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1772 | Train score: 0.9316 | Val loss: 0.1744 | Val score: 0.9411\u001b[0m\n",
      "\u001b[32m2024-09-10 17:23:31.804\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1328 | Train score: 0.9492 | Val loss: 0.1708 | Val score: 0.9392\u001b[0m\n",
      "\u001b[32m2024-09-10 17:24:19.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1405 | Train score: 0.9570 | Val loss: 0.1667 | Val score: 0.9431\u001b[0m\n",
      "\u001b[32m2024-09-10 17:25:01.392\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1396 | Train score: 0.9570 | Val loss: 0.1665 | Val score: 0.9431\u001b[0m\n",
      "\u001b[32m2024-09-10 17:25:43.202\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1462 | Train score: 0.9551 | Val loss: 0.1675 | Val score: 0.9385\u001b[0m\n",
      "\u001b[32m2024-09-10 17:26:25.011\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1698 | Train score: 0.9434 | Val loss: 0.1637 | Val score: 0.9451\u001b[0m\n",
      "\u001b[32m2024-09-10 17:27:08.065\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1614 | Train score: 0.9492 | Val loss: 0.1646 | Val score: 0.9424\u001b[0m\n",
      "\u001b[32m2024-09-10 17:28:41.092\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1778 | Val score: 0.9424\u001b[0m\n",
      "\u001b[32m2024-09-10 17:29:29.912\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1532 | Train score: 0.9512 | Val loss: 0.1773 | Val score: 0.9411\u001b[0m\n",
      "\u001b[32m2024-09-10 17:30:16.918\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1670 | Train score: 0.9434 | Val loss: 0.1735 | Val score: 0.9451\u001b[0m\n",
      "\u001b[32m2024-09-10 17:31:00.825\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1962 | Train score: 0.9453 | Val loss: 0.1735 | Val score: 0.9457\u001b[0m\n",
      "\u001b[32m2024-09-10 17:31:44.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1616 | Train score: 0.9434 | Val loss: 0.1767 | Val score: 0.9424\u001b[0m\n",
      "\u001b[32m2024-09-10 17:32:26.050\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1558 | Train score: 0.9512 | Val loss: 0.1770 | Val score: 0.9438\u001b[0m\n",
      "\u001b[32m2024-09-10 17:33:07.909\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1971 | Train score: 0.9355 | Val loss: 0.1744 | Val score: 0.9444\u001b[0m\n",
      "\u001b[32m2024-09-10 17:33:50.327\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1631 | Train score: 0.9473 | Val loss: 0.1731 | Val score: 0.9438\u001b[0m\n",
      "\u001b[32m2024-09-10 17:34:33.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1669 | Train score: 0.9492 | Val loss: 0.1715 | Val score: 0.9424\u001b[0m\n",
      "\u001b[32m2024-09-10 17:35:24.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1805 | Train score: 0.9395 | Val loss: 0.1715 | Val score: 0.9457\u001b[0m\n",
      "\u001b[32m2024-09-10 17:36:09.781\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1618 | Train score: 0.9473 | Val loss: 0.1677 | Val score: 0.9464\u001b[0m\n",
      "\u001b[32m2024-09-10 17:37:38.259\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mEpoch 000 | Train loss: -.---- | Train score: -.---- | Val loss: 0.1692 | Val score: 0.9424\u001b[0m\n",
      "\u001b[32m2024-09-10 17:38:22.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 001 | Train loss: 0.1944 | Train score: 0.9414 | Val loss: 0.1639 | Val score: 0.9431\u001b[0m\n",
      "\u001b[32m2024-09-10 17:39:06.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 002 | Train loss: 0.1733 | Train score: 0.9355 | Val loss: 0.1597 | Val score: 0.9385\u001b[0m\n",
      "\u001b[32m2024-09-10 17:39:48.901\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 003 | Train loss: 0.1722 | Train score: 0.9492 | Val loss: 0.1638 | Val score: 0.9379\u001b[0m\n",
      "\u001b[32m2024-09-10 17:40:31.950\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 004 | Train loss: 0.1377 | Train score: 0.9551 | Val loss: 0.1634 | Val score: 0.9379\u001b[0m\n",
      "\u001b[32m2024-09-10 17:41:15.425\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 005 | Train loss: 0.1620 | Train score: 0.9551 | Val loss: 0.1665 | Val score: 0.9392\u001b[0m\n",
      "\u001b[32m2024-09-10 17:42:09.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 006 | Train loss: 0.1785 | Train score: 0.9473 | Val loss: 0.1625 | Val score: 0.9392\u001b[0m\n",
      "\u001b[32m2024-09-10 17:42:55.716\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 007 | Train loss: 0.1932 | Train score: 0.9297 | Val loss: 0.1645 | Val score: 0.9379\u001b[0m\n",
      "\u001b[32m2024-09-10 17:43:39.140\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 008 | Train loss: 0.1949 | Train score: 0.9492 | Val loss: 0.1671 | Val score: 0.9385\u001b[0m\n",
      "\u001b[32m2024-09-10 17:44:24.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 009 | Train loss: 0.1586 | Train score: 0.9434 | Val loss: 0.1686 | Val score: 0.9411\u001b[0m\n",
      "\u001b[32m2024-09-10 17:45:22.739\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtabularbench.core.trainer_finetune\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mEpoch 010 | Train loss: 0.1663 | Train score: 0.9492 | Val loss: 0.1635 | Val score: 0.9411\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "cv = 3\n",
    "n_optim = 10\n",
    "ft_epochs = 10\n",
    "sampling = None\n",
    "metrics = metrics = [\"accuracy\", \"precision\", \"recall\", \"roc_auc\"]\n",
    "models = [\n",
    "    XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic'),\n",
    "    XGBoostOptim(n_optim=n_optim),\n",
    "    LogisticRegression(max_iter=500), \n",
    "    TabPFNClassifier(device='cpu', N_ensemble_configurations=3),\n",
    "    TabForestPFNClassifier(\"saved_models/tabforest/mix600k/tabforestpfn.pt\", \"saved_models/tabforest/mix600k/config_run.yaml\")\n",
    "]\n",
    "results = pd.DataFrame(np.zeros((len(models), len(metrics))), \n",
    "                       index=[m.__class__.__name__ for m in models],\n",
    "                      columns=metrics)\n",
    "\n",
    "for ii, model in enumerate(models):\n",
    "    results.iloc[ii,:] = cross_validate_sample(model, data, labels, metrics, cv, sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5983e6a1-a7ce-4694-b775-e83498cd3be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        accuracy  precision    recall   roc_auc\n",
      "XGBClassifier           0.932030   0.423717  0.248904  0.613192\n",
      "XGBoostOptim            0.942414   0.850587  0.102089  0.550206\n",
      "LogisticRegression      0.933601   0.310317  0.053072  0.522628\n",
      "TabPFNClassifier        0.938574   1.000000  0.015378  0.507689\n",
      "TabForestPFNClassifier  0.943635   0.735670  0.150965  0.573668\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a85224c2-7299-482c-a13c-5d9af4270816",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = oversample(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addcaa01-6c4b-47dd-bc77-602a694852fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41838718-4603-4bb6-a446-090d8808c220",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
