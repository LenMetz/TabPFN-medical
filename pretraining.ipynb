{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6166d675-1df4-4dd9-ad77-020e642c6d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "np.warnings = warnings\n",
    "import matplotlib.pyplot as plt\n",
    "#from tabpfn_new.scripts.differentiable_pfn_evaluation import eval_model_range\n",
    "from tabpfn_new.scripts.model_builder import get_model, get_default_spec, save_model, load_model\n",
    "from tabpfn_new.scripts.transformer_prediction_interface import transformer_predict, get_params_from_config, load_model_workflow\n",
    "\n",
    "from tabpfn_new.scripts.model_configs import *\n",
    "\n",
    "#from datasets import load_openml_list, open_cc_dids, open_cc_valid_dids\n",
    "from tabpfn_new.priors.utils import plot_prior, plot_features\n",
    "from tabpfn_new.priors.utils import uniform_int_sampler_f\n",
    "\n",
    "#from tabpfn_new.scripts.tabular_metrics import calculate_score_per_method, calculate_score\n",
    "#from tabpfn_new.scripts.tabular_evaluation import evaluate\n",
    "\n",
    "from tabpfn_new.priors.differentiable_prior import DifferentiableHyperparameterList, draw_random_style, merge_style_with_info\n",
    "from tabpfn_new.scripts import tabular_metrics\n",
    "from tabpfn.notebook_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09e1f2e3-46b8-498f-b951-eeccacacd438",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "base_path = '.'\n",
    "max_features = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66cfe79b-6ae0-4e42-a19e-7c90fd4f05aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reload_config(prior_type='forest', config_type='causal', task_type='binary', longer=0):\n",
    "    config = get_prior_config(config_type=config_type)\n",
    "    \n",
    "    config['prior_type'] = prior_type\n",
    "    \n",
    "    model_string = ''\n",
    "    \n",
    "    config['epochs'] = 12000\n",
    "    config['recompute_attn'] = True\n",
    "\n",
    "    config['max_num_classes'] = 10\n",
    "    config['num_classes'] = uniform_int_sampler_f(2, config['max_num_classes'])\n",
    "    config['balanced'] = False\n",
    "    model_string = model_string + '_multiclass'\n",
    "    \n",
    "    model_string = model_string + '_'+datetime.now().strftime(\"%m_%d_%Y_%H_%M_%S\")\n",
    "    \n",
    "    return config, model_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8db7d21d-6f37-459c-ba7e-3ca3ab05b406",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for key in config_sample:\\n    #if key == \"check_is_compatible\":\\n    print(key, config_sample[key])\\nfor key in config_sample[\"differentiable_hyperparameters\"]:\\n    print(key, config_sample[\"differentiable_hyperparameters\"][key])'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior_type = 'mlp'\n",
    "config, model_string = reload_config(prior_type, longer=1)\n",
    "\n",
    "config['differentiable'] = True\n",
    "config['flexible'] = True\n",
    "config['bptt_extra_samples'] = None\n",
    "\n",
    "# diff\n",
    "config['output_multiclass_ordered_p'] = 0.0\n",
    "del config['differentiable_hyperparameters']['output_multiclass_ordered_p']\n",
    "\n",
    "\n",
    "\n",
    "config['sampling'] = 'normal' # vielleicht schlecht?\n",
    "del config['differentiable_hyperparameters']['sampling']\n",
    "\n",
    "config['pre_sample_causes'] = True\n",
    "# end diff\n",
    "\n",
    "config['multiclass_loss_type'] = 'nono' # 'compatible'\n",
    "\n",
    "config['categorical_feature_p'] = 0 # diff: .0\n",
    "\n",
    "# turn this back on in a random search!?\n",
    "config['nan_prob_no_reason'] = .0\n",
    "config['nan_prob_unknown_reason'] = .0 # diff: .0\n",
    "config['set_value_to_nan'] = .0 # diff: 1.\n",
    "\n",
    "\n",
    "config['new_mlp_per_example'] = True\n",
    "config['prior_mlp_scale_weights_sqrt'] = True\n",
    "config['batch_size_per_gp_sample'] = None\n",
    "\n",
    "\n",
    "\n",
    "config['differentiable_hps_as_style'] = False\n",
    "config['max_eval_pos'] = 1025\n",
    "config['min_eval_pos'] = 1024\n",
    "\n",
    "config['random_feature_rotation'] = True\n",
    "config['rotate_normalized_labels'] = True\n",
    "\n",
    "config[\"mix_activations\"] = True # False heisst eig True\n",
    "\n",
    "config['n_layers'] = 2\n",
    "config['emsize'] = 64\n",
    "config['nhead'] = config['emsize'] // 16\n",
    "config['bptt'] = 1024+128\n",
    "config['canonical_y_encoder'] = False\n",
    "\n",
    "\n",
    "config['total_available_time_in_s'] = None #60*60*22 # 22 hours for some safety...\n",
    "\n",
    "config['train_mixed_precision'] = False\n",
    "config['efficient_eval_masking'] = True\n",
    "\n",
    "# mlp params\n",
    "config['is_causal'] = False # False for data from MLP input\n",
    "config['num_causes'] = 5\n",
    "config['prior_mlp_hidden_dim'] = 50\n",
    "config['num_layers'] = 4\n",
    "config['noise_std'] = 0.05\n",
    "config['init_std'] = 0.05\n",
    "config['y_is_effect'] = True\n",
    "config['pre_sample_weights'] = True\n",
    "config['prior_mlp_dropout_prob'] = 0\n",
    "config['pre_sample_causes'] = True\n",
    "config[\"prior_mlp_activations\"] = torch.nn.ReLU\n",
    "config[\"block_wise_dropout\"] = True\n",
    "config[\"sort_features\"] = False\n",
    "config[\"in_clique\"] = False\n",
    "\n",
    "# general data params\n",
    "config['balanced'] = True\n",
    "config['max_features'] = 100\n",
    "config['num_features_used'] = 100\n",
    "\n",
    "config['differentiable'] = True\n",
    "config['flexible'] = True\n",
    "\n",
    "# forest params\n",
    "config[\"min_features\"] = 100\n",
    "config[\"max_features\"] = 100\n",
    "config[\"n_samples\"] = 1000\n",
    "config[\"base_size\"] = 1000\n",
    "config[\"n_estimators\"] = 1\n",
    "config[\"categorical_x\"] = False\n",
    "config[\"comp\"] = False\n",
    "\n",
    "config['no_encoder'] = False\n",
    "config['normalize_to_ranking'] = False # False\n",
    "config['normalize_with_sqrt'] = False\n",
    "config['normalize_ignore_label_too'] = False\n",
    "config[\"normalize_labels\"] = False\n",
    "config[\"normalize\"] = False\n",
    "config[\"clr\"] = True\n",
    "config[\"num_classes\"] = 2\n",
    "config[\"max_num_classes\"] = 2\n",
    "\n",
    "# forest params\n",
    "config[\"min_depth\"] = 5\n",
    "config[\"max_depth\"] = 10\n",
    "config[\"data_sample_func\"] = \"mnd\"\n",
    "\n",
    "# mlp params\n",
    "config[\"mlp_noise\"] = False # needs to be false such that noise doesn't get drown out information from input to final output\n",
    "config[\"sampling\"] = \"mnd\"\n",
    "if \"is_causal\" in config['differentiable_hyperparameters']:\n",
    "    del config['differentiable_hyperparameters']['is_causal']\n",
    "config[\"is_causal\"] = False # needs to be false such that mnd causes are x\n",
    "if \"block_wise_dropout\" in config['differentiable_hyperparameters']:\n",
    "    del config['differentiable_hyperparameters']['block_wise_dropout']\n",
    "config[\"block_wise_dropout\"] = False # needs to be false for final output = y, otherwise setting last-layer block to dropout creates bad datasets\n",
    "# increase lower bound of hidden dim for more complex datasets\n",
    "config['differentiable_hyperparameters'][\"prior_mlp_hidden_dim\"] = {'distribution': 'meta_gamma', 'max_alpha': 3, 'max_scale': 100, 'round': True, 'lower_bound': 25} \n",
    "\n",
    "# general data params\n",
    "config[\"prior_type\"] = \"mlp\"\n",
    "config['multiclass_type'] = 'static_balance'\n",
    "del config['differentiable_hyperparameters']['multiclass_type']\n",
    "config[\"align_majority\"] = False\n",
    "config[\"limit_imbalance\"] = False\n",
    "config[\"microbiome_test\"] = True\n",
    "config[\"weight_classes\"] = False\n",
    "\n",
    "# training params\n",
    "config['aggregate_k_gradients'] = 1\n",
    "config['batch_size'] = 1*config['aggregate_k_gradients']\n",
    "config['num_steps'] = 1*config['aggregate_k_gradients']//config['aggregate_k_gradients']\n",
    "config['epochs'] = 10\n",
    "config[\"lr\"] = 1e-2\n",
    "config[\"frac\"] = 0.35\n",
    "#config['warmup_epochs'] = 10\n",
    "\n",
    "config[\"run_name\"] = \"time\"\n",
    "\n",
    "config_sample = evaluate_hypers(config)\n",
    "\"\"\"for key in config_sample:\n",
    "    #if key == \"check_is_compatible\":\n",
    "    print(key, config_sample[key])\n",
    "for key in config_sample[\"differentiable_hyperparameters\"]:\n",
    "    print(key, config_sample[\"differentiable_hyperparameters\"][key])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e7739e4-6111-449d-9b79-7018702c98d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "% Positive predictions:\n",
      "1.000  \n",
      "% Positive targets:\n",
      "0.594  \n",
      "Train sample accuracy: 0.594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master4\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master4\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master4\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master4\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "% of positive predictions:  0.0\n",
      "                accuracy  precision  recall   roc_auc   f1  runtime\n",
      "Medical TabPFN  0.941176        0.0     0.0  0.492188  0.0     0.53\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time:  3.43s | mean loss  0.68 |  mean accuracy 0.5938 |  preds imbalance measure  0.41 |  lr 0.01 |  data time  0.07 step time  0.27 forward time  0.12 nan share  0.00 ignore share (for classification tasks) 0.0000\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "% Positive predictions:\n",
      "1.000  \n",
      "% Positive targets:\n",
      "0.672  \n",
      "Train sample accuracy: 0.672\n",
      "\n",
      "% of positive predictions:  1.0\n",
      "                accuracy  precision  recall   roc_auc        f1   runtime\n",
      "Medical TabPFN  0.058824   0.058824     1.0  0.489844  0.111111  0.395622\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time:  2.74s | mean loss  0.71 |  mean accuracy 0.6719 |  preds imbalance measure  0.33 |  lr 0.009755282581475769 |  data time  0.04 step time  0.31 forward time  0.12 nan share  0.00 ignore share (for classification tasks) 0.0000\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "% Positive predictions:\n",
      "0.000  \n",
      "% Positive targets:\n",
      "0.227  \n",
      "Train sample accuracy: 0.773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenna\\anaconda3\\envs\\master4\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master4\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master4\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenna\\anaconda3\\envs\\master4\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "% of positive predictions:  0.0\n",
      "                accuracy  precision  recall   roc_auc   f1   runtime\n",
      "Medical TabPFN  0.941176        0.0     0.0  0.476562  0.0  0.377131\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time:  2.64s | mean loss  0.56 |  mean accuracy 0.7734 |  preds imbalance measure  0.23 |  lr 0.009045084971874737 |  data time  0.04 step time  0.26 forward time  0.11 nan share  0.00 ignore share (for classification tasks) 0.0000\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "% Positive predictions:\n",
      "1.000  \n",
      "% Positive targets:\n",
      "0.328  \n",
      "Train sample accuracy: 0.328\n"
     ]
    }
   ],
   "source": [
    "model = get_model(config_sample, device, should_train=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93ab5d9f-93ac-4027-b97a-ba0b78277f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "names = [\n",
    "        \"forest_balanced_noweight\",\n",
    "        \"forest_balanced\",\n",
    "        \"forest_nonorm\",\n",
    "        \"mlp_baseline\",\n",
    "        \"forest_longer\"]\n",
    "metrics = [\"accuracy\", \"precision\", \"recall\", \"roc_auc\"]\n",
    "for name in names:\n",
    "    losses, mb_results, _ = load_train_results(name)\n",
    "    plot_metrics(losses, mb_results, metrics, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242e9159-3e49-4fc7-b8e6-8cabdc42ed2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaaf85c-9dd6-4efe-b333-c195a04678c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "b = torch.randint(0,2,(100,2))\n",
    "a = torch.rand((100,2,3))\n",
    "a[3,0,:] = 100\n",
    "\n",
    "for i in range(20):\n",
    "    split = torch.randint(8,100,(1,))\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size = a.shape[0]-split)\n",
    "    sss.get_n_splits(a,b)\n",
    "    \n",
    "    train_index, test_index= next(sss.split(a,b))\n",
    "    X_train, y_train, X_test, y_test = a[train_index], b[train_index], a[test_index], b[test_index]\n",
    "    #print(X_train, X_test)\n",
    "    print(torch.where(X_train>10)[1])\n",
    "    print(torch.where(X_test>10)[1])\n",
    "    #print(split)\n",
    "    #print(y_test.shape)\n",
    "    #for i in range(2):\n",
    "        #print(torch.unique(y_train[:,i], return_counts=True)[1]/y_train.shape[0])\n",
    "        #print(torch.unique(y_test[:,i], return_counts=True)[1]/y_test.shape[0])\n",
    "    X = torch.cat((X_train,X_test), dim=0)\n",
    "    y = torch.cat((y_train,y_test), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43aed9c-9cfa-4278-9f75-d91decd8c3bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
