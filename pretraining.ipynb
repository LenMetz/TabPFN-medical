{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6166d675-1df4-4dd9-ad77-020e642c6d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "np.warnings = warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from tabpfn_new.scripts.differentiable_pfn_evaluation import eval_model_range\n",
    "from tabpfn_new.scripts.model_builder import get_model, get_default_spec, save_model, load_model\n",
    "from tabpfn_new.scripts.transformer_prediction_interface import transformer_predict, get_params_from_config, load_model_workflow\n",
    "\n",
    "from tabpfn_new.scripts.model_configs import *\n",
    "\n",
    "#from datasets import load_openml_list, open_cc_dids, open_cc_valid_dids\n",
    "from tabpfn_new.priors.utils import plot_prior, plot_features\n",
    "from tabpfn_new.priors.utils import uniform_int_sampler_f\n",
    "\n",
    "from tabpfn_new.scripts.tabular_metrics import calculate_score_per_method, calculate_score\n",
    "from tabpfn_new.scripts.tabular_evaluation import evaluate\n",
    "\n",
    "from tabpfn_new.priors.differentiable_prior import DifferentiableHyperparameterList, draw_random_style, merge_style_with_info\n",
    "from tabpfn_new.scripts import tabular_metrics\n",
    "from tabpfn.notebook_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09e1f2e3-46b8-498f-b951-eeccacacd438",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "base_path = '.'\n",
    "max_features = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66cfe79b-6ae0-4e42-a19e-7c90fd4f05aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reload_config(prior_type='forest', config_type='causal', task_type='binary', longer=0):\n",
    "    config = get_prior_config(config_type=config_type)\n",
    "    \n",
    "    config['prior_type'] = prior_type\n",
    "    \n",
    "    model_string = ''\n",
    "    \n",
    "    config['epochs'] = 12000\n",
    "    config['recompute_attn'] = True\n",
    "\n",
    "    config['max_num_classes'] = 10\n",
    "    config['num_classes'] = uniform_int_sampler_f(2, config['max_num_classes'])\n",
    "    config['balanced'] = False\n",
    "    model_string = model_string + '_multiclass'\n",
    "    \n",
    "    model_string = model_string + '_'+datetime.now().strftime(\"%m_%d_%Y_%H_%M_%S\")\n",
    "    \n",
    "    return config, model_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8db7d21d-6f37-459c-ba7e-3ca3ab05b406",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.00011882987797788477\n",
      "dropout 0.0\n",
      "emsize 512\n",
      "batch_size 32\n",
      "nlayers 12\n",
      "num_features 100\n",
      "nhead 4\n",
      "nhid_factor 2\n",
      "bptt 1152\n",
      "eval_positions None\n",
      "seq_len_used 50\n",
      "sampling normal\n",
      "epochs 100\n",
      "num_steps 8\n",
      "verbose False\n",
      "mix_activations True\n",
      "pre_sample_causes True\n",
      "multiclass_type rank\n",
      "nan_prob_unknown_reason_reason_prior 0.5\n",
      "categorical_feature_p 0\n",
      "nan_prob_no_reason 0.0\n",
      "nan_prob_unknown_reason 0.0\n",
      "nan_prob_a_reason 0.0\n",
      "max_num_classes 2\n",
      "num_classes 2\n",
      "noise_type Gaussian\n",
      "balanced False\n",
      "normalize_to_ranking False\n",
      "set_value_to_nan 0.0\n",
      "normalize_by_used_features True\n",
      "num_features_used 100\n",
      "num_categorical_features_sampler_a -1.0\n",
      "differentiable_hyperparameters {'prior_bag_exp_weights_1': {'distribution': 'uniform', 'min': 2.0, 'max': 10.0}, 'num_layers': {'distribution': 'meta_gamma', 'max_alpha': 2, 'max_scale': 3, 'round': True, 'lower_bound': 2}, 'prior_mlp_hidden_dim': {'distribution': 'meta_gamma', 'max_alpha': 3, 'max_scale': 100, 'round': True, 'lower_bound': 4}, 'prior_mlp_dropout_prob': {'distribution': 'meta_beta', 'scale': 0.6, 'min': 0.1, 'max': 5.0}, 'noise_std': {'distribution': 'meta_trunc_norm_log_scaled', 'max_mean': 0.3, 'min_mean': 0.0001, 'round': False, 'lower_bound': 0.0}, 'init_std': {'distribution': 'meta_trunc_norm_log_scaled', 'max_mean': 10.0, 'min_mean': 0.01, 'round': False, 'lower_bound': 0.0}, 'num_causes': {'distribution': 'meta_gamma', 'max_alpha': 3, 'max_scale': 7, 'round': True, 'lower_bound': 2}, 'is_causal': {'distribution': 'meta_choice', 'choice_values': [True, False]}, 'pre_sample_weights': {'distribution': 'meta_choice', 'choice_values': [True, False]}, 'y_is_effect': {'distribution': 'meta_choice', 'choice_values': [True, False]}, 'prior_mlp_activations': {'distribution': 'meta_choice_mixed', 'choice_values': [<class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.ReLU'>]}, 'block_wise_dropout': {'distribution': 'meta_choice', 'choice_values': [True, False]}, 'sort_features': {'distribution': 'meta_choice', 'choice_values': [True, False]}, 'in_clique': {'distribution': 'meta_choice', 'choice_values': [True, False]}, 'outputscale': {'distribution': 'meta_trunc_norm_log_scaled', 'max_mean': 10.0, 'min_mean': 1e-05, 'round': False, 'lower_bound': 0}, 'lengthscale': {'distribution': 'meta_trunc_norm_log_scaled', 'max_mean': 10.0, 'min_mean': 1e-05, 'round': False, 'lower_bound': 0}, 'noise': {'distribution': 'meta_choice', 'choice_values': [1e-05, 0.0001, 0.01]}}\n",
      "prior_type forest\n",
      "recompute_attn True\n",
      "differentiable True\n",
      "flexible True\n",
      "bptt_extra_samples None\n",
      "output_multiclass_ordered_p 0.0\n",
      "multiclass_loss_type nono\n",
      "normalize_with_sqrt False\n",
      "new_mlp_per_example True\n",
      "prior_mlp_scale_weights_sqrt True\n",
      "batch_size_per_gp_sample None\n",
      "normalize_ignore_label_too False\n",
      "differentiable_hps_as_style False\n",
      "max_eval_pos 1000\n",
      "random_feature_rotation True\n",
      "rotate_normalized_labels True\n",
      "canonical_y_encoder False\n",
      "aggregate_k_gradients 4\n",
      "total_available_time_in_s None\n",
      "train_mixed_precision False\n",
      "efficient_eval_masking True\n",
      "is_causal True\n",
      "num_causes 5\n",
      "prior_mlp_hidden_dim 50\n",
      "num_layers 4\n",
      "noise_std 0.05\n",
      "init_std 0.05\n",
      "y_is_effect True\n",
      "pre_sample_weights True\n",
      "prior_mlp_dropout_prob 0\n",
      "prior_mlp_activations <class 'torch.nn.modules.activation.ReLU'>\n",
      "block_wise_dropout True\n",
      "sort_features False\n",
      "in_clique False\n",
      "max_features 100\n",
      "min_features 100\n",
      "n_samples 1000\n",
      "base_size 1000\n",
      "n_estimators 1\n",
      "min_depth 1\n",
      "max_depth 25\n",
      "categorical_x False\n",
      "data_sample_func mnd\n",
      "comp False\n",
      "prior_bag_exp_weights_1 {'distribution': 'uniform', 'min': 2.0, 'max': 10.0}\n",
      "num_layers {'distribution': 'meta_gamma', 'max_alpha': 2, 'max_scale': 3, 'round': True, 'lower_bound': 2}\n",
      "prior_mlp_hidden_dim {'distribution': 'meta_gamma', 'max_alpha': 3, 'max_scale': 100, 'round': True, 'lower_bound': 4}\n",
      "prior_mlp_dropout_prob {'distribution': 'meta_beta', 'scale': 0.6, 'min': 0.1, 'max': 5.0}\n",
      "noise_std {'distribution': 'meta_trunc_norm_log_scaled', 'max_mean': 0.3, 'min_mean': 0.0001, 'round': False, 'lower_bound': 0.0}\n",
      "init_std {'distribution': 'meta_trunc_norm_log_scaled', 'max_mean': 10.0, 'min_mean': 0.01, 'round': False, 'lower_bound': 0.0}\n",
      "num_causes {'distribution': 'meta_gamma', 'max_alpha': 3, 'max_scale': 7, 'round': True, 'lower_bound': 2}\n",
      "is_causal {'distribution': 'meta_choice', 'choice_values': [True, False]}\n",
      "pre_sample_weights {'distribution': 'meta_choice', 'choice_values': [True, False]}\n",
      "y_is_effect {'distribution': 'meta_choice', 'choice_values': [True, False]}\n",
      "prior_mlp_activations {'distribution': 'meta_choice_mixed', 'choice_values': [<class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.ReLU'>]}\n",
      "block_wise_dropout {'distribution': 'meta_choice', 'choice_values': [True, False]}\n",
      "sort_features {'distribution': 'meta_choice', 'choice_values': [True, False]}\n",
      "in_clique {'distribution': 'meta_choice', 'choice_values': [True, False]}\n",
      "outputscale {'distribution': 'meta_trunc_norm_log_scaled', 'max_mean': 10.0, 'min_mean': 1e-05, 'round': False, 'lower_bound': 0}\n",
      "lengthscale {'distribution': 'meta_trunc_norm_log_scaled', 'max_mean': 10.0, 'min_mean': 1e-05, 'round': False, 'lower_bound': 0}\n",
      "noise {'distribution': 'meta_choice', 'choice_values': [1e-05, 0.0001, 0.01]}\n"
     ]
    }
   ],
   "source": [
    "prior_type = 'mlp'\n",
    "config, model_string = reload_config(prior_type, longer=1)\n",
    "\n",
    "config['differentiable'] = True\n",
    "config['flexible'] = True\n",
    "config['bptt_extra_samples'] = None\n",
    "\n",
    "# diff\n",
    "config['output_multiclass_ordered_p'] = 0.0\n",
    "del config['differentiable_hyperparameters']['output_multiclass_ordered_p']\n",
    "\n",
    "\n",
    "\n",
    "config['sampling'] = 'normal' # vielleicht schlecht?\n",
    "del config['differentiable_hyperparameters']['sampling']\n",
    "\n",
    "config['pre_sample_causes'] = True\n",
    "# end diff\n",
    "\n",
    "config['multiclass_loss_type'] = 'nono' # 'compatible'\n",
    "config['normalize_to_ranking'] = False # False\n",
    "\n",
    "config['categorical_feature_p'] = 0 # diff: .0\n",
    "\n",
    "# turn this back on in a random search!?\n",
    "config['nan_prob_no_reason'] = .0\n",
    "config['nan_prob_unknown_reason'] = .0 # diff: .0\n",
    "config['set_value_to_nan'] = .0 # diff: 1.\n",
    "\n",
    "config['normalize_with_sqrt'] = False\n",
    "\n",
    "config['new_mlp_per_example'] = True\n",
    "config['prior_mlp_scale_weights_sqrt'] = True\n",
    "config['batch_size_per_gp_sample'] = None\n",
    "\n",
    "config['normalize_ignore_label_too'] = False\n",
    "\n",
    "config['differentiable_hps_as_style'] = False\n",
    "config['max_eval_pos'] = 1000\n",
    "\n",
    "config['random_feature_rotation'] = True\n",
    "config['rotate_normalized_labels'] = True\n",
    "\n",
    "config[\"mix_activations\"] = True # False heisst eig True\n",
    "\n",
    "config['emsize'] = 512\n",
    "config['nhead'] = config['emsize'] // 128\n",
    "config['bptt'] = 1024+128\n",
    "config['canonical_y_encoder'] = False\n",
    "\n",
    "    \n",
    "config['aggregate_k_gradients'] = 4\n",
    "config['batch_size'] = 8*config['aggregate_k_gradients']\n",
    "config['num_steps'] = 32//config['aggregate_k_gradients']\n",
    "config['epochs'] = 100\n",
    "\n",
    "config['total_available_time_in_s'] = None #60*60*22 # 22 hours for some safety...\n",
    "\n",
    "config['train_mixed_precision'] = False\n",
    "config['efficient_eval_masking'] = True\n",
    "\n",
    "# mlp params\n",
    "config['is_causal'] = True\n",
    "config['num_causes'] = 5\n",
    "config['prior_mlp_hidden_dim'] = 50\n",
    "config['num_layers'] = 4\n",
    "config['noise_std'] = 0.05\n",
    "config['init_std'] = 0.05\n",
    "config['y_is_effect'] = True\n",
    "config['pre_sample_weights'] = True\n",
    "config['prior_mlp_dropout_prob'] = 0\n",
    "config['pre_sample_causes'] = True\n",
    "config[\"prior_mlp_activations\"] = torch.nn.ReLU\n",
    "config[\"block_wise_dropout\"] = True\n",
    "config[\"sort_features\"] = False\n",
    "config[\"in_clique\"] = False\n",
    "\n",
    "# general data params\n",
    "config['balanced'] = True\n",
    "config['max_num_classes'] = 10\n",
    "config['max_features'] = 100\n",
    "config['num_features_used'] = 100\n",
    "\n",
    "config['differentiable'] = True\n",
    "config['flexible'] = True\n",
    "\n",
    "# forest params\n",
    "config[\"min_features\"] = 100\n",
    "config[\"max_features\"] = 100\n",
    "config[\"n_samples\"] = 1000\n",
    "config[\"max_num_classes\"] = 2\n",
    "config[\"base_size\"] = 1000\n",
    "config[\"n_estimators\"] = 1\n",
    "config[\"min_depth\"] = 1\n",
    "config[\"max_depth\"] = 25\n",
    "config[\"categorical_x\"] = False\n",
    "config[\"data_sample_func\"] = \"mnd\"\n",
    "config[\"comp\"] = False\n",
    "\n",
    "config['num_classes'] = 2\n",
    "config[\"balanced\"] = False\n",
    "config['multiclass_type'] = 'rank'\n",
    "del config['differentiable_hyperparameters']['multiclass_type']\n",
    "\n",
    "config[\"prior_type\"] = \"forest\"\n",
    "\n",
    "config_sample = evaluate_hypers(config)\n",
    "for key in config_sample:\n",
    "    #if key == \"check_is_compatible\":\n",
    "    print(key, config_sample[key])\n",
    "for key in config_sample[\"differentiable_hyperparameters\"]:\n",
    "    print(key, config_sample[\"differentiable_hyperparameters\"][key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e7739e4-6111-449d-9b79-7018702c98d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "Using cpu:0 device\n",
      "Using a Transformer with 25.81 M parameters\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 275.26s | mean loss  0.70 |  data time  0.51 step time  6.50 forward time  2.33 nan share  0.00 ignore share (for classification tasks) 0.0000\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 269.85s | mean loss  0.66 |  data time  0.54 step time  7.11 forward time  2.70 nan share  0.00 ignore share (for classification tasks) 0.0000\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 273.79s | mean loss  0.53 |  data time  0.60 step time  5.10 forward time  1.71 nan share  0.00 ignore share (for classification tasks) 0.0000\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time: 276.85s | mean loss  0.49 |  data time  0.55 step time  5.86 forward time  2.21 nan share  0.00 ignore share (for classification tasks) 0.0000\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time: 294.61s | mean loss  0.45 |  data time  0.57 step time  5.00 forward time  1.54 nan share  0.00 ignore share (for classification tasks) 0.0000\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time: 293.23s | mean loss  0.46 |  data time  0.61 step time  4.54 forward time  1.56 nan share  0.00 ignore share (for classification tasks) 0.0000\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time: 299.74s | mean loss  0.46 |  data time  0.67 step time  9.28 forward time  3.90 nan share  0.00 ignore share (for classification tasks) 0.0000\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time: 298.02s | mean loss  0.43 |  data time  0.56 step time  7.62 forward time  2.92 nan share  0.00 ignore share (for classification tasks) 0.0000\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   9 | time: 278.84s | mean loss  0.44 |  data time  0.51 step time  4.99 forward time  1.90 nan share  0.00 ignore share (for classification tasks) 0.0000\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  10 | time: 283.84s | mean loss  0.42 |  data time  0.58 step time  8.55 forward time  3.56 nan share  0.00 ignore share (for classification tasks) 0.0000\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  11 | time: 281.93s | mean loss  0.46 |  data time  0.51 step time  9.78 forward time  3.57 nan share  0.00 ignore share (for classification tasks) 0.0000\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  12 | time: 272.48s | mean loss  0.44 |  data time  0.55 step time  9.06 forward time  3.53 nan share  0.00 ignore share (for classification tasks) 0.0000\n",
      "-----------------------------------------------------------------------------------------\n",
      "Invalid optimization step encountered\n"
     ]
    }
   ],
   "source": [
    "model = get_model(config_sample, device, should_train=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d588d728-1676-4614-885b-39a99d64ecdc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "Using cpu:0 device\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m config_sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshould_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# , state_dict=model[2].state_dict()\u001b[39;00m\n\u001b[0;32m      3\u001b[0m (hp_embedding, data, _), targets, single_eval_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(model[\u001b[38;5;241m3\u001b[39m]))\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#from utils import normalize_data\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\MT\\TabPFN-medical\\tabpfn_new\\scripts\\model_builder.py:300\u001b[0m, in \u001b[0;36mget_model\u001b[1;34m(config, device, should_train, verbose, state_dict, epoch_callback)\u001b[0m\n\u001b[0;32m    298\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_train \u001b[38;5;28;01melse\u001b[39;00m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    299\u001b[0m \u001b[38;5;66;03m#print('MODEL BUILDER', model_proto, extra_kwargs['get_batch'])\u001b[39;00m\n\u001b[1;32m--> 300\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_proto\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataLoader\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle_encoder_generator\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mencoders\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStyleEncoder\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43muse_style\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[0;32m    304\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43memsize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnhead\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnhead\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# For unsupervised learning change to NanHandlingEncoder\u001b[39;49;00m\n\u001b[0;32m    307\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_encoder_generator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mencoders\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_Canonical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_num_classes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcanonical_y_encoder\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mencoders\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLinear\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_encoder_generator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[0;32m    309\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnlayers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnlayers\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnhid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43memsize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnhid_factor\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarmup_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\n\u001b[0;32m    314\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbptt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbptt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpu_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdropout\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_steps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msingle_eval_pos_gen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_uniform_single_eval_pos_sampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_eval_pos\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbptt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmin_eval_pos\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_weights_from_this_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maggregate_k_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maggregate_k_gradients\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecompute_attn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrecompute_attn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_callback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch_callback\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbptt_extra_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbptt_extra_samples\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_mixed_precision\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_mixed_precision\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_prior_kwargs_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_features\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_features\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m        \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhyperparameters\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprior_hyperparameters\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#, 'dynamic_batch_size': 1 if ('num_global_att_tokens' in config and config['num_global_att_tokens']) else 2\u001b[39;49;00m\n\u001b[0;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size_per_gp_sample\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size_per_gp_sample\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kwargs\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m              \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32m~\\Desktop\\MT\\TabPFN-medical\\tabpfn_new\\train.py:64\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(priordataloader_class, criterion, encoder_generator, emsize, nhid, nlayers, nhead, dropout, epochs, steps_per_epoch, batch_size, bptt, lr, weight_decay, warmup_epochs, input_normalization, y_encoder_generator, pos_encoder_generator, decoder, extra_prior_kwargs_dict, scheduler, load_weights_from_this_state_dict, validation_period, single_eval_pos_gen, bptt_extra_samples, gpu_device, aggregate_k_gradients, verbose, style_encoder_generator, epoch_callback, initializer, initialize_with_model, train_mixed_precision, efficient_eval_masking, **model_extra_args)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     63\u001b[0m     n_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 64\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mTransformerModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnhid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnlayers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle_encoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstyle_encoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m                         \u001b[49m\u001b[43my_encoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_encoder_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memsize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_normalization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_normalization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mpos_encoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpos_encoder_generator\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpositional_encodings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNoPositionalEncoding\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43memsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbptt\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mefficient_eval_masking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mefficient_eval_masking\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_extra_args\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m                         \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m model\u001b[38;5;241m.\u001b[39mcriterion \u001b[38;5;241m=\u001b[39m criterion\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_weights_from_this_state_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master3\\Lib\\site-packages\\tabpfn\\transformer.py:24\u001b[0m, in \u001b[0;36mTransformerModel.__init__\u001b[1;34m(self, encoder, n_out, ninp, nhead, nhid, nlayers, dropout, style_encoder, y_encoder, pos_encoder, decoder, input_normalization, init_method, pre_norm, activation, recompute_attn, num_global_att_tokens, full_attention, all_layers_same_init, efficient_eval_masking)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransformer\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     21\u001b[0m encoder_layer_creator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m: TransformerEncoderLayer(ninp, nhead, nhid, dropout, activation\u001b[38;5;241m=\u001b[39mactivation,\n\u001b[0;32m     22\u001b[0m                                                         pre_norm\u001b[38;5;241m=\u001b[39mpre_norm, recompute_attn\u001b[38;5;241m=\u001b[39mrecompute_attn)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer_encoder \u001b[38;5;241m=\u001b[39m TransformerEncoder(encoder_layer_creator(), nlayers)\\\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m all_layers_same_init \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mTransformerEncoderDiffInit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_layer_creator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnlayers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mninp \u001b[38;5;241m=\u001b[39m ninp\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m encoder\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master3\\Lib\\site-packages\\tabpfn\\transformer.py:209\u001b[0m, in \u001b[0;36mTransformerEncoderDiffInit.__init__\u001b[1;34m(self, encoder_layer_creator, num_layers, norm)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, encoder_layer_creator, num_layers, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m--> 209\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList(\u001b[43m[\u001b[49m\u001b[43mencoder_layer_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers \u001b[38;5;241m=\u001b[39m num_layers\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;241m=\u001b[39m norm\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master3\\Lib\\site-packages\\tabpfn\\transformer.py:209\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, encoder_layer_creator, num_layers, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m--> 209\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([\u001b[43mencoder_layer_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_layers)])\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers \u001b[38;5;241m=\u001b[39m num_layers\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;241m=\u001b[39m norm\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master3\\Lib\\site-packages\\tabpfn\\transformer.py:21\u001b[0m, in \u001b[0;36mTransformerModel.__init__.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransformer\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 21\u001b[0m encoder_layer_creator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mTransformerEncoderLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mninp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnhid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mactivation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[43mpre_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecompute_attn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecompute_attn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer_encoder \u001b[38;5;241m=\u001b[39m TransformerEncoder(encoder_layer_creator(), nlayers)\\\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m all_layers_same_init \u001b[38;5;28;01melse\u001b[39;00m TransformerEncoderDiffInit(encoder_layer_creator, nlayers)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mninp \u001b[38;5;241m=\u001b[39m ninp\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master3\\Lib\\site-packages\\tabpfn\\layer.py:44\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.__init__\u001b[1;34m(self, d_model, nhead, dim_feedforward, dropout, activation, layer_norm_eps, batch_first, pre_norm, device, dtype, recompute_attn)\u001b[0m\n\u001b[0;32m     42\u001b[0m factory_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m: device, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m'\u001b[39m: dtype}\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m---> 44\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn \u001b[38;5;241m=\u001b[39m \u001b[43mMultiheadAttention\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m                                    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfactory_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Implementation of Feedforward model\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear1 \u001b[38;5;241m=\u001b[39m Linear(d_model, dim_feedforward, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master3\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:1038\u001b[0m, in \u001b[0;36mMultiheadAttention.__init__\u001b[1;34m(self, embed_dim, num_heads, dropout, bias, add_bias_kv, add_zero_attn, kdim, vdim, batch_first, device, dtype)\u001b[0m\n\u001b[0;32m   1034\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias_k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias_v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_zero_attn \u001b[38;5;241m=\u001b[39m add_zero_attn\n\u001b[1;32m-> 1038\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reset_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master3\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:1042\u001b[0m, in \u001b[0;36mMultiheadAttention._reset_parameters\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_reset_parameters\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1041\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qkv_same_embed_dim:\n\u001b[1;32m-> 1042\u001b[0m         \u001b[43mxavier_uniform_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1043\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1044\u001b[0m         xavier_uniform_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_proj_weight)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master3\\Lib\\site-packages\\torch\\nn\\init.py:362\u001b[0m, in \u001b[0;36mxavier_uniform_\u001b[1;34m(tensor, gain, generator)\u001b[0m\n\u001b[0;32m    359\u001b[0m std \u001b[38;5;241m=\u001b[39m gain \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m2.0\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(fan_in \u001b[38;5;241m+\u001b[39m fan_out))\n\u001b[0;32m    360\u001b[0m a \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m3.0\u001b[39m) \u001b[38;5;241m*\u001b[39m std  \u001b[38;5;66;03m# Calculate uniform bounds from standard deviation\u001b[39;00m\n\u001b[1;32m--> 362\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_no_grad_uniform_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\master3\\Lib\\site-packages\\torch\\nn\\init.py:15\u001b[0m, in \u001b[0;36m_no_grad_uniform_\u001b[1;34m(tensor, a, b, generator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_no_grad_uniform_\u001b[39m(tensor, a, b, generator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 15\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muniform_\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "config_sample['batch_size'] = 4\n",
    "model = get_model(config_sample, device, should_train=False, verbose=2) # , state_dict=model[2].state_dict()\n",
    "(hp_embedding, data, _), targets, single_eval_pos = next(iter(model[3]))\n",
    "\n",
    "#from utils import normalize_data\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "N = 100\n",
    "plot_features(data[0:N, 0, 0:4], targets[0:N, 0], fig=fig)\n",
    "\n",
    "d = np.concatenate([data[:, 0, :].T, np.expand_dims(targets[:, 0], -1).T])\n",
    "d[np.isnan(d)] = 0\n",
    "c = np.corrcoef(d)\n",
    "plt.matshow(np.abs(c), vmin=0, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3aa715b-9b2b-4ba9-803d-2a7eff330808",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15aa27ce-f26d-488b-8d0a-5ee66939538d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
